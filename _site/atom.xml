<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

 <title>Deep learning in Data Science</title>
 <link href="http://localhost:4000/deep-learning-self-learning/atom.xml" rel="self"/>
 <link href="http://localhost:4000/deep-learning-self-learning/"/>
 <updated>2025-11-09T21:12:51+07:00</updated>
 <id>http://localhost:4000</id>
 <author>
   <name>Nguyen Le Linh</name>
   <email>nglelinh@gmail.com</email>
 </author>

 
 <entry>
   <title>author details</title>
   <link href="http://localhost:4000/home/author-details/"/>
   <updated>2021-05-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/home/author-details</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>References and Resources</title>
   <link href="http://localhost:4000/reference/26_reference/"/>
   <updated>2021-03-28T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/reference/26_reference</id>
   <content type="html">&lt;h2 id=&quot;essential-deep-learning-books&quot;&gt;Essential Deep Learning Books&lt;/h2&gt;

&lt;h3 id=&quot;primary-textbooks&quot;&gt;Primary Textbooks&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Goodfellow, I., Bengio, Y., and Courville, A. (2016).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;Deep Learning&lt;/a&gt;&lt;/em&gt;. MIT Press.&lt;br /&gt;
The definitive textbook on deep learning theory and mathematics.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;G√©ron, A. (2022).&lt;/strong&gt; &lt;em&gt;Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (3rd Edition)&lt;/em&gt;. O‚ÄôReilly Media.&lt;br /&gt;
Practical guide to implementing deep learning models.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Prince, S. J. D. (2023).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://udlbook.github.io/udlbook/&quot;&gt;Understanding Deep Learning&lt;/a&gt;&lt;/em&gt;. MIT Press.&lt;br /&gt;
Modern introduction with excellent visualizations.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;MIT Deep Learning Book.&lt;/strong&gt; From MIT 6.S191 course.&lt;br /&gt;
Rigorous academic treatment of deep learning fundamentals.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;domain-specific-books&quot;&gt;Domain-Specific Books&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Shanmugamani, R. (2018).&lt;/strong&gt; &lt;em&gt;Deep Learning for Computer Vision&lt;/em&gt;. Packt Publishing.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Tunstall, L., von Werra, L., and Wolf, T. (2022).&lt;/strong&gt; &lt;em&gt;Natural Language Processing with Transformers&lt;/em&gt;. O‚ÄôReilly Media.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sutton, R. S. and Barto, A. G. (2018).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://incompleteideas.net/book/the-book-2nd.html&quot;&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/a&gt;&lt;/em&gt;. MIT Press.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;foundational-papers&quot;&gt;Foundational Papers&lt;/h2&gt;

&lt;h3 id=&quot;neural-networks-and-training&quot;&gt;Neural Networks and Training&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Rumelhart, D. E., Hinton, G. E., and Williams, R. J. (1986).&lt;/strong&gt; ‚ÄúLearning representations by back-propagating errors.‚Äù &lt;em&gt;Nature&lt;/em&gt;, 323(6088), 533-536.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;LeCun, Y., Bottou, L., Bengio, Y., and Haffner, P. (1998).&lt;/strong&gt; ‚ÄúGradient-based learning applied to document recognition.‚Äù &lt;em&gt;Proceedings of the IEEE&lt;/em&gt;, 86(11), 2278-2324.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Glorot, X. and Bengio, Y. (2010).&lt;/strong&gt; ‚ÄúUnderstanding the difficulty of training deep feedforward neural networks.‚Äù &lt;em&gt;AISTATS&lt;/em&gt;.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;optimization-and-regularization&quot;&gt;Optimization and Regularization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kingma, D. P. and Ba, J. (2015).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;Adam: A Method for Stochastic Optimization&lt;/a&gt;&lt;/em&gt;. ICLR.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ioffe, S. and Szegedy, C. (2015).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.03167&quot;&gt;Batch Normalization: Accelerating Deep Network Training&lt;/a&gt;&lt;/em&gt;. ICML.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Srivastava, N., et al. (2014).&lt;/strong&gt; ‚ÄúDropout: A Simple Way to Prevent Neural Networks from Overfitting.‚Äù &lt;em&gt;JMLR&lt;/em&gt;, 15, 1929-1958.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;convolutional-neural-networks&quot;&gt;Convolutional Neural Networks&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Krizhevsky, A., Sutskever, I., and Hinton, G. E. (2012).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;ImageNet Classification with Deep Convolutional Neural Networks&lt;/a&gt;&lt;/em&gt;. NeurIPS.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Simonyan, K. and Zisserman, A. (2015).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.1556&quot;&gt;Very Deep Convolutional Networks for Large-Scale Image Recognition&lt;/a&gt;&lt;/em&gt;. ICLR.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;He, K., et al. (2016).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;Deep Residual Learning for Image Recognition&lt;/a&gt;&lt;/em&gt;. CVPR.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;recurrent-networks-and-sequence-models&quot;&gt;Recurrent Networks and Sequence Models&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Hochreiter, S. and Schmidhuber, J. (1997).&lt;/strong&gt; ‚ÄúLong Short-Term Memory.‚Äù &lt;em&gt;Neural Computation&lt;/em&gt;, 9(8), 1735-1780.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Cho, K., et al. (2014).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.1078&quot;&gt;Learning Phrase Representations using RNN Encoder-Decoder&lt;/a&gt;&lt;/em&gt;. EMNLP.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;attention-and-transformers&quot;&gt;Attention and Transformers&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vaswani, A., et al. (2017).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;Attention Is All You Need&lt;/a&gt;&lt;/em&gt;. NeurIPS.&lt;br /&gt;
   The foundational Transformer paper.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Devlin, J., et al. (2019).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;BERT: Pre-training of Deep Bidirectional Transformers&lt;/a&gt;&lt;/em&gt;. NAACL.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Radford, A., et al. (2019).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;Language Models are Unsupervised Multitask Learners&lt;/a&gt;&lt;/em&gt;. OpenAI.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;generative-models&quot;&gt;Generative Models&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Goodfellow, I., et al. (2014).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;Generative Adversarial Networks&lt;/a&gt;&lt;/em&gt;. NeurIPS.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kingma, D. P. and Welling, M. (2014).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;Auto-Encoding Variational Bayes&lt;/a&gt;&lt;/em&gt;. ICLR.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Karras, T., et al. (2019).&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://arxiv.org/abs/1812.04948&quot;&gt;A Style-Based Generator Architecture for GANs&lt;/a&gt;&lt;/em&gt;. CVPR.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Mnih, V., et al. (2015).&lt;/strong&gt; ‚ÄúHuman-level control through deep reinforcement learning.‚Äù &lt;em&gt;Nature&lt;/em&gt;, 518(7540), 529-533.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Silver, D., et al. (2017).&lt;/strong&gt; ‚ÄúMastering the game of Go without human knowledge.‚Äù &lt;em&gt;Nature&lt;/em&gt;, 550(7676), 354-359.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;online-courses-and-resources&quot;&gt;Online Courses and Resources&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Stanford CS231n:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://cs231n.stanford.edu/&quot;&gt;Convolutional Neural Networks for Visual Recognition&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Stanford CS224n:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://web.stanford.edu/class/cs224n/&quot;&gt;Natural Language Processing with Deep Learning&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;MIT 6.S191:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;http://introtodeeplearning.com/&quot;&gt;Introduction to Deep Learning&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Fast.ai:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://www.fast.ai/&quot;&gt;Practical Deep Learning for Coders&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;online-resources&quot;&gt;Online Resources&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;ArXiv.org:&lt;/strong&gt; Pre-print server for latest research papers&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Papers with Code:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://paperswithcode.com/&quot;&gt;paperwithcode.com&lt;/a&gt;&lt;/em&gt; - Papers with implementations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Distill.pub:&lt;/strong&gt; Interactive machine learning research explanations&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;PyTorch Tutorials:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://pytorch.org/tutorials/&quot;&gt;pytorch.org/tutorials&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;TensorFlow Tutorials:&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://www.tensorflow.org/tutorials&quot;&gt;tensorflow.org/tutorials&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;mathematical-foundations&quot;&gt;Mathematical Foundations&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wikipedia.&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Backpropagation&quot;&gt;Backpropagation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wikipedia.&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Gradient_descent&quot;&gt;Gradient descent&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wikipedia.&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Automatic_differentiation&quot;&gt;Automatic differentiation&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wikipedia.&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Cross_entropy&quot;&gt;Cross entropy&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Wikipedia.&lt;/strong&gt; &lt;em&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Softmax_function&quot;&gt;Softmax function&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;p&gt;For the most up-to-date resources and research, check:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://arxiv.org/&quot;&gt;ArXiv.org&lt;/a&gt; for latest papers&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://paperswithcode.com/&quot;&gt;Papers with Code&lt;/a&gt; for implementations&lt;/li&gt;
  &lt;li&gt;Course GitHub repository for code examples and notebooks&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>makers</title>
   <link href="http://localhost:4000/home/makers/"/>
   <updated>2021-02-03T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/home/makers</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>contents</title>
   <link href="http://localhost:4000/home/link_to_how_to_contribute/"/>
   <updated>2021-01-27T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/home/link_to_how_to_contribute</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>introduction</title>
   <link href="http://localhost:4000/home/introduction/"/>
   <updated>2021-01-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/home/introduction</id>
   <content type="html">
</content>
 </entry>
 
 <entry>
   <title>Course Contents</title>
   <link href="http://localhost:4000/home/contents/"/>
   <updated>2021-01-20T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/home/contents</id>
   <content type="html">&lt;p&gt;A comprehensive introduction to deep learning, covering neural network fundamentals, modern architectures (CNNs, RNNs, Transformers), training techniques, generative models, and practical applications in computer vision, natural language processing, and beyond.&lt;/p&gt;

&lt;h1 id=&quot;course-objectives&quot;&gt;Course Objectives&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;Provide students with fundamental knowledge of deep learning theory and practice to support their study and research in data science and AI.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Enable students to understand, implement, and train deep neural networks from scratch and using modern frameworks.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Develop skills in applying deep learning to real-world problems across various domains including computer vision, NLP, and reinforcement learning.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Prepare students to read and implement cutting-edge research papers and contribute to the advancement of deep learning.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;main-textbooks&quot;&gt;Main Textbooks&lt;/h2&gt;

&lt;h3 id=&quot;primary-references&quot;&gt;Primary References&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. Deep Learning&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ian Goodfellow, Yoshua Bengio, and Aaron Courville&lt;br /&gt;
&lt;em&gt;Publisher&lt;/em&gt;: MIT Press, 2016&lt;br /&gt;
&lt;em&gt;Online&lt;/em&gt;: &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;deeplearningbook.org&lt;/a&gt; (Free)&lt;br /&gt;
The definitive textbook covering theory and mathematics of deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow (3rd Edition)&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Aur√©lien G√©ron&lt;br /&gt;
&lt;em&gt;Publisher&lt;/em&gt;: O‚ÄôReilly Media, 2022&lt;br /&gt;
Practical guide to implementing and deploying deep learning models.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Understanding Deep Learning&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Simon J.D. Prince&lt;br /&gt;
&lt;em&gt;Publisher&lt;/em&gt;: MIT Press, 2023&lt;br /&gt;
&lt;em&gt;Online&lt;/em&gt;: &lt;a href=&quot;https://udlbook.github.io/udlbook/&quot;&gt;udlbook.github.io&lt;/a&gt;&lt;br /&gt;
Modern introduction with excellent visualizations and intuitive explanations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. MIT Deep Learning Book&lt;/strong&gt;&lt;br /&gt;
From MIT‚Äôs Deep Learning course&lt;br /&gt;
Rigorous academic treatment with strong theoretical foundations.&lt;/p&gt;

&lt;h2 id=&quot;additional-references&quot;&gt;Additional References&lt;/h2&gt;

&lt;h3 id=&quot;computer-vision&quot;&gt;Computer Vision&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Deep Learning for Computer Vision&lt;/strong&gt; by Rajalingappaa Shanmugamani, Packt Publishing, 2018&lt;/li&gt;
  &lt;li&gt;Stanford CS231n Course Materials&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;natural-language-processing&quot;&gt;Natural Language Processing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Natural Language Processing with Transformers&lt;/strong&gt; by Lewis Tunstall, Leandro von Werra, and Thomas Wolf, O‚ÄôReilly, 2022&lt;/li&gt;
  &lt;li&gt;Stanford CS224n Course Materials&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Reinforcement Learning: An Introduction (2nd Edition)&lt;/strong&gt; by Richard S. Sutton and Andrew G. Barto, MIT Press, 2018&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;research-papers-and-advanced-topics&quot;&gt;Research Papers and Advanced Topics&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;‚ÄúAttention Is All You Need‚Äù - Vaswani et al., 2017 (Transformers)&lt;/li&gt;
  &lt;li&gt;‚ÄúGenerative Adversarial Networks‚Äù - Goodfellow et al., 2014 (GANs)&lt;/li&gt;
  &lt;li&gt;‚ÄúDeep Residual Learning for Image Recognition‚Äù - He et al., 2015 (ResNet)&lt;/li&gt;
  &lt;li&gt;ArXiv.org and Papers with Code for latest research&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;course-materials&quot;&gt;Course Materials&lt;/h2&gt;

&lt;p&gt;All lecture notes, code examples, and assignments are available in this repository. Each chapter includes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Theoretical explanations with mathematical foundations&lt;/li&gt;
  &lt;li&gt;Python/NumPy implementations for educational clarity&lt;/li&gt;
  &lt;li&gt;Practical examples using PyTorch and TensorFlow&lt;/li&gt;
  &lt;li&gt;Exercises and projects for hands-on learning&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>00 Gi·ªõi thi·ªáu</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_Introduction</id>
   <content type="html">&lt;p&gt;T·ªëi ∆∞u h√≥a l√† tr√°i tim c·ªßa khoa h·ªçc d·ªØ li·ªáu. D√π b·∫°n ƒëang hu·∫•n luy·ªán m·ªôt m·∫°ng n∆°-ron, t·ªëi thi·ªÉu h√≥a l·ªói trong c√°c m√¥ h√¨nh h·ªìi quy, hay ph√¢n b·ªï t√†i nguy√™n hi·ªáu qu·∫£ trong h·ªá th·ªëng g·ª£i √Ω, v·ªÅ b·∫£n ch·∫•t b·∫°n ƒëang gi·∫£i quy·∫øt c√°c b√†i to√°n t√¨m ki·∫øm gi·∫£i ph√°p ‚Äút·ªët nh·∫•t‚Äù t·ª´ m·ªôt t·∫≠p h·ª£p kh·ªïng l·ªì c√°c kh·∫£ nƒÉng. Nh∆∞ng ƒë·ªÉ l√†m ƒëi·ªÅu n√†y m·ªôt c√°ch hi·ªáu qu·∫£, b·∫°n c·∫ßn n√≥i ƒë∆∞·ª£c ng√¥n ng·ªØ c·ªßa to√°n h·ªçc. Ch√∫ng ta s·∫Ω √¥n l·∫°i c√°c √Ω t∆∞·ªüng ch√≠nh t·ª´ ƒë·∫°i s·ªë tuy·∫øn t√≠nh, l√Ω thuy·∫øt t·∫≠p h·ª£p v√† gi·∫£i t√≠ch, ƒë·∫£m b·∫£o b·∫°n ƒë∆∞·ª£c trang b·ªã ƒë·ªÉ x·ª≠ l√Ω c√°c gradient, ma tr·∫≠n, r√†ng bu·ªôc v√† s·ª± b·∫•t ƒë·ªãnh ph√°t sinh trong c√°c t√°c v·ª• t·ªëi ∆∞u h√≥a.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-05 B√†i t·∫≠p tr·∫Øc nghi·ªám - Kh√°i ni·ªám c∆° b·∫£n</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_05_Quiz_Basic_Concepts/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_05_Quiz_Basic_Concepts</id>
   <content type="html">&lt;p&gt;B√†i t·∫≠p tr·∫Øc nghi·ªám n√†y ki·ªÉm tra hi·ªÉu bi·∫øt c·ªßa b·∫°n v·ªÅ c√°c kh√°i ni·ªám c∆° b·∫£n trong gi·∫£i t√≠ch v√† ƒë·∫°i s·ªë tuy·∫øn t√≠nh, l√† n·ªÅn t·∫£ng cho t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;-√¥n-t·∫≠p-l√Ω-thuy·∫øt&quot;&gt;üìö √în t·∫≠p l√Ω thuy·∫øt&lt;/h2&gt;

&lt;p&gt;Tr∆∞·ªõc khi l√†m b√†i t·∫≠p, h√£y √¥n l·∫°i c√°c kh√°i ni·ªám ch√≠nh trong ch∆∞∆°ng n√†y:&lt;/p&gt;

&lt;h3 id=&quot;-gi·∫£i-t√≠ch-c∆°-b·∫£n&quot;&gt;üî¢ &lt;strong&gt;Gi·∫£i t√≠ch c∆° b·∫£n&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ƒê·∫°o h√†m v√† ƒë·∫°o h√†m ri√™ng:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ƒê·∫°o h√†m: \(f&apos;(x) = \lim_{h \to 0} \frac{f(x+h) - f(x)}{h}\)&lt;/li&gt;
  &lt;li&gt;ƒê·∫°o h√†m ri√™ng: \(\frac{\partial f}{\partial x_i}\) - ƒë·∫°o h√†m theo \(x_i\) khi c√°c bi·∫øn kh√°c c·ªë ƒë·ªãnh&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Gradient v√† ƒë·∫°o h√†m c√≥ h∆∞·ªõng:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gradient: \(\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\) - vector ch·ªâ h∆∞·ªõng tƒÉng d·ªëc nh·∫•t&lt;/li&gt;
  &lt;li&gt;ƒê·∫°o h√†m c√≥ h∆∞·ªõng: \(D_{\mathbf{u}}f = \nabla f \cdot \mathbf{u} = \|\nabla f\| \cos \theta\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Chu·ªói Taylor:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;B·∫≠c 1: \(f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\)&lt;/li&gt;
  &lt;li&gt;B·∫≠c 2: \(f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \nabla^2 f(\mathbf{x}_0) (\mathbf{x} - \mathbf{x}_0)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-ƒë·∫°i-s·ªë-tuy·∫øn-t√≠nh&quot;&gt;üìê &lt;strong&gt;ƒê·∫°i s·ªë tuy·∫øn t√≠nh&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Vector v√† kh√¥ng gian vector:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Vector: danh s√°ch c√≥ th·ª© t·ª± c√°c s·ªë \(\mathbf{v} = \begin{pmatrix} v_1 \\ \vdots \\ v_n \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Kh√¥ng gian \(\mathbb{R}^n\): t·∫≠p t·∫•t c·∫£ vector c√≥ \(n\) th√†nh ph·∫ßn&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;C√°c ph√©p to√°n vector:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;C·ªông vector: \(\mathbf{u} + \mathbf{v} = \begin{pmatrix} u_1 + v_1 \\ \vdots \\ u_n + v_n \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Nh√¢n v√¥ h∆∞·ªõng: \(c\mathbf{v} = \begin{pmatrix} cv_1 \\ \vdots \\ cv_n \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;T√≠ch v√¥ h∆∞·ªõng: \(\mathbf{u} \cdot \mathbf{v} = \sum_{i=1}^n u_i v_i = \|\mathbf{u}\| \|\mathbf{v}\| \cos \theta\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Chu·∫©n vector:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chu·∫©n L2 (Euclid): \(\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2}\)&lt;/li&gt;
  &lt;li&gt;Chu·∫©n L1 (Manhattan): \(\|\mathbf{x}\|_1 = \sum_{i=1}^n \lvert x_i \rvert\)&lt;/li&gt;
  &lt;li&gt;Chu·∫©n L‚àû (Max): \(\|\mathbf{x}\|_\infty = \max_i \lvert x_i \rvert\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ma tr·∫≠n:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ph√©p nh√¢n ma tr·∫≠n: \((AB)_{ij} = \sum_{k} A_{ik} B_{kj}\)&lt;/li&gt;
  &lt;li&gt;Ma tr·∫≠n ngh·ªãch ƒë·∫£o: \(AA^{-1} = I\) (n·∫øu t·ªìn t·∫°i)&lt;/li&gt;
  &lt;li&gt;ƒê·ªãnh th·ª©c: \(\det(A)\) - ƒëo ‚Äúth·ªÉ t√≠ch‚Äù bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Eigenvalue v√† eigenvector:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(A\mathbf{v} = \lambda \mathbf{v}\) v·ªõi \(\mathbf{v} \neq \mathbf{0}\)&lt;/li&gt;
  &lt;li&gt;\(\lambda\): eigenvalue, \(\mathbf{v}\): eigenvector t∆∞∆°ng ·ª©ng&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-l√Ω-thuy·∫øt-t·∫≠p-h·ª£p-v√†-gi·∫£i-t√≠ch-th·ª±c&quot;&gt;üìä &lt;strong&gt;L√Ω thuy·∫øt t·∫≠p h·ª£p v√† gi·∫£i t√≠ch th·ª±c&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;T·∫≠p h·ª£p c∆° b·∫£n:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;T·∫≠p m·ªü: m·ªçi ƒëi·ªÉm ƒë·ªÅu c√≥ l√¢n c·∫≠n n·∫±m trong t·∫≠p&lt;/li&gt;
  &lt;li&gt;T·∫≠p ƒë√≥ng: ch·ª©a t·∫•t c·∫£ ƒëi·ªÉm bi√™n&lt;/li&gt;
  &lt;li&gt;T·∫≠p compact: ƒë√≥ng v√† b·ªã ch·∫∑n trong \(\mathbb{R}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;H√†m li√™n t·ª•c t·∫°i \(x_0\): \(\lim_{x \to x_0} f(x) = f(x_0)\)&lt;/li&gt;
  &lt;li&gt;Li√™n t·ª•c ƒë·ªÅu: \(\forall \epsilon &amp;gt; 0, \exists \delta &amp;gt; 0\) sao cho \(\lvert x-y \rvert &amp;lt; \delta \Rightarrow \lvert f(x)-f(y) \rvert &amp;lt; \epsilon\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;-x√°c-su·∫•t-c∆°-b·∫£n&quot;&gt;üé≤ &lt;strong&gt;X√°c su·∫•t c∆° b·∫£n&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kh√°i ni·ªám c∆° b·∫£n:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;X√°c su·∫•t: \(P(A) \in [0,1]\), \(P(\Omega) = 1\)&lt;/li&gt;
  &lt;li&gt;Bi·∫øn ng·∫´u nhi√™n: h√†m t·ª´ kh√¥ng gian m·∫´u ƒë·∫øn s·ªë th·ª±c&lt;/li&gt;
  &lt;li&gt;K·ª≥ v·ªçng: \(E[X] = \int x f(x) dx\) (li√™n t·ª•c) ho·∫∑c \(E[X] = \sum x P(X=x)\) (r·ªùi r·∫°c)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Ph√¢n ph·ªëi th√¥ng d·ª•ng:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Chu·∫©n: \(X \sim N(\mu, \sigma^2)\)&lt;/li&gt;
  &lt;li&gt;ƒê·ªÅu: \(X \sim U(a,b)\)&lt;/li&gt;
  &lt;li&gt;Bernoulli: \(X \sim \text{Ber}(p)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;p&gt;üí° &lt;strong&gt;M·∫πo:&lt;/strong&gt; C√°c kh√°i ni·ªám n√†y l√† n·ªÅn t·∫£ng cho t·ªëi ∆∞u h√≥a. Gradient ch·ªâ h∆∞·ªõng tƒÉng nhanh nh·∫•t, ma tr·∫≠n Hessian m√¥ t·∫£ ƒë·ªô cong, v√† chu·ªói Taylor gi√∫p x·∫•p x·ªâ h√†m c·ª•c b·ªô.&lt;/p&gt;

&lt;hr /&gt;

&lt;div id=&quot;quiz-container&quot;&gt;
    &lt;div id=&quot;quiz-header&quot;&gt;
        &lt;h2&gt;B√†i t·∫≠p tr·∫Øc nghi·ªám: Kh√°i ni·ªám c∆° b·∫£n&lt;/h2&gt;
        &lt;p&gt;Ch·ªçn ƒë√°p √°n ƒë√∫ng nh·∫•t cho m·ªói c√¢u h·ªèi. B·∫°n s·∫Ω nh·∫≠n ƒë∆∞·ª£c k·∫øt qu·∫£ ngay sau khi ho√†n th√†nh.&lt;/p&gt;
        &lt;div id=&quot;progress-bar&quot;&gt;
            &lt;div id=&quot;progress-fill&quot;&gt;&lt;/div&gt;
        &lt;/div&gt;
        &lt;p id=&quot;progress-text&quot;&gt;C√¢u h·ªèi 1/25&lt;/p&gt;
    &lt;/div&gt;

    &lt;div id=&quot;quiz-questions&quot;&gt;
        &lt;!-- C√¢u h·ªèi 1: ƒê·∫°o h√†m c∆° b·∫£n --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q1&quot;&gt;
            &lt;h3&gt;C√¢u 1: ƒê·∫°o h√†m c·ªßa h√†m s·ªë $$f(x) = x^3 + 2x^2 - 5x + 1$$ t·∫°i $$x = 1$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q1&quot; value=&quot;a&quot; /&gt; A) $$4$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q1&quot; value=&quot;b&quot; /&gt; B) $$2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q1&quot; value=&quot;c&quot; /&gt; C) $$-1$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q1&quot; value=&quot;d&quot; /&gt; D) $$6$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: B) $$2$$&lt;/strong&gt;&lt;br /&gt;
                $$f&apos;(x) = 3x^2 + 4x - 5$$&lt;br /&gt;
                $$f&apos;(1) = 3(1)^2 + 4(1) - 5 = 3 + 4 - 5 = 2$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 2: ƒê·∫°o h√†m ri√™ng --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q2&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 2: Cho $$f(x,y) = x^2y + 3xy^2$$. ƒê·∫°o h√†m ri√™ng $$\frac{\partial f}{\partial x}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q2&quot; value=&quot;a&quot; /&gt; A) $$2xy + 3y^2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q2&quot; value=&quot;b&quot; /&gt; B) $$x^2 + 6xy$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q2&quot; value=&quot;c&quot; /&gt; C) $$2xy + 6xy$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q2&quot; value=&quot;d&quot; /&gt; D) $$x^2 + 3y^2$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$2xy + 3y^2$$&lt;/strong&gt;&lt;br /&gt;
                Khi t√≠nh ƒë·∫°o h√†m ri√™ng theo $$x$$, ta coi $$y$$ l√† h·∫±ng s·ªë:&lt;br /&gt;
                $$\frac{\partial f}{\partial x} = \frac{\partial}{\partial x}(x^2y + 3xy^2) = 2xy + 3y^2$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 3: Gradient --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q3&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 3: Gradient c·ªßa h√†m $$f(x,y) = x^2 + 2xy + y^2$$ t·∫°i ƒëi·ªÉm $$(1,1)$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q3&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 4 \\ 4 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q3&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 2 \\ 2 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q3&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 3 \\ 3 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q3&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 1 \\ 1 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 4 \\ 4 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                $$\frac{\partial f}{\partial x} = 2x + 2y$$, $$\frac{\partial f}{\partial y} = 2x + 2y$$&lt;br /&gt;
                T·∫°i $$(1,1)$$: $$\nabla f(1,1) = \begin{pmatrix} 2(1) + 2(1) \\ 2(1) + 2(1) \end{pmatrix} = \begin{pmatrix} 4 \\ 4 \end{pmatrix}$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 4: ƒê·∫°o h√†m c√≥ h∆∞·ªõng --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q4&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 4: Cho gradient $$\nabla f = \begin{pmatrix} 3 \\ 4 \end{pmatrix}$$ v√† vector ƒë∆°n v·ªã $$\mathbf{u} = \begin{pmatrix} 0.6 \\ 0.8 \end{pmatrix}$$. ƒê·∫°o h√†m c√≥ h∆∞·ªõng $$D_{\mathbf{u}}f$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q4&quot; value=&quot;a&quot; /&gt; A) $$5$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q4&quot; value=&quot;b&quot; /&gt; B) $$5.0$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q4&quot; value=&quot;c&quot; /&gt; C) $$3.2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q4&quot; value=&quot;d&quot; /&gt; D) $$7$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$5$$&lt;/strong&gt;&lt;br /&gt;
                $$D_{\mathbf{u}}f = \nabla f \cdot \mathbf{u} = 3(0.6) + 4(0.8) = 1.8 + 3.2 = 5$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 5: H∆∞·ªõng tƒÉng d·ªëc nh·∫•t --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q5&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 5: H∆∞·ªõng tƒÉng d·ªëc nh·∫•t c·ªßa h√†m s·ªë lu√¥n l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q5&quot; value=&quot;a&quot; /&gt; A) H∆∞·ªõng c·ªßa vector gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q5&quot; value=&quot;b&quot; /&gt; B) H∆∞·ªõng ng∆∞·ª£c v·ªõi vector gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q5&quot; value=&quot;c&quot; /&gt; C) H∆∞·ªõng vu√¥ng g√≥c v·ªõi vector gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q5&quot; value=&quot;d&quot; /&gt; D) H∆∞·ªõng c·ªßa tr·ª•c x&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) H∆∞·ªõng c·ªßa vector gradient&lt;/strong&gt;&lt;br /&gt;
                Gradient lu√¥n ch·ªâ theo h∆∞·ªõng tƒÉng d·ªëc nh·∫•t c·ªßa h√†m s·ªë. ƒê√¢y l√† m·ªôt t√≠nh ch·∫•t c∆° b·∫£n c·ªßa gradient.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 6: Ph√©p c·ªông vector --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q6&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 6: Cho $$\mathbf{u} = \begin{pmatrix} 2 \\ -1 \\ 3 \end{pmatrix}$$ v√† $$\mathbf{v} = \begin{pmatrix} 1 \\ 4 \\ -2 \end{pmatrix}$$. Vector $$\mathbf{u} + \mathbf{v}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q6&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 3 \\ 3 \\ 1 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q6&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 1 \\ -5 \\ 5 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q6&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 2 \\ 4 \\ -6 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q6&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 3 \\ -3 \\ 1 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 3 \\ 3 \\ 1 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                $$\mathbf{u} + \mathbf{v} = \begin{pmatrix} 2+1 \\ -1+4 \\ 3+(-2) \end{pmatrix} = \begin{pmatrix} 3 \\ 3 \\ 1 \end{pmatrix}$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 7: T√≠ch v√¥ h∆∞·ªõng --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q7&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 7: T√≠ch v√¥ h∆∞·ªõng c·ªßa $$\mathbf{a} = \begin{pmatrix} 1 \\ 2 \\ 3 \end{pmatrix}$$ v√† $$\mathbf{b} = \begin{pmatrix} 4 \\ 5 \\ 6 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q7&quot; value=&quot;a&quot; /&gt; A) $$32$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q7&quot; value=&quot;b&quot; /&gt; B) $$14$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q7&quot; value=&quot;c&quot; /&gt; C) $$18$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q7&quot; value=&quot;d&quot; /&gt; D) $$24$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$32$$&lt;/strong&gt;&lt;br /&gt;
                $$\mathbf{a} \cdot \mathbf{b} = 1 \cdot 4 + 2 \cdot 5 + 3 \cdot 6 = 4 + 10 + 18 = 32$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 8: Chu·∫©n Euclid --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q8&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 8: Chu·∫©n Euclid c·ªßa vector $$\mathbf{v} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q8&quot; value=&quot;a&quot; /&gt; A) $$5$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q8&quot; value=&quot;b&quot; /&gt; B) $$7$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q8&quot; value=&quot;c&quot; /&gt; C) $$25$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q8&quot; value=&quot;d&quot; /&gt; D) $$\sqrt{7}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$5$$&lt;/strong&gt;&lt;br /&gt;
                $$\|\mathbf{v}\|_2 = \sqrt{3^2 + 4^2} = \sqrt{9 + 16} = \sqrt{25} = 5$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 9: Vector tr·ª±c giao --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q9&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 9: Hai vector $$\mathbf{u}$$ v√† $$\mathbf{v}$$ ƒë∆∞·ª£c g·ªçi l√† tr·ª±c giao khi:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q9&quot; value=&quot;a&quot; /&gt; A) $$\mathbf{u} \cdot \mathbf{v} = 0$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q9&quot; value=&quot;b&quot; /&gt; B) $$\mathbf{u} \cdot \mathbf{v} = 1$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q9&quot; value=&quot;c&quot; /&gt; C) $$\|\mathbf{u}\| = \|\mathbf{v}\|$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q9&quot; value=&quot;d&quot; /&gt; D) $$\mathbf{u} + \mathbf{v} = \mathbf{0}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\mathbf{u} \cdot \mathbf{v} = 0$$&lt;/strong&gt;&lt;br /&gt;
                Hai vector tr·ª±c giao (vu√¥ng g√≥c) khi v√† ch·ªâ khi t√≠ch v√¥ h∆∞·ªõng c·ªßa ch√∫ng b·∫±ng 0.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 10: Ph√©p nh√¢n ma tr·∫≠n --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q10&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 10: T√≠ch c·ªßa hai ma tr·∫≠n $$\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} \begin{pmatrix} 2 &amp;amp; 0 \\ 1 &amp;amp; 3 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q10&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 4 &amp;amp; 6 \\ 10 &amp;amp; 12 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q10&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 4 &amp;amp; 6 \\ 10 &amp;amp; 12 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q10&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 2 &amp;amp; 0 \\ 3 &amp;amp; 12 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q10&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 4 &amp;amp; 6 \\ 10 &amp;amp; 12 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 4 &amp;amp; 6 \\ 10 &amp;amp; 12 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                Ph·∫ßn t·ª≠ $$(1,1)$$: $$1 \cdot 2 + 2 \cdot 1 = 4$$&lt;br /&gt;
                Ph·∫ßn t·ª≠ $$(1,2)$$: $$1 \cdot 0 + 2 \cdot 3 = 6$$&lt;br /&gt;
                Ph·∫ßn t·ª≠ $$(2,1)$$: $$3 \cdot 2 + 4 \cdot 1 = 10$$&lt;br /&gt;
                Ph·∫ßn t·ª≠ $$(2,2)$$: $$3 \cdot 0 + 4 \cdot 3 = 12$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 11: Ma tr·∫≠n ƒë∆°n v·ªã --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q11&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 11: Ma tr·∫≠n ƒë∆°n v·ªã $$2 \times 2$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q11&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q11&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q11&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; 1 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q11&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; 2 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                Ma tr·∫≠n ƒë∆°n v·ªã c√≥ c√°c ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o ch√≠nh b·∫±ng 1 v√† c√°c ph·∫ßn t·ª≠ kh√°c b·∫±ng 0.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 12: Ma tr·∫≠n chuy·ªÉn v·ªã --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q12&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 12: Chuy·ªÉn v·ªã c·ªßa ma tr·∫≠n $$\begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q12&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q12&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 6 &amp;amp; 5 &amp;amp; 4 \\ 3 &amp;amp; 2 &amp;amp; 1 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q12&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 4 &amp;amp; 1 \\ 5 &amp;amp; 2 \\ 6 &amp;amp; 3 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q12&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                Chuy·ªÉn v·ªã c·ªßa ma tr·∫≠n ƒë∆∞·ª£c t·∫°o b·∫±ng c√°ch ho√°n ƒë·ªïi h√†ng v√† c·ªôt.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 13: ƒê·ªãnh th·ª©c 2x2 --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q13&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 13: ƒê·ªãnh th·ª©c c·ªßa ma tr·∫≠n $$\begin{pmatrix} 3 &amp;amp; 1 \\ 2 &amp;amp; 4 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q13&quot; value=&quot;a&quot; /&gt; A) $$10$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q13&quot; value=&quot;b&quot; /&gt; B) $$14$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q13&quot; value=&quot;c&quot; /&gt; C) $$2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q13&quot; value=&quot;d&quot; /&gt; D) $$12$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$10$$&lt;/strong&gt;&lt;br /&gt;
                $$\det\begin{pmatrix} 3 &amp;amp; 1 \\ 2 &amp;amp; 4 \end{pmatrix} = 3 \cdot 4 - 1 \cdot 2 = 12 - 2 = 10$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 14: ƒê·ªôc l·∫≠p tuy·∫øn t√≠nh --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q14&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 14: Hai vector $$\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}$$ v√† $$\mathbf{v}_2 = \begin{pmatrix} 2 \\ 4 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q14&quot; value=&quot;a&quot; /&gt; A) ƒê·ªôc l·∫≠p tuy·∫øn t√≠nh&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q14&quot; value=&quot;b&quot; /&gt; B) Ph·ª• thu·ªôc tuy·∫øn t√≠nh&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q14&quot; value=&quot;c&quot; /&gt; C) Tr·ª±c giao&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q14&quot; value=&quot;d&quot; /&gt; D) Kh√¥ng th·ªÉ x√°c ƒë·ªãnh&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: B) Ph·ª• thu·ªôc tuy·∫øn t√≠nh&lt;/strong&gt;&lt;br /&gt;
                $$\mathbf{v}_2 = 2\mathbf{v}_1$$, do ƒë√≥ hai vector n√†y ph·ª• thu·ªôc tuy·∫øn t√≠nh.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 15: Chu·∫©n Manhattan --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q15&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 15: Chu·∫©n Manhattan (L1) c·ªßa vector $$\mathbf{v} = \begin{pmatrix} -2 \\ 3 \\ -1 \end{pmatrix}$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q15&quot; value=&quot;a&quot; /&gt; A) $$6$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q15&quot; value=&quot;b&quot; /&gt; B) $$0$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q15&quot; value=&quot;c&quot; /&gt; C) $$4$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q15&quot; value=&quot;d&quot; /&gt; D) $$\sqrt{14}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$6$$&lt;/strong&gt;&lt;br /&gt;
                $$\|\mathbf{v}\|_1 = |-2| + |3| + |-1| = 2 + 3 + 1 = 6$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 16: Quy t·∫Øc d√¢y chuy·ªÅn --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q16&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 16: Cho $$z = x^2 + y^2$$ v·ªõi $$x = 2t$$ v√† $$y = 3t$$. ƒê·∫°o h√†m $$\frac{dz}{dt}$$ t·∫°i $$t = 1$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q16&quot; value=&quot;a&quot; /&gt; A) $$26$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q16&quot; value=&quot;b&quot; /&gt; B) $$13$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q16&quot; value=&quot;c&quot; /&gt; C) $$10$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q16&quot; value=&quot;d&quot; /&gt; D) $$5$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$26$$&lt;/strong&gt;&lt;br /&gt;
                $$\frac{dz}{dt} = \frac{\partial z}{\partial x}\frac{dx}{dt} + \frac{\partial z}{\partial y}\frac{dy}{dt} = 2x \cdot 2 + 2y \cdot 3$$&lt;br /&gt;
                T·∫°i $$t = 1$$: $$x = 2, y = 3$$, n√™n $$\frac{dz}{dt} = 2(2)(2) + 2(3)(3) = 8 + 18 = 26$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 17: ƒêi·ªÉm t·ªõi h·∫°n --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q17&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 17: ƒêi·ªÉm t·ªõi h·∫°n c·ªßa h√†m s·ªë l√† ƒëi·ªÉm m√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q17&quot; value=&quot;a&quot; /&gt; A) Gradient b·∫±ng vector kh√¥ng&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q17&quot; value=&quot;b&quot; /&gt; B) H√†m s·ªë ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q17&quot; value=&quot;c&quot; /&gt; C) H√†m s·ªë ƒë·∫°t gi√° tr·ªã nh·ªè nh·∫•t&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q17&quot; value=&quot;d&quot; /&gt; D) H√†m s·ªë kh√¥ng x√°c ƒë·ªãnh&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) Gradient b·∫±ng vector kh√¥ng&lt;/strong&gt;&lt;br /&gt;
                ƒêi·ªÉm t·ªõi h·∫°n l√† ƒëi·ªÉm m√† gradient c·ªßa h√†m s·ªë b·∫±ng vector kh√¥ng, t·ª©c l√† $$\nabla f = \mathbf{0}$$.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 18: Ma tr·∫≠n ngh·ªãch ƒë·∫£o --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q18&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 18: Ma tr·∫≠n $$\begin{pmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 1 \end{pmatrix}$$ c√≥ ngh·ªãch ƒë·∫£o l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q18&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 1 &amp;amp; -1 \\ -1 &amp;amp; 2 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q18&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 1 &amp;amp; 1 \\ 1 &amp;amp; 2 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q18&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 2 &amp;amp; -1 \\ -1 &amp;amp; 1 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q18&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 0.5 &amp;amp; 0.5 \\ 0.5 &amp;amp; 1 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 1 &amp;amp; -1 \\ -1 &amp;amp; 2 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                $$\det(A) = 2 \cdot 1 - 1 \cdot 1 = 1$$&lt;br /&gt;
                $$A^{-1} = \frac{1}{1}\begin{pmatrix} 1 &amp;amp; -1 \\ -1 &amp;amp; 2 \end{pmatrix} = \begin{pmatrix} 1 &amp;amp; -1 \\ -1 &amp;amp; 2 \end{pmatrix}$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 19: ƒê∆∞·ªùng m·ª©c --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q19&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 19: Gradient c·ªßa h√†m s·ªë t·∫°i m·ªôt ƒëi·ªÉm lu√¥n:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q19&quot; value=&quot;a&quot; /&gt; A) Vu√¥ng g√≥c v·ªõi ƒë∆∞·ªùng m·ª©c t·∫°i ƒëi·ªÉm ƒë√≥&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q19&quot; value=&quot;b&quot; /&gt; B) Song song v·ªõi ƒë∆∞·ªùng m·ª©c t·∫°i ƒëi·ªÉm ƒë√≥&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q19&quot; value=&quot;c&quot; /&gt; C) T·∫°o g√≥c 45¬∞ v·ªõi ƒë∆∞·ªùng m·ª©c&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q19&quot; value=&quot;d&quot; /&gt; D) Kh√¥ng c√≥ m·ªëi quan h·ªá v·ªõi ƒë∆∞·ªùng m·ª©c&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) Vu√¥ng g√≥c v·ªõi ƒë∆∞·ªùng m·ª©c t·∫°i ƒëi·ªÉm ƒë√≥&lt;/strong&gt;&lt;br /&gt;
                Gradient lu√¥n vu√¥ng g√≥c v·ªõi ƒë∆∞·ªùng m·ª©c v√¨ ƒë∆∞·ªùng m·ª©c l√† t·∫≠p h·ª£p c√°c ƒëi·ªÉm c√≥ c√πng gi√° tr·ªã h√†m s·ªë.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 20: ·ª®ng d·ª•ng trong t·ªëi ∆∞u h√≥a --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q20&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 20: Trong thu·∫≠t to√°n gradient descent, ch√∫ng ta di chuy·ªÉn theo h∆∞·ªõng:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q20&quot; value=&quot;a&quot; /&gt; A) Ng∆∞·ª£c v·ªõi h∆∞·ªõng gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q20&quot; value=&quot;b&quot; /&gt; B) C√πng h∆∞·ªõng v·ªõi gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q20&quot; value=&quot;c&quot; /&gt; C) Vu√¥ng g√≥c v·ªõi gradient&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q20&quot; value=&quot;d&quot; /&gt; D) H∆∞·ªõng ng·∫´u nhi√™n&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) Ng∆∞·ª£c v·ªõi h∆∞·ªõng gradient&lt;/strong&gt;&lt;br /&gt;
                Gradient descent di chuy·ªÉn theo h∆∞·ªõng $$-\nabla f$$ ƒë·ªÉ t√¨m ƒëi·ªÉm c·ª±c ti·ªÉu c·ªßa h√†m s·ªë.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 21: T√≠nh to√°n ƒë·∫°o h√†m b·∫≠c hai --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q21&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 21: ƒê·∫°o h√†m b·∫≠c hai c·ªßa h√†m $$f(x) = 3x^4 - 2x^3 + x^2 - 5x + 1$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q21&quot; value=&quot;a&quot; /&gt; A) $$36x^2 - 12x + 2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q21&quot; value=&quot;b&quot; /&gt; B) $$12x^3 - 6x^2 + 2x - 5$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q21&quot; value=&quot;c&quot; /&gt; C) $$36x^2 - 12x + 1$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q21&quot; value=&quot;d&quot; /&gt; D) $$12x^2 - 6x + 2$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$36x^2 - 12x + 2$$&lt;/strong&gt;&lt;br /&gt;
                $$f&apos;(x) = 12x^3 - 6x^2 + 2x - 5$$&lt;br /&gt;
                $$f&apos;&apos;(x) = 36x^2 - 12x + 2$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 22: ·ª®ng d·ª•ng ma tr·∫≠n Hessian --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q22&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 22: Cho $$f(x,y) = x^2 + 2xy + 3y^2$$. Ma tr·∫≠n Hessian t·∫°i ƒëi·ªÉm $$(1,1)$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q22&quot; value=&quot;a&quot; /&gt; A) $$\begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q22&quot; value=&quot;b&quot; /&gt; B) $$\begin{pmatrix} 1 &amp;amp; 2 \\ 2 &amp;amp; 3 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q22&quot; value=&quot;c&quot; /&gt; C) $$\begin{pmatrix} 2 &amp;amp; 1 \\ 1 &amp;amp; 6 \end{pmatrix}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q22&quot; value=&quot;d&quot; /&gt; D) $$\begin{pmatrix} 4 &amp;amp; 4 \\ 4 &amp;amp; 8 \end{pmatrix}$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}$$&lt;/strong&gt;&lt;br /&gt;
                $$\frac{\partial^2 f}{\partial x^2} = 2$$, $$\frac{\partial^2 f}{\partial y^2} = 6$$, $$\frac{\partial^2 f}{\partial x \partial y} = 2$$&lt;br /&gt;
                Ma tr·∫≠n Hessian kh√¥ng ph·ª• thu·ªôc v√†o ƒëi·ªÉm c·ª• th·ªÉ trong tr∆∞·ªùng h·ª£p n√†y.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 23: T√≠nh to√°n th·ª±c t·∫ø v·ªõi vector --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q23&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 23: Kho·∫£ng c√°ch t·ª´ ƒëi·ªÉm $$A(1,2)$$ ƒë·∫øn ƒëi·ªÉm $$B(4,6)$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q23&quot; value=&quot;a&quot; /&gt; A) $$5$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q23&quot; value=&quot;b&quot; /&gt; B) $$7$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q23&quot; value=&quot;c&quot; /&gt; C) $$\sqrt{25}$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q23&quot; value=&quot;d&quot; /&gt; D) $$3$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$5$$&lt;/strong&gt;&lt;br /&gt;
                Kho·∫£ng c√°ch = $$\sqrt{(4-1)^2 + (6-2)^2} = \sqrt{9 + 16} = \sqrt{25} = 5$$
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 24: ·ª®ng d·ª•ng eigenvalue --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q24&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 24: Ma tr·∫≠n $$A = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}$$ c√≥ eigenvalue l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q24&quot; value=&quot;a&quot; /&gt; A) $$\lambda_1 = 3, \lambda_2 = 2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q24&quot; value=&quot;b&quot; /&gt; B) $$\lambda_1 = 2, \lambda_2 = 3$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q24&quot; value=&quot;c&quot; /&gt; C) $$\lambda_1 = 1, \lambda_2 = 5$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q24&quot; value=&quot;d&quot; /&gt; D) $$\lambda_1 = 0, \lambda_2 = 5$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$\lambda_1 = 3, \lambda_2 = 2$$&lt;/strong&gt;&lt;br /&gt;
                ƒê·ªëi v·ªõi ma tr·∫≠n tam gi√°c tr√™n, eigenvalue ch√≠nh l√† c√°c ph·∫ßn t·ª≠ tr√™n ƒë∆∞·ªùng ch√©o ch√≠nh.
            &lt;/div&gt;
        &lt;/div&gt;

        &lt;!-- C√¢u h·ªèi 25: T·ªëi ∆∞u h√≥a ƒë∆°n gi·∫£n --&gt;
        &lt;div class=&quot;question&quot; id=&quot;q25&quot; style=&quot;display: none;&quot;&gt;
            &lt;h3&gt;C√¢u 25: ƒêi·ªÉm c·ª±c ti·ªÉu c·ªßa h√†m $$f(x) = x^2 - 4x + 5$$ l√†:&lt;/h3&gt;
            &lt;div class=&quot;options&quot;&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q25&quot; value=&quot;a&quot; /&gt; A) $$x = 2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q25&quot; value=&quot;b&quot; /&gt; B) $$x = -2$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q25&quot; value=&quot;c&quot; /&gt; C) $$x = 4$$&lt;/label&gt;
                &lt;label&gt;&lt;input type=&quot;radio&quot; name=&quot;q25&quot; value=&quot;d&quot; /&gt; D) $$x = 0$$&lt;/label&gt;
            &lt;/div&gt;
            &lt;div class=&quot;explanation&quot; style=&quot;display: none;&quot;&gt;
                &lt;strong&gt;ƒê√°p √°n ƒë√∫ng: A) $$x = 2$$&lt;/strong&gt;&lt;br /&gt;
                $$f&apos;(x) = 2x - 4 = 0 \Rightarrow x = 2$$&lt;br /&gt;
                $$f&apos;&apos;(x) = 2 &amp;gt; 0$$, n√™n $$x = 2$$ l√† ƒëi·ªÉm c·ª±c ti·ªÉu.
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;

    &lt;div id=&quot;quiz-navigation&quot;&gt;
        &lt;button id=&quot;prev-btn&quot; onclick=&quot;previousQuestion()&quot; disabled=&quot;&quot;&gt;C√¢u tr∆∞·ªõc&lt;/button&gt;
        &lt;button id=&quot;next-btn&quot; onclick=&quot;nextQuestion()&quot;&gt;C√¢u ti·∫øp&lt;/button&gt;
        &lt;button id=&quot;submit-btn&quot; onclick=&quot;submitQuiz()&quot; style=&quot;display: none;&quot;&gt;N·ªôp b√†i&lt;/button&gt;
    &lt;/div&gt;

    &lt;div id=&quot;quiz-results&quot; style=&quot;display: none;&quot;&gt;
        &lt;h3&gt;K·∫øt qu·∫£ b√†i t·∫≠p&lt;/h3&gt;
        &lt;div id=&quot;score-display&quot;&gt;&lt;/div&gt;
        &lt;div id=&quot;detailed-results&quot;&gt;&lt;/div&gt;
        &lt;button onclick=&quot;restartQuiz()&quot;&gt;L√†m l·∫°i&lt;/button&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;style&gt;
#quiz-container {
    max-width: 800px;
    margin: 0 auto;
    padding: 20px;
    font-family: &apos;Segoe UI&apos;, Tahoma, Geneva, Verdana, sans-serif;
}

#quiz-header {
    text-align: center;
    margin-bottom: 30px;
}

#progress-bar {
    width: 100%;
    height: 10px;
    background-color: #e0e0e0;
    border-radius: 5px;
    margin: 20px 0;
    overflow: hidden;
}

#progress-fill {
    height: 100%;
    background: linear-gradient(90deg, #4CAF50, #45a049);
    width: 5%;
    transition: width 0.3s ease;
}

.question {
    background: #f9f9f9;
    border: 1px solid #ddd;
    border-radius: 8px;
    padding: 25px;
    margin-bottom: 20px;
    box-shadow: 0 2px 4px rgba(0,0,0,0.1);
}

.question h3 {
    color: #333;
    margin-bottom: 20px;
    font-size: 1.1em;
    line-height: 1.4;
}

.options {
    display: flex;
    flex-direction: column;
    gap: 12px;
}

.options label {
    display: flex;
    align-items: center;
    padding: 12px;
    background: white;
    border: 2px solid #e0e0e0;
    border-radius: 6px;
    cursor: pointer;
    transition: all 0.2s ease;
    font-size: 1em;
}

.options label:hover {
    border-color: #4CAF50;
    background-color: #f0f8f0;
}

.options input[type=&quot;radio&quot;] {
    margin-right: 12px;
    transform: scale(1.2);
}

.options label.selected {
    border-color: #4CAF50;
    background-color: #e8f5e8;
}

.explanation {
    margin-top: 20px;
    padding: 15px;
    background-color: #e3f2fd;
    border-left: 4px solid #2196F3;
    border-radius: 4px;
    font-size: 0.95em;
    line-height: 1.5;
}

.explanation strong {
    color: #1976D2;
}

#quiz-navigation {
    text-align: center;
    margin: 30px 0;
    display: flex;
    justify-content: space-between;
    align-items: center;
}

#quiz-navigation button {
    background: #4CAF50;
    color: white;
    border: none;
    padding: 12px 24px;
    border-radius: 6px;
    cursor: pointer;
    font-size: 1em;
    transition: background-color 0.2s ease;
}

#quiz-navigation button:hover:not(:disabled) {
    background: #45a049;
}

#quiz-navigation button:disabled {
    background: #cccccc;
    cursor: not-allowed;
}

#quiz-results {
    text-align: center;
    padding: 30px;
    background: #f0f8f0;
    border-radius: 8px;
    border: 2px solid #4CAF50;
}

#score-display {
    font-size: 1.5em;
    font-weight: bold;
    margin: 20px 0;
    color: #2E7D32;
}

#detailed-results {
    text-align: left;
    margin: 20px 0;
    max-height: 400px;
    overflow-y: auto;
}

.result-item {
    padding: 10px;
    margin: 5px 0;
    border-radius: 4px;
    border-left: 4px solid;
}

.result-item.correct {
    background-color: #e8f5e8;
    border-left-color: #4CAF50;
}

.result-item.incorrect {
    background-color: #ffebee;
    border-left-color: #f44336;
}

@media (max-width: 600px) {
    #quiz-container {
        padding: 10px;
    }
    
    .question {
        padding: 15px;
    }
    
    #quiz-navigation {
        flex-direction: column;
        gap: 10px;
    }
    
    #quiz-navigation button {
        width: 100%;
    }
}
&lt;/style&gt;

&lt;script&gt;
let currentQuestion = 1;
const totalQuestions = 25;
let userAnswers = {};
let quizSubmitted = false;

// ƒê√°p √°n ƒë√∫ng cho t·ª´ng c√¢u h·ªèi
const correctAnswers = {
    q1: &apos;b&apos;, q2: &apos;a&apos;, q3: &apos;a&apos;, q4: &apos;a&apos;, q5: &apos;a&apos;,
    q6: &apos;a&apos;, q7: &apos;a&apos;, q8: &apos;a&apos;, q9: &apos;a&apos;, q10: &apos;a&apos;,
    q11: &apos;a&apos;, q12: &apos;a&apos;, q13: &apos;a&apos;, q14: &apos;b&apos;, q15: &apos;a&apos;,
    q16: &apos;a&apos;, q17: &apos;a&apos;, q18: &apos;a&apos;, q19: &apos;a&apos;, q20: &apos;a&apos;,
    q21: &apos;a&apos;, q22: &apos;a&apos;, q23: &apos;a&apos;, q24: &apos;a&apos;, q25: &apos;a&apos;
};

/**
 * C·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh v√† hi·ªÉn th·ªã c√¢u h·ªèi hi·ªán t·∫°i
 */
function updateProgress() {
    const progressFill = document.getElementById(&apos;progress-fill&apos;);
    const progressText = document.getElementById(&apos;progress-text&apos;);
    
    const percentage = (currentQuestion / totalQuestions) * 100;
    progressFill.style.width = percentage + &apos;%&apos;;
    progressText.textContent = `C√¢u h·ªèi ${currentQuestion}/${totalQuestions}`;
}

/**
 * Hi·ªÉn th·ªã c√¢u h·ªèi theo s·ªë th·ª© t·ª±
 */
function showQuestion(questionNum) {
    // ·∫®n t·∫•t c·∫£ c√¢u h·ªèi
    for (let i = 1; i &lt;= totalQuestions; i++) {
        document.getElementById(`q${i}`).style.display = &apos;none&apos;;
    }
    
    // Hi·ªÉn th·ªã c√¢u h·ªèi hi·ªán t·∫°i
    document.getElementById(`q${questionNum}`).style.display = &apos;block&apos;;
    
    // C·∫≠p nh·∫≠t tr·∫°ng th√°i n√∫t ƒëi·ªÅu h∆∞·ªõng
    document.getElementById(&apos;prev-btn&apos;).disabled = (questionNum === 1);
    document.getElementById(&apos;next-btn&apos;).style.display = (questionNum === totalQuestions) ? &apos;none&apos; : &apos;inline-block&apos;;
    document.getElementById(&apos;submit-btn&apos;).style.display = (questionNum === totalQuestions) ? &apos;inline-block&apos; : &apos;none&apos;;
    
    updateProgress();
}

/**
 * Chuy·ªÉn ƒë·∫øn c√¢u h·ªèi ti·∫øp theo
 */
function nextQuestion() {
    if (currentQuestion &lt; totalQuestions) {
        currentQuestion++;
        showQuestion(currentQuestion);
    }
}

/**
 * Quay l·∫°i c√¢u h·ªèi tr∆∞·ªõc
 */
function previousQuestion() {
    if (currentQuestion &gt; 1) {
        currentQuestion--;
        showQuestion(currentQuestion);
    }
}

/**
 * L∆∞u ƒë√°p √°n c·ªßa ng∆∞·ªùi d√πng
 */
function saveAnswer(questionId, answer) {
    userAnswers[questionId] = answer;
    
    // C·∫≠p nh·∫≠t giao di·ªán ƒë·ªÉ hi·ªÉn th·ªã ƒë√°p √°n ƒë√£ ch·ªçn
    const labels = document.querySelectorAll(`#${questionId} .options label`);
    labels.forEach(label =&gt; {
        label.classList.remove(&apos;selected&apos;);
        if (label.querySelector(&apos;input&apos;).value === answer) {
            label.classList.add(&apos;selected&apos;);
        }
    });
}

/**
 * N·ªôp b√†i v√† hi·ªÉn th·ªã k·∫øt qu·∫£
 */
function submitQuiz() {
    if (quizSubmitted) return;
    
    quizSubmitted = true;
    let correctCount = 0;
    let detailedResults = &apos;&apos;;
    
    // T√≠nh ƒëi·ªÉm v√† t·∫°o b√°o c√°o chi ti·∫øt
    for (let i = 1; i &lt;= totalQuestions; i++) {
        const questionId = `q${i}`;
        const userAnswer = userAnswers[questionId];
        const correctAnswer = correctAnswers[questionId];
        const isCorrect = userAnswer === correctAnswer;
        
        if (isCorrect) correctCount++;
        
        // Hi·ªÉn th·ªã gi·∫£i th√≠ch cho t·∫•t c·∫£ c√¢u h·ªèi
        const explanation = document.querySelector(`#${questionId} .explanation`);
        if (explanation) {
            explanation.style.display = &apos;block&apos;;
        }
        
        // T·∫°o b√°o c√°o chi ti·∫øt
        detailedResults += `
            &lt;div class=&quot;result-item ${isCorrect ? &apos;correct&apos; : &apos;incorrect&apos;}&quot;&gt;
                &lt;strong&gt;C√¢u ${i}:&lt;/strong&gt; ${isCorrect ? &apos;ƒê√∫ng&apos; : &apos;Sai&apos;}
                ${!isCorrect ? `&lt;br&gt;&lt;small&gt;ƒê√°p √°n c·ªßa b·∫°n: ${userAnswer || &apos;Ch∆∞a tr·∫£ l·ªùi&apos;} | ƒê√°p √°n ƒë√∫ng: ${correctAnswer}&lt;/small&gt;` : &apos;&apos;}
            &lt;/div&gt;
        `;
    }
    
    // Hi·ªÉn th·ªã k·∫øt qu·∫£
    const scorePercentage = Math.round((correctCount / totalQuestions) * 100);
    document.getElementById(&apos;score-display&apos;).innerHTML = `
        &lt;div&gt;ƒêi·ªÉm s·ªë: ${correctCount}/${totalQuestions} (${scorePercentage}%)&lt;/div&gt;
        &lt;div style=&quot;margin-top: 10px; font-size: 0.9em;&quot;&gt;
            ${scorePercentage &gt;= 80 ? &apos;üéâ Xu·∫•t s·∫Øc!&apos; : 
              scorePercentage &gt;= 60 ? &apos;üëç Kh√° t·ªët!&apos; : 
              scorePercentage &gt;= 40 ? &apos;üìö C·∫ßn √¥n t·∫≠p th√™m&apos; : &apos;üí™ H√£y c·ªë g·∫Øng h∆°n!&apos;}
        &lt;/div&gt;
    `;
    
    document.getElementById(&apos;detailed-results&apos;).innerHTML = detailedResults;
    document.getElementById(&apos;quiz-results&apos;).style.display = &apos;block&apos;;
    document.getElementById(&apos;quiz-navigation&apos;).style.display = &apos;none&apos;;
    
    // Cu·ªôn ƒë·∫øn k·∫øt qu·∫£
    document.getElementById(&apos;quiz-results&apos;).scrollIntoView({ behavior: &apos;smooth&apos; });
}

/**
 * Kh·ªüi ƒë·ªông l·∫°i b√†i t·∫≠p
 */
function restartQuiz() {
    currentQuestion = 1;
    userAnswers = {};
    quizSubmitted = false;
    
    // ·∫®n k·∫øt qu·∫£ v√† hi·ªÉn th·ªã l·∫°i ƒëi·ªÅu h∆∞·ªõng
    document.getElementById(&apos;quiz-results&apos;).style.display = &apos;none&apos;;
    document.getElementById(&apos;quiz-navigation&apos;).style.display = &apos;flex&apos;;
    
    // ·∫®n t·∫•t c·∫£ gi·∫£i th√≠ch
    document.querySelectorAll(&apos;.explanation&apos;).forEach(exp =&gt; {
        exp.style.display = &apos;none&apos;;
    });
    
    // X√≥a t·∫•t c·∫£ l·ª±a ch·ªçn
    document.querySelectorAll(&apos;input[type=&quot;radio&quot;]&apos;).forEach(input =&gt; {
        input.checked = false;
    });
    
    document.querySelectorAll(&apos;.options label&apos;).forEach(label =&gt; {
        label.classList.remove(&apos;selected&apos;);
    });
    
    // Hi·ªÉn th·ªã c√¢u h·ªèi ƒë·∫ßu ti√™n
    showQuestion(1);
    
    // Cu·ªôn l√™n ƒë·∫ßu
    document.getElementById(&apos;quiz-header&apos;).scrollIntoView({ behavior: &apos;smooth&apos; });
}

// Kh·ªüi t·∫°o b√†i t·∫≠p khi trang ƒë∆∞·ª£c t·∫£i
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    showQuestion(1);
    
    // Th√™m event listener cho t·∫•t c·∫£ radio button
    document.querySelectorAll(&apos;input[type=&quot;radio&quot;]&apos;).forEach(input =&gt; {
        input.addEventListener(&apos;change&apos;, function() {
            const questionId = this.name;
            const answer = this.value;
            saveAnswer(questionId, answer);
        });
    });
    
    // Render MathJax sau khi DOM ƒë∆∞·ª£c t·∫£i
    if (window.MathJax) {
        MathJax.typesetPromise();
    }
});

// X·ª≠ l√Ω ph√≠m t·∫Øt
document.addEventListener(&apos;keydown&apos;, function(event) {
    if (quizSubmitted) return;
    
    switch(event.key) {
        case &apos;ArrowLeft&apos;:
            if (currentQuestion &gt; 1) previousQuestion();
            break;
        case &apos;ArrowRight&apos;:
            if (currentQuestion &lt; totalQuestions) nextQuestion();
            break;
        case &apos;Enter&apos;:
            if (currentQuestion === totalQuestions) submitQuiz();
            break;
    }
});
&lt;/script&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04 X√°c Su·∫•t v√† Th·ªëng K√™</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_Probability_and_Statistics/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_04_Probability_and_Statistics</id>
   <content type="html">&lt;h2 id=&quot;x√°c-su·∫•t-v√†-th·ªëng-k√™-cho-t·ªëi-∆∞u-h√≥a-l·ªìi&quot;&gt;X√°c Su·∫•t v√† Th·ªëng K√™ cho T·ªëi ∆Øu H√≥a L·ªìi&lt;/h2&gt;

&lt;p&gt;X√°c su·∫•t v√† th·ªëng k√™ t·∫°o n√™n n·ªÅn t·∫£ng quan tr·ªçng ƒë·ªÉ hi·ªÉu nhi·ªÅu b√†i to√°n t·ªëi ∆∞u h√≥a, ƒë·∫∑c bi·ªát trong h·ªçc m√°y v√† khoa h·ªçc d·ªØ li·ªáu. Ph·∫ßn n√†y gi·ªõi thi·ªáu c√°c kh√°i ni·ªám x√°c su·∫•t thi·∫øt y·∫øu th∆∞·ªùng xu·∫•t hi·ªán trong t·ªëi ∆∞u h√≥a l·ªìi, t·ª´ ∆∞·ªõc l∆∞·ª£ng h·ª£p l√Ω t·ªëi ƒëa ƒë·∫øn t·ªëi ∆∞u h√≥a Bayes.&lt;/p&gt;

&lt;h3 id=&quot;t·∫°i-sao-x√°c-su·∫•t-quan-tr·ªçng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;T·∫°i Sao X√°c Su·∫•t Quan Tr·ªçng trong T·ªëi ∆Øu H√≥a&lt;/h3&gt;

&lt;p&gt;Nhi·ªÅu b√†i to√°n t·ªëi ∆∞u h√≥a ph√°t sinh t·ª´ m√¥ h√¨nh h√≥a th·ªëng k√™:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;∆Ø·ªõc L∆∞·ª£ng H·ª£p L√Ω T·ªëi ƒêa (MLE)&lt;/strong&gt;: T√¨m tham s·ªë ƒë·ªÉ t·ªëi ƒëa h√≥a kh·∫£ nƒÉng c·ªßa d·ªØ li·ªáu quan s√°t&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·ªëi ∆Øu H√≥a Bayes&lt;/strong&gt;: S·ª≠ d·ª•ng m√¥ h√¨nh x√°c su·∫•t ƒë·ªÉ h∆∞·ªõng d·∫´n t√¨m ki·∫øm gi·∫£i ph√°p t·ªëi ∆∞u&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·ªëi ∆Øu H√≥a Ng·∫´u Nhi√™n&lt;/strong&gt;: X·ª≠ l√Ω s·ª± b·∫•t ƒë·ªãnh v√† ng·∫´u nhi√™n trong h√†m m·ª•c ti√™u&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Th√™m prior x√°c su·∫•t ƒë·ªÉ ngƒÉn overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·ªëi Thi·ªÉu H√≥a R·ªßi Ro&lt;/strong&gt;: T·ªëi ∆∞u h√≥a k·ª≥ v·ªçng loss tr√™n ph√¢n ph·ªëi x√°c su·∫•t&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c√°c-ch·ªß-ƒë·ªÅ-ch√≠nh&quot;&gt;C√°c Ch·ªß ƒê·ªÅ Ch√≠nh&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;L√Ω Thuy·∫øt X√°c Su·∫•t C∆° B·∫£n&lt;/strong&gt;: Kh√¥ng gian m·∫´u, bi·∫øn c·ªë v√† ti√™n ƒë·ªÅ x√°c su·∫•t&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;C√°c Ph√¢n Ph·ªëi X√°c Su·∫•t Th√¥ng D·ª•ng&lt;/strong&gt;: Ph√¢n ph·ªëi chu·∫©n, m≈© v√† c√°c ph√¢n ph·ªëi quan tr·ªçng kh√°c&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K·ª≥ V·ªçng v√† Ph∆∞∆°ng Sai&lt;/strong&gt;: T√≠nh to√°n v√† t·ªëi ∆∞u h√≥a gi√° tr·ªã k·ª≥ v·ªçng&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ƒê·ªãnh L√Ω Bayes&lt;/strong&gt;: N·ªÅn t·∫£ng cho t·ªëi ∆∞u h√≥a v√† suy lu·∫≠n Bayes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;∆Ø·ªõc L∆∞·ª£ng Th·ªëng K√™&lt;/strong&gt;: K·∫øt n·ªëi l√Ω thuy·∫øt x√°c su·∫•t v·ªõi b√†i to√°n t·ªëi ∆∞u h√≥a&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;k·∫øt-n·ªëi-v·ªõi-t·ªëi-∆∞u-h√≥a-l·ªìi&quot;&gt;K·∫øt N·ªëi v·ªõi T·ªëi ∆Øu H√≥a L·ªìi&lt;/h3&gt;

&lt;p&gt;Hi·ªÉu x√°c su·∫•t gi√∫p b·∫°n:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;X√¢y D·ª±ng B√†i To√°n&lt;/strong&gt;: Chuy·ªÉn ƒë·ªïi s·ª± b·∫•t ƒë·ªãnh th·ª±c t·∫ø th√†nh b√†i to√°n t·ªëi ∆∞u h√≥a to√°n h·ªçc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ch·ªçn H√†m M·ª•c Ti√™u&lt;/strong&gt;: L·ª±a ch·ªçn h√†m loss ph√π h·ª£p d·ª±a tr√™n gi·∫£ thuy·∫øt x√°c su·∫•t&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Di·ªÖn Gi·∫£i K·∫øt Qu·∫£&lt;/strong&gt;: Hi·ªÉu kho·∫£ng tin c·∫≠y v√† √Ω nghƒ©a th·ªëng k√™ c·ªßa nghi·ªám&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;X·ª≠ L√Ω Nhi·ªÖu&lt;/strong&gt;: ƒê·ªëi ph√≥ v·ªõi l·ªói ƒëo l∆∞·ªùng v√† qu√° tr√¨nh ng·∫´u nhi√™n&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thi·∫øt K·∫ø Thu·∫≠t To√°n&lt;/strong&gt;: Ph√°t tri·ªÉn ph∆∞∆°ng ph√°p t·ªëi ∆∞u h√≥a b·ªÅn v·ªØng ho·∫°t ƒë·ªông d∆∞·ªõi s·ª± b·∫•t ƒë·ªãnh&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;N·ªÅn t·∫£ng n√†y s·∫Ω r·∫•t quan tr·ªçng khi ch√∫ng ta kh√°m ph√° c√°ch c√°c m√¥ h√¨nh x√°c su·∫•t d·∫´n ƒë·∫øn b√†i to√°n t·ªëi ∆∞u h√≥a l·ªìi trong h·ªçc m√°y, th·ªëng k√™ v√† c√°c ·ª©ng d·ª•ng k·ªπ thu·∫≠t.&lt;/p&gt;

&lt;div style=&quot;background: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0;&quot;&gt;
&lt;strong&gt;üí° L·ªô Tr√¨nh H·ªçc:&lt;/strong&gt; B·∫Øt ƒë·∫ßu v·ªõi c√°c kh√°i ni·ªám x√°c su·∫•t c∆° b·∫£n, sau ƒë√≥ kh√°m ph√° c√°ch ch√∫ng k·∫øt n·ªëi v·ªõi t·ªëi ∆∞u h√≥a th√¥ng qua ∆∞·ªõc l∆∞·ª£ng h·ª£p l√Ω t·ªëi ƒëa v√† ph∆∞∆°ng ph√°p Bayes. M·ªói b√†i h·ªçc x√¢y d·ª±ng h∆∞·ªõng t·ªõi vi·ªác hi·ªÉu c√°ch s·ª± b·∫•t ƒë·ªãnh v√† ng·∫´u nhi√™n t·∫°o ra c√°c b√†i to√°n t·ªëi ∆∞u h√≥a.
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04-03 Likelihood v√† ∆Ø·ªõc L∆∞·ª£ng H·ª£p L√Ω T·ªëi ƒêa (MLE)</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_03_Likelihood_and_Maximum_Likelihood_Estimation/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_04_03_Likelihood_and_Maximum_Likelihood_Estimation</id>
   <content type="html">&lt;h2 id=&quot;likelihood-v√†-∆∞·ªõc-l∆∞·ª£ng-h·ª£p-l√Ω-t·ªëi-ƒëa&quot;&gt;Likelihood v√† ∆Ø·ªõc L∆∞·ª£ng H·ª£p L√Ω T·ªëi ƒêa&lt;/h2&gt;

&lt;p&gt;Trong x√°c su·∫•t th·ªëng k√™, &lt;strong&gt;likelihood&lt;/strong&gt; (t·∫°m d·ªãch: kh·∫£ nƒÉng x·∫£y ra ho·∫∑c ƒë·ªô h·ª£p l√Ω) l√† m·ªôt kh√°i ni·ªám quan tr·ªçng, bi·ªÉu th·ªã x√°c su·∫•t quan s√°t ƒë∆∞·ª£c d·ªØ li·ªáu c·ª• th·ªÉ khi gi·∫£ ƒë·ªãnh m·ªôt m√¥ h√¨nh ho·∫∑c m·ªôt t·∫≠p h·ª£p c√°c tham s·ªë nh·∫•t ƒë·ªãnh l√† ƒë√∫ng. Tuy nhi√™n, likelihood kh√¥ng ph·∫£i l√† x√°c su·∫•t th√¥ng th∆∞·ªùng m√† l√† m·ªôt h√†m ƒëo l∆∞·ªùng m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa m√¥ h√¨nh v·ªõi d·ªØ li·ªáu.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a-likelihood&quot;&gt;ƒê·ªãnh Nghƒ©a Likelihood&lt;/h3&gt;

&lt;p&gt;Likelihood c·ªßa m·ªôt tham s·ªë \(\theta\) (ho·∫∑c m·ªôt m√¥ h√¨nh) ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a l√† x√°c su·∫•t c·ªßa d·ªØ li·ªáu quan s√°t ƒë∆∞·ª£c, gi·∫£ s·ª≠ tham s·ªë \(\theta\) l√† ƒë√∫ng. N√≥ th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† \(L(\theta \mid x)\), trong ƒë√≥ \(x\) l√† d·ªØ li·ªáu quan s√°t ƒë∆∞·ª£c.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C√¥ng th·ª©c:&lt;/strong&gt;
\(L(\theta \mid x) = P(x \mid \theta)\)&lt;/p&gt;

&lt;p&gt;·ªû ƒë√¢y, \(P(x \mid \theta)\) l√† x√°c su·∫•t x·∫£y ra d·ªØ li·ªáu \(x\) khi tham s·ªë \(\theta\) ƒë∆∞·ª£c cho tr∆∞·ªõc.&lt;/p&gt;

&lt;h3 id=&quot;ƒëi·ªÉm-kh√°c-bi·ªát-v·ªõi-x√°c-su·∫•t&quot;&gt;ƒêi·ªÉm Kh√°c Bi·ªát v·ªõi X√°c Su·∫•t&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;X√°c su·∫•t&lt;/strong&gt; m√¥ t·∫£ kh·∫£ nƒÉng x·∫£y ra c·ªßa m·ªôt s·ª± ki·ªán trong t∆∞∆°ng lai, v·ªõi c√°c tham s·ªë ƒë√£ bi·∫øt.&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Likelihood&lt;/strong&gt; ng∆∞·ª£c l·∫°i, ƒëo l∆∞·ªùng m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa c√°c tham s·ªë kh√°c nhau ƒë·ªëi v·ªõi d·ªØ li·ªáu ƒë√£ quan s√°t.&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background: #fff3cd; padding: 15px; border-left: 4px solid #ffc107; margin: 20px 0;&quot;&gt;
&lt;strong&gt;‚ö†Ô∏è L∆∞u √Ω quan tr·ªçng:&lt;/strong&gt; Likelihood kh√¥ng ph·∫£i l√† x√°c su·∫•t c·ªßa tham s·ªë Œ∏, v√¨ n√≥ kh√¥ng ƒë∆∞·ª£c chu·∫©n h√≥a nh∆∞ m·ªôt ph√¢n ph·ªëi x√°c su·∫•t (t·ªïng t√≠ch ph√¢n c·ªßa likelihood kh√¥ng nh·∫•t thi·∫øt b·∫±ng 1).
&lt;/div&gt;

&lt;h3 id=&quot;v√≠-d·ª•-minh-h·ªça-tung-ƒë·ªìng-xu&quot;&gt;V√≠ D·ª• Minh H·ªça: Tung ƒê·ªìng Xu&lt;/h3&gt;

&lt;p&gt;Gi·∫£ s·ª≠ b·∫°n tung m·ªôt ƒë·ªìng xu v√† quan s√°t ƒë∆∞·ª£c k·∫øt qu·∫£ l√† 3 l·∫ßn ‚Äúm·∫∑t s·∫•p‚Äù (S) v√† 2 l·∫ßn ‚Äúm·∫∑t ng·ª≠a‚Äù (N) trong 5 l·∫ßn tung. B·∫°n mu·ªën bi·∫øt x√°c su·∫•t tung ƒë∆∞·ª£c m·∫∑t s·∫•p l√† \(p\).&lt;/p&gt;

&lt;p&gt;Likelihood c·ªßa \(p\) l√† x√°c su·∫•t quan s√°t ƒë∆∞·ª£c d·ªØ li·ªáu (3 s·∫•p, 2 ng·ª≠a) khi \(p\) ƒë∆∞·ª£c cho tr∆∞·ªõc:&lt;/p&gt;

\[L(p \mid \text{d·ªØ li·ªáu}) = P(\text{3 s·∫•p, 2 ng·ª≠a} \mid p) = \binom{5}{3} p^3 (1-p)^2\]

&lt;p&gt;Trong ƒë√≥:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\binom{5}{3}\) l√† h·ªá s·ªë nh·ªã th·ª©c&lt;/li&gt;
  &lt;li&gt;\(p^3\) l√† x√°c su·∫•t cho 3 l·∫ßn s·∫•p&lt;/li&gt;
  &lt;li&gt;\((1-p)^2\) l√† x√°c su·∫•t cho 2 l·∫ßn ng·ª≠a&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Th·ª≠ nghi·ªám v·ªõi c√°c gi√° tr·ªã kh√°c nhau:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;V·ªõi \(p = 0.6\):
\(L(0.6 \mid \text{d·ªØ li·ªáu}) = \binom{5}{3} (0.6)^3 (0.4)^2 = 10 \times 0.216 \times 0.16 \approx 0.3456\)&lt;/p&gt;

&lt;p&gt;V·ªõi \(p = 0.5\):
\(L(0.5 \mid \text{d·ªØ li·ªáu}) = \binom{5}{3} (0.5)^3 (0.5)^2 = 10 \times 0.125 \times 0.25 \approx 0.3125\)&lt;/p&gt;

&lt;p&gt;Likelihood cao h∆°n v·ªõi \(p = 0.6\) cho th·∫•y gi√° tr·ªã n√†y ph√π h·ª£p h∆°n v·ªõi d·ªØ li·ªáu quan s√°t ƒë∆∞·ª£c so v·ªõi \(p = 0.5\).&lt;/p&gt;

&lt;h3 id=&quot;v√≠-d·ª•-t∆∞∆°ng-t√°c-tung-ƒë·ªìng-xu&quot;&gt;V√≠ D·ª• T∆∞∆°ng T√°c: Tung ƒê·ªìng Xu&lt;/h3&gt;

&lt;div id=&quot;coin-flip-example&quot; style=&quot;border: 1px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 8px;&quot;&gt;
    &lt;h4&gt;Th√≠ Nghi·ªám Tung ƒê·ªìng Xu&lt;/h4&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;label for=&quot;p-slider&quot;&gt;X√°c su·∫•t m·∫∑t s·∫•p (p): &lt;span id=&quot;p-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;p-slider&quot; min=&quot;0.01&quot; max=&quot;0.99&quot; step=&quot;0.01&quot; value=&quot;0.5&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;label for=&quot;heads-input&quot;&gt;S·ªë l·∫ßn s·∫•p: &lt;/label&gt;
        &lt;input type=&quot;number&quot; id=&quot;heads-input&quot; value=&quot;3&quot; min=&quot;0&quot; max=&quot;20&quot; style=&quot;width: 60px;&quot; /&gt;
        
        &lt;label for=&quot;tails-input&quot; style=&quot;margin-left: 20px;&quot;&gt;S·ªë l·∫ßn ng·ª≠a: &lt;/label&gt;
        &lt;input type=&quot;number&quot; id=&quot;tails-input&quot; value=&quot;2&quot; min=&quot;0&quot; max=&quot;20&quot; style=&quot;width: 60px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;canvas id=&quot;likelihood-plot&quot; width=&quot;600&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc;&quot;&gt;&lt;/canvas&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;likelihood-result&quot; style=&quot;background: #f8f9fa; padding: 10px; border-radius: 4px; margin: 10px 0;&quot;&gt;
        &lt;strong&gt;Likelihood hi·ªán t·∫°i:&lt;/strong&gt; &lt;span id=&quot;current-likelihood&quot;&gt;0.3125&lt;/span&gt;&lt;br /&gt;
        &lt;strong&gt;Log-likelihood:&lt;/strong&gt; &lt;span id=&quot;current-log-likelihood&quot;&gt;-1.16&lt;/span&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    const pSlider = document.getElementById(&apos;p-slider&apos;);
    const pValue = document.getElementById(&apos;p-value&apos;);
    const headsInput = document.getElementById(&apos;heads-input&apos;);
    const tailsInput = document.getElementById(&apos;tails-input&apos;);
    const canvas = document.getElementById(&apos;likelihood-plot&apos;);
    const ctx = canvas.getContext(&apos;2d&apos;);
    const likelihoodResult = document.getElementById(&apos;current-likelihood&apos;);
    const logLikelihoodResult = document.getElementById(&apos;current-log-likelihood&apos;);
    
    function binomialCoeff(n, k) {
        if (k &gt; n) return 0;
        if (k === 0 || k === n) return 1;
        
        let result = 1;
        for (let i = 0; i &lt; k; i++) {
            result = result * (n - i) / (i + 1);
        }
        return result;
    }
    
    function likelihood(p, heads, tails) {
        const n = heads + tails;
        const coeff = binomialCoeff(n, heads);
        return coeff * Math.pow(p, heads) * Math.pow(1 - p, tails);
    }
    
    function logLikelihood(p, heads, tails) {
        const n = heads + tails;
        const logCoeff = Math.log(binomialCoeff(n, heads));
        return logCoeff + heads * Math.log(p) + tails * Math.log(1 - p);
    }
    
    function plotLikelihood() {
        const heads = parseInt(headsInput.value);
        const tails = parseInt(tailsInput.value);
        const currentP = parseFloat(pSlider.value);
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        // V·∫Ω tr·ª•c
        ctx.strokeStyle = &apos;#333&apos;;
        ctx.lineWidth = 1;
        ctx.beginPath();
        ctx.moveTo(50, 250);
        ctx.lineTo(550, 250);
        ctx.moveTo(50, 250);
        ctx.lineTo(50, 50);
        ctx.stroke();
        
        // Nh√£n tr·ª•c
        ctx.fillStyle = &apos;#333&apos;;
        ctx.font = &apos;12px Arial&apos;;
        ctx.fillText(&apos;p (x√°c su·∫•t m·∫∑t s·∫•p)&apos;, 250, 280);
        ctx.save();
        ctx.translate(20, 150);
        ctx.rotate(-Math.PI/2);
        ctx.fillText(&apos;Likelihood&apos;, 0, 0);
        ctx.restore();
        
        // V·∫Ω ƒë∆∞·ªùng likelihood
        ctx.strokeStyle = &apos;#2196F3&apos;;
        ctx.lineWidth = 2;
        ctx.beginPath();
        
        let maxLikelihood = 0;
        const points = [];
        
        for (let i = 0; i &lt;= 500; i++) {
            const p = 0.01 + (i / 500) * 0.98;
            const l = likelihood(p, heads, tails);
            points.push({p: p, l: l});
            maxLikelihood = Math.max(maxLikelihood, l);
        }
        
        for (let i = 0; i &lt; points.length; i++) {
            const x = 50 + (points[i].p - 0.01) / 0.98 * 500;
            const y = 250 - (points[i].l / maxLikelihood) * 200;
            
            if (i === 0) {
                ctx.moveTo(x, y);
            } else {
                ctx.lineTo(x, y);
            }
        }
        ctx.stroke();
        
        // V·∫Ω ƒëi·ªÉm hi·ªán t·∫°i
        const currentLikelihood = likelihood(currentP, heads, tails);
        const currentX = 50 + (currentP - 0.01) / 0.98 * 500;
        const currentY = 250 - (currentLikelihood / maxLikelihood) * 200;
        
        ctx.fillStyle = &apos;#f44336&apos;;
        ctx.beginPath();
        ctx.arc(currentX, currentY, 5, 0, 2 * Math.PI);
        ctx.fill();
        
        // C·∫≠p nh·∫≠t k·∫øt qu·∫£
        likelihoodResult.textContent = currentLikelihood.toFixed(6);
        logLikelihoodResult.textContent = logLikelihood(currentP, heads, tails).toFixed(4);
        
        // V·∫Ω c√°c tick marks
        ctx.fillStyle = &apos;#666&apos;;
        ctx.font = &apos;10px Arial&apos;;
        for (let i = 0; i &lt;= 10; i++) {
            const p = i / 10;
            const x = 50 + (p - 0.01) / 0.98 * 500;
            ctx.fillText(p.toFixed(1), x - 10, 265);
        }
    }
    
    function updateDisplay() {
        pValue.textContent = pSlider.value;
        plotLikelihood();
    }
    
    pSlider.addEventListener(&apos;input&apos;, updateDisplay);
    headsInput.addEventListener(&apos;input&apos;, plotLikelihood);
    tailsInput.addEventListener(&apos;input&apos;, plotLikelihood);
    
    // Kh·ªüi t·∫°o
    updateDisplay();
});
&lt;/script&gt;

&lt;h3 id=&quot;maximum-likelihood-estimation-mle&quot;&gt;Maximum Likelihood Estimation (MLE)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;∆Ø·ªõc l∆∞·ª£ng h·ª£p l√Ω t·ªëi ƒëa&lt;/strong&gt; l√† ph∆∞∆°ng ph√°p t√¨m gi√° tr·ªã c·ªßa tham s·ªë \(\theta\) sao cho h√†m likelihood \(L(\theta \mid x)\) ƒë·∫°t gi√° tr·ªã l·ªõn nh·∫•t.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C√¥ng th·ª©c MLE:&lt;/strong&gt;
\(\hat{\theta}_{MLE} = \arg\max_{\theta} L(\theta \mid x)\)&lt;/p&gt;

&lt;p&gt;Th∆∞·ªùng th√¨ vi·ªác t·ªëi ƒëa h√≥a log-likelihood d·ªÖ d√†ng h∆°n:
\(\hat{\theta}_{MLE} = \arg\max_{\theta} \log L(\theta \mid x)\)&lt;/p&gt;

&lt;h3 id=&quot;v√≠-d·ª•-mle-ph√¢n-ph·ªëi-chu·∫©n&quot;&gt;V√≠ D·ª• MLE: Ph√¢n Ph·ªëi Chu·∫©n&lt;/h3&gt;

&lt;p&gt;Gi·∫£ s·ª≠ ch√∫ng ta c√≥ \(n\) quan s√°t ƒë·ªôc l·∫≠p \(x_1, x_2, \ldots, x_n\) t·ª´ ph√¢n ph·ªëi chu·∫©n \(N(\mu, \sigma^2)\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;H√†m likelihood:&lt;/strong&gt;
\(L(\mu, \sigma^2 \mid x_1, \ldots, x_n) = \prod_{i=1}^{n} \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x_i - \mu)^2}{2\sigma^2}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log-likelihood:&lt;/strong&gt;
\(\ell(\mu, \sigma^2) = -\frac{n}{2}\log(2\pi) - \frac{n}{2}\log(\sigma^2) - \frac{1}{2\sigma^2}\sum_{i=1}^{n}(x_i - \mu)^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;∆Ø·ªõc l∆∞·ª£ng MLE:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;ƒê·ªÉ t√¨m \(\hat{\mu}\), l·∫•y ƒë·∫°o h√†m theo \(\mu\) v√† ƒë·∫∑t b·∫±ng 0:
\(\frac{\partial \ell}{\partial \mu} = \frac{1}{\sigma^2}\sum_{i=1}^{n}(x_i - \mu) = 0\)&lt;/p&gt;

&lt;p&gt;Gi·∫£i ƒë∆∞·ª£c: \(\hat{\mu}_{MLE} = \frac{1}{n}\sum_{i=1}^{n} x_i = \bar{x}\)&lt;/p&gt;

&lt;p&gt;T∆∞∆°ng t·ª± cho \(\sigma^2\):
\(\hat{\sigma^2}_{MLE} = \frac{1}{n}\sum_{i=1}^{n}(x_i - \bar{x})^2\)&lt;/p&gt;

&lt;h3 id=&quot;v√≠-d·ª•-t∆∞∆°ng-t√°c-mle-cho-ph√¢n-ph·ªëi-chu·∫©n&quot;&gt;V√≠ D·ª• T∆∞∆°ng T√°c: MLE cho Ph√¢n Ph·ªëi Chu·∫©n&lt;/h3&gt;

&lt;div id=&quot;normal-mle-example&quot; style=&quot;border: 1px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 8px;&quot;&gt;
    &lt;h4&gt;MLE cho Ph√¢n Ph·ªëi Chu·∫©n&lt;/h4&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;button id=&quot;generate-data&quot; style=&quot;background: #4CAF50; color: white; padding: 8px 16px; border: none; border-radius: 4px; cursor: pointer;&quot;&gt;T·∫°o D·ªØ Li·ªáu M·ªõi&lt;/button&gt;
        &lt;span style=&quot;margin-left: 20px;&quot;&gt;S·ªë m·∫´u: &lt;/span&gt;
        &lt;input type=&quot;number&quot; id=&quot;sample-size&quot; value=&quot;50&quot; min=&quot;10&quot; max=&quot;200&quot; style=&quot;width: 60px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;label for=&quot;mu-guess&quot;&gt;∆Ø·ªõc l∆∞·ª£ng Œº: &lt;span id=&quot;mu-guess-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;mu-guess&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;label for=&quot;sigma-guess&quot;&gt;∆Ø·ªõc l∆∞·ª£ng œÉ: &lt;span id=&quot;sigma-guess-value&quot;&gt;1&lt;/span&gt;&lt;/label&gt;&lt;br /&gt;
        &lt;input type=&quot;range&quot; id=&quot;sigma-guess&quot; min=&quot;0.1&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1&quot; style=&quot;width: 300px;&quot; /&gt;
    &lt;/div&gt;
    
    &lt;div style=&quot;margin: 15px 0;&quot;&gt;
        &lt;canvas id=&quot;normal-plot&quot; width=&quot;600&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc;&quot;&gt;&lt;/canvas&gt;
    &lt;/div&gt;
    
    &lt;div id=&quot;mle-results&quot; style=&quot;background: #f8f9fa; padding: 10px; border-radius: 4px; margin: 10px 0;&quot;&gt;
        &lt;div&gt;&lt;strong&gt;D·ªØ li·ªáu th·ª±c:&lt;/strong&gt; Œº = &lt;span id=&quot;true-mu&quot;&gt;1.0&lt;/span&gt;, œÉ = &lt;span id=&quot;true-sigma&quot;&gt;1.5&lt;/span&gt;&lt;/div&gt;
        &lt;div&gt;&lt;strong&gt;MLE ∆∞·ªõc l∆∞·ª£ng:&lt;/strong&gt; ŒºÃÇ = &lt;span id=&quot;mle-mu&quot;&gt;0.95&lt;/span&gt;, œÉÃÇ = &lt;span id=&quot;mle-sigma&quot;&gt;1.48&lt;/span&gt;&lt;/div&gt;
        &lt;div&gt;&lt;strong&gt;∆Ø·ªõc l∆∞·ª£ng hi·ªán t·∫°i:&lt;/strong&gt; Œº = &lt;span id=&quot;current-mu&quot;&gt;0&lt;/span&gt;, œÉ = &lt;span id=&quot;current-sigma&quot;&gt;1&lt;/span&gt;&lt;/div&gt;
        &lt;div&gt;&lt;strong&gt;Log-likelihood hi·ªán t·∫°i:&lt;/strong&gt; &lt;span id=&quot;current-ll&quot;&gt;-75.2&lt;/span&gt;&lt;/div&gt;
        &lt;div&gt;&lt;strong&gt;Log-likelihood t·ªëi ƒëa:&lt;/strong&gt; &lt;span id=&quot;max-ll&quot;&gt;-72.1&lt;/span&gt;&lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;script&gt;
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    const generateBtn = document.getElementById(&apos;generate-data&apos;);
    const sampleSizeInput = document.getElementById(&apos;sample-size&apos;);
    const muGuess = document.getElementById(&apos;mu-guess&apos;);
    const sigmaGuess = document.getElementById(&apos;sigma-guess&apos;);
    const muGuessValue = document.getElementById(&apos;mu-guess-value&apos;);
    const sigmaGuessValue = document.getElementById(&apos;sigma-guess-value&apos;);
    const canvas = document.getElementById(&apos;normal-plot&apos;);
    const ctx = canvas.getContext(&apos;2d&apos;);
    
    let data = [];
    let trueMu = 1.0;
    let trueSigma = 1.5;
    
    function normalRandom(mu, sigma) {
        let u = 0, v = 0;
        while(u === 0) u = Math.random();
        while(v === 0) v = Math.random();
        return Math.sqrt(-2.0 * Math.log(u)) * Math.cos(2.0 * Math.PI * v) * sigma + mu;
    }
    
    function generateData() {
        const n = parseInt(sampleSizeInput.value);
        trueMu = (Math.random() - 0.5) * 4; // -2 to 2
        trueSigma = 0.5 + Math.random() * 2; // 0.5 to 2.5
        
        data = [];
        for (let i = 0; i &lt; n; i++) {
            data.push(normalRandom(trueMu, trueSigma));
        }
        
        // T√≠nh MLE
        const mleMu = data.reduce((sum, x) =&gt; sum + x, 0) / data.length;
        const mleSigma = Math.sqrt(data.reduce((sum, x) =&gt; sum + (x - mleMu) ** 2, 0) / data.length);
        
        document.getElementById(&apos;true-mu&apos;).textContent = trueMu.toFixed(2);
        document.getElementById(&apos;true-sigma&apos;).textContent = trueSigma.toFixed(2);
        document.getElementById(&apos;mle-mu&apos;).textContent = mleMu.toFixed(2);
        document.getElementById(&apos;mle-sigma&apos;).textContent = mleSigma.toFixed(2);
        
        plotData();
    }
    
    function logLikelihood(mu, sigma, data) {
        const n = data.length;
        const sumSquares = data.reduce((sum, x) =&gt; sum + (x - mu) ** 2, 0);
        return -n/2 * Math.log(2 * Math.PI) - n * Math.log(sigma) - sumSquares / (2 * sigma ** 2);
    }
    
    function normalPDF(x, mu, sigma) {
        return (1 / (sigma * Math.sqrt(2 * Math.PI))) * Math.exp(-0.5 * ((x - mu) / sigma) ** 2);
    }
    
    function plotData() {
        if (data.length === 0) return;
        
        ctx.clearRect(0, 0, canvas.width, canvas.height);
        
        const currentMu = parseFloat(muGuess.value);
        const currentSigma = parseFloat(sigmaGuess.value);
        
        // T√¨m ph·∫°m vi d·ªØ li·ªáu
        const minX = Math.min(...data) - 1;
        const maxX = Math.max(...data) + 1;
        const range = maxX - minX;
        
        // V·∫Ω histogram
        const bins = 20;
        const binWidth = range / bins;
        const binCounts = new Array(bins).fill(0);
        
        data.forEach(x =&gt; {
            const binIndex = Math.floor((x - minX) / binWidth);
            if (binIndex &gt;= 0 &amp;&amp; binIndex &lt; bins) {
                binCounts[binIndex]++;
            }
        });
        
        const maxCount = Math.max(...binCounts);
        
        ctx.fillStyle = &apos;rgba(33, 150, 243, 0.3)&apos;;
        for (let i = 0; i &lt; bins; i++) {
            const x = 50 + (i * binWidth / range) * 500;
            const height = (binCounts[i] / maxCount) * 200;
            const width = (binWidth / range) * 500;
            ctx.fillRect(x, 250 - height, width, height);
        }
        
        // V·∫Ω ƒë∆∞·ªùng ph√¢n ph·ªëi th·ª±c
        ctx.strokeStyle = &apos;#4CAF50&apos;;
        ctx.lineWidth = 2;
        ctx.beginPath();
        for (let i = 0; i &lt;= 500; i++) {
            const x = minX + (i / 500) * range;
            const y = normalPDF(x, trueMu, trueSigma);
            const plotX = 50 + (i / 500) * 500;
            const plotY = 250 - (y / (1 / (trueSigma * Math.sqrt(2 * Math.PI)))) * 200;
            
            if (i === 0) ctx.moveTo(plotX, plotY);
            else ctx.lineTo(plotX, plotY);
        }
        ctx.stroke();
        
        // V·∫Ω ƒë∆∞·ªùng ∆∞·ªõc l∆∞·ª£ng hi·ªán t·∫°i
        ctx.strokeStyle = &apos;#f44336&apos;;
        ctx.lineWidth = 2;
        ctx.setLineDash([5, 5]);
        ctx.beginPath();
        for (let i = 0; i &lt;= 500; i++) {
            const x = minX + (i / 500) * range;
            const y = normalPDF(x, currentMu, currentSigma);
            const plotX = 50 + (i / 500) * 500;
            const plotY = 250 - (y / (1 / (currentSigma * Math.sqrt(2 * Math.PI)))) * 200;
            
            if (i === 0) ctx.moveTo(plotX, plotY);
            else ctx.lineTo(plotX, plotY);
        }
        ctx.stroke();
        ctx.setLineDash([]);
        
        // V·∫Ω tr·ª•c
        ctx.strokeStyle = &apos;#333&apos;;
        ctx.lineWidth = 1;
        ctx.beginPath();
        ctx.moveTo(50, 250);
        ctx.lineTo(550, 250);
        ctx.stroke();
        
        // C·∫≠p nh·∫≠t k·∫øt qu·∫£
        const currentLL = logLikelihood(currentMu, currentSigma, data);
        const mleMu = data.reduce((sum, x) =&gt; sum + x, 0) / data.length;
        const mleSigma = Math.sqrt(data.reduce((sum, x) =&gt; sum + (x - mleMu) ** 2, 0) / data.length);
        const maxLL = logLikelihood(mleMu, mleSigma, data);
        
        document.getElementById(&apos;current-mu&apos;).textContent = currentMu.toFixed(2);
        document.getElementById(&apos;current-sigma&apos;).textContent = currentSigma.toFixed(2);
        document.getElementById(&apos;current-ll&apos;).textContent = currentLL.toFixed(2);
        document.getElementById(&apos;max-ll&apos;).textContent = maxLL.toFixed(2);
        
        // Th√™m ch√∫ th√≠ch
        ctx.fillStyle = &apos;#4CAF50&apos;;
        ctx.fillRect(450, 60, 15, 3);
        ctx.fillStyle = &apos;#333&apos;;
        ctx.font = &apos;12px Arial&apos;;
        ctx.fillText(&apos;Ph√¢n ph·ªëi th·ª±c&apos;, 470, 65);
        
        ctx.strokeStyle = &apos;#f44336&apos;;
        ctx.setLineDash([5, 5]);
        ctx.beginPath();
        ctx.moveTo(450, 80);
        ctx.lineTo(465, 80);
        ctx.stroke();
        ctx.setLineDash([]);
        ctx.fillText(&apos;∆Ø·ªõc l∆∞·ª£ng hi·ªán t·∫°i&apos;, 470, 85);
    }
    
    function updateDisplay() {
        muGuessValue.textContent = muGuess.value;
        sigmaGuessValue.textContent = sigmaGuess.value;
        plotData();
    }
    
    generateBtn.addEventListener(&apos;click&apos;, generateData);
    muGuess.addEventListener(&apos;input&apos;, updateDisplay);
    sigmaGuess.addEventListener(&apos;input&apos;, updateDisplay);
    sampleSizeInput.addEventListener(&apos;change&apos;, generateData);
    
    // Kh·ªüi t·∫°o
    generateData();
});
&lt;/script&gt;

&lt;h3 id=&quot;t√≠nh-ch·∫•t-c·ªßa-mle&quot;&gt;T√≠nh Ch·∫•t c·ªßa MLE&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh Nh·∫•t Qu√°n (Consistency)&lt;/strong&gt;: Khi k√≠ch th∆∞·ªõc m·∫´u tƒÉng, ∆∞·ªõc l∆∞·ª£ng MLE h·ªôi t·ª• v·ªÅ gi√° tr·ªã th·ª±c c·ªßa tham s·ªë.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh Ti·ªám C·∫≠n Chu·∫©n (Asymptotic Normality)&lt;/strong&gt;: V·ªõi m·∫´u l·ªõn, ph√¢n ph·ªëi c·ªßa ∆∞·ªõc l∆∞·ª£ng MLE x·∫•p x·ªâ ph√¢n ph·ªëi chu·∫©n.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh Hi·ªáu Qu·∫£ Ti·ªám C·∫≠n (Asymptotic Efficiency)&lt;/strong&gt;: MLE ƒë·∫°t ƒë∆∞·ª£c c·∫≠n Cram√©r-Rao, nghƒ©a l√† c√≥ ph∆∞∆°ng sai nh·ªè nh·∫•t trong c√°c ∆∞·ªõc l∆∞·ª£ng kh√¥ng thi√™n l·ªách.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;B·∫•t Bi·∫øn (Invariance)&lt;/strong&gt;: N·∫øu \(\hat{\theta}\) l√† MLE c·ªßa \(\theta\), th√¨ \(g(\hat{\theta})\) l√† MLE c·ªßa \(g(\theta)\) v·ªõi \(g\) l√† h√†m kh·∫£ ngh·ªãch.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;·ª©ng-d·ª•ng-c·ªßa-mle&quot;&gt;·ª®ng D·ª•ng c·ªßa MLE&lt;/h3&gt;

&lt;h4 id=&quot;1-∆∞·ªõc-l∆∞·ª£ng-tham-s·ªë&quot;&gt;1. ∆Ø·ªõc L∆∞·ª£ng Tham S·ªë&lt;/h4&gt;

&lt;p&gt;MLE ƒë∆∞·ª£c s·ª≠ d·ª•ng r·ªông r√£i ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng tham s·ªë trong c√°c m√¥ h√¨nh th·ªëng k√™:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ph√¢n ph·ªëi chu·∫©n: ∆∞·ªõc l∆∞·ª£ng trung b√¨nh v√† ph∆∞∆°ng sai&lt;/li&gt;
  &lt;li&gt;Ph√¢n ph·ªëi Poisson: ∆∞·ªõc l∆∞·ª£ng tham s·ªë Œª&lt;/li&gt;
  &lt;li&gt;H·ªìi quy tuy·∫øn t√≠nh: ∆∞·ªõc l∆∞·ª£ng h·ªá s·ªë h·ªìi quy&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;2-so-s√°nh-m√¥-h√¨nh&quot;&gt;2. So S√°nh M√¥ H√¨nh&lt;/h4&gt;

&lt;p&gt;Likelihood ƒë∆∞·ª£c d√πng ƒë·ªÉ so s√°nh c√°c m√¥ h√¨nh th·ªëng k√™ kh√°c nhau:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Likelihood Ratio Test&lt;/strong&gt;: So s√°nh hai m√¥ h√¨nh l·ªìng nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;AIC/BIC&lt;/strong&gt;: Ti√™u ch√≠ l·ª±a ch·ªçn m√¥ h√¨nh d·ª±a tr√™n likelihood&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;3-th·ªëng-k√™-bayes&quot;&gt;3. Th·ªëng K√™ Bayes&lt;/h4&gt;

&lt;p&gt;Trong th·ªëng k√™ Bayes, likelihood k·∫øt h·ª£p v·ªõi ph√¢n ph·ªëi ti√™n nghi·ªám (prior) ƒë·ªÉ t√≠nh ph√¢n ph·ªëi h·∫≠u nghi·ªám (posterior):&lt;/p&gt;

\[P(\theta \mid x) \propto L(\theta \mid x) \cdot P(\theta)\]

&lt;h3 id=&quot;k·∫øt-n·ªëi-v·ªõi-t·ªëi-∆∞u-h√≥a&quot;&gt;K·∫øt N·ªëi v·ªõi T·ªëi ∆Øu H√≥a&lt;/h3&gt;

&lt;p&gt;MLE t·∫°o ra m·ªôt b√†i to√°n t·ªëi ∆∞u h√≥a:&lt;/p&gt;

\[\max_{\theta} L(\theta \mid x) \quad \text{ho·∫∑c} \quad \max_{\theta} \log L(\theta \mid x)\]

&lt;p&gt;ƒêi·ªÅu n√†y th∆∞·ªùng d·∫´n ƒë·∫øn:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;T·ªëi ∆∞u h√≥a kh√¥ng r√†ng bu·ªôc&lt;/strong&gt;: Khi kh√¥ng c√≥ r√†ng bu·ªôc tr√™n tham s·ªë&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·ªëi ∆∞u h√≥a c√≥ r√†ng bu·ªôc&lt;/strong&gt;: Khi tham s·ªë ph·∫£i th·ªèa m√£n ƒëi·ªÅu ki·ªán nh·∫•t ƒë·ªãnh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;B√†i to√°n l·ªìi&lt;/strong&gt;: Nhi·ªÅu h√†m log-likelihood l√† l·ªìi, ƒë·∫£m b·∫£o nghi·ªám t·ªëi ∆∞u to√†n c·ª•c&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0;&quot;&gt;
&lt;strong&gt;üí° K·∫øt N·ªëi v·ªõi T·ªëi ∆Øu H√≥a L·ªìi:&lt;/strong&gt; Nhi·ªÅu b√†i to√°n MLE d·∫´n ƒë·∫øn t·ªëi ∆∞u h√≥a l·ªìi, ƒë·∫∑c bi·ªát trong h·ªç ph√¢n ph·ªëi m≈©. ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o r·∫±ng nghi·ªám t√¨m ƒë∆∞·ª£c l√† t·ªëi ∆∞u to√†n c·ª•c v√† c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a s·∫Ω h·ªôi t·ª• ƒë·∫øn nghi·ªám ƒë√∫ng.
&lt;/div&gt;

&lt;h3 id=&quot;v√≠-d·ª•-th·ª±c-t·∫ø-h·ªìi-quy-logistic&quot;&gt;V√≠ D·ª• Th·ª±c T·∫ø: H·ªìi Quy Logistic&lt;/h3&gt;

&lt;p&gt;Trong h·ªìi quy logistic, ch√∫ng ta m√¥ h√¨nh h√≥a x√°c su·∫•t c·ªßa bi·∫øn nh·ªã ph√¢n:&lt;/p&gt;

\[P(y = 1 \mid x) = \frac{1}{1 + e^{-(\beta_0 + \beta_1 x)}}\]

&lt;p&gt;&lt;strong&gt;Log-likelihood:&lt;/strong&gt;
\(\ell(\beta_0, \beta_1) = \sum_{i=1}^{n} \left[ y_i \log(p_i) + (1-y_i) \log(1-p_i) \right]\)&lt;/p&gt;

&lt;p&gt;ƒê√¢y l√† m·ªôt b√†i to√°n t·ªëi ∆∞u h√≥a l·ªìi, c√≥ th·ªÉ gi·∫£i b·∫±ng gradient descent ho·∫∑c Newton‚Äôs method.&lt;/p&gt;

&lt;h3 id=&quot;t√≥m-t·∫Øt&quot;&gt;T√≥m T·∫Øt&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Likelihood&lt;/strong&gt; ƒëo l∆∞·ªùng m·ª©c ƒë·ªô ph√π h·ª£p c·ªßa tham s·ªë v·ªõi d·ªØ li·ªáu quan s√°t&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;MLE&lt;/strong&gt; t√¨m tham s·ªë t·ªëi ƒëa h√≥a likelihood&lt;/li&gt;
  &lt;li&gt;MLE c√≥ nhi·ªÅu t√≠nh ch·∫•t th·ªëng k√™ t·ªët: nh·∫•t qu√°n, hi·ªáu qu·∫£, ti·ªám c·∫≠n chu·∫©n&lt;/li&gt;
  &lt;li&gt;MLE t·∫°o ra c√°c b√†i to√°n t·ªëi ∆∞u h√≥a, nhi·ªÅu trong s·ªë ƒë√≥ l√† l·ªìi&lt;/li&gt;
  &lt;li&gt;·ª®ng d·ª•ng r·ªông r√£i trong th·ªëng k√™, h·ªçc m√°y v√† khoa h·ªçc d·ªØ li·ªáu&lt;/li&gt;
&lt;/ul&gt;

&lt;div style=&quot;background: #d4edda; padding: 15px; border-left: 4px solid #28a745; margin: 20px 0;&quot;&gt;
&lt;strong&gt;üéØ ƒêi·ªÉm Quan Tr·ªçng:&lt;/strong&gt; MLE l√† c·∫ßu n·ªëi quan tr·ªçng gi·ªØa th·ªëng k√™ v√† t·ªëi ∆∞u h√≥a. Hi·ªÉu r√µ MLE gi√∫p b·∫°n n·∫Øm v·ªØng c√°ch c√°c m√¥ h√¨nh th·ªëng k√™ ƒë∆∞·ª£c ∆∞·ªõc l∆∞·ª£ng th√¥ng qua c√°c ph∆∞∆°ng ph√°p t·ªëi ∆∞u h√≥a, ƒë·∫∑c bi·ªát l√† t·ªëi ∆∞u h√≥a l·ªìi.
&lt;/div&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04-02 C√°c Ph√¢n Ph·ªëi X√°c Su·∫•t Th√¥ng D·ª•ng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_02_Common_Probability_Distributions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_04_02_Common_Probability_Distributions</id>
   <content type="html">&lt;h2 id=&quot;c√°c-ph√¢n-ph·ªëi-x√°c-su·∫•t-th√¥ng-d·ª•ng&quot;&gt;C√°c Ph√¢n Ph·ªëi X√°c Su·∫•t Th√¥ng D·ª•ng&lt;/h2&gt;

&lt;p&gt;Hi·ªÉu c√°c ph√¢n ph·ªëi x√°c su·∫•t ch√≠nh l√† ƒëi·ªÅu thi·∫øt y·∫øu cho c√°c b√†i to√°n t·ªëi ∆∞u h√≥a trong h·ªçc m√°y v√† th·ªëng k√™. C√°c ph√¢n ph·ªëi n√†y th∆∞·ªùng xu·∫•t hi·ªán nh∆∞ gi·∫£ thuy·∫øt trong m√¥ h√¨nh, prior trong ph∆∞∆°ng ph√°p Bayes, v√† m√¥ h√¨nh l·ªói trong h·ªìi quy.&lt;/p&gt;

&lt;h3 id=&quot;1-ph√¢n-ph·ªëi-r·ªùi-r·∫°c&quot;&gt;1. Ph√¢n Ph·ªëi R·ªùi R·∫°c&lt;/h3&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-bernoulli&quot;&gt;Ph√¢n Ph·ªëi Bernoulli&lt;/h4&gt;

&lt;p&gt;M√¥ h√¨nh m·ªôt th√≠ nghi·ªám ƒë∆°n v·ªõi hai k·∫øt qu·∫£ (th√†nh c√¥ng/th·∫•t b·∫°i).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(p \in [0,1]\) (x√°c su·∫•t th√†nh c√¥ng)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = p^k (1-p)^{1-k}\) v·ªõi \(k \in \{0,1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = p\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = p(1-p)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;·ª®ng d·ª•ng&lt;/strong&gt;: Ph√¢n lo·∫°i nh·ªã ph√¢n, tung ƒë·ªìng xu, ki·ªÉm ƒë·ªãnh A/B&lt;/p&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-nh·ªã-th·ª©c&quot;&gt;Ph√¢n Ph·ªëi Nh·ªã Th·ª©c&lt;/h4&gt;

&lt;p&gt;M√¥ h√¨nh s·ªë l·∫ßn th√†nh c√¥ng trong $n$ th√≠ nghi·ªám Bernoulli ƒë·ªôc l·∫≠p.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(n \in \mathbb{N}\) (s·ªë th√≠ nghi·ªám), \(p \in [0,1]\) (x√°c su·∫•t th√†nh c√¥ng)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\) v·ªõi \(k = 0,1,\ldots,n\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = np\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = np(1-p)\)&lt;/p&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-poisson&quot;&gt;Ph√¢n Ph·ªëi Poisson&lt;/h4&gt;

&lt;p&gt;M√¥ h√¨nh s·ªë s·ª± ki·ªán trong m·ªôt kho·∫£ng th·ªùi gian c·ªë ƒë·ªãnh khi c√°c s·ª± ki·ªán x·∫£y ra ƒë·ªôc l·∫≠p v·ªõi t·ªëc ƒë·ªô kh√¥ng ƒë·ªïi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (tham s·ªë t·ªëc ƒë·ªô)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\) v·ªõi \(k = 0,1,2,\ldots\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;·ª®ng d·ª•ng&lt;/strong&gt;: D·ªØ li·ªáu ƒë·∫øm, s·ª± ki·ªán hi·∫øm, l√Ω thuy·∫øt h√†ng ƒë·ª£i&lt;/p&gt;

&lt;div id=&quot;discrete-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Ph√¢n Ph·ªëi R·ªùi R·∫°c T∆∞∆°ng T√°c&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;discreteCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Tr·ª±c quan h√≥a:&lt;/strong&gt; H√†m kh·ªëi x√°c su·∫•t c·ªßa c√°c ph√¢n ph·ªëi r·ªùi r·∫°c.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Lo·∫°i Ph√¢n Ph·ªëi&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;bernoulli&quot; checked=&quot;&quot; /&gt; Bernoulli
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;binomial&quot; /&gt; Nh·ªã Th·ª©c
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;poisson&quot; /&gt; Poisson
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-params&quot;&gt;
                    &lt;div id=&quot;p-param&quot; style=&quot;margin-bottom: 15px;&quot;&gt;
                        &lt;label for=&quot;p-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;p: &lt;span id=&quot;p-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;p-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;n-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;n-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;n: &lt;span id=&quot;n-value&quot;&gt;10&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;n-slider&quot; min=&quot;5&quot; max=&quot;50&quot; step=&quot;1&quot; value=&quot;10&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;lambda-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œª: &lt;span id=&quot;lambda-value&quot;&gt;3.0&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;lambda-slider&quot; min=&quot;0.5&quot; max=&quot;10&quot; step=&quot;0.5&quot; value=&quot;3.0&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Th·ªëng K√™:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;K·ª≥ v·ªçng: &lt;span id=&quot;discrete-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Ph∆∞∆°ng sai: &lt;span id=&quot;discrete-variance&quot;&gt;0.250&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Mode: &lt;span id=&quot;discrete-mode&quot;&gt;0 ho·∫∑c 1&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-ph√¢n-ph·ªëi-li√™n-t·ª•c&quot;&gt;2. Ph√¢n Ph·ªëi Li√™n T·ª•c&lt;/h3&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-ƒë·ªÅu&quot;&gt;Ph√¢n Ph·ªëi ƒê·ªÅu&lt;/h4&gt;

&lt;p&gt;T·∫•t c·∫£ c√°c gi√° tr·ªã trong m·ªôt kho·∫£ng ƒë·ªÅu c√≥ kh·∫£ nƒÉng x·∫£y ra nh∆∞ nhau.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(a, b \in \mathbb{R}\) v·ªõi \(a &amp;lt; b\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{b-a}\) v·ªõi \(x \in [a,b]\), 0 n·∫øu ng∆∞·ª£c l·∫°i&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{a+b}{2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{(b-a)^2}{12}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;·ª®ng d·ª•ng&lt;/strong&gt;: L·∫•y m·∫´u ng·∫´u nhi√™n, kh·ªüi t·∫°o trong thu·∫≠t to√°n&lt;/p&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-chu·∫©n-gaussian&quot;&gt;Ph√¢n Ph·ªëi Chu·∫©n (Gaussian)&lt;/h4&gt;

&lt;p&gt;Ph√¢n ph·ªëi quan tr·ªçng nh·∫•t trong th·ªëng k√™ v√† t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(\mu \in \mathbb{R}\) (k·ª≥ v·ªçng), \(\sigma^2 &amp;gt; 0\) (ph∆∞∆°ng sai)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = \mu\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = \sigma^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh ch·∫•t&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ƒê·ªëi x·ª©ng quanh \(\mu\)&lt;/li&gt;
  &lt;li&gt;Quy t·∫Øc 68-95-99.7&lt;/li&gt;
  &lt;li&gt;ƒê·ªãnh l√Ω gi·ªõi h·∫°n trung t√¢m&lt;/li&gt;
  &lt;li&gt;Entropy t·ªëi ƒëa v·ªõi k·ª≥ v·ªçng v√† ph∆∞∆°ng sai cho tr∆∞·ªõc&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-m≈©&quot;&gt;Ph√¢n Ph·ªëi M≈©&lt;/h4&gt;

&lt;p&gt;M√¥ h√¨nh th·ªùi gian ch·ªù gi·ªØa c√°c s·ª± ki·ªán trong qu√° tr√¨nh Poisson.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (tham s·ªë t·ªëc ƒë·ªô)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \lambda e^{-\lambda x}\) v·ªõi \(x \geq 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{1}{\lambda}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{1}{\lambda^2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh ch·∫•t&lt;/strong&gt;: T√≠nh ch·∫•t kh√¥ng nh·ªõ&lt;/p&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-beta&quot;&gt;Ph√¢n Ph·ªëi Beta&lt;/h4&gt;

&lt;p&gt;Ph√¢n ph·ªëi linh ho·∫°t tr√™n \([0,1]\), th∆∞·ªùng d√πng ƒë·ªÉ m√¥ h√¨nh h√≥a x√°c su·∫•t.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(\alpha, \beta &amp;gt; 0\) (tham s·ªë h√¨nh d·∫°ng)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}\) v·ªõi \(x \in [0,1]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;K·ª≥ v·ªçng&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{\alpha}{\alpha+\beta}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng sai&lt;/strong&gt;: \(\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)&lt;/p&gt;

&lt;div id=&quot;continuous-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Ph√¢n Ph·ªëi Li√™n T·ª•c T∆∞∆°ng T√°c&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;continuousCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Tr·ª±c quan h√≥a:&lt;/strong&gt; H√†m m·∫≠t ƒë·ªô x√°c su·∫•t c·ªßa c√°c ph√¢n ph·ªëi li√™n t·ª•c.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Lo·∫°i Ph√¢n Ph·ªëi&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;uniform&quot; checked=&quot;&quot; /&gt; ƒê·ªÅu
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;normal&quot; /&gt; Chu·∫©n
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;exponential&quot; /&gt; M≈©
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;beta&quot; /&gt; Beta
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-params&quot;&gt;
                    &lt;div id=&quot;uniform-params&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;a: &lt;span id=&quot;a-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;a-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;b: &lt;span id=&quot;b-value&quot;&gt;1&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;0.5&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;1&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;normal-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº: &lt;span id=&quot;mu-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;mu-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;sigma-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ: &lt;span id=&quot;sigma-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;sigma-slider&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;exponential-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;exp-lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œª: &lt;span id=&quot;exp-lambda-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;exp-lambda-slider&quot; min=&quot;0.2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;beta-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;alpha-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œ±: &lt;span id=&quot;alpha-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;alpha-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;beta-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œ≤: &lt;span id=&quot;beta-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;beta-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Th·ªëng K√™:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;K·ª≥ v·ªçng: &lt;span id=&quot;continuous-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Ph∆∞∆°ng sai: &lt;span id=&quot;continuous-variance&quot;&gt;0.083&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Mi·ªÅn x√°c ƒë·ªãnh: &lt;span id=&quot;continuous-support&quot;&gt;[0, 1]&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;3-ph√¢n-ph·ªëi-ƒëa-bi·∫øn&quot;&gt;3. Ph√¢n Ph·ªëi ƒêa Bi·∫øn&lt;/h3&gt;

&lt;h4 id=&quot;ph√¢n-ph·ªëi-chu·∫©n-ƒëa-bi·∫øn&quot;&gt;Ph√¢n Ph·ªëi Chu·∫©n ƒêa Bi·∫øn&lt;/h4&gt;

&lt;p&gt;M·ªü r·ªông c·ªßa ph√¢n ph·ªëi chu·∫©n cho nhi·ªÅu chi·ªÅu.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Tham s·ªë&lt;/strong&gt;: \(\boldsymbol{\mu} \in \mathbb{R}^d\) (vector k·ª≥ v·ªçng), \(\boldsymbol{\Sigma} \in \mathbb{R}^{d \times d}\) (ma tr·∫≠n hi·ªáp ph∆∞∆°ng sai, x√°c ƒë·ªãnh d∆∞∆°ng)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;PDF&lt;/strong&gt;: $$f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}&lt;/td&gt;
      &lt;td&gt;\boldsymbol{\Sigma}&lt;/td&gt;
      &lt;td&gt;^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh ch·∫•t&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Ph√¢n ph·ªëi bi√™n l√† chu·∫©n&lt;/li&gt;
  &lt;li&gt;T·ªï h·ª£p tuy·∫øn t√≠nh l√† chu·∫©n&lt;/li&gt;
  &lt;li&gt;Ph√¢n ph·ªëi c√≥ ƒëi·ªÅu ki·ªán l√† chu·∫©n&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;multivariate-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Ph√¢n Ph·ªëi Chu·∫©n ƒêa Bi·∫øn&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;multivariateCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Tr·ª±c Quan 2D:&lt;/strong&gt; ƒê·ªì th·ªã ƒë∆∞·ªùng ƒë·ªìng m·ª©c c·ªßa ph√¢n ph·ªëi chu·∫©n hai bi·∫øn. C√°c m·∫´u hi·ªÉn th·ªã d∆∞·ªõi d·∫°ng ch·∫•m.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Tham S·ªë&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº‚ÇÅ: &lt;span id=&quot;mu1-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu1-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº‚ÇÇ: &lt;span id=&quot;mu2-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu2-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ‚ÇÅ: &lt;span id=&quot;sigma1-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma1-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ‚ÇÇ: &lt;span id=&quot;sigma2-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma2-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;rho-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÅ (t∆∞∆°ng quan): &lt;span id=&quot;rho-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;rho-slider&quot; min=&quot;-0.9&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-samples&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;T·∫°o M·∫´u&lt;/button&gt;
                
                &lt;div id=&quot;multivariate-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Ma Tr·∫≠n Hi·ªáp Ph∆∞∆°ng Sai:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÅ‚ÇÅ: &lt;span id=&quot;cov11&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÅ‚ÇÇ: &lt;span id=&quot;cov12&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÇ‚ÇÇ: &lt;span id=&quot;cov22&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Det(Œ£): &lt;span id=&quot;det-cov&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;4-·ª©ng-d·ª•ng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;4. ·ª®ng D·ª•ng trong T·ªëi ∆Øu H√≥a&lt;/h3&gt;

&lt;h4 id=&quot;∆∞·ªõc-l∆∞·ª£ng-h·ª£p-l√Ω-t·ªëi-ƒëa&quot;&gt;∆Ø·ªõc L∆∞·ª£ng H·ª£p L√Ω T·ªëi ƒêa&lt;/h4&gt;
&lt;p&gt;Nhi·ªÅu b√†i to√°n t·ªëi ∆∞u h√≥a li√™n quan ƒë·∫øn vi·ªác t√¨m tham s·ªë ƒë·ªÉ t·ªëi ƒëa h√≥a likelihood c·ªßa d·ªØ li·ªáu quan s√°t d∆∞·ªõi m·ªôt ph√¢n ph·ªëi c·ª• th·ªÉ:&lt;/p&gt;

\[\hat{\theta} = \arg\max_\theta \prod_{i=1}^n f(x_i; \theta)\]

&lt;h4 id=&quot;t·ªëi-∆∞u-h√≥a-bayes&quot;&gt;T·ªëi ∆Øu H√≥a Bayes&lt;/h4&gt;
&lt;p&gt;Ph√¢n ph·ªëi prior m√£ h√≥a ni·ªÅm tin v·ªÅ tham s·ªë tr∆∞·ªõc khi th·∫•y d·ªØ li·ªáu:&lt;/p&gt;

\[p(\theta|d·ªØ\ li·ªáu) \propto p(d·ªØ\ li·ªáu|\theta) \cdot p(\theta)\]

&lt;h4 id=&quot;regularization&quot;&gt;Regularization&lt;/h4&gt;
&lt;p&gt;Ph√¢n ph·ªëi c√≥ th·ªÉ ƒë∆∞·ª£c s·ª≠ d·ª•ng nh∆∞ prior ƒë·ªÉ regularize b√†i to√°n t·ªëi ∆∞u h√≥a:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;L2 regularization ‚Üî Prior Gaussian&lt;/li&gt;
  &lt;li&gt;L1 regularization ‚Üî Prior Laplace&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;t·ªëi-∆∞u-h√≥a-ng·∫´u-nhi√™n&quot;&gt;T·ªëi ∆Øu H√≥a Ng·∫´u Nhi√™n&lt;/h4&gt;
&lt;p&gt;Ph√¢n ph·ªëi m√¥ h√¨nh nhi·ªÖu v√† s·ª± b·∫•t ƒë·ªãnh trong h√†m m·ª•c ti√™u v√† r√†ng bu·ªôc.&lt;/p&gt;

&lt;h3 id=&quot;nh·ªØng-hi·ªÉu-bi·∫øt-quan-tr·ªçng-cho-t·ªëi-∆∞u-h√≥a&quot;&gt;Nh·ªØng Hi·ªÉu Bi·∫øt Quan Tr·ªçng cho T·ªëi ∆Øu H√≥a&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;L·ª±a Ch·ªçn M√¥ H√¨nh&lt;/strong&gt;: Ch·ªçn ph√¢n ph·ªëi ph√π h·ª£p v·ªõi ƒë·∫∑c ƒëi·ªÉm d·ªØ li·ªáu c·ªßa b·∫°n&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;∆Ø·ªõc L∆∞·ª£ng Tham S·ªë&lt;/strong&gt;: S·ª≠ d·ª•ng MLE ho·∫∑c ph∆∞∆°ng ph√°p Bayes ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng tham s·ªë ph√¢n ph·ªëi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ƒê·ªãnh L∆∞·ª£ng S·ª± B·∫•t ƒê·ªãnh&lt;/strong&gt;: Ph√¢n ph·ªëi cung c·∫•p c√°ch t·ª± nhi√™n ƒë·ªÉ ƒë·ªãnh l∆∞·ª£ng s·ª± b·∫•t ƒë·ªãnh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Ph√¢n ph·ªëi prior c√≥ th·ªÉ ngƒÉn overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hi·ªáu Qu·∫£ T√≠nh To√°n&lt;/strong&gt;: M·ªôt s·ªë ph√¢n ph·ªëi c√≥ nghi·ªám d·∫°ng ƒë√≥ng cho c√°c ph√©p to√°n th√¥ng d·ª•ng&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hi·ªÉu c√°c ph√¢n ph·ªëi n√†y v√† t√≠nh ch·∫•t c·ªßa ch√∫ng l√† quan tr·ªçng ƒë·ªÉ x√¢y d·ª±ng v√† gi·∫£i quy·∫øt c√°c b√†i to√°n t·ªëi ∆∞u h√≥a trong h·ªçc m√°y, th·ªëng k√™ v√† c√°c ·ª©ng d·ª•ng k·ªπ thu·∫≠t.&lt;/p&gt;

&lt;script&gt;
// Discrete Distributions Demo
class DiscreteDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;discreteCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;bernoulli&apos;;
        this.params = { p: 0.5, n: 10, lambda: 3.0 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;discrete-dist&quot;]&apos;);
        const pSlider = document.getElementById(&apos;p-slider&apos;);
        const nSlider = document.getElementById(&apos;n-slider&apos;);
        const lambdaSlider = document.getElementById(&apos;lambda-slider&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        pSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.p = parseFloat(e.target.value);
            document.getElementById(&apos;p-value&apos;).textContent = this.params.p.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        nSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.n = parseInt(e.target.value);
            document.getElementById(&apos;n-value&apos;).textContent = this.params.n;
            this.updateStats();
            this.draw();
        });
        
        lambdaSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.lambda = parseFloat(e.target.value);
            document.getElementById(&apos;lambda-value&apos;).textContent = this.params.lambda.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;p-param&apos;).style.display = 
            (this.distType === &apos;bernoulli&apos; || this.distType === &apos;binomial&apos;) ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;n-param&apos;).style.display = 
            this.distType === &apos;binomial&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;lambda-param&apos;).style.display = 
            this.distType === &apos;poisson&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, mode;
        
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                mean = this.params.p;
                variance = this.params.p * (1 - this.params.p);
                mode = this.params.p &gt; 0.5 ? &apos;1&apos; : (this.params.p &lt; 0.5 ? &apos;0&apos; : &apos;0 ho·∫∑c 1&apos;);
                break;
            case &apos;binomial&apos;:
                mean = this.params.n * this.params.p;
                variance = this.params.n * this.params.p * (1 - this.params.p);
                mode = Math.floor((this.params.n + 1) * this.params.p).toString();
                break;
            case &apos;poisson&apos;:
                mean = this.params.lambda;
                variance = this.params.lambda;
                mode = Math.floor(this.params.lambda).toString();
                break;
        }
        
        document.getElementById(&apos;discrete-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;discrete-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;discrete-mode&apos;).textContent = mode;
    }
    
    factorial(n) {
        if (n &lt;= 1) return 1;
        return n * this.factorial(n - 1);
    }
    
    binomialCoeff(n, k) {
        if (k &gt; n) return 0;
        return this.factorial(n) / (this.factorial(k) * this.factorial(n - k));
    }
    
    getProbability(k) {
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                return k === 0 ? (1 - this.params.p) : (k === 1 ? this.params.p : 0);
            case &apos;binomial&apos;:
                if (k &lt; 0 || k &gt; this.params.n) return 0;
                return this.binomialCoeff(this.params.n, k) * 
                       Math.pow(this.params.p, k) * 
                       Math.pow(1 - this.params.p, this.params.n - k);
            case &apos;poisson&apos;:
                if (k &lt; 0) return 0;
                return Math.pow(this.params.lambda, k) * Math.exp(-this.params.lambda) / this.factorial(k);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Determine range
        let maxK;
        switch(this.distType) {
            case &apos;bernoulli&apos;: maxK = 1; break;
            case &apos;binomial&apos;: maxK = this.params.n; break;
            case &apos;poisson&apos;: maxK = Math.min(20, this.params.lambda + 3 * Math.sqrt(this.params.lambda)); break;
        }
        
        // Find max probability for scaling
        let maxProb = 0;
        for (let k = 0; k &lt;= maxK; k++) {
            maxProb = Math.max(maxProb, this.getProbability(k));
        }
        
        // Draw bars
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        const barWidth = plotWidth / (maxK + 2);
        
        for (let k = 0; k &lt;= maxK; k++) {
            const prob = this.getProbability(k);
            const x = marginX + (k + 0.5) * barWidth;
            const height = (prob / maxProb) * plotHeight * 0.8;
            const y = this.height - marginY - height;
            
            this.ctx.fillRect(x - barWidth * 0.3, y, barWidth * 0.6, height);
            
            // Label
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(k.toString(), x, this.height - marginY + 15);
            this.ctx.fillText(prob.toFixed(3), x, y - 5);
            this.ctx.fillStyle = &apos;#2196f3&apos;;
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;k&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;P(X = k)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Continuous Distributions Demo
class ContinuousDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;continuousCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;uniform&apos;;
        this.params = { a: 0, b: 1, mu: 0, sigma: 1, lambda: 1, alpha: 2, beta: 2 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;continuous-dist&quot;]&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        // Setup all sliders
        const sliders = [&apos;a&apos;, &apos;b&apos;, &apos;mu&apos;, &apos;sigma&apos;, &apos;exp-lambda&apos;, &apos;alpha&apos;, &apos;beta&apos;];
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            if (element) {
                element.addEventListener(&apos;input&apos;, (e) =&gt; {
                    const value = parseFloat(e.target.value);
                    const param = slider === &apos;exp-lambda&apos; ? &apos;lambda&apos; : slider;
                    this.params[param] = value;
                    
                    const valueSpan = document.getElementById(slider + &apos;-value&apos;);
                    if (valueSpan) {
                        valueSpan.textContent = value.toFixed(1);
                    }
                    
                    this.updateStats();
                    this.draw();
                });
            }
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;uniform-params&apos;).style.display = 
            this.distType === &apos;uniform&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;normal-params&apos;).style.display = 
            this.distType === &apos;normal&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;exponential-params&apos;).style.display = 
            this.distType === &apos;exponential&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;beta-params&apos;).style.display = 
            this.distType === &apos;beta&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, support;
        
        switch(this.distType) {
            case &apos;uniform&apos;:
                mean = (this.params.a + this.params.b) / 2;
                variance = Math.pow(this.params.b - this.params.a, 2) / 12;
                support = `[${this.params.a}, ${this.params.b}]`;
                break;
            case &apos;normal&apos;:
                mean = this.params.mu;
                variance = this.params.sigma * this.params.sigma;
                support = &apos;(-‚àû, ‚àû)&apos;;
                break;
            case &apos;exponential&apos;:
                mean = 1 / this.params.lambda;
                variance = 1 / (this.params.lambda * this.params.lambda);
                support = &apos;[0, ‚àû)&apos;;
                break;
            case &apos;beta&apos;:
                mean = this.params.alpha / (this.params.alpha + this.params.beta);
                variance = (this.params.alpha * this.params.beta) / 
                          (Math.pow(this.params.alpha + this.params.beta, 2) * 
                           (this.params.alpha + this.params.beta + 1));
                support = &apos;[0, 1]&apos;;
                break;
        }
        
        document.getElementById(&apos;continuous-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;continuous-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;continuous-support&apos;).textContent = support;
    }
    
    gamma(z) {
        // Stirling&apos;s approximation for gamma function
        if (z &lt; 0.5) return Math.PI / (Math.sin(Math.PI * z) * this.gamma(1 - z));
        z -= 1;
        let x = 0.99999999999980993;
        const p = [676.5203681218851, -1259.1392167224028, 771.32342877765313,
                  -176.61502916214059, 12.507343278686905, -0.13857109526572012,
                  9.9843695780195716e-6, 1.5056327351493116e-7];
        for (let i = 0; i &lt; p.length; i++) {
            x += p[i] / (z + i + 1);
        }
        const t = z + p.length - 0.5;
        return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;
    }
    
    getPDF(x) {
        switch(this.distType) {
            case &apos;uniform&apos;:
                return (x &gt;= this.params.a &amp;&amp; x &lt;= this.params.b) ? 
                       1 / (this.params.b - this.params.a) : 0;
            case &apos;normal&apos;:
                return Math.exp(-0.5 * Math.pow((x - this.params.mu) / this.params.sigma, 2)) / 
                       (this.params.sigma * Math.sqrt(2 * Math.PI));
            case &apos;exponential&apos;:
                return x &gt;= 0 ? this.params.lambda * Math.exp(-this.params.lambda * x) : 0;
            case &apos;beta&apos;:
                if (x &lt; 0 || x &gt; 1) return 0;
                const B = this.gamma(this.params.alpha) * this.gamma(this.params.beta) / 
                         this.gamma(this.params.alpha + this.params.beta);
                return Math.pow(x, this.params.alpha - 1) * Math.pow(1 - x, this.params.beta - 1) / B;
        }
    }
    
    getRange() {
        switch(this.distType) {
            case &apos;uniform&apos;: return [this.params.a - 0.5, this.params.b + 0.5];
            case &apos;normal&apos;: return [this.params.mu - 4 * this.params.sigma, this.params.mu + 4 * this.params.sigma];
            case &apos;exponential&apos;: return [0, 5 / this.params.lambda];
            case &apos;beta&apos;: return [0, 1];
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        const [minX, maxX] = this.getRange();
        
        // Find max PDF for scaling
        let maxPDF = 0;
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            maxPDF = Math.max(maxPDF, this.getPDF(x));
        }
        
        // Draw PDF curve
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            const pdf = this.getPDF(x);
            const plotX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            const plotY = this.height - marginY - (pdf / maxPDF) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(plotX, plotY);
            } else {
                this.ctx.lineTo(plotX, plotY);
            }
        }
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;x&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;f(x)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Multivariate Normal Demo
class MultivariateDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;multivariateCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.params = { mu1: 0, mu2: 0, sigma1: 1, sigma2: 1, rho: 0 };
        this.samples = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const sliders = [&apos;mu1&apos;, &apos;mu2&apos;, &apos;sigma1&apos;, &apos;sigma2&apos;, &apos;rho&apos;];
        
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            element.addEventListener(&apos;input&apos;, (e) =&gt; {
                this.params[slider] = parseFloat(e.target.value);
                document.getElementById(slider + &apos;-value&apos;).textContent = this.params[slider].toFixed(1);
                this.updateStats();
                this.draw();
            });
        });
        
        document.getElementById(&apos;generate-samples&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.generateSamples();
            this.draw();
        });
        
        this.updateStats();
    }
    
    updateStats() {
        const cov11 = this.params.sigma1 * this.params.sigma1;
        const cov12 = this.params.rho * this.params.sigma1 * this.params.sigma2;
        const cov22 = this.params.sigma2 * this.params.sigma2;
        const det = cov11 * cov22 - cov12 * cov12;
        
        document.getElementById(&apos;cov11&apos;).textContent = cov11.toFixed(3);
        document.getElementById(&apos;cov12&apos;).textContent = cov12.toFixed(3);
        document.getElementById(&apos;cov22&apos;).textContent = cov22.toFixed(3);
        document.getElementById(&apos;det-cov&apos;).textContent = det.toFixed(3);
    }
    
    generateSamples() {
        this.samples = [];
        const n = 100;
        
        for (let i = 0; i &lt; n; i++) {
            // Box-Muller transform
            const u1 = Math.random();
            const u2 = Math.random();
            const z1 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            const z2 = Math.sqrt(-2 * Math.log(u1)) * Math.sin(2 * Math.PI * u2);
            
            // Transform to correlated normal
            const x1 = this.params.mu1 + this.params.sigma1 * z1;
            const x2 = this.params.mu2 + this.params.sigma2 * (this.params.rho * z1 + Math.sqrt(1 - this.params.rho * this.params.rho) * z2);
            
            this.samples.push([x1, x2]);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Draw contour ellipses
        const levels = [0.5, 1, 1.5, 2];
        const colors = [&apos;#ff9999&apos;, &apos;#ff6666&apos;, &apos;#ff3333&apos;, &apos;#ff0000&apos;];
        
        levels.forEach((level, idx) =&gt; {
            this.ctx.strokeStyle = colors[idx];
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            
            const a = level * this.params.sigma1;
            const b = level * this.params.sigma2;
            const angle = 0.5 * Math.atan2(2 * this.params.rho * this.params.sigma1 * this.params.sigma2,
                                          this.params.sigma1 * this.params.sigma1 - this.params.sigma2 * this.params.sigma2);
            
            for (let i = 0; i &lt;= 100; i++) {
                const t = 2 * Math.PI * i / 100;
                const x = a * Math.cos(t) * Math.cos(angle) - b * Math.sin(t) * Math.sin(angle) + this.params.mu1;
                const y = a * Math.cos(t) * Math.sin(angle) + b * Math.sin(t) * Math.cos(angle) + this.params.mu2;
                
                const plotX = marginX + (x + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (y + 4) / 8 * plotHeight;
                
                if (i === 0) {
                    this.ctx.moveTo(plotX, plotY);
                } else {
                    this.ctx.lineTo(plotX, plotY);
                }
            }
            this.ctx.stroke();
        });
        
        // Draw samples
        if (this.samples.length &gt; 0) {
            this.ctx.fillStyle = &apos;#2196f3&apos;;
            this.samples.forEach(([x1, x2]) =&gt; {
                const plotX = marginX + (x1 + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (x2 + 4) / 8 * plotHeight;
                
                if (plotX &gt;= marginX &amp;&amp; plotX &lt;= this.width - marginX &amp;&amp;
                    plotY &gt;= marginY &amp;&amp; plotY &lt;= this.height - marginY) {
                    this.ctx.beginPath();
                    this.ctx.arc(plotX, plotY, 2, 0, 2 * Math.PI);
                    this.ctx.fill();
                }
            });
        }
        
        // Draw mean point
        const meanX = marginX + (this.params.mu1 + 4) / 8 * plotWidth;
        const meanY = this.height - marginY - (this.params.mu2 + 4) / 8 * plotHeight;
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.beginPath();
        this.ctx.arc(meanX, meanY, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;X‚ÇÅ&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;X‚ÇÇ&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new DiscreteDistributionsDemo();
    new ContinuousDistributionsDemo();
    new MultivariateDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04-01 L√Ω Thuy·∫øt X√°c Su·∫•t C∆° B·∫£n</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_04_01_Basic_Probability_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_04_01_Basic_Probability_Theory</id>
   <content type="html">&lt;h2 id=&quot;l√Ω-thuy·∫øt-x√°c-su·∫•t-c∆°-b·∫£n&quot;&gt;L√Ω Thuy·∫øt X√°c Su·∫•t C∆° B·∫£n&lt;/h2&gt;

&lt;p&gt;L√Ω thuy·∫øt x√°c su·∫•t cung c·∫•p khung to√°n h·ªçc ƒë·ªÉ l√Ω lu·∫≠n v·ªÅ s·ª± b·∫•t ƒë·ªãnh, ƒëi·ªÅu n√†y l√† n·ªÅn t·∫£ng cho nhi·ªÅu b√†i to√°n t·ªëi ∆∞u h√≥a trong h·ªçc m√°y v√† khoa h·ªçc d·ªØ li·ªáu.&lt;/p&gt;

&lt;h3 id=&quot;1-kh√¥ng-gian-m·∫´u-v√†-bi·∫øn-c·ªë&quot;&gt;1. Kh√¥ng Gian M·∫´u v√† Bi·∫øn C·ªë&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Kh√¥ng Gian M·∫´u (Œ©)&lt;/strong&gt;: T·∫≠p h·ª£p t·∫•t c·∫£ c√°c k·∫øt qu·∫£ c√≥ th·ªÉ c√≥ c·ªßa m·ªôt th√≠ nghi·ªám.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bi·∫øn C·ªë (A)&lt;/strong&gt;: M·ªôt t·∫≠p con c·ªßa kh√¥ng gian m·∫´u ƒë·∫°i di·ªán cho m·ªôt t·∫≠p h·ª£p c√°c k·∫øt qu·∫£.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Tung ƒë·ªìng xu: Œ© = {S, N}&lt;/li&gt;
  &lt;li&gt;Tung x√∫c x·∫Øc: Œ© = {1, 2, 3, 4, 5, 6}&lt;/li&gt;
  &lt;li&gt;Li√™n t·ª•c: Œ© = [0, 1] cho bi·∫øn ng·∫´u nhi√™n ƒë·ªÅu&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;sample-space-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Tr·ª±c Quan H√≥a Kh√¥ng Gian M·∫´u T∆∞∆°ng T√°c&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;sampleSpaceCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Tr·ª±c quan h√≥a:&lt;/strong&gt; Nh·∫•p ƒë·ªÉ t·∫°o m·∫´u ng·∫´u nhi√™n. C√°c m√†u kh√°c nhau ƒë·∫°i di·ªán cho c√°c bi·∫øn c·ªë kh√°c nhau.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Lo·∫°i Th√≠ Nghi·ªám&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;coin&quot; checked=&quot;&quot; /&gt; Tung ƒê·ªìng Xu
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;dice&quot; /&gt; Tung X√∫c X·∫Øc
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;uniform&quot; /&gt; ƒê·ªÅu [0,1]
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-sample&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;T·∫°o M·∫´u&lt;/button&gt;
                &lt;button id=&quot;clear-samples&quot; style=&quot;width: 100%; padding: 8px; background: #6c757d; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;X√≥a&lt;/button&gt;
                
                &lt;div id=&quot;sample-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Th·ªëng K√™:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;T·ªïng m·∫´u: &lt;span id=&quot;total-samples&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Bi·∫øn c·ªë A: &lt;span id=&quot;event-a-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Bi·∫øn c·ªë B: &lt;span id=&quot;event-b-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) ‚âà &lt;span id=&quot;prob-a&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) ‚âà &lt;span id=&quot;prob-b&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-ti√™n-ƒë·ªÅ-x√°c-su·∫•t-ti√™n-ƒë·ªÅ-kolmogorov&quot;&gt;2. Ti√™n ƒê·ªÅ X√°c Su·∫•t (Ti√™n ƒê·ªÅ Kolmogorov)&lt;/h3&gt;

&lt;p&gt;V·ªõi b·∫•t k·ª≥ ƒë·ªô ƒëo x√°c su·∫•t P n√†o, c√°c ti√™n ƒë·ªÅ sau ph·∫£i ƒë∆∞·ª£c th·ªèa m√£n:&lt;/p&gt;

&lt;h4 id=&quot;ti√™n-ƒë·ªÅ-1-t√≠nh-kh√¥ng-√¢m&quot;&gt;Ti√™n ƒê·ªÅ 1: T√≠nh Kh√¥ng √Çm&lt;/h4&gt;
&lt;p&gt;\(P(A) \geq 0 \text{ v·ªõi m·ªçi bi·∫øn c·ªë } A\)&lt;/p&gt;

&lt;h4 id=&quot;ti√™n-ƒë·ªÅ-2-chu·∫©n-h√≥a&quot;&gt;Ti√™n ƒê·ªÅ 2: Chu·∫©n H√≥a&lt;/h4&gt;
&lt;p&gt;\(P(\Omega) = 1\)&lt;/p&gt;

&lt;h4 id=&quot;ti√™n-ƒë·ªÅ-3-t√≠nh-c·ªông-ƒë·∫øm-ƒë∆∞·ª£c&quot;&gt;Ti√™n ƒê·ªÅ 3: T√≠nh C·ªông ƒê·∫øm ƒê∆∞·ª£c&lt;/h4&gt;
&lt;p&gt;V·ªõi c√°c bi·∫øn c·ªë xung kh·∫Øc \(A_1, A_2, \ldots\):
\(P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)\)&lt;/p&gt;

&lt;h3 id=&quot;3-t√≠nh-ch·∫•t-v√†-quy-t·∫Øc-c∆°-b·∫£n&quot;&gt;3. T√≠nh Ch·∫•t v√† Quy T·∫Øc C∆° B·∫£n&lt;/h3&gt;

&lt;h4 id=&quot;quy-t·∫Øc-ph·∫ßn-b√π&quot;&gt;Quy T·∫Øc Ph·∫ßn B√π&lt;/h4&gt;
&lt;p&gt;\(P(A^c) = 1 - P(A)\)&lt;/p&gt;

&lt;h4 id=&quot;quy-t·∫Øc-c·ªông&quot;&gt;Quy T·∫Øc C·ªông&lt;/h4&gt;
&lt;p&gt;V·ªõi hai bi·∫øn c·ªë A v√† B b·∫•t k·ª≥:
\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)&lt;/p&gt;

&lt;h4 id=&quot;quy-t·∫Øc-nh√¢n&quot;&gt;Quy T·∫Øc Nh√¢n&lt;/h4&gt;
&lt;p&gt;\(P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)\)&lt;/p&gt;

&lt;h3 id=&quot;4-x√°c-su·∫•t-c√≥-ƒëi·ªÅu-ki·ªán&quot;&gt;4. X√°c Su·∫•t C√≥ ƒêi·ªÅu Ki·ªán&lt;/h3&gt;

&lt;p&gt;X√°c su·∫•t c·ªßa bi·∫øn c·ªë A khi bi·∫øt r·∫±ng bi·∫øn c·ªë B ƒë√£ x·∫£y ra:&lt;/p&gt;

\[P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) &amp;gt; 0\]

&lt;p&gt;&lt;strong&gt;Di·ªÖn gi·∫£i&lt;/strong&gt;: X√°c su·∫•t c√≥ ƒëi·ªÅu ki·ªán c·∫≠p nh·∫≠t ni·ªÅm tin c·ªßa ch√∫ng ta v·ªÅ A khi c√≥ th√¥ng tin v·ªÅ B.&lt;/p&gt;

&lt;div id=&quot;conditional-prob-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Tr·ª±c Quan H√≥a X√°c Su·∫•t C√≥ ƒêi·ªÅu Ki·ªán&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;conditionalCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Bi·ªÉu ƒê·ªì Venn:&lt;/strong&gt; H√¨nh tr√≤n xanh l√† bi·∫øn c·ªë A, h√¨nh tr√≤n ƒë·ªè l√† bi·∫øn c·ªë B. Giao m√†u t√≠m th·ªÉ hi·ªán A ‚à© B.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;ƒêi·ªÅu Ch·ªânh X√°c Su·∫•t&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(A): &lt;span id=&quot;prob-a-value&quot;&gt;0.4&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-a-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.4&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(B): &lt;span id=&quot;prob-b-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-b-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;overlap-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Giao: &lt;span id=&quot;overlap-value&quot;&gt;0.2&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;overlap-slider&quot; min=&quot;0&quot; max=&quot;0.4&quot; step=&quot;0.05&quot; value=&quot;0.2&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;conditional-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;X√°c Su·∫•t:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) = &lt;span id=&quot;display-prob-a&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) = &lt;span id=&quot;display-prob-b&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ‚à© B) = &lt;span id=&quot;display-prob-ab&quot;&gt;0.200&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ‚à™ B) = &lt;span id=&quot;display-prob-union&quot;&gt;0.700&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;C√≥ ƒêi·ªÅu Ki·ªán:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A|B) = &lt;span id=&quot;display-prob-a-given-b&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B|A) = &lt;span id=&quot;display-prob-b-given-a&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;5-t√≠nh-ƒë·ªôc-l·∫≠p&quot;&gt;5. T√≠nh ƒê·ªôc L·∫≠p&lt;/h3&gt;

&lt;p&gt;Hai bi·∫øn c·ªë A v√† B &lt;strong&gt;ƒë·ªôc l·∫≠p&lt;/strong&gt; n·∫øu:
\(P(A \cap B) = P(A) \cdot P(B)\)&lt;/p&gt;

&lt;p&gt;T∆∞∆°ng ƒë∆∞∆°ng:
\(P(A|B) = P(A) \quad \text{v√†} \quad P(B|A) = P(B)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Di·ªÖn gi·∫£i&lt;/strong&gt;: Ki·∫øn th·ª©c v·ªÅ m·ªôt bi·∫øn c·ªë kh√¥ng thay ƒë·ªïi x√°c su·∫•t c·ªßa bi·∫øn c·ªë kia.&lt;/p&gt;

&lt;h3 id=&quot;6-bi·∫øn-ng·∫´u-nhi√™n&quot;&gt;6. Bi·∫øn Ng·∫´u Nhi√™n&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Bi·∫øn ng·∫´u nhi√™n&lt;/strong&gt; X l√† m·ªôt h√†m g√°n m·ªôt s·ªë th·ª±c cho m·ªói k·∫øt qu·∫£ trong kh√¥ng gian m·∫´u:
\(X: \Omega \rightarrow \mathbb{R}\)&lt;/p&gt;

&lt;h4 id=&quot;c√°c-lo·∫°i-bi·∫øn-ng·∫´u-nhi√™n&quot;&gt;C√°c Lo·∫°i Bi·∫øn Ng·∫´u Nhi√™n:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;R·ªùi r·∫°c&lt;/strong&gt;: Nh·∫≠n c√°c gi√° tr·ªã ƒë·∫øm ƒë∆∞·ª£c (v√≠ d·ª•: s·ªë l·∫ßn xu·∫•t hi·ªán m·∫∑t s·∫•p)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;H√†m Kh·ªëi X√°c Su·∫•t (PMF): \(P(X = x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Li√™n t·ª•c&lt;/strong&gt;: Nh·∫≠n c√°c gi√° tr·ªã kh√¥ng ƒë·∫øm ƒë∆∞·ª£c (v√≠ d·ª•: chi·ªÅu cao, c√¢n n·∫∑ng)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;H√†m M·∫≠t ƒê·ªô X√°c Su·∫•t (PDF): \(f_X(x)\)&lt;/li&gt;
  &lt;li&gt;
\[P(a \leq X \leq b) = \int_a^b f_X(x) dx\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-k·∫øt-n·ªëi-v·ªõi-t·ªëi-∆∞u-h√≥a&quot;&gt;7. K·∫øt N·ªëi v·ªõi T·ªëi ∆Øu H√≥a&lt;/h3&gt;

&lt;p&gt;L√Ω thuy·∫øt x√°c su·∫•t k·∫øt n·ªëi v·ªõi t·ªëi ∆∞u h√≥a theo nhi·ªÅu c√°ch:&lt;/p&gt;

&lt;h4 id=&quot;∆∞·ªõc-l∆∞·ª£ng-h·ª£p-l√Ω-t·ªëi-ƒëa&quot;&gt;∆Ø·ªõc L∆∞·ª£ng H·ª£p L√Ω T·ªëi ƒêa&lt;/h4&gt;
&lt;p&gt;T√¨m tham s·ªë Œ∏ ƒë·ªÉ t·ªëi ƒëa h√≥a likelihood:
\(\hat{\theta} = \arg\max_\theta P(\text{d·ªØ li·ªáu}|\theta)\)&lt;/p&gt;

&lt;h4 id=&quot;t·ªëi-∆∞u-h√≥a-gi√°-tr·ªã-k·ª≥-v·ªçng&quot;&gt;T·ªëi ∆Øu H√≥a Gi√° Tr·ªã K·ª≥ V·ªçng&lt;/h4&gt;
&lt;p&gt;T·ªëi thi·ªÉu h√≥a k·ª≥ v·ªçng loss:
\(\min_\theta \mathbb{E}[L(Y, f(X; \theta))]\)&lt;/p&gt;

&lt;h4 id=&quot;t·ªëi-∆∞u-h√≥a-bayes&quot;&gt;T·ªëi ∆Øu H√≥a Bayes&lt;/h4&gt;
&lt;p&gt;S·ª≠ d·ª•ng ph√¢n ph·ªëi x√°c su·∫•t ƒë·ªÉ m√¥ h√¨nh h√≥a s·ª± b·∫•t ƒë·ªãnh trong h√†m m·ª•c ti√™u v√† h∆∞·ªõng d·∫´n t√¨m ki·∫øm nghi·ªám t·ªëi ∆∞u.&lt;/p&gt;

&lt;div id=&quot;deep-learning-connection&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;V√≠ D·ª• X√°c Su·∫•t trong T·ªëi ∆Øu H√≥a&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;deep-learningCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;V√≠ D·ª• MLE:&lt;/strong&gt; T√¨m tham s·ªë Œº ƒë·ªÉ t·ªëi ƒëa h√≥a likelihood c·ªßa d·ªØ li·ªáu quan s√°t t·ª´ Normal(Œº, 1).
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Demo MLE&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;true-mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº Th·ª±c: &lt;span id=&quot;true-mu-value&quot;&gt;2.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;true-mu-slider&quot; min=&quot;-2&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;2.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sample-size-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;K√≠ch Th∆∞·ªõc M·∫´u: &lt;span id=&quot;sample-size-value&quot;&gt;20&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sample-size-slider&quot; min=&quot;5&quot; max=&quot;100&quot; step=&quot;5&quot; value=&quot;20&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-mle-data&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;T·∫°o D·ªØ Li·ªáu &amp;amp; T√¨m MLE&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;K·∫øt Qu·∫£:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Œº Th·ª±c: &lt;span id=&quot;display-true-mu&quot;&gt;2.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Trung b√¨nh m·∫´u: &lt;span id=&quot;sample-mean&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;∆Ø·ªõc l∆∞·ª£ng MLE: &lt;span id=&quot;mle-estimate&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Sai s·ªë: &lt;span id=&quot;mle-error&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;nh·ªØng-ƒëi·ªÉm-ch√≠nh&quot;&gt;Nh·ªØng ƒêi·ªÉm Ch√≠nh&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;N·ªÅn T·∫£ng&lt;/strong&gt;: Ti√™n ƒë·ªÅ x√°c su·∫•t cung c·∫•p n·ªÅn t·∫£ng to√°n h·ªçc ƒë·ªÉ l√Ω lu·∫≠n v·ªÅ s·ª± b·∫•t ƒë·ªãnh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;X√°c Su·∫•t C√≥ ƒêi·ªÅu Ki·ªán&lt;/strong&gt;: Thi·∫øt y·∫øu ƒë·ªÉ c·∫≠p nh·∫≠t ni·ªÅm tin v·ªõi th√¥ng tin m·ªõi&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T√≠nh ƒê·ªôc L·∫≠p&lt;/strong&gt;: ƒê∆°n gi·∫£n h√≥a t√≠nh to√°n v√† gi·∫£ thuy·∫øt m√¥ h√¨nh h√≥a&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bi·∫øn Ng·∫´u Nhi√™n&lt;/strong&gt;: C·∫ßu n·ªëi gi·ªØa x√°c su·∫•t tr·ª´u t∆∞·ª£ng v√† ·ª©ng d·ª•ng c·ª• th·ªÉ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K·∫øt N·ªëi T·ªëi ∆Øu H√≥a&lt;/strong&gt;: Nhi·ªÅu b√†i to√°n t·ªëi ∆∞u h√≥a ph√°t sinh t·ª´ m√¥ h√¨nh h√≥a x√°c su·∫•t&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Hi·ªÉu nh·ªØng kh√°i ni·ªám c∆° b·∫£n n√†y chu·∫©n b·ªã cho b·∫°n c√°c ch·ªß ƒë·ªÅ n√¢ng cao h∆°n nh∆∞ suy lu·∫≠n Bayes, ∆∞·ªõc l∆∞·ª£ng h·ª£p l√Ω t·ªëi ƒëa v√† t·ªëi ∆∞u h√≥a ng·∫´u nhi√™n - nh·ªØng y·∫øu t·ªë trung t√¢m c·ªßa h·ªçc m√°y v√† khoa h·ªçc d·ªØ li·ªáu hi·ªán ƒë·∫°i.&lt;/p&gt;

&lt;script&gt;
// Sample Space Visualization
class SampleSpaceDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;sampleSpaceCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.samples = [];
        this.experimentType = &apos;coin&apos;;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;experiment&quot;]&apos;);
        const generateBtn = document.getElementById(&apos;generate-sample&apos;);
        const clearBtn = document.getElementById(&apos;clear-samples&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.experimentType = e.target.value;
                this.samples = [];
                this.updateStats();
                this.draw();
            });
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
        clearBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.samples = [];
            this.updateStats();
            this.draw();
        });
        
        this.canvas.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
    }
    
    generateSample() {
        let sample;
        
        switch(this.experimentType) {
            case &apos;coin&apos;:
                sample = {
                    value: Math.random() &lt; 0.5 ? &apos;S&apos; : &apos;N&apos;,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: Math.random() &lt; 0.5, // Bi·∫øn c·ªë A: S·∫•p
                    eventB: Math.random() &lt; 0.3  // Bi·∫øn c·ªë B: May m·∫Øn
                };
                break;
            case &apos;dice&apos;:
                const diceValue = Math.floor(Math.random() * 6) + 1;
                sample = {
                    value: diceValue,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: diceValue &gt;= 4, // Bi·∫øn c·ªë A: 4, 5, ho·∫∑c 6
                    eventB: diceValue % 2 === 0 // Bi·∫øn c·ªë B: Ch·∫µn
                };
                break;
            case &apos;uniform&apos;:
                const uniformValue = Math.random();
                sample = {
                    value: uniformValue.toFixed(3),
                    x: uniformValue * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: uniformValue &gt; 0.5, // Bi·∫øn c·ªë A: &gt; 0.5
                    eventB: uniformValue &lt; 0.7  // Bi·∫øn c·ªë B: &lt; 0.7
                };
                break;
        }
        
        this.samples.push(sample);
        this.updateStats();
        this.draw();
    }
    
    updateStats() {
        const total = this.samples.length;
        const eventACount = this.samples.filter(s =&gt; s.eventA).length;
        const eventBCount = this.samples.filter(s =&gt; s.eventB).length;
        
        document.getElementById(&apos;total-samples&apos;).textContent = total;
        document.getElementById(&apos;event-a-count&apos;).textContent = eventACount;
        document.getElementById(&apos;event-b-count&apos;).textContent = eventBCount;
        document.getElementById(&apos;prob-a&apos;).textContent = total &gt; 0 ? (eventACount / total).toFixed(3) : &apos;0.000&apos;;
        document.getElementById(&apos;prob-b&apos;).textContent = total &gt; 0 ? (eventBCount / total).toFixed(3) : &apos;0.000&apos;;
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw background
        this.ctx.fillStyle = &apos;#f8f9fa&apos;;
        this.ctx.fillRect(0, 0, this.width, this.height);
        
        // Draw samples
        this.samples.forEach(sample =&gt; {
            // Determine color based on events
            let color = &apos;#666&apos;;
            if (sample.eventA &amp;&amp; sample.eventB) color = &apos;#9c27b0&apos;; // C·∫£ hai bi·∫øn c·ªë
            else if (sample.eventA) color = &apos;#2196f3&apos;; // Ch·ªâ bi·∫øn c·ªë A
            else if (sample.eventB) color = &apos;#f44336&apos;; // Ch·ªâ bi·∫øn c·ªë B
            
            this.ctx.fillStyle = color;
            this.ctx.beginPath();
            this.ctx.arc(sample.x, sample.y, 5, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw value
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(sample.value, sample.x, sample.y - 8);
        });
        
        // Draw legend
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;Ch√∫ th√≠ch:&apos;, 10, 20);
        
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 35, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Ch·ªâ bi·∫øn c·ªë A&apos;, 30, 38);
        
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 50, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Ch·ªâ bi·∫øn c·ªë B&apos;, 30, 53);
        
        this.ctx.fillStyle = &apos;#9c27b0&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 65, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;C·∫£ A v√† B&apos;, 30, 68);
    }
}

// Conditional Probability Visualization
class ConditionalProbDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;conditionalCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.probA = 0.4;
        this.probB = 0.5;
        this.overlap = 0.2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const probASlider = document.getElementById(&apos;prob-a-slider&apos;);
        const probBSlider = document.getElementById(&apos;prob-b-slider&apos;);
        const overlapSlider = document.getElementById(&apos;overlap-slider&apos;);
        
        probASlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probA = parseFloat(e.target.value);
            document.getElementById(&apos;prob-a-value&apos;).textContent = this.probA.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        probBSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probB = parseFloat(e.target.value);
            document.getElementById(&apos;prob-b-value&apos;).textContent = this.probB.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        overlapSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.overlap = parseFloat(e.target.value);
            document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            // Ensure overlap doesn&apos;t exceed min(probA, probB)
            const maxOverlap = Math.min(this.probA, this.probB);
            if (this.overlap &gt; maxOverlap) {
                this.overlap = maxOverlap;
                overlapSlider.value = this.overlap;
                document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            }
            this.updateCalculations();
            this.draw();
        });
        
        this.updateCalculations();
    }
    
    updateCalculations() {
        const probUnion = this.probA + this.probB - this.overlap;
        const probAGivenB = this.probB &gt; 0 ? this.overlap / this.probB : 0;
        const probBGivenA = this.probA &gt; 0 ? this.overlap / this.probA : 0;
        
        document.getElementById(&apos;display-prob-a&apos;).textContent = this.probA.toFixed(3);
        document.getElementById(&apos;display-prob-b&apos;).textContent = this.probB.toFixed(3);
        document.getElementById(&apos;display-prob-ab&apos;).textContent = this.overlap.toFixed(3);
        document.getElementById(&apos;display-prob-union&apos;).textContent = probUnion.toFixed(3);
        document.getElementById(&apos;display-prob-a-given-b&apos;).textContent = probAGivenB.toFixed(3);
        document.getElementById(&apos;display-prob-b-given-a&apos;).textContent = probBGivenA.toFixed(3);
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw universe rectangle
        this.ctx.strokeStyle = &apos;#000&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.strokeRect(50, 50, 300, 200);
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;14px Arial&apos;;
        this.ctx.fillText(&apos;Œ© (Kh√¥ng gian m·∫´u)&apos;, 55, 45);
        
        // Calculate circle parameters
        const centerAX = 150;
        const centerAY = 150;
        const centerBX = 250;
        const centerBY = 150;
        
        // Calculate radii based on probabilities (area proportional to probability)
        const radiusA = Math.sqrt(this.probA * 10000 / Math.PI);
        const radiusB = Math.sqrt(this.probB * 10000 / Math.PI);
        
        // Draw circle A
        this.ctx.globalAlpha = 0.3;
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw circle B
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw intersection (approximate)
        if (this.overlap &gt; 0) {
            this.ctx.fillStyle = &apos;#9c27b0&apos;;
            const overlapRadius = Math.sqrt(this.overlap * 5000 / Math.PI);
            this.ctx.beginPath();
            this.ctx.arc((centerAX + centerBX) / 2, (centerAY + centerBY) / 2, overlapRadius, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        this.ctx.globalAlpha = 1.0;
        
        // Draw circle outlines
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;16px Arial&apos;;
        this.ctx.fillText(&apos;A&apos;, centerAX - 40, centerAY);
        this.ctx.fillText(&apos;B&apos;, centerBX + 30, centerBY);
        
        if (this.overlap &gt; 0) {
            this.ctx.fillText(&apos;A‚à©B&apos;, (centerAX + centerBX) / 2 - 15, (centerAY + centerBY) / 2 + 5);
        }
    }
}

// MLE Deep Learning Demo
class MLEDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;deep-learningCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.trueMu = 2.0;
        this.sampleSize = 20;
        this.data = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const trueMuSlider = document.getElementById(&apos;true-mu-slider&apos;);
        const sampleSizeSlider = document.getElementById(&apos;sample-size-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-mle-data&apos;);
        
        trueMuSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueMu = parseFloat(e.target.value);
            document.getElementById(&apos;true-mu-value&apos;).textContent = this.trueMu.toFixed(1);
            document.getElementById(&apos;display-true-mu&apos;).textContent = this.trueMu.toFixed(3);
        });
        
        sampleSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.sampleSize = parseInt(e.target.value);
            document.getElementById(&apos;sample-size-value&apos;).textContent = this.sampleSize;
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateDataAndFindMLE());
    }
    
    generateDataAndFindMLE() {
        // Generate data from Normal(trueMu, 1)
        this.data = [];
        for (let i = 0; i &lt; this.sampleSize; i++) {
            // Box-Muller transform for normal distribution
            const u1 = Math.random();
            const u2 = Math.random();
            const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            this.data.push(this.trueMu + z); // Normal(trueMu, 1)
        }
        
        // Calculate MLE (sample mean for normal distribution)
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const error = Math.abs(sampleMean - this.trueMu);
        
        // Update display
        document.getElementById(&apos;sample-mean&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-estimate&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-error&apos;).textContent = error.toFixed(3);
        
        this.draw();
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        if (this.data.length === 0) {
            this.ctx.fillStyle = &apos;#666&apos;;
            this.ctx.font = &apos;16px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(&apos;Nh·∫•p &quot;T·∫°o D·ªØ Li·ªáu &amp; T√¨m MLE&quot; ƒë·ªÉ b·∫Øt ƒë·∫ßu&apos;, this.width / 2, this.height / 2);
            return;
        }
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Find data range
        const minX = Math.min(...this.data) - 1;
        const maxX = Math.max(...this.data) + 1;
        
        // Draw likelihood function
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 100; i++) {
            const mu = minX + (maxX - minX) * i / 100;
            let logLikelihood = 0;
            
            // Calculate log-likelihood
            for (const x of this.data) {
                logLikelihood -= 0.5 * Math.log(2 * Math.PI);
                logLikelihood -= 0.5 * (x - mu) * (x - mu);
            }
            
            const x = marginX + (mu - minX) / (maxX - minX) * plotWidth;
            const y = this.height - marginY - (logLikelihood - (-this.data.length * 2)) / (this.data.length) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(x, y);
            } else {
                this.ctx.lineTo(x, y);
            }
        }
        this.ctx.stroke();
        
        // Mark MLE
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const mleX = marginX + (sampleMean - minX) / (maxX - minX) * plotWidth;
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(mleX, marginY);
        this.ctx.lineTo(mleX, this.height - marginY);
        this.ctx.stroke();
        
        // Mark true value
        const trueX = marginX + (this.trueMu - minX) / (maxX - minX) * plotWidth;
        this.ctx.strokeStyle = &apos;#4caf50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(trueX, marginY);
        this.ctx.lineTo(trueX, this.height - marginY);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw data points
        this.ctx.fillStyle = &apos;#666&apos;;
        for (const x of this.data) {
            const pointX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            this.ctx.beginPath();
            this.ctx.arc(pointX, this.height - marginY + 10, 2, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;Œº&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;Log-Likelihood&apos;, 0, 0);
        this.ctx.restore();
        
        // Legend
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;‚Äî Likelihood&apos;, 10, 20);
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.fillText(&apos;‚Äî MLE&apos;, 10, 35);
        this.ctx.fillStyle = &apos;#4caf50&apos;;
        this.ctx.fillText(&apos;--- Œº Th·ª±c&apos;, 10, 50);
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SampleSpaceDemo();
    new ConditionalProbDemo();
    new MLEDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-03 Gi·∫£i t√≠ch th·ª±c v√† L√Ω thuy·∫øt t·∫≠p h·ª£p</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_03_Real_Analysis_and_Set_Theory</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm c√°c kh√°i ni·ªám c·∫ßn thi·∫øt t·ª´ gi·∫£i t√≠ch th·ª±c v√† l√Ω thuy·∫øt t·∫≠p h·ª£p c·∫ßn thi·∫øt cho t·ªëi ∆∞u h√≥a, ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh hai ph·∫ßn ch√≠nh ƒë·ªÉ hi·ªÉu m·ªôt c√°ch to√†n di·ªán.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-02 T√¥p√¥ trong Gi·∫£i t√≠ch th·ª±c</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_03_02_Topology_in_Real_Analysis</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm c√°c kh√°i ni·ªám t√¥p√¥ c·∫ßn thi·∫øt t·ª´ gi·∫£i t√≠ch th·ª±c, r·∫•t quan tr·ªçng ƒë·ªÉ hi·ªÉu c·∫•u tr√∫c c·ªßa c√°c v√πng kh·∫£ thi, t√≠nh li√™n t·ª•c v√† s·ª± t·ªìn t·∫°i c·ªßa nghi·ªám t·ªëi ∆∞u trong c√°c b√†i to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gi·ªõi-thi·ªáu-v·ªÅ-t√¥p√¥&quot;&gt;Gi·ªõi thi·ªáu v·ªÅ T√¥p√¥&lt;/h2&gt;

&lt;p&gt;T√¥p√¥ nghi√™n c·ª©u c√°c t√≠nh ch·∫•t c·ªßa kh√¥ng gian ƒë∆∞·ª£c b·∫£o to√†n d∆∞·ªõi c√°c bi·∫øn d·∫°ng li√™n t·ª•c. Trong t·ªëi ∆∞u h√≥a, c√°c kh√°i ni·ªám t√¥p√¥ gi√∫p ch√∫ng ta hi·ªÉu c·∫•u tr√∫c c·ªßa c√°c v√πng kh·∫£ thi v√† h√†nh vi c·ªßa c√°c h√†m s·ªë, ƒë·∫∑c bi·ªát li√™n quan ƒë·∫øn s·ª± t·ªìn t·∫°i v√† ƒë·∫∑c tr∆∞ng c·ªßa nghi·ªám t·ªëi ∆∞u.&lt;/p&gt;

&lt;h3 id=&quot;kh√¥ng-gian-metric-v√†-kho·∫£ng-c√°ch&quot;&gt;Kh√¥ng gian metric v√† Kho·∫£ng c√°ch&lt;/h3&gt;

&lt;p&gt;Tr∆∞·ªõc khi th·∫£o lu·∫≠n v·ªÅ t√¥p√¥, ch√∫ng ta c·∫ßn kh√°i ni·ªám kho·∫£ng c√°ch. Trong \(\mathbb{R}^n\), &lt;strong&gt;kho·∫£ng c√°ch Euclid&lt;/strong&gt; chu·∫©n gi·ªØa c√°c ƒëi·ªÉm \(\mathbf{x}\) v√† \(\mathbf{y}\) l√†:&lt;/p&gt;

\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}\]

&lt;h3 id=&quot;h√¨nh-c·∫ßu-m·ªü-v√†-l√¢n-c·∫≠n&quot;&gt;H√¨nh c·∫ßu m·ªü v√† L√¢n c·∫≠n&lt;/h3&gt;

&lt;p&gt;M·ªôt &lt;strong&gt;h√¨nh c·∫ßu m·ªü&lt;/strong&gt; c√≥ t√¢m t·∫°i \(\mathbf{x}_0\) v·ªõi b√°n k√≠nh \(\epsilon &amp;gt; 0\) l√†:&lt;/p&gt;

\[B(\mathbf{x}_0, \epsilon) = \{\mathbf{y} \in \mathbb{R}^n : d(\mathbf{x}_0, \mathbf{y}) &amp;lt; \epsilon\}\]

&lt;p&gt;This represents all points within distance \(\epsilon\) from \(\mathbf{x}_0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In \(\mathbb{R}\): \(B(0, 1) = (-1, 1)\) (open interval)&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^2\): \(B(\mathbf{0}, 1) = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;open-sets&quot;&gt;Open Sets&lt;/h2&gt;

&lt;p&gt;An &lt;strong&gt;open set&lt;/strong&gt; is characterized by the property that it &lt;strong&gt;contains none of its boundary points&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) in \(\mathbb{R}^n\) is &lt;strong&gt;open&lt;/strong&gt; if for every point \(\mathbf{x} \in S\), there exists a positive real number \(\epsilon &amp;gt; 0\) such that the open ball \(B(\mathbf{x}, \epsilon)\) is entirely contained within \(S\):&lt;/p&gt;

\[\forall \mathbf{x} \in S, \exists \epsilon &amp;gt; 0 : B(\mathbf{x}, \epsilon) \subseteq S\]

&lt;h3 id=&quot;intuitive-understanding&quot;&gt;Intuitive Understanding&lt;/h3&gt;

&lt;p&gt;An open set has the property that if you‚Äôre inside it, you can move a small distance in any direction and still remain inside the set. There‚Äôs always some ‚Äúwiggle room‚Äù around every point.&lt;/p&gt;

&lt;h3 id=&quot;examples-of-open-sets&quot;&gt;Examples of Open Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(0, 1) = \{x : 0 &amp;lt; x &amp;lt; 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(-\infty, 5) = \{x : x &amp;lt; 5\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x &amp;gt; 0, y &amp;gt; 0\}\) (first quadrant, excluding axes)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^2\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any open ball \(B(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set - vacuously open)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-open-sets&quot;&gt;Properties of Open Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The union of any collection of open sets is open&lt;/li&gt;
  &lt;li&gt;The intersection of finitely many open sets is open&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both open&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;closed-sets&quot;&gt;Closed Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;closed set&lt;/strong&gt; is defined as a set that contains all of its boundary points. Equivalently, a set \(S\) is closed if its complement \(\mathbb{R}^n \setminus S\) is an &lt;strong&gt;open set&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition-1&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) is &lt;strong&gt;closed&lt;/strong&gt; if it contains all its limit points. That is, if a sequence of points \((x_n)\) from \(S\) converges to a point \(\mathbf{x}\), then \(\mathbf{x}\) must also be in \(S\):&lt;/p&gt;

\[\text{If } \mathbf{x}_n \in S \text{ for all } n \text{ and } \lim_{n \to \infty} \mathbf{x}_n = \mathbf{x}, \text{ then } \mathbf{x} \in S\]

&lt;h3 id=&quot;examples-of-closed-sets&quot;&gt;Examples of Closed Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[[0, 1] = \{x : 0 \leq x \leq 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[[a, \infty) = \{x : x \geq a\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{Z}\) (integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x \geq 0, y \geq 0\}\) (first quadrant, including axes)&lt;/li&gt;
  &lt;li&gt;\(\{(0, 0)\}\) (single point)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r) = \{\mathbf{x} : d(\mathbf{x}, \mathbf{x}_0) \leq r\}\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-closed-sets&quot;&gt;Properties of Closed Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The intersection of any collection of closed sets is closed&lt;/li&gt;
  &lt;li&gt;The union of finitely many closed sets is closed&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both closed&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;important-note&quot;&gt;Important Note&lt;/h3&gt;

&lt;p&gt;Sets can be:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open but not closed:&lt;/strong&gt; \((0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed but not open:&lt;/strong&gt; \([0, 1]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Both open and closed:&lt;/strong&gt; \(\mathbb{R}^n\), \(\emptyset\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neither open nor closed:&lt;/strong&gt; \([0, 1)\), \((0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boundary-interior-and-closure&quot;&gt;Boundary, Interior, and Closure&lt;/h2&gt;

&lt;h3 id=&quot;boundary&quot;&gt;Boundary&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;boundary&lt;/strong&gt; of a set \(S\), denoted \(\partial S\), consists of points that are ‚Äúon the edge‚Äù of the set. A point \(\mathbf{x}\) is a &lt;strong&gt;boundary point&lt;/strong&gt; of \(S\) if every open ball centered at \(\mathbf{x}\) intersects both \(S\) and its complement \(S^c\):&lt;/p&gt;

\[\partial S = \{\mathbf{x} : \forall \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \cap S \neq \emptyset \text{ and } B(\mathbf{x}, \epsilon) \cap S^c \neq \emptyset\}\]

&lt;h3 id=&quot;interior&quot;&gt;Interior&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;interior&lt;/strong&gt; of a set \(S\), denoted \(S^\circ\) or \(\text{int}(S)\), includes all points strictly ‚Äúinside‚Äù the set, excluding the boundary:&lt;/p&gt;

\[S^\circ = \{\mathbf{x} \in S : \exists \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \subseteq S\}\]

&lt;h3 id=&quot;closure&quot;&gt;Closure&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;closure&lt;/strong&gt; of a set \(S\), denoted \(\overline{S}\) or \(\text{cl}(S)\), is the smallest closed set containing \(S\):&lt;/p&gt;

\[\overline{S} = S \cup \partial S\]

&lt;h3 id=&quot;example-analysis&quot;&gt;Example Analysis&lt;/h3&gt;

&lt;p&gt;For the interval \(S = [0, 1)\) in \(\mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = (0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{0, 1\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = [0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the open disk \(S = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) in \(\mathbb{R}^2\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = S\) (the set is already open)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{(x, y) : x^2 + y^2 = 1\}\) (unit circle)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = \{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;compact-sets&quot;&gt;Compact Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;compact set&lt;/strong&gt; is one of the most important concepts in deep-learning theory.&lt;/p&gt;

&lt;h3 id=&quot;definition-in-euclidean-spaces&quot;&gt;Definition in Euclidean Spaces&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Heine-Borel Theorem:&lt;/strong&gt; In Euclidean spaces (\(\mathbb{R}^n\)), a set is compact if and only if it is both &lt;strong&gt;closed and bounded&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; A set \(S\) is bounded if it can be contained within some sufficiently large open ball: \(\exists M &amp;gt; 0, \mathbf{x}_0\) such that \(S \subseteq B(\mathbf{x}_0, M)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; As defined above&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples-of-compact-sets&quot;&gt;Examples of Compact Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\([a, b]\) (any closed, bounded interval)&lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\([0, 1] \times [0, 1]\) (unit square)&lt;/li&gt;
  &lt;li&gt;Any finite set of points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;Any closed, bounded rectangle \([a_1, b_1] \times [a_2, b_2] \times \cdots \times [a_n, b_n]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;non-compact-sets&quot;&gt;Non-Compact Sets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\((0, 1)\) (bounded but not closed)&lt;/li&gt;
  &lt;li&gt;\([0, \infty)\) (closed but not bounded)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) (not bounded)&lt;/li&gt;
  &lt;li&gt;\(\{1, 1/2, 1/3, 1/4, \ldots\}\) (bounded but not closed, since 0 is a limit point not in the set)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-of-functions&quot;&gt;Continuity of Functions&lt;/h2&gt;

&lt;h3 id=&quot;point-wise-continuity&quot;&gt;Point-wise Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is &lt;strong&gt;continuous at a point&lt;/strong&gt; \(\mathbf{c} \in A\) if for every \(\varepsilon &amp;gt; 0\), there exists \(\delta &amp;gt; 0\) such that for all \(\mathbf{x} \in A\):&lt;/p&gt;

\[\|\mathbf{x} - \mathbf{c}\| &amp;lt; \delta \implies |f(\mathbf{x}) - f(\mathbf{c})| &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;Intuitive meaning:&lt;/strong&gt; Small changes in input lead to small changes in output.&lt;/p&gt;

&lt;h3 id=&quot;global-continuity&quot;&gt;Global Continuity&lt;/h3&gt;

&lt;p&gt;\(f\) is &lt;strong&gt;continuous on \(A\)&lt;/strong&gt; if it‚Äôs continuous at every point in \(A\).&lt;/p&gt;

&lt;h3 id=&quot;sequential-characterization&quot;&gt;Sequential Characterization&lt;/h3&gt;

&lt;p&gt;\(f\) is continuous at \(\mathbf{c}\) if and only if for every sequence \((\mathbf{x}_n)\) in \(A\) converging to \(\mathbf{c}\):&lt;/p&gt;

\[\lim_{n \to \infty} f(\mathbf{x}_n) = f(\mathbf{c})\]

&lt;hr /&gt;

&lt;h2 id=&quot;important-theorems-for-deep-learning&quot;&gt;Important Theorems for Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;extreme-value-theorem&quot;&gt;Extreme Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on a compact set \(K\), then \(f\) attains its maximum and minimum on \(K\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is fundamental for deep-learning: it guarantees that continuous objective functions have optimal solutions on compact feasible regions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof idea:&lt;/strong&gt; Compactness ensures that the supremum and infimum of \(f\) on \(K\) are actually achieved at points in \(K\).&lt;/p&gt;

&lt;h3 id=&quot;intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on \([a, b]\) and \(y\) is between \(f(a)\) and \(f(b)\), then there exists \(c \in [a, b]\) such that \(f(c) = y\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This helps establish the existence of solutions to equations \(f(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;bolzano-weierstrass-theorem&quot;&gt;Bolzano-Weierstrass Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every bounded sequence in \(\mathbb{R}^n\) has a convergent subsequence.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is crucial for proving convergence of deep-learning algorithms.&lt;/p&gt;

&lt;h3 id=&quot;weierstrass-approximation-theorem&quot;&gt;Weierstrass Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every continuous function on a closed interval can be uniformly approximated by polynomials.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This justifies using polynomial approximations in deep-learning algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;1-existence-of-solutions&quot;&gt;1. Existence of Solutions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compact feasible sets guarantee optimal solutions exist:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the feasible region \(S\) is compact and the objective function \(f\) is continuous, then the deep-learning problem \(\min_{\mathbf{x} \in S} f(\mathbf{x})\) has a solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-constraint-qualification&quot;&gt;2. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding topological properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Regular points:&lt;/strong&gt; Points where constraint gradients are linearly independent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interior point methods:&lt;/strong&gt; Require the feasible region to have non-empty interior&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-convergence-analysis&quot;&gt;3. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Analyzing whether deep-learning algorithms converge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed sets:&lt;/strong&gt; Ensure limit points of convergent sequences remain feasible&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compactness:&lt;/strong&gt; Guarantees convergent subsequences exist&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-local-vs-global-optima&quot;&gt;4. Local vs Global Optima&lt;/h3&gt;

&lt;p&gt;Using neighborhoods to define optimality:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in some neighborhood of \(\mathbf{x}^*\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Global minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in the feasible region&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-feasible-region-analysis&quot;&gt;5. Feasible Region Analysis&lt;/h3&gt;

&lt;p&gt;Determining properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear constraints:&lt;/strong&gt; Define closed sets (half-spaces)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinear constraints:&lt;/strong&gt; May create sets that are neither open nor closed&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact feasible regions:&lt;/strong&gt; Guarantee existence of optimal solutions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-portfolio-deep-learning&quot;&gt;Example: Portfolio Deep Learning&lt;/h3&gt;

&lt;p&gt;Consider minimizing portfolio risk subject to constraints:&lt;/p&gt;

\[\begin{align}
\min_{\mathbf{w}} \quad &amp;amp; \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} \\
\text{s.t.} \quad &amp;amp; \mathbf{1}^T \mathbf{w} = 1 \\
&amp;amp; \mathbf{w} \geq \mathbf{0}
\end{align}\]

&lt;p&gt;The feasible region \(S = \{\mathbf{w} : \mathbf{1}^T \mathbf{w} = 1, \mathbf{w} \geq \mathbf{0}\}\) is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; It‚Äôs the intersection of closed sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; The constraint \(\mathbf{1}^T \mathbf{w} = 1\) with \(\mathbf{w} \geq \mathbf{0}\) bounds the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact:&lt;/strong&gt; Being closed and bounded in \(\mathbb{R}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the objective function \(\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}\) is continuous and \(S\) is compact, the Extreme Value Theorem guarantees that an optimal portfolio exists.&lt;/p&gt;

&lt;p&gt;Understanding topology and real analysis provides the rigorous foundation needed to prove that deep-learning problems have solutions and that algorithms will find them. These concepts are essential for both theoretical analysis and practical algorithm design.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-01 C∆° s·ªü L√Ω thuy·∫øt t·∫≠p h·ª£p</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_03_01_Set_Theory_Fundamentals</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm c√°c kh√°i ni·ªám c∆° b·∫£n t·ª´ l√Ω thuy·∫øt t·∫≠p h·ª£p cung c·∫•p n·ªÅn t·∫£ng to√°n h·ªçc ƒë·ªÉ hi·ªÉu c√°c b√†i to√°n t·ªëi ∆∞u h√≥a, r√†ng bu·ªôc v√† v√πng kh·∫£ thi.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gi·ªõi-thi·ªáu-v·ªÅ-l√Ω-thuy·∫øt-t·∫≠p-h·ª£p&quot;&gt;Gi·ªõi thi·ªáu v·ªÅ L√Ω thuy·∫øt t·∫≠p h·ª£p&lt;/h2&gt;

&lt;p&gt;L√Ω thuy·∫øt t·∫≠p h·ª£p cung c·∫•p n·ªÅn t·∫£ng cho to√°n h·ªçc hi·ªán ƒë·∫°i v√† r·∫•t c·∫ßn thi·∫øt ƒë·ªÉ hi·ªÉu c√°c kh√°i ni·ªám t·ªëi ∆∞u h√≥a. M·ªôt &lt;strong&gt;t·∫≠p h·ª£p&lt;/strong&gt; ƒë∆°n gi·∫£n l√† m·ªôt b·ªô s∆∞u t·∫≠p c√°c ƒë·ªëi t∆∞·ª£ng ri√™ng bi·ªát, ƒë∆∞·ª£c g·ªçi l√† c√°c ph·∫ßn t·ª≠ ho·∫∑c th√†nh vi√™n.&lt;/p&gt;

&lt;h3 id=&quot;k√Ω-hi·ªáu-c∆°-b·∫£n&quot;&gt;K√Ω hi·ªáu c∆° b·∫£n&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;K√Ω hi·ªáu t·∫≠p h·ª£p:&lt;/strong&gt; \(A = \{1, 2, 3, 4\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quan h·ªá th√†nh vi√™n:&lt;/strong&gt; \(x \in A\) (x thu·ªôc A) ho·∫∑c \(x \notin A\) (x kh√¥ng thu·ªôc A)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·∫≠p r·ªóng:&lt;/strong&gt; \(\emptyset = \{\}\) (t·∫≠p h·ª£p kh√¥ng c√≥ ph·∫ßn t·ª≠ n√†o)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;K√Ω hi·ªáu x√¢y d·ª±ng t·∫≠p h·ª£p:&lt;/strong&gt; \(A = \{x : P(x)\}\) (t·∫≠p h·ª£p t·∫•t c·∫£ x sao cho t√≠nh ch·∫•t P(x) ƒë√∫ng)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;v√≠-d·ª•&quot;&gt;V√≠ d·ª•&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(A = \{1, 2, 3, 4\}\) (li·ªát k√™ t∆∞·ªùng minh)&lt;/li&gt;
  &lt;li&gt;\(B = \{x \in \mathbb{R} : x^2 &amp;lt; 4\} = (-2, 2)\) (k√Ω hi·ªáu x√¢y d·ª±ng t·∫≠p h·ª£p)&lt;/li&gt;
  &lt;li&gt;\(C = \{x \in \mathbb{Z} : x \text{ l√† s·ªë ch·∫µn}\}\) (t·∫•t c·∫£ s·ªë nguy√™n ch·∫µn)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;c√°c-ph√©p-to√°n-t·∫≠p-h·ª£p-c∆°-b·∫£n&quot;&gt;C√°c ph√©p to√°n t·∫≠p h·ª£p c∆° b·∫£n&lt;/h2&gt;

&lt;h3 id=&quot;t·∫≠p-h·ª£p-v√†-t·∫≠p-con&quot;&gt;T·∫≠p h·ª£p v√† T·∫≠p con&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;T·∫≠p con:&lt;/strong&gt; \(A \subseteq B\) c√≥ nghƒ©a l√† m·ªçi ph·∫ßn t·ª≠ c·ªßa \(A\) c≈©ng thu·ªôc \(B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T·∫≠p con th·ª±c s·ª±:&lt;/strong&gt; \(A \subset B\) c√≥ nghƒ©a l√† \(A \subseteq B\) v√† \(A \neq B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;B·∫±ng nhau gi·ªØa c√°c t·∫≠p h·ª£p:&lt;/strong&gt; \(A = B\) khi v√† ch·ªâ khi \(A \subseteq B\) v√† \(B \subseteq A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\{1, 2\} \subseteq \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\{1, 2\} \subset \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\emptyset \subseteq A\) v·ªõi m·ªçi t·∫≠p h·ª£p \(A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;h·ª£p-v√†-giao&quot;&gt;H·ª£p v√† Giao&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;H·ª£p (\(A \cup B\)):&lt;/strong&gt; T·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ thu·ªôc \(A\) ho·∫∑c \(B\) (ho·∫∑c c·∫£ hai)
\(A \cup B = \{x : x \in A \text{ ho·∫∑c } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Giao (\(A \cap B\)):&lt;/strong&gt; T·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ thu·ªôc c·∫£ \(A\) v√† \(B\)
\(A \cap B = \{x : x \in A \text{ v√† } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;N·∫øu \(A = \{1, 2, 3\}\) v√† \(B = \{3, 4, 5\}\), th√¨:
    &lt;ul&gt;
      &lt;li&gt;
\[A \cup B = \{1, 2, 3, 4, 5\}\]
      &lt;/li&gt;
      &lt;li&gt;
\[A \cap B = \{3\}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;T·∫≠p h·ª£p r·ªùi nhau:&lt;/strong&gt; \(A\) v√† \(B\) r·ªùi nhau n·∫øu \(A \cap B = \emptyset\)&lt;/p&gt;

&lt;h3 id=&quot;ph·∫ßn-b√π-v√†-hi·ªáu&quot;&gt;Ph·∫ßn b√π v√† Hi·ªáu&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ph·∫ßn b√π (\(A^c\)):&lt;/strong&gt; T·∫•t c·∫£ c√°c ph·∫ßn t·ª≠ kh√¥ng thu·ªôc \(A\) (trong m·ªôt t·∫≠p h·ª£p to√†n th·ªÉ \(U\) n√†o ƒë√≥)
\(A^c = \{x \in U : x \notin A\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hi·ªáu t·∫≠p h·ª£p (\(A \setminus B\)):&lt;/strong&gt; C√°c ph·∫ßn t·ª≠ thu·ªôc \(A\) nh∆∞ng kh√¥ng thu·ªôc \(B\)
\(A \setminus B = \{x : x \in A \text{ v√† } x \notin B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hi·ªáu ƒë·ªëi x·ª©ng:&lt;/strong&gt; \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\)&lt;/p&gt;

&lt;h3 id=&quot;c√°c-lu·∫≠t-t·∫≠p-h·ª£p&quot;&gt;C√°c lu·∫≠t t·∫≠p h·ª£p&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Lu·∫≠t giao ho√°n:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cup B = B \cup A\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cap B = B \cap A\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lu·∫≠t k·∫øt h·ª£p:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B) \cup C = A \cup (B \cup C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B) \cap C = A \cap (B \cap C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lu·∫≠t ph√¢n ph·ªëi:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Lu·∫≠t De Morgan:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B)^c = A^c \cap B^c\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B)^c = A^c \cup B^c\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;c√°c-t·∫≠p-s·ªë-quan-tr·ªçng&quot;&gt;C√°c t·∫≠p s·ªë quan tr·ªçng&lt;/h2&gt;

&lt;p&gt;Hi·ªÉu bi·∫øt v·ªÅ h·ªá th·ªëng ph√¢n c·∫•p c√°c t·∫≠p s·ªë l√† r·∫•t quan tr·ªçng cho t·ªëi ∆∞u h√≥a:&lt;/p&gt;

&lt;h3 id=&quot;s·ªë-t·ª±-nhi√™n&quot;&gt;S·ªë t·ª± nhi√™n&lt;/h3&gt;
&lt;p&gt;\(\mathbb{N} = \{1, 2, 3, 4, \ldots\}\)
(Th·ªânh tho·∫£ng bao g·ªìm 0: \(\mathbb{N}_0 = \{0, 1, 2, 3, \ldots\}\))&lt;/p&gt;

&lt;h3 id=&quot;s·ªë-nguy√™n&quot;&gt;S·ªë nguy√™n&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Z} = \{\ldots, -2, -1, 0, 1, 2, \ldots\}\)&lt;/p&gt;

&lt;h3 id=&quot;s·ªë-h·ªØu-t·ªâ&quot;&gt;S·ªë h·ªØu t·ªâ&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Q} = \left\{\frac{p}{q} : p, q \in \mathbb{Z}, q \neq 0\right\}\)&lt;/p&gt;

&lt;p&gt;T·∫•t c·∫£ c√°c s·ªë c√≥ th·ªÉ bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng ph√¢n s·ªë.&lt;/p&gt;

&lt;h3 id=&quot;s·ªë-th·ª±c&quot;&gt;S·ªë th·ª±c&lt;/h3&gt;
&lt;p&gt;\(\mathbb{R}\) bao g·ªìm t·∫•t c·∫£ c√°c s·ªë h·ªØu t·ªâ v√† v√¥ t·ªâ (nh∆∞ \(\pi\), \(e\), \(\sqrt{2}\)).&lt;/p&gt;

&lt;h3 id=&quot;s·ªë-ph·ª©c&quot;&gt;S·ªë ph·ª©c&lt;/h3&gt;
&lt;p&gt;\(\mathbb{C} = \{a + bi : a, b \in \mathbb{R}, i^2 = -1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph√¢n c·∫•p:&lt;/strong&gt; \(\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;h√†m-s·ªë-mi·ªÅn-x√°c-ƒë·ªãnh-v√†-mi·ªÅn-gi√°-tr·ªã&quot;&gt;H√†m s·ªë: Mi·ªÅn x√°c ƒë·ªãnh v√† Mi·ªÅn gi√° tr·ªã&lt;/h2&gt;

&lt;p&gt;M·ªôt &lt;strong&gt;h√†m s·ªë&lt;/strong&gt; \(f: A \to B\) l√† m·ªôt quy t·∫Øc g√°n cho m·ªói ph·∫ßn t·ª≠ trong t·∫≠p h·ª£p \(A\) ƒë√∫ng m·ªôt ph·∫ßn t·ª≠ trong t·∫≠p h·ª£p \(B\).&lt;/p&gt;

&lt;h3 id=&quot;c√°c-kh√°i-ni·ªám-ch√≠nh&quot;&gt;C√°c kh√°i ni·ªám ch√≠nh&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Mi·ªÅn x√°c ƒë·ªãnh:&lt;/strong&gt; T·∫≠p h·ª£p \(A\) c·ªßa t·∫•t c·∫£ c√°c gi√° tr·ªã ƒë·∫ßu v√†o c√≥ th·ªÉ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mi·ªÅn ƒë·ªìng bi·∫øn:&lt;/strong&gt; T·∫≠p h·ª£p \(B\) n∆°i c√°c gi√° tr·ªã ƒë·∫ßu ra ƒë∆∞·ª£c l·∫•y t·ª´&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mi·ªÅn gi√° tr·ªã (·∫¢nh):&lt;/strong&gt; T·∫≠p h·ª£p t·∫•t c·∫£ c√°c gi√° tr·ªã ƒë·∫ßu ra th·ª±c t·∫ø: \(\text{Range}(f) = \{f(x) : x \in A\} \subseteq B\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt; V·ªõi \(f(x) = x^2\) v√† \(f: \mathbb{R} \to \mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Mi·ªÅn x√°c ƒë·ªãnh: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Mi·ªÅn ƒë·ªìng bi·∫øn: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Mi·ªÅn gi√° tr·ªã: \([0, \infty)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c√°c-lo·∫°i-h√†m-s·ªë&quot;&gt;C√°c lo·∫°i h√†m s·ªë&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ƒê∆°n √°nh (M·ªôt-ƒë·∫øn-M·ªôt):&lt;/strong&gt; M·ªói ph·∫ßn t·ª≠ trong mi·ªÅn gi√° tr·ªã t∆∞∆°ng ·ª©ng v·ªõi ƒë√∫ng m·ªôt ph·∫ßn t·ª≠ trong mi·ªÅn x√°c ƒë·ªãnh
\(f(x_1) = f(x_2) \implies x_1 = x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;To√†n √°nh (L√™n):&lt;/strong&gt; M·ªçi ph·∫ßn t·ª≠ trong mi·ªÅn ƒë·ªìng bi·∫øn ƒë·ªÅu n·∫±m trong mi·ªÅn gi√° tr·ªã
V·ªõi m·ªçi \(y \in B\), t·ªìn t·∫°i \(x \in A\) sao cho \(f(x) = y\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Song √°nh:&lt;/strong&gt; V·ª´a l√† ƒë∆°n √°nh v·ª´a l√† to√†n √°nh
C√≥ m·ªôt t∆∞∆°ng ·ª©ng ho√†n h·∫£o m·ªôt-ƒë·∫øn-m·ªôt gi·ªØa mi·ªÅn x√°c ƒë·ªãnh v√† mi·ªÅn ƒë·ªìng bi·∫øn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = 2x\) tr√™n \(\mathbb{R}\) l√† song √°nh&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) tr√™n \(\mathbb{R}\) kh√¥ng l√† ƒë∆°n √°nh c≈©ng kh√¥ng l√† to√†n √°nh&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) tr√™n \([0, \infty) \to [0, \infty)\) l√† song √°nh&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;b·∫•t-ƒë·∫≥ng-th·ª©c&quot;&gt;B·∫•t ƒë·∫≥ng th·ª©c&lt;/h2&gt;

&lt;p&gt;Hi·ªÉu bi·∫øt v·ªÅ b·∫•t ƒë·∫≥ng th·ª©c l√† r·∫•t quan tr·ªçng cho t·ªëi ∆∞u h√≥a, v√¨ c√°c r√†ng bu·ªôc th∆∞·ªùng ƒë∆∞·ª£c bi·ªÉu di·ªÖn d∆∞·ªõi d·∫°ng b·∫•t ƒë·∫≥ng th·ª©c.&lt;/p&gt;

&lt;h3 id=&quot;c√°c-k√Ω-hi·ªáu-b·∫•t-ƒë·∫≥ng-th·ª©c-c∆°-b·∫£n&quot;&gt;C√°c k√Ω hi·ªáu b·∫•t ƒë·∫≥ng th·ª©c c∆° b·∫£n&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(a &amp;lt; b\): \(a\) nh·ªè h∆°n \(b\) m·ªôt c√°ch nghi√™m ng·∫∑t&lt;/li&gt;
  &lt;li&gt;\(a \leq b\): \(a\) nh·ªè h∆°n ho·∫∑c b·∫±ng \(b\)&lt;/li&gt;
  &lt;li&gt;\(a &amp;gt; b\): \(a\) l·ªõn h∆°n \(b\) m·ªôt c√°ch nghi√™m ng·∫∑t&lt;/li&gt;
  &lt;li&gt;\(a \geq b\): \(a\) l·ªõn h∆°n ho·∫∑c b·∫±ng \(b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;t√≠nh-ch·∫•t-c·ªßa-b·∫•t-ƒë·∫≥ng-th·ª©c&quot;&gt;T√≠nh ch·∫•t c·ªßa b·∫•t ƒë·∫≥ng th·ª©c&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh b·∫Øc c·∫ßu:&lt;/strong&gt; N·∫øu \(a \leq b\) v√† \(b \leq c\), th√¨ \(a \leq c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Ph√©p c·ªông:&lt;/strong&gt; N·∫øu \(a \leq b\), th√¨ \(a + c \leq b + c\) v·ªõi m·ªçi \(c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nh√¢n v·ªõi s·ªë d∆∞∆°ng:&lt;/strong&gt; N·∫øu \(a \leq b\) v√† \(c &amp;gt; 0\), th√¨ \(ac \leq bc\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Nh√¢n v·ªõi s·ªë √¢m:&lt;/strong&gt; N·∫øu \(a \leq b\) v√† \(c &amp;lt; 0\), th√¨ \(ac \geq bc\) (b·∫•t ƒë·∫≥ng th·ª©c ƒë·∫£o chi·ªÅu!)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;k√Ω-hi·ªáu-kho·∫£ng&quot;&gt;K√Ω hi·ªáu kho·∫£ng&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Kho·∫£ng m·ªü:&lt;/strong&gt; \((a, b) = \{x \in \mathbb{R} : a &amp;lt; x &amp;lt; b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kho·∫£ng ƒë√≥ng:&lt;/strong&gt; \([a, b] = \{x \in \mathbb{R} : a \leq x \leq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kho·∫£ng n·ª≠a m·ªü:&lt;/strong&gt; \([a, b)\), \((a, b]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kho·∫£ng kh√¥ng b·ªã ch·∫∑n:&lt;/strong&gt; \((-\infty, a)\), \([a, \infty)\), \((-\infty, \infty) = \mathbb{R}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;·ª©ng-d·ª•ng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;·ª®ng d·ª•ng trong T·ªëi ∆∞u h√≥a&lt;/h2&gt;

&lt;p&gt;C√°c kh√°i ni·ªám l√Ω thuy·∫øt t·∫≠p h·ª£p l√† c∆° b·∫£n cho t·ªëi ∆∞u h√≥a:&lt;/p&gt;

&lt;h3 id=&quot;1-v√πng-kh·∫£-thi&quot;&gt;1. V√πng kh·∫£ thi&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;V√πng kh·∫£ thi&lt;/strong&gt; l√† t·∫≠p h·ª£p t·∫•t c·∫£ c√°c ƒëi·ªÉm th·ªèa m√£n c√°c r√†ng bu·ªôc:
\(S = \{x \in \mathbb{R}^n : g_i(x) \leq 0, i = 1, \ldots, m; h_j(x) = 0, j = 1, \ldots, p\}\)&lt;/p&gt;

&lt;h3 id=&quot;2-t·∫≠p-m·ª©c&quot;&gt;2. T·∫≠p m·ª©c&lt;/h3&gt;

&lt;p&gt;V·ªõi m·ªôt h√†m s·ªë \(f: \mathbb{R}^n \to \mathbb{R}\), &lt;strong&gt;t·∫≠p m·ª©c&lt;/strong&gt; t·∫°i m·ª©c \(c\) l√†:
\(L_c = \{x \in \mathbb{R}^n : f(x) = c\}\)&lt;/p&gt;

&lt;h3 id=&quot;3-ƒëi·ªÅu-ki·ªán-r√†ng-bu·ªôc&quot;&gt;3. ƒêi·ªÅu ki·ªán r√†ng bu·ªôc&lt;/h3&gt;

&lt;p&gt;Hi·ªÉu bi·∫øt khi n√†o c√°c t·∫≠p r√†ng bu·ªôc c√≥ c√°c t√≠nh ch·∫•t ‚Äút·ªët‚Äù (nh∆∞ ƒë√≥ng ho·∫∑c c√≥ ph·∫ßn trong kh√¥ng r·ªóng) ·∫£nh h∆∞·ªüng ƒë·∫øn s·ª± t·ªìn t·∫°i v√† ƒë·∫∑c tr∆∞ng c·ªßa c√°c nghi·ªám t·ªëi ∆∞u.&lt;/p&gt;

&lt;h3 id=&quot;4-ph√¢n-t√≠ch-h·ªôi-t·ª•&quot;&gt;4. Ph√¢n t√≠ch h·ªôi t·ª•&lt;/h3&gt;

&lt;p&gt;D√£y s·ªë v√† gi·ªõi h·∫°n l√† thi·∫øt y·∫øu ƒë·ªÉ ph√¢n t√≠ch li·ªáu c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a c√≥ h·ªôi t·ª• v·ªÅ nghi·ªám t·ªëi ∆∞u hay kh√¥ng.&lt;/p&gt;

&lt;h3 id=&quot;5-c√°c-ph√©p-to√°n-t·∫≠p-h·ª£p-trong-thu·∫≠t-to√°n&quot;&gt;5. C√°c ph√©p to√°n t·∫≠p h·ª£p trong thu·∫≠t to√°n&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Giao:&lt;/strong&gt; T√¨m c√°c ƒëi·ªÉm th·ªèa m√£n nhi·ªÅu r√†ng bu·ªôc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;H·ª£p:&lt;/strong&gt; K·∫øt h·ª£p c√°c v√πng kh·∫£ thi t·ª´ c√°c k·ªãch b·∫£n kh√°c nhau&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ph·∫ßn b√π:&lt;/strong&gt; Hi·ªÉu bi·∫øt v·ªÅ c√°c v√πng kh√¥ng kh·∫£ thi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt; Trong quy ho·∫°ch tuy·∫øn t√≠nh, v√πng kh·∫£ thi l√†:
\(S = \{x \in \mathbb{R}^n : Ax \leq b, x \geq 0\} = \bigcap_{i=1}^{m} \{x : a_i^T x \leq b_i\} \cap \{x : x \geq 0\}\)&lt;/p&gt;

&lt;p&gt;ƒê√¢y l√† giao c·ªßa c√°c n·ª≠a kh√¥ng gian, minh h·ªça c√°ch c√°c ph√©p to√°n t·∫≠p h·ª£p xu·∫•t hi·ªán t·ª± nhi√™n trong vi·ªác x√¢y d·ª±ng b√†i to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;p&gt;Hi·ªÉu bi·∫øt v·ªÅ l√Ω thuy·∫øt t·∫≠p h·ª£p cung c·∫•p n·ªÅn t·∫£ng to√°n h·ªçc ch·∫∑t ch·∫Ω c·∫ßn thi·∫øt ƒë·ªÉ x√¢y d·ª±ng c√°c b√†i to√°n t·ªëi ∆∞u h√≥a m·ªôt c√°ch ch√≠nh x√°c v√† ph√¢n t√≠ch c√°c t√≠nh ch·∫•t c·ªßa ch√∫ng m·ªôt c√°ch h·ªá th·ªëng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02 ƒê·∫°i s·ªë tuy·∫øn t√≠nh c∆° b·∫£n</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_Basic_Linear_Algebra/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_02_Basic_Linear_Algebra</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm c√°c kh√°i ni·ªám ƒë·∫°i s·ªë tuy·∫øn t√≠nh c·∫ßn thi·∫øt cho t·ªëi ∆∞u h√≥a, ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh ba ph·∫ßn ch√≠nh ƒë·ªÉ h·ªçc t·∫≠p c√≥ h·ªá th·ªëng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-03 Gi√° tr·ªã ri√™ng v√† Vector ri√™ng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_02_03_Eigenvalues_and_Eigenvectors</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm gi√° tr·ªã ri√™ng v√† vector ri√™ng, r·∫•t quan tr·ªçng ƒë·ªÉ hi·ªÉu h√†nh vi c·ªßa c√°c ph√©p bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh v√† h√†m b·∫≠c hai trong t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ƒë·ªãnh-nghƒ©a-v√†-tr·ª±c-gi√°c&quot;&gt;ƒê·ªãnh nghƒ©a v√† Tr·ª±c gi√°c&lt;/h2&gt;

&lt;p&gt;Khi m·ªôt ma tr·∫≠n bi·∫øn ƒë·ªïi m·ªôt vector, n√≥ th∆∞·ªùng thay ƒë·ªïi c·∫£ h∆∞·ªõng v√† ƒë·ªô d√†i c·ªßa vector. Tuy nhi√™n, &lt;strong&gt;vector ri√™ng&lt;/strong&gt; l√† nh·ªØng vector ƒë·∫∑c bi·ªát m√† khi ƒë∆∞·ª£c bi·∫øn ƒë·ªïi b·ªüi m·ªôt ma tr·∫≠n cho tr∆∞·ªõc, ch·ªâ b·ªã thay ƒë·ªïi t·ªâ l·ªá nh∆∞ng kh√¥ng thay ƒë·ªïi h∆∞·ªõng.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a-to√°n-h·ªçc&quot;&gt;ƒê·ªãnh nghƒ©a To√°n h·ªçc&lt;/h3&gt;

&lt;p&gt;V·ªõi m·ªôt ma tr·∫≠n vu√¥ng \(\mathbf{A}\) v√† m·ªôt vector kh√°c kh√¥ng \(\mathbf{v}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}\) l√† m·ªôt &lt;strong&gt;vector ri√™ng&lt;/strong&gt; c·ªßa \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;\(\lambda\) l√† &lt;strong&gt;gi√° tr·ªã ri√™ng&lt;/strong&gt; t∆∞∆°ng ·ª©ng&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;n·∫øu ch√∫ng th·ªèa m√£n &lt;strong&gt;ph∆∞∆°ng tr√¨nh gi√° tr·ªã ri√™ng&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\]

&lt;h3 id=&quot;gi·∫£i-th√≠ch-h√¨nh-h·ªçc&quot;&gt;Gi·∫£i th√≠ch H√¨nh h·ªçc&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vector ri√™ng:&lt;/strong&gt; C√°c vector kh√°c kh√¥ng duy tr√¨ h∆∞·ªõng c·ªßa ch√∫ng d∆∞·ªõi ph√©p bi·∫øn ƒë·ªïi \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gi√° tr·ªã ri√™ng:&lt;/strong&gt; C√°c h·ªá s·ªë v√¥ h∆∞·ªõng m√† c√°c vector ri√™ng ƒë∆∞·ª£c nh√¢n v·ªõi&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Hi·ªÉu bi·∫øt Tr·ª±c quan:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;N·∫øu \(\lambda &amp;gt; 1\): Vector ri√™ng b·ªã k√©o d√†i&lt;/li&gt;
  &lt;li&gt;N·∫øu \(0 &amp;lt; \lambda &amp;lt; 1\): Vector ri√™ng b·ªã co l·∫°i&lt;/li&gt;
  &lt;li&gt;N·∫øu \(\lambda &amp;lt; 0\): Vector ri√™ng b·ªã nh√¢n t·ªâ l·ªá v√† ƒë·∫£o ng∆∞·ª£c&lt;/li&gt;
  &lt;li&gt;N·∫øu \(\lambda = 0\): Vector ri√™ng ƒë∆∞·ª£c √°nh x·∫° th√†nh vector kh√¥ng&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;t√¨m-gi√°-tr·ªã-ri√™ng-v√†-vector-ri√™ng&quot;&gt;T√¨m Gi√° tr·ªã ri√™ng v√† Vector ri√™ng&lt;/h2&gt;

&lt;h3 id=&quot;b∆∞·ªõc-1-t√¨m-gi√°-tr·ªã-ri√™ng&quot;&gt;B∆∞·ªõc 1: T√¨m Gi√° tr·ªã ri√™ng&lt;/h3&gt;

&lt;p&gt;S·∫Øp x·∫øp l·∫°i ph∆∞∆°ng tr√¨nh gi√° tr·ªã ri√™ng:
\(\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\)
\(\mathbf{A}\mathbf{v} - \lambda\mathbf{v} = \mathbf{0}\)
\((\mathbf{A} - \lambda\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;For a non-trivial solution (\(\mathbf{v} \neq \mathbf{0}\)), the matrix \((\mathbf{A} - \lambda\mathbf{I})\) must be singular, so:&lt;/p&gt;

\[\det(\mathbf{A} - \lambda\mathbf{I}) = 0\]

&lt;p&gt;This is called the &lt;strong&gt;characteristic equation&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;For each eigenvalue \(\lambda_i\), solve the system:
\((\mathbf{A} - \lambda_i\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;The solutions form the &lt;strong&gt;eigenspace&lt;/strong&gt; corresponding to \(\lambda_i\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;detailed-example&quot;&gt;Detailed Example&lt;/h2&gt;

&lt;p&gt;Let‚Äôs find the eigenvalues and eigenvectors of \(\mathbf{A} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\).&lt;/p&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

\[\mathbf{A} - \lambda\mathbf{I} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix} - \lambda\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} = \begin{pmatrix} 3-\lambda &amp;amp; 1 \\ 0 &amp;amp; 2-\lambda \end{pmatrix}\]

\[\det(\mathbf{A} - \lambda\mathbf{I}) = (3-\lambda)(2-\lambda) - (1)(0) = (3-\lambda)(2-\lambda) = 0\]

&lt;p&gt;This gives us \(\lambda_1 = 3\) and \(\lambda_2 = 2\).&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors-1&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_1 = 3\):&lt;/strong&gt;
\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = \begin{pmatrix} 0 &amp;amp; 1 \\ 0 &amp;amp; -1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_2 = 0\) and \(v_1\) can be any non-zero value. So \(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_2 = 2\):&lt;/strong&gt;
\((\mathbf{A} - 2\mathbf{I})\mathbf{v} = \begin{pmatrix} 1 &amp;amp; 1 \\ 0 &amp;amp; 0 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_1 + v_2 = 0\), so \(v_2 = -v_1\). Thus \(\mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;h3 id=&quot;verification&quot;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Let‚Äôs verify our results:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_1 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} = 3\begin{pmatrix} 1 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\) ‚úì&lt;/li&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_2 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = \begin{pmatrix} 2 \\ -2 \end{pmatrix} = 2\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 2\mathbf{v}_2\) ‚úì&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;properties-and-important-theorems&quot;&gt;Properties and Important Theorems&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sum of eigenvalues = trace of matrix:&lt;/strong&gt;
\(\sum_{i=1}^n \lambda_i = \text{tr}(\mathbf{A}) = \sum_{i=1}^n a_{ii}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Product of eigenvalues = determinant of matrix:&lt;/strong&gt;
\(\prod_{i=1}^n \lambda_i = \det(\mathbf{A})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Eigenvectors corresponding to different eigenvalues are linearly independent&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;If \(\mathbf{A}\) is symmetric, all eigenvalues are real and eigenvectors are orthogonal&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;eigenvalue-multiplicity&quot;&gt;Eigenvalue Multiplicity&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Algebraic multiplicity:&lt;/strong&gt; How many times \(\lambda\) appears as a root of the characteristic polynomial&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Geometric multiplicity:&lt;/strong&gt; The dimension of the eigenspace (number of linearly independent eigenvectors)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any eigenvalue: geometric multiplicity ‚â§ algebraic multiplicity&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ph√¢n-t√≠ch-eigendecomposition&quot;&gt;Ph√¢n T√≠ch Eigendecomposition&lt;/h2&gt;

&lt;h3 id=&quot;ma-tr·∫≠n-ƒë·ªëi-x·ª©ng-symmetric-matrices&quot;&gt;Ma Tr·∫≠n ƒê·ªëi X·ª©ng (Symmetric Matrices)&lt;/h3&gt;

&lt;p&gt;Ma tr·∫≠n ƒë·ªëi x·ª©ng \(\mathbf{A} = \mathbf{A}^T\) c√≥ nh·ªØng t√≠nh ch·∫•t ƒë·∫∑c bi·ªát quan tr·ªçng:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;T·∫•t c·∫£ gi√° tr·ªã ri√™ng ƒë·ªÅu l√† s·ªë th·ª±c&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;C√°c vector ri√™ng t∆∞∆°ng ·ª©ng v·ªõi gi√° tr·ªã ri√™ng kh√°c nhau l√† tr·ª±c giao&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Lu√¥n c√≥ th·ªÉ ch√©o h√≥a ƒë∆∞·ª£c v·ªõi ma tr·∫≠n tr·ª±c giao&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;V·ªõi ma tr·∫≠n ƒë·ªëi x·ª©ng, ta c√≥ ph√¢n t√≠ch ƒë·∫∑c bi·ªát:&lt;/p&gt;

\[\mathbf{A} = \mathbf{Q}\mathbf{\Lambda}\mathbf{Q}^T\]

&lt;p&gt;trong ƒë√≥:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{Q}\) l√† ma tr·∫≠n tr·ª±c giao (\(\mathbf{Q}^T\mathbf{Q} = \mathbf{I}\)) v·ªõi c√°c c·ªôt l√† vector ri√™ng chu·∫©n h√≥a&lt;/li&gt;
  &lt;li&gt;\(\mathbf{\Lambda}\) l√† ma tr·∫≠n ch√©o ch·ª©a c√°c gi√° tr·ªã ri√™ng&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c√°c-ph√©p-to√°n-tr√™n-eigendecomposition&quot;&gt;C√°c Ph√©p To√°n Tr√™n Eigendecomposition&lt;/h3&gt;

&lt;p&gt;Eigendecomposition cho ph√©p th·ª±c hi·ªán nhi·ªÅu ph√©p to√°n ph·ª©c t·∫°p m·ªôt c√°ch hi·ªáu qu·∫£:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. L≈©y th·ª´a ma tr·∫≠n:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1}\]

&lt;p&gt;ƒêi·ªÅu n√†y ƒë·∫∑c bi·ªát h·ªØu √≠ch khi \(k\) l·ªõn, v√¨ vi·ªác l≈©y th·ª´a ma tr·∫≠n ch√©o r·∫•t ƒë∆°n gi·∫£n:&lt;/p&gt;

\[\mathbf{D}^k = \begin{pmatrix} \lambda_1^k &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\ 0 &amp;amp; \lambda_2^k &amp;amp; \cdots &amp;amp; 0 \\ \vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\ 0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; \lambda_n^k \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;2. Ma tr·∫≠n ngh·ªãch ƒë·∫£o:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;N·∫øu t·∫•t c·∫£ gi√° tr·ªã ri√™ng kh√°c 0:&lt;/p&gt;

\[\mathbf{A}^{-1} = \mathbf{P}\mathbf{D}^{-1}\mathbf{P}^{-1}\]

&lt;p&gt;v·ªõi \(\mathbf{D}^{-1}\) c√≥ c√°c ph·∫ßn t·ª≠ ch√©o l√† \(1/\lambda_i\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Ma tr·∫≠n h√†m m≈©:&lt;/strong&gt;&lt;/p&gt;

\[e^{\mathbf{A}} = \mathbf{P}e^{\mathbf{D}}\mathbf{P}^{-1}\]

&lt;p&gt;v·ªõi \(e^{\mathbf{D}} = \text{diag}(e^{\lambda_1}, e^{\lambda_2}, \ldots, e^{\lambda_n})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. ƒê·ªãnh th·ª©c v√† v·∫øt (trace):&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\det(\mathbf{A}) = \prod_i \lambda_i\) (t√≠ch c√°c gi√° tr·ªã ri√™ng)&lt;/li&gt;
  &lt;li&gt;\(\text{tr}(\mathbf{A}) = \sum_i \lambda_i\) (t·ªïng c√°c gi√° tr·ªã ri√™ng)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ƒë·ªãnh-l√Ω-gershgorin-circle&quot;&gt;ƒê·ªãnh L√Ω Gershgorin Circle&lt;/h2&gt;

&lt;p&gt;ƒê·ªãnh l√Ω Gershgorin Circle cung c·∫•p m·ªôt c√°ch ƒë∆°n gi·∫£n ƒë·ªÉ ∆∞·ªõc l∆∞·ª£ng v·ªã tr√≠ c·ªßa c√°c gi√° tr·ªã ri√™ng m√† kh√¥ng c·∫ßn t√≠nh to√°n ch√≠nh x√°c.&lt;/p&gt;

&lt;h3 id=&quot;ph√°t-bi·ªÉu-ƒë·ªãnh-l√Ω&quot;&gt;Ph√°t Bi·ªÉu ƒê·ªãnh L√Ω&lt;/h3&gt;

&lt;p&gt;Cho ma tr·∫≠n \(\mathbf{A} = [a_{ij}]_{n \times n}\). ƒê·ªãnh nghƒ©a:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;T√¢m (center):&lt;/strong&gt; \(a_{ii}\) (ph·∫ßn t·ª≠ ch√©o th·ª© \(i\))&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;B√°n k√≠nh (radius):&lt;/strong&gt; $$r_i = \sum_{j \neq i}&lt;/td&gt;
          &lt;td&gt;a_{ij}&lt;/td&gt;
          &lt;td&gt;\((t·ªïng gi√° tr·ªã tuy·ªát ƒë·ªëi c√°c ph·∫ßn t·ª≠ ngo√†i ƒë∆∞·ªùng ch√©o ·ªü h√†ng\)i$$)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ƒê·ªãnh l√Ω:&lt;/strong&gt; M·ªçi gi√° tr·ªã ri√™ng c·ªßa \(\mathbf{A}\) n·∫±m trong h·ª£p c·ªßa c√°c ƒëƒ©a Gershgorin:&lt;/p&gt;

\[D_i = \{z \in \mathbb{C} : |z - a_{ii}| \leq r_i\}\]

&lt;h3 id=&quot;v√≠-d·ª•&quot;&gt;V√≠ D·ª•&lt;/h3&gt;

&lt;p&gt;X√©t ma tr·∫≠n: \(\mathbf{A} = \begin{pmatrix} 4 &amp;amp; 0.3 &amp;amp; 0.2 \\ 0.3 &amp;amp; 5 &amp;amp; 0.1 \\ 0.2 &amp;amp; 0.1 &amp;amp; 3 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;C√°c ƒëƒ©a Gershgorin:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(D_1\): t√¢m = 4, b√°n k√≠nh = 0.5, n√™n \(3.5 \leq \lambda \leq 4.5\)&lt;/li&gt;
  &lt;li&gt;\(D_2\): t√¢m = 5, b√°n k√≠nh = 0.4, n√™n \(4.6 \leq \lambda \leq 5.4\)&lt;/li&gt;
  &lt;li&gt;\(D_3\): t√¢m = 3, b√°n k√≠nh = 0.3, n√™n \(2.7 \leq \lambda \leq 3.3\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;K·∫øt lu·∫≠n:&lt;/strong&gt; T·∫•t c·∫£ gi√° tr·ªã ri√™ng ph·∫£i n·∫±m trong \([2.7, 5.4]\).&lt;/p&gt;

&lt;h3 id=&quot;·ª©ng-d·ª•ng-th·ª±c-t·∫ø&quot;&gt;·ª®ng D·ª•ng Th·ª±c T·∫ø&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Ki·ªÉm tra nhanh t√≠nh positive definite:&lt;/strong&gt; N·∫øu t·∫•t c·∫£ ƒëƒ©a Gershgorin n·∫±m b√™n ph·∫£i tr·ª•c t∆∞·ªüng, ma tr·∫≠n c√≥ th·ªÉ l√† positive definite&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;∆Ø·ªõc l∆∞·ª£ng condition number:&lt;/strong&gt; Gi√∫p ƒë√°nh gi√° ƒë·ªô ·ªïn ƒë·ªãnh s·ªë h·ªçc&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Thi·∫øt k·∫ø ma tr·∫≠n:&lt;/strong&gt; ƒê·∫£m b·∫£o c√°c thu·ªôc t√≠nh mong mu·ªën b·∫±ng c√°ch ƒëi·ªÅu ch·ªânh ph·∫ßn t·ª≠ ch√©o v√† ngo√†i ƒë∆∞·ªùng ch√©o&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;diagonalization&quot;&gt;Diagonalization&lt;/h2&gt;

&lt;p&gt;A matrix \(\mathbf{A}\) is &lt;strong&gt;diagonalizable&lt;/strong&gt; if it can be written as:&lt;/p&gt;

\[\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{D}\) is a diagonal matrix of eigenvalues&lt;/li&gt;
  &lt;li&gt;\(\mathbf{P}\) is a matrix whose columns are the corresponding eigenvectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;benefits-of-diagonalization&quot;&gt;Benefits of Diagonalization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Easy computation of powers:&lt;/strong&gt; \(\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Understanding behavior:&lt;/strong&gt; The eigenvalues determine the transformation‚Äôs behavior along each eigenvector direction&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;·ª©ng-d·ª•ng-h√†nh-vi-c·ªßa-ph√©p-nh√¢n-ma-tr·∫≠n-l·∫∑p&quot;&gt;·ª®ng D·ª•ng: H√†nh Vi c·ªßa Ph√©p Nh√¢n Ma Tr·∫≠n L·∫∑p&lt;/h2&gt;

&lt;p&gt;M·ªôt ·ª©ng d·ª•ng quan tr·ªçng c·ªßa eigenvalues l√† hi·ªÉu h√†nh vi c·ªßa vi·ªác nh√¢n ma tr·∫≠n l·∫∑p l·∫°i: \(\mathbf{A}\mathbf{x}, \mathbf{A}^2\mathbf{x}, \mathbf{A}^3\mathbf{x}, \ldots\)&lt;/p&gt;

&lt;h3 id=&quot;vector-ri√™ng-v√†-h√†nh-vi-d√†i-h·∫°n&quot;&gt;Vector Ri√™ng v√† H√†nh Vi D√†i H·∫°n&lt;/h3&gt;

&lt;p&gt;Gi·∫£ s·ª≠ ma tr·∫≠n \(\mathbf{A}\) c√≥ eigendecomposition:&lt;/p&gt;

\[\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}\]

&lt;p&gt;Khi ƒë√≥:&lt;/p&gt;

\[\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1} = \mathbf{P}\begin{pmatrix} \lambda_1^k &amp;amp; 0 &amp;amp; \cdots \\ 0 &amp;amp; \lambda_2^k &amp;amp; \cdots \\ \vdots &amp;amp; \vdots &amp;amp; \ddots \end{pmatrix}\mathbf{P}^{-1}\]

&lt;p&gt;&lt;strong&gt;Quan s√°t quan tr·ªçng:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;**N·∫øu $$&lt;/td&gt;
          &lt;td&gt;\lambda_{\max}&lt;/td&gt;
          &lt;td&gt;&amp;gt; 1$$:** Vector s·∫Ω tƒÉng theo c·∫•p s·ªë nh√¢n (explode)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;**N·∫øu $$&lt;/td&gt;
          &lt;td&gt;\lambda_{\max}&lt;/td&gt;
          &lt;td&gt;&amp;lt; 1$$:** Vector s·∫Ω gi·∫£m d·∫ßn v·ªÅ 0 (vanish)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;**N·∫øu $$&lt;/td&gt;
          &lt;td&gt;\lambda_{\max}&lt;/td&gt;
          &lt;td&gt;= 1$$:** Vector s·∫Ω ·ªïn ƒë·ªãnh ho·∫∑c dao ƒë·ªông&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;v√≠-d·ª•-ma-tr·∫≠n-ng·∫´u-nhi√™n&quot;&gt;V√≠ D·ª•: Ma Tr·∫≠n Ng·∫´u Nhi√™n&lt;/h3&gt;

&lt;p&gt;X√©t ma tr·∫≠n ng·∫´u nhi√™n \(5 \times 5\) v·ªõi c√°c ph·∫ßn t·ª≠ tu√¢n theo ph√¢n ph·ªëi Gaussian chu·∫©n (mean = 0, variance = 1).&lt;/p&gt;

&lt;p&gt;N·∫øu ta √°p d·ª•ng ma tr·∫≠n n√†y l√™n m·ªôt vector ng·∫´u nhi√™n nhi·ªÅu l·∫ßn, ta quan s√°t:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ƒê·ªô d√†i c·ªßa vector tƒÉng theo c·∫•p s·ªë nh√¢n&lt;/li&gt;
  &lt;li&gt;T·ªëc ƒë·ªô tƒÉng ƒë∆∞·ª£c chi ph·ªëi b·ªüi gi√° tr·ªã ri√™ng l·ªõn nh·∫•t \(\lambda_{\max}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;ƒê·ªãnh lu·∫≠t Circular Law:&lt;/strong&gt; ƒê·ªëi v·ªõi ma tr·∫≠n ng·∫´u nhi√™n l·ªõn \(n \times n\) v·ªõi c√°c ph·∫ßn t·ª≠ ƒë·ªôc l·∫≠p, mean = 0, variance = 1, gi√° tr·ªã ri√™ng l·ªõn nh·∫•t trung b√¨nh x·∫•p x·ªâ \(\sqrt{n}\).&lt;/p&gt;

&lt;h3 id=&quot;chu·∫©n-h√≥a-ma-tr·∫≠n&quot;&gt;Chu·∫©n H√≥a Ma Tr·∫≠n&lt;/h3&gt;

&lt;p&gt;ƒê·ªÉ ki·ªÉm so√°t h√†nh vi n√†y, ta c√≥ th·ªÉ chu·∫©n h√≥a ma tr·∫≠n:&lt;/p&gt;

\[\mathbf{A}_{\text{normalized}} = \frac{\mathbf{A}}{\lambda_{\max}}\]

&lt;p&gt;Sau khi chu·∫©n h√≥a:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Gi√° tr·ªã ri√™ng l·ªõn nh·∫•t = 1&lt;/li&gt;
  &lt;li&gt;Vector kh√¥ng tƒÉng ho·∫∑c gi·∫£m theo c·∫•p s·ªë nh√¢n&lt;/li&gt;
  &lt;li&gt;H√†nh vi ·ªïn ƒë·ªãnh, h·ªôi t·ª• v·ªÅ tr·∫°ng th√°i c√¢n b·∫±ng&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;√Ω-nghƒ©a-trong-deep-learning&quot;&gt;√ù Nghƒ©a Trong Deep Learning&lt;/h3&gt;

&lt;p&gt;Hi·ªán t∆∞·ª£ng n√†y c√≥ √Ω nghƒ©a quan tr·ªçng trong neural networks:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Vanishing/Exploding Gradients:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;N·∫øu c√°c tr·ªçng s·ªë (weights) c√≥ eigenvalues qu√° l·ªõn ‚Üí gradients explode&lt;/li&gt;
      &lt;li&gt;N·∫øu eigenvalues qu√° nh·ªè ‚Üí gradients vanish&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Kh·ªüi T·∫°o Tr·ªçng S·ªë (Weight Initialization):&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;C·∫ßn kh·ªüi t·∫°o sao cho eigenvalues g·∫ßn 1&lt;/li&gt;
      &lt;li&gt;C√°c ph∆∞∆°ng ph√°p nh∆∞ Xavier/He initialization d·ª±a tr√™n nguy√™n l√Ω n√†y&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Batch Normalization:&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Gi√∫p ki·ªÉm so√°t ph√¢n ph·ªëi c·ªßa activations&lt;/li&gt;
      &lt;li&gt;NgƒÉn ch·∫∑n exploding/vanishing trong qu√° tr√¨nh training&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Residual Connections (ResNet):&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Th√™m skip connections gi√∫p gradient flow t·ªët h∆°n&lt;/li&gt;
      &lt;li&gt;T∆∞∆°ng ƒë∆∞∆°ng v·ªõi vi·ªác th√™m ma tr·∫≠n ƒë∆°n v·ªã, ƒë·∫£m b·∫£o eigenvalue = 1&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;ph√¢n-t√≠ch-h·ªôi-t·ª•-c·ªßa-thu·∫≠t-to√°n&quot;&gt;Ph√¢n T√≠ch H·ªôi T·ª• C·ªßa Thu·∫≠t To√°n&lt;/h3&gt;

&lt;p&gt;Trong c√°c thu·∫≠t to√°n l·∫∑p (nh∆∞ gradient descent, power iteration):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;T·ªëc ƒë·ªô h·ªôi t·ª•&lt;/strong&gt; ph·ª• thu·ªôc v√†o t·ª∑ s·ªë c·ªßa c√°c eigenvalues:&lt;/p&gt;

\[\text{Convergence rate} \propto \left|\frac{\lambda_2}{\lambda_1}\right|\]

&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;N·∫øu $$&lt;/td&gt;
          &lt;td&gt;\lambda_2&lt;/td&gt;
          &lt;td&gt;\ll&lt;/td&gt;
          &lt;td&gt;\lambda_1&lt;/td&gt;
          &lt;td&gt;$$: H·ªôi t·ª• nhanh&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;N·∫øu $$&lt;/td&gt;
          &lt;td&gt;\lambda_2&lt;/td&gt;
          &lt;td&gt;\approx&lt;/td&gt;
          &lt;td&gt;\lambda_1&lt;/td&gt;
          &lt;td&gt;$$: H·ªôi t·ª• ch·∫≠m&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Power Iteration Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;B·∫Øt ƒë·∫ßu v·ªõi vector ng·∫´u nhi√™n \(\mathbf{v}_0\)&lt;/li&gt;
  &lt;li&gt;L·∫∑p: \(\mathbf{v}_{k+1} = \frac{\mathbf{A}\mathbf{v}_k}{\|\mathbf{A}\mathbf{v}_k\|}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Vector s·∫Ω h·ªôi t·ª• v·ªÅ eigenvector t∆∞∆°ng ·ª©ng v·ªõi $$&lt;/td&gt;
          &lt;td&gt;\lambda_{\max}&lt;/td&gt;
          &lt;td&gt;$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ƒê√¢y l√† c∆° s·ªü cho nhi·ªÅu thu·∫≠t to√°n t√≠nh eigenvalues/eigenvectors hi·ªáu qu·∫£.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Eigenvalues and eigenvectors are crucial in deep-learning for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-quadratic-forms-and-definiteness&quot;&gt;1. Quadratic Forms and Definiteness&lt;/h3&gt;

&lt;p&gt;For a quadratic function \(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;gt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues of \(\mathbf{Q}\) are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite&lt;/strong&gt; (\(f(\mathbf{x}) \geq 0\)): All eigenvalues are non-negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Negative definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;lt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues are negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Indefinite&lt;/strong&gt; (\(f(\mathbf{x})\) can be positive or negative): Mixed positive and negative eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-second-order-optimality-conditions&quot;&gt;2. Second-Order Optimality Conditions&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) at a critical point \(\mathbf{x}^*\) (where \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; Hessian \(\nabla^2 f(\mathbf{x}^*)\) is positive definite (all eigenvalues &amp;gt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local maximum:&lt;/strong&gt; Hessian is negative definite (all eigenvalues &amp;lt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Saddle point:&lt;/strong&gt; Hessian is indefinite (mixed eigenvalues)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-principal-component-analysis-pca&quot;&gt;3. Principal Component Analysis (PCA)&lt;/h3&gt;

&lt;p&gt;PCA finds the directions of maximum variance in data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Eigenvectors of the covariance matrix give the principal directions&lt;/li&gt;
  &lt;li&gt;Eigenvalues give the variance along each principal direction&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;In iterative deep-learning algorithms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;condition number&lt;/strong&gt; \(\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}\) affects convergence speed&lt;/li&gt;
  &lt;li&gt;Large condition numbers lead to slow convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-newtons-method&quot;&gt;5. Newton‚Äôs Method&lt;/h3&gt;

&lt;p&gt;Newton‚Äôs method uses the inverse Hessian:
\(\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\)&lt;/p&gt;

&lt;p&gt;The eigenvalues of the Hessian determine the method‚Äôs behavior and convergence rate.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-deep-learning-application&quot;&gt;Example: Deep Learning Application&lt;/h2&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = 2x^2 + 3y^2 + 2xy\).&lt;/p&gt;

&lt;p&gt;The Hessian is: \(\mathbf{H} = \begin{pmatrix} 4 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding eigenvalues:&lt;/strong&gt;
\(\det(\mathbf{H} - \lambda\mathbf{I}) = (4-\lambda)(6-\lambda) - 4 = \lambda^2 - 10\lambda + 20 = 0\)&lt;/p&gt;

\[\lambda = \frac{10 \pm \sqrt{100-80}}{2} = \frac{10 \pm 2\sqrt{5}}{2} = 5 \pm \sqrt{5}\]

&lt;p&gt;Since both eigenvalues are positive (\(\lambda_1 = 5 + \sqrt{5} &amp;gt; 0\) and \(\lambda_2 = 5 - \sqrt{5} &amp;gt; 0\)), the Hessian is positive definite, confirming that the origin is a global minimum.&lt;/p&gt;

&lt;p&gt;The condition number is \(\kappa = \frac{5 + \sqrt{5}}{5 - \sqrt{5}} \approx 4.24\), indicating reasonably good conditioning for deep-learning algorithms.&lt;/p&gt;

&lt;p&gt;Understanding eigenvalues and eigenvectors provides deep insights into the geometric and analytical properties of deep-learning problems, enabling better algorithm design and convergence analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-02 Ma tr·∫≠n v√† Ph√©p bi·∫øn ƒë·ªïi Tuy·∫øn t√≠nh</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_02_02_Matrices_and_Linear_Transformations</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm ma tr·∫≠n, c√°c ph√©p to√°n ma tr·∫≠n, v√† ph√©p bi·∫øn ƒë·ªïi tuy·∫øn t√≠nh, l√† nh·ªØng c√¥ng c·ª• c∆° b·∫£n ƒë·ªÉ bi·ªÉu di·ªÖn v√† gi·∫£i quy·∫øt c√°c b√†i to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ma-tr·∫≠n-v√†-c√°c-ph√©p-to√°n-ma-tr·∫≠n&quot;&gt;Ma tr·∫≠n v√† C√°c Ph√©p to√°n Ma tr·∫≠n&lt;/h2&gt;

&lt;h3 id=&quot;ma-tr·∫≠n-l√†-g√¨&quot;&gt;Ma tr·∫≠n l√† g√¨?&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;matrix&lt;/strong&gt; is a rectangular grid of numbers arranged in rows and columns. Matrices represent data, transformations, systems of equations, and relationships between variables.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General Form:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 
a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\
a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}
\end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This is an \(m \times n\) matrix (\(m\) rows, \(n\) columns).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\) is a \(2 \times 3\) matrix.&lt;/p&gt;

&lt;h3 id=&quot;matrix-addition&quot;&gt;Matrix Addition&lt;/h3&gt;

&lt;p&gt;Matrices are added by summing corresponding elements. Both matrices must have the same dimensions.&lt;/p&gt;

\[\mathbf{A} + \mathbf{B} = \begin{pmatrix} a_{11} + b_{11} &amp;amp; a_{12} + b_{12} \\ a_{21} + b_{21} &amp;amp; a_{22} + b_{22} \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} + \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 6 &amp;amp; 8 \\ 10 &amp;amp; 12 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;scalar-multiplication&quot;&gt;Scalar Multiplication&lt;/h3&gt;

&lt;p&gt;Multiply every element of the matrix by the scalar:&lt;/p&gt;

\[c\mathbf{A} = \begin{pmatrix} ca_{11} &amp;amp; ca_{12} \\ ca_{21} &amp;amp; ca_{22} \end{pmatrix}\]

&lt;h3 id=&quot;matrix-multiplication&quot;&gt;Matrix Multiplication&lt;/h3&gt;

&lt;p&gt;For matrices \(\mathbf{A}_{m \times n}\) and \(\mathbf{B}_{n \times p}\), the product \(\mathbf{C}_{m \times p}\) is formed by taking the dot product of rows from \(\mathbf{A}\) and columns from \(\mathbf{B}\):&lt;/p&gt;

\[c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 1 \cdot 5 + 2 \cdot 7 &amp;amp; 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 &amp;amp; 3 \cdot 6 + 4 \cdot 8 \end{pmatrix} = \begin{pmatrix} 19 &amp;amp; 22 \\ 43 &amp;amp; 50 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Matrix multiplication is &lt;strong&gt;not commutative&lt;/strong&gt;: \(\mathbf{AB} \neq \mathbf{BA}\) in general.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;linear transformation&lt;/strong&gt; is a function \(T: \mathbb{R}^n \to \mathbb{R}^m\) that preserves vector addition and scalar multiplication. Every linear transformation can be represented by a matrix.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;A transformation \(T(\mathbf{v}) = \mathbf{Av}\) is linear if and only if:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Additivity:&lt;/strong&gt; \(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; \(T(c\mathbf{v}) = cT(\mathbf{v})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These can be combined into: \(T(c_1\mathbf{u} + c_2\mathbf{v}) = c_1T(\mathbf{u}) + c_2T(\mathbf{v})\)&lt;/p&gt;

&lt;h3 id=&quot;matrix-vector-multiplication&quot;&gt;Matrix-Vector Multiplication&lt;/h3&gt;

&lt;p&gt;If \(\mathbf{A}\) is an \(m \times n\) matrix and \(\mathbf{v}\) is an \(n \times 1\) column vector, their product \(\mathbf{Av}\) is an \(m \times 1\) column vector:&lt;/p&gt;

\[\mathbf{w} = \mathbf{Av} = \begin{pmatrix} 
a_{11}v_1 + a_{12}v_2 + \cdots + a_{1n}v_n \\
a_{21}v_1 + a_{22}v_2 + \cdots + a_{2n}v_n \\
\vdots \\
a_{m1}v_1 + a_{m2}v_2 + \cdots + a_{mn}v_n
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 2 &amp;amp; 1 \\ 0 &amp;amp; 3 \end{pmatrix} \begin{pmatrix} 4 \\ 5 \end{pmatrix} = \begin{pmatrix} 2 \cdot 4 + 1 \cdot 5 \\ 0 \cdot 4 + 3 \cdot 5 \end{pmatrix} = \begin{pmatrix} 13 \\ 15 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;common-2d-transformations&quot;&gt;Common 2D Transformations&lt;/h2&gt;

&lt;p&gt;Understanding geometric transformations helps visualize how matrices affect vectors.&lt;/p&gt;

&lt;h3 id=&quot;scaling&quot;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Scaling Matrix:&lt;/strong&gt;
\(\mathbf{S} = \begin{pmatrix} s_x &amp;amp; 0 \\ 0 &amp;amp; s_y \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scales x-coordinates by \(s_x\) and y-coordinates by \(s_y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; \(\begin{pmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; 3 \end{pmatrix}\) doubles x-values and triples y-values&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Rotation Matrix (counter-clockwise by angle \(\theta\)):&lt;/strong&gt;
\(\mathbf{R} = \begin{pmatrix} \cos\theta &amp;amp; -\sin\theta \\ \sin\theta &amp;amp; \cos\theta \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; 90¬∞ rotation: \(\begin{pmatrix} 0 &amp;amp; -1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Transforms \((x, y) \mapsto (-y, x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Reflection across x-axis:&lt;/strong&gt;
\(\mathbf{F}_x = \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across y-axis:&lt;/strong&gt;
\(\mathbf{F}_y = \begin{pmatrix} -1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across line \(y = x\):&lt;/strong&gt;
\(\mathbf{F}_{y=x} = \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;shearing&quot;&gt;Shearing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Horizontal Shear:&lt;/strong&gt;
\(\mathbf{H} = \begin{pmatrix} 1 &amp;amp; k \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Transforms \((x, y) \mapsto (x + ky, y)\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;special-types-of-matrices&quot;&gt;Special Types of Matrices&lt;/h2&gt;

&lt;h3 id=&quot;identity-matrix&quot;&gt;Identity Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;identity matrix&lt;/strong&gt; \(\mathbf{I}\) acts like the number 1 for matrix multiplication:&lt;/p&gt;

\[\mathbf{I}_n = \begin{pmatrix} 
1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Property:&lt;/strong&gt; \(\mathbf{AI} = \mathbf{IA} = \mathbf{A}\) for any compatible matrix \(\mathbf{A}\).&lt;/p&gt;

&lt;h3 id=&quot;transpose&quot;&gt;Transpose&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;transpose&lt;/strong&gt; \(\mathbf{A}^T\) flips a matrix across its main diagonal:&lt;/p&gt;

\[\text{If } \mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}, \text{ then } \mathbf{A}^T = \begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(\mathbf{A}^T)^T = \mathbf{A}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{A} + \mathbf{B})^T = \mathbf{A}^T + \mathbf{B}^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{AB})^T = \mathbf{B}^T\mathbf{A}^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;symmetric-matrices&quot;&gt;Symmetric Matrices&lt;/h3&gt;

&lt;p&gt;A matrix is &lt;strong&gt;symmetric&lt;/strong&gt; if \(\mathbf{A} = \mathbf{A}^T\):&lt;/p&gt;

\[\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;Symmetric matrices have special properties important in deep-learning.&lt;/p&gt;

&lt;h3 id=&quot;inverse-matrix&quot;&gt;Inverse Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;inverse&lt;/strong&gt; \(\mathbf{A}^{-1}\) of a square matrix \(\mathbf{A}\) satisfies:&lt;/p&gt;

\[\mathbf{A}\mathbf{A}^{-1} = \mathbf{A}^{-1}\mathbf{A} = \mathbf{I}\]

&lt;p&gt;&lt;strong&gt;For 2√ó2 matrices:&lt;/strong&gt;
\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{pmatrix} d &amp;amp; -b \\ -c &amp;amp; a \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{A} = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d \end{pmatrix}\) and \(\det(\mathbf{A}) = ad - bc\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Not all matrices have inverses. A matrix is &lt;strong&gt;invertible&lt;/strong&gt; (non-singular) if and only if its determinant is non-zero.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Matrices and linear transformations are fundamental in deep-learning for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-system-of-linear-equations&quot;&gt;1. System of Linear Equations&lt;/h3&gt;

&lt;p&gt;Many deep-learning problems involve solving \(\mathbf{Ax} = \mathbf{b}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Unique solution:&lt;/strong&gt; \(\mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\) (when \(\mathbf{A}\) is invertible)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Least squares:&lt;/strong&gt; Minimize \(\|\mathbf{Ax} - \mathbf{b}\|^2\) when no exact solution exists&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-quadratic-forms&quot;&gt;2. Quadratic Forms&lt;/h3&gt;

&lt;p&gt;Quadratic functions appear frequently in deep-learning:
\(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x} + d\)&lt;/p&gt;

&lt;p&gt;The matrix \(\mathbf{Q}\) determines the curvature properties of the function.&lt;/p&gt;

&lt;h3 id=&quot;3-linear-programming&quot;&gt;3. Linear Programming&lt;/h3&gt;

&lt;p&gt;Standard form: Minimize \(\mathbf{c}^T\mathbf{x}\) subject to \(\mathbf{Ax} = \mathbf{b}\), \(\mathbf{x} \geq \mathbf{0}\)&lt;/p&gt;

&lt;h3 id=&quot;4-constraint-representation&quot;&gt;4. Constraint Representation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Equality constraints:&lt;/strong&gt; \(\mathbf{Ax} = \mathbf{b}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inequality constraints:&lt;/strong&gt; \(\mathbf{Ax} \leq \mathbf{b}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-transformations-of-variables&quot;&gt;5. Transformations of Variables&lt;/h3&gt;

&lt;p&gt;Change of variables: \(\mathbf{y} = \mathbf{T}\mathbf{x}\) can simplify deep-learning problems.&lt;/p&gt;

&lt;h3 id=&quot;example-portfolio-deep-learning&quot;&gt;Example: Portfolio Deep Learning&lt;/h3&gt;

&lt;p&gt;In finance, we might minimize portfolio risk:
\(\text{minimize } \mathbf{w}^T\mathbf{\Sigma}\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{w}\) is the vector of portfolio weights and \(\mathbf{\Sigma}\) is the covariance matrix of asset returns.&lt;/p&gt;

&lt;p&gt;Understanding matrices and linear transformations provides the tools to formulate, analyze, and solve a wide variety of deep-learning problems efficiently.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-01 Vector v√† Kh√¥ng gian Vector</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_02_01_Vectors_and_Vector_Spaces</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y gi·ªõi thi·ªáu vector, kh√¥ng gian vector, v√† c√°c kh√°i ni·ªám c∆° b·∫£n t·∫°o n·ªÅn t·∫£ng ƒë·ªÉ hi·ªÉu ƒë·∫°i s·ªë tuy·∫øn t√≠nh trong ng·ªØ c·∫£nh t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vector-v√†-kh√¥ng-gian-vector-mathbbrn&quot;&gt;Vector v√† Kh√¥ng gian Vector (\(\mathbb{R}^n\))&lt;/h2&gt;

&lt;h3 id=&quot;vector-l√†-g√¨&quot;&gt;Vector l√† g√¨?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vector:&lt;/strong&gt; H√£y nghƒ© v·ªÅ vector nh∆∞ m·ªôt m≈©i t√™n trong kh√¥ng gian, bi·ªÉu di·ªÖn c·∫£ h∆∞·ªõng v√† ƒë·ªô l·ªõn (ƒë·ªô d√†i). V·ªÅ m·∫∑t to√°n h·ªçc, n√≥ l√† m·ªôt danh s√°ch c√≥ th·ª© t·ª± c√°c s·ªë, gi·ªëng nh∆∞ t·ªça ƒë·ªô. V√≠ d·ª•, m·ªôt vector trong kh√¥ng gian 2D c√≥ th·ªÉ l√† \(\mathbf{v} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\), c√≥ nghƒ©a l√† 3 ƒë∆°n v·ªã d·ªçc theo tr·ª•c x v√† 4 ƒë∆°n v·ªã d·ªçc theo tr·ª•c y.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;G√≥c nh√¨n H√¨nh h·ªçc vs ƒê·∫°i s·ªë:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;H√¨nh h·ªçc:&lt;/strong&gt; Vector l√† m≈©i t√™n c√≥ h∆∞·ªõng v√† ƒë·ªô l·ªõn&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;ƒê·∫°i s·ªë:&lt;/strong&gt; Vector l√† danh s√°ch c√≥ th·ª© t·ª± c√°c s·ªë th·ª±c&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;kh√¥ng-gian-vector&quot;&gt;Kh√¥ng gian Vector&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kh√¥ng gian Vector (\(\mathbb{R}^n\)):&lt;/strong&gt; ƒê√¢y l√† t·∫≠p h·ª£p t·∫•t c·∫£ c√°c vector c√≥ th·ªÉ c√≥ \(n\) th√†nh ph·∫ßn (s·ªë). V√≠ d·ª•, \(\mathbb{R}^2\) bao g·ªìm t·∫•t c·∫£ vector 2 th√†nh ph·∫ßn, bi·ªÉu di·ªÖn t·∫•t c·∫£ c√°c ƒëi·ªÉm ho·∫∑c m≈©i t√™n trong m·∫∑t ph·∫≥ng 2D.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;\(\mathbb{R}^2 = \left\{\begin{pmatrix} x \\ y \end{pmatrix} : x, y \in \mathbb{R}\right\}\) (m·∫∑t ph·∫≥ng)&lt;/li&gt;
      &lt;li&gt;\(\mathbb{R}^3 = \left\{\begin{pmatrix} x \\ y \\ z \end{pmatrix} : x, y, z \in \mathbb{R}\right\}\) (kh√¥ng gian 3D)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c√°c-ph√©p-to√°n-vector&quot;&gt;C√°c Ph√©p to√°n Vector&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ph√©p C·ªông Vector:&lt;/strong&gt;
\(\mathbf{u} + \mathbf{v} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \\ \vdots \\ u_n + v_n \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph√©p Nh√¢n V√¥ h∆∞·ªõng:&lt;/strong&gt;
\(c\mathbf{v} = c \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} cv_1 \\ cv_2 \\ \vdots \\ cv_n \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ƒë·ªôc-l·∫≠p-tuy·∫øn-t√≠nh-c∆°-s·ªü-v√†-chi·ªÅu&quot;&gt;ƒê·ªôc l·∫≠p Tuy·∫øn t√≠nh, C∆° s·ªü, v√† Chi·ªÅu&lt;/h2&gt;

&lt;h3 id=&quot;ƒë·ªôc-l·∫≠p-tuy·∫øn-t√≠nh&quot;&gt;ƒê·ªôc l·∫≠p Tuy·∫øn t√≠nh&lt;/h3&gt;

&lt;p&gt;M·ªôt t·∫≠p h·ª£p vector \(\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_k\}\) l√† &lt;strong&gt;ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh&lt;/strong&gt; n·∫øu nghi·ªám duy nh·∫•t c·ªßa:&lt;/p&gt;

\[c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \cdots + c_k\mathbf{v}_k = \mathbf{0}\]

&lt;p&gt;l√† \(c_1 = c_2 = \cdots = c_k = 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hi·ªÉu bi·∫øt Tr·ª±c quan:&lt;/strong&gt; M·ªôt t·∫≠p h·ª£p vector ‚Äúƒë·ªôc l·∫≠p tuy·∫øn t√≠nh‚Äù n·∫øu kh√¥ng c√≥ vector n√†o trong t·∫≠p c√≥ th·ªÉ ƒë∆∞·ª£c t·∫°o ra b·∫±ng c√°ch chia t·ª∑ l·ªá v√† c·ªông c√°c vector kh√°c trong t·∫≠p. T·∫•t c·∫£ ch√∫ng ƒë·ªÅu ch·ªâ theo c√°c h∆∞·ªõng ‚Äúƒë·ªß kh√°c nhau‚Äù.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• trong \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) v√† \(\mathbf{v}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) l√† ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh&lt;/li&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) v√† \(\mathbf{v}_2 = \begin{pmatrix} 2 \\ 4 \end{pmatrix}\) l√† ph·ª• thu·ªôc tuy·∫øn t√≠nh (v√¨ \(\mathbf{v}_2 = 2\mathbf{v}_1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;c∆°-s·ªü&quot;&gt;C∆° s·ªü&lt;/h3&gt;

&lt;p&gt;M·ªôt &lt;strong&gt;c∆° s·ªü&lt;/strong&gt; cho m·ªôt kh√¥ng gian vector l√† m·ªôt t·∫≠p h·ª£p t·ªëi thi·ªÉu c√°c vector ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh c√≥ th·ªÉ ƒë∆∞·ª£c k·∫øt h·ª£p (chia t·ª∑ l·ªá v√† c·ªông) ƒë·ªÉ t·∫°o ra &lt;em&gt;b·∫•t k·ª≥&lt;/em&gt; vector n√†o kh√°c trong kh√¥ng gian ƒë√≥. N√≥ gi·ªëng nh∆∞ m·ªôt t·∫≠p h·ª£p c√°c kh·ªëi x√¢y d·ª±ng c∆° b·∫£n.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh ch·∫•t c·ªßa m·ªôt C∆° s·ªü:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;C√°c vector ƒë·ªôc l·∫≠p tuy·∫øn t√≠nh&lt;/li&gt;
  &lt;li&gt;Ch√∫ng sinh ra to√†n b·ªô kh√¥ng gian vector&lt;/li&gt;
  &lt;li&gt;M·ªçi vector trong kh√¥ng gian c√≥ th·ªÉ ƒë∆∞·ª£c vi·∫øt duy nh·∫•t nh∆∞ m·ªôt t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa c√°c vector c∆° s·ªü&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;C∆° s·ªü Chu·∫©n cho \(\mathbb{R}^n\):&lt;/strong&gt;
\(\mathbf{e}_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, \mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}, \ldots, \mathbf{e}_n = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;chi·ªÅu&quot;&gt;Chi·ªÅu&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Chi·ªÅu&lt;/strong&gt; c·ªßa m·ªôt kh√¥ng gian vector ƒë∆°n gi·∫£n l√† s·ªë l∆∞·ª£ng vector trong b·∫•t k·ª≥ c∆° s·ªü n√†o c·ªßa n√≥. N√≥ cho b·∫°n bi·∫øt c·∫ßn bao nhi√™u h∆∞·ªõng ƒë·ªôc l·∫≠p ƒë·ªÉ m√¥ t·∫£ kh√¥ng gian.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^2) = 2\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^3) = 3\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^n) = n\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chu·∫©n-c·ªßa-vector&quot;&gt;Chu·∫©n c·ªßa Vector&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Chu·∫©n&lt;/strong&gt; l√† m·ªôt h√†m g√°n ‚Äúƒë·ªô d√†i‚Äù ho·∫∑c ‚Äúk√≠ch th∆∞·ªõc‚Äù cho m·ªôt vector. N√≥ t·ªïng qu√°t h√≥a kh√°i ni·ªám kho·∫£ng c√°ch t·ª´ g·ªëc t·ªça ƒë·ªô.&lt;/p&gt;

&lt;h3 id=&quot;t√≠nh-ch·∫•t-c·ªßa-chu·∫©n&quot;&gt;T√≠nh ch·∫•t c·ªßa Chu·∫©n&lt;/h3&gt;

&lt;p&gt;B·∫•t k·ª≥ chu·∫©n \(\|\cdot\|\) n√†o c≈©ng ph·∫£i th·ªèa m√£n ba t√≠nh ch·∫•t:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Kh√¥ng √¢m:&lt;/strong&gt; \(\|\mathbf{x}\| \geq 0\), v√† \(\|\mathbf{x}\| = 0\) khi v√† ch·ªâ khi \(\mathbf{x} = \mathbf{0}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;ƒê·ªìng nh·∫•t:&lt;/strong&gt; $$|t\mathbf{x}| =&lt;/td&gt;
          &lt;td&gt;t&lt;/td&gt;
          &lt;td&gt;|\mathbf{x}|\(v·ªõi b·∫•t k·ª≥ v√¥ h∆∞·ªõng\)t$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;B·∫•t ƒë·∫≥ng th·ª©c Tam gi√°c:&lt;/strong&gt; \(\|\mathbf{x} + \mathbf{y}\| \leq \|\mathbf{x}\| + \|\mathbf{y}\|\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;c√°c-chu·∫©n-th√¥ng-d·ª•ng&quot;&gt;C√°c Chu·∫©n Th√¥ng d·ª•ng&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Chu·∫©n Euclid (Chu·∫©n L2):&lt;/strong&gt;
\(\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2} = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}\)&lt;/p&gt;

&lt;p&gt;ƒê√¢y l√† kho·∫£ng c√°ch ‚Äúth√¥ng th∆∞·ªùng‚Äù m√† ch√∫ng ta quen thu·ªôc.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chu·∫©n Manhattan (Chu·∫©n L1):&lt;/strong&gt;
\(\|\mathbf{x}\|_1 = \sum_{i=1}^n |x_i| = |x_1| + |x_2| + \cdots + |x_n|\)&lt;/p&gt;

&lt;p&gt;C√≤n ƒë∆∞·ª£c g·ªçi l√† ‚Äúchu·∫©n taxi‚Äù - kho·∫£ng c√°ch m√† m·ªôt chi·∫øc taxi s·∫Ω ƒëi trong th√†nh ph·ªë c√≥ b·ªë c·ª•c d·∫°ng l∆∞·ªõi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Chu·∫©n T·ªëi ƒëa (Chu·∫©n L‚àû):&lt;/strong&gt;
\(\|\mathbf{x}\|_\infty = \max_{i} |x_i|\)&lt;/p&gt;

&lt;p&gt;Th√†nh ph·∫ßn l·ªõn nh·∫•t theo gi√° tr·ªã tuy·ªát ƒë·ªëi.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt; V·ªõi \(\mathbf{x} = \begin{pmatrix} 3 \\ -4 \\ 1 \end{pmatrix}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_2 = \sqrt{3^2 + (-4)^2 + 1^2} = \sqrt{26} \approx 5.1\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_1 = |3| + |-4| + |1| = 8\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_\infty = \max\{|3|, |-4|, |1|\} = 4\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;t√≠ch-v√¥-h∆∞·ªõng-t√≠ch-ch·∫•m&quot;&gt;T√≠ch V√¥ h∆∞·ªõng (T√≠ch Ch·∫•m)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;T√≠ch ch·∫•m&lt;/strong&gt; (ho·∫∑c t√≠ch v√¥ h∆∞·ªõng) l√† c√°ch ph·ªï bi·∫øn nh·∫•t ƒë·ªÉ nh√¢n hai vector, t·∫°o ra k·∫øt qu·∫£ v√¥ h∆∞·ªõng.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a&quot;&gt;ƒê·ªãnh nghƒ©a&lt;/h3&gt;

&lt;p&gt;V·ªõi hai vector \(\mathbf{x}\) v√† \(\mathbf{y}\) trong \(\mathbb{R}^n\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = \mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^n x_i y_i = x_1 y_1 + x_2 y_2 + \cdots + x_n y_n\]

&lt;h3 id=&quot;di·ªÖn-gi·∫£i-h√¨nh-h·ªçc&quot;&gt;Di·ªÖn gi·∫£i H√¨nh h·ªçc&lt;/h3&gt;

\[\mathbf{x} \cdot \mathbf{y} = \|\mathbf{x}\| \|\mathbf{y}\| \cos \theta\]

&lt;p&gt;trong ƒë√≥ \(\theta\) l√† g√≥c gi·ªØa c√°c vector.&lt;/p&gt;

&lt;h3 id=&quot;t√≠nh-ch·∫•t&quot;&gt;T√≠nh ch·∫•t&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Giao ho√°n:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \mathbf{y} \cdot \mathbf{x}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ph√¢n ph·ªëi:&lt;/strong&gt; \(\mathbf{x} \cdot (\mathbf{y} + \mathbf{z}) = \mathbf{x} \cdot \mathbf{y} + \mathbf{x} \cdot \mathbf{z}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ƒê·ªìng nh·∫•t:&lt;/strong&gt; \((c\mathbf{x}) \cdot \mathbf{y} = c(\mathbf{x} \cdot \mathbf{y})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tr∆∞·ªùng-h·ª£p-ƒë·∫∑c-bi·ªát&quot;&gt;Tr∆∞·ªùng h·ª£p ƒê·∫∑c bi·ªát&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Vector tr·ª±c giao:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = 0\) (vu√¥ng g√≥c)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vector song song:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \pm \|\mathbf{x}\| \|\mathbf{y}\|\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;T√≠ch ch·∫•m b·∫£n th√¢n:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{x} = \|\mathbf{x}\|_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;v√≠-d·ª•&quot;&gt;V√≠ d·ª•&lt;/h3&gt;

&lt;p&gt;V·ªõi \(\mathbf{x} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) v√† \(\mathbf{y} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = (1)(3) + (2)(4) = 3 + 8 = 11\]

&lt;hr /&gt;

&lt;h2 id=&quot;·ª©ng-d·ª•ng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;·ª®ng d·ª•ng trong T·ªëi ∆∞u h√≥a&lt;/h2&gt;

&lt;p&gt;Hi·ªÉu v·ªÅ vector v√† kh√¥ng gian vector l√† r·∫•t quan tr·ªçng cho t·ªëi ∆∞u h√≥a v√¨:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bi·∫øn Quy·∫øt ƒë·ªãnh:&lt;/strong&gt; C√°c b√†i to√°n t·ªëi ∆∞u h√≥a th∆∞·ªùng li√™n quan ƒë·∫øn vi·ªác t√¨m gi√° tr·ªã t·ªët nh·∫•t cho nhi·ªÅu bi·∫øn, ƒë∆∞·ª£c bi·ªÉu di·ªÖn t·ª± nhi√™n nh∆∞ vector.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt; Gradient c·ªßa m·ªôt h√†m l√† m·ªôt vector ch·ªâ theo h∆∞·ªõng tƒÉng d·ªëc nh·∫•t.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;R√†ng bu·ªôc:&lt;/strong&gt; R√†ng bu·ªôc tuy·∫øn t√≠nh trong t·ªëi ∆∞u h√≥a c√≥ th·ªÉ ƒë∆∞·ª£c bi·ªÉu di·ªÖn b·∫±ng t√≠ch ch·∫•m: \(\mathbf{a}^T \mathbf{x} \leq b\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kho·∫£ng c√°ch v√† ƒê·ªô t∆∞∆°ng t·ª±:&lt;/strong&gt; C√°c chu·∫©n kh√°c nhau cung c·∫•p c√°c c√°ch kh√°c nhau ƒë·ªÉ ƒëo kho·∫£ng c√°ch gi·ªØa c√°c nghi·ªám ho·∫∑c k√≠ch th∆∞·ªõc c·ªßa c√°c thay ƒë·ªïi.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh tr·ª±c giao:&lt;/strong&gt; Nhi·ªÅu kh√°i ni·ªám t·ªëi ∆∞u h√≥a d·ª±a v√†o t√≠nh vu√¥ng g√≥c, ch·∫≥ng h·∫°n nh∆∞ m·ªëi quan h·ªá gi·ªØa gradient v√† ƒë∆∞·ªùng m·ª©c.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T·ªï h·ª£p Tuy·∫øn t√≠nh:&lt;/strong&gt; V√πng kh·∫£ thi th∆∞·ªùng ƒë∆∞·ª£c ƒë·ªãnh nghƒ©a nh∆∞ t·ªï h·ª£p tuy·∫øn t√≠nh c·ªßa vector (bao l·ªìi, h√¨nh n√≥n, v.v.).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Khung kh√¥ng gian vector cung c·∫•p n·ªÅn t·∫£ng to√°n h·ªçc ƒë·ªÉ x√¢y d·ª±ng v√† gi·∫£i quy·∫øt c√°c b√†i to√°n t·ªëi ∆∞u h√≥a m·ªôt c√°ch c√≥ h·ªá th·ªëng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01 Gi·∫£i t√≠ch</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_01_Calculus</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm c√°c kh√°i ni·ªám gi·∫£i t√≠ch c·∫ßn thi·∫øt cho t·ªëi ∆∞u h√≥a, ƒë∆∞·ª£c t·ªï ch·ª©c th√†nh b·ªën ph·∫ßn ch√≠nh ƒë·ªÉ hi·ªÉu r√µ h∆°n.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-04 Chu·ªói Taylor</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_04_Taylor_Series/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_01_04_Taylor_Series</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm vi·ªác khai tri·ªÉn chu·ªói Taylor, ƒëi·ªÅu n√†y r·∫•t c∆° b·∫£n ƒë·ªÉ x·∫•p x·ªâ c√°c h√†m v√† hi·ªÉu h√†nh vi c·ª•c b·ªô c·ªßa c√°c h√†m trong c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ƒë·ªãnh-nghƒ©a-chu·ªói-taylor&quot;&gt;ƒê·ªãnh nghƒ©a Chu·ªói Taylor&lt;/h2&gt;

&lt;p&gt;Chu·ªói Taylor l√† m·ªôt bi·ªÉu di·ªÖn c·ªßa m·ªôt h√†m d∆∞·ªõi d·∫°ng t·ªïng v√¥ h·∫°n c√°c s·ªë h·∫°ng ƒë∆∞·ª£c t√≠nh t·ª´ gi√° tr·ªã c√°c ƒë·∫°o h√†m c·ªßa h√†m t·∫°i m·ªôt ƒëi·ªÉm duy nh·∫•t. N√≥ cung c·∫•p m·ªôt c√°ch ƒë·ªÉ x·∫•p x·ªâ c√°c h√†m ph·ª©c t·∫°p b·∫±ng c√°ch s·ª≠ d·ª•ng ƒëa th·ª©c.&lt;/p&gt;

&lt;h3 id=&quot;chu·ªói-taylor-m·ªôt-bi·∫øn&quot;&gt;Chu·ªói Taylor M·ªôt Bi·∫øn&lt;/h3&gt;

&lt;p&gt;Chu·ªói Taylor l√† m·ªôt khai tri·ªÉn chu·ªói c·ªßa h√†m \(f(x)\) t·∫°i ƒëi·ªÉm \(a\):&lt;/p&gt;

\[f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\]

&lt;p&gt;D∆∞·ªõi d·∫°ng khai tri·ªÉn:&lt;/p&gt;

\[f(x) = f(a) + \frac{f&apos;(a)}{1!}(x-a) + \frac{f&apos;&apos;(a)}{2!}(x-a)^2 + \frac{f&apos;&apos;&apos;(a)}{3!}(x-a)^3 + \dots\]

&lt;h3 id=&quot;chu·ªói-maclaurin&quot;&gt;Chu·ªói Maclaurin&lt;/h3&gt;

&lt;p&gt;Khi khai tri·ªÉn t·∫°i \(a = 0\), chu·ªói Taylor ƒë∆∞·ª£c g·ªçi l√† &lt;strong&gt;chu·ªói Maclaurin&lt;/strong&gt;:&lt;/p&gt;

\[f(x) = f(0) + f&apos;(0)x + \frac{f&apos;&apos;(0)}{2!}x^2 + \frac{f&apos;&apos;&apos;(0)}{3!}x^3 + \dots\]

&lt;h3 id=&quot;c√°c-chu·ªói-maclaurin-th√¥ng-d·ª•ng&quot;&gt;C√°c Chu·ªói Maclaurin Th√¥ng D·ª•ng&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;H√†m M≈©:&lt;/strong&gt;
\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \dots = \sum_{n=0}^{\infty} \frac{x^n}{n!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;H√†m Sin:&lt;/strong&gt;
\(\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;H√†m Cosin:&lt;/strong&gt;
\(\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Logarit T·ª± Nhi√™n (v·ªõi \(|x| &amp;lt; 1\)):&lt;/strong&gt;
\(\ln(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dots = \sum_{n=1}^{\infty} \frac{(-1)^{n+1} x^n}{n}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chu·ªói-taylor-ƒëa-bi·∫øn&quot;&gt;Chu·ªói Taylor ƒêa Bi·∫øn&lt;/h2&gt;

&lt;p&gt;ƒê·ªëi v·ªõi c√°c h√†m nhi·ªÅu bi·∫øn, chu·ªói Taylor tr·ªü n√™n ph·ª©c t·∫°p h∆°n nh∆∞ng tu√¢n theo c√°c nguy√™n l√Ω t∆∞∆°ng t·ª±. Vi·ªác khai tri·ªÉn t·∫°i ƒëi·ªÉm \(\mathbf{x}_0\) li√™n quan ƒë·∫øn c√°c ƒë·∫°o h√†m ri√™ng.&lt;/p&gt;

&lt;h3 id=&quot;khai-tri·ªÉn-taylor-b·∫≠c-nh·∫•t&quot;&gt;Khai tri·ªÉn Taylor B·∫≠c Nh·∫•t&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;X·∫•p x·ªâ tuy·∫øn t√≠nh&lt;/strong&gt; c·ªßa \(f(\mathbf{x})\) t·∫°i \(\mathbf{x}_0\):&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;ƒê√¢y l√† ph∆∞∆°ng tr√¨nh c·ªßa m·∫∑t ph·∫≥ng ti·∫øp tuy·∫øn v·ªõi h√†m t·∫°i \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;khai-tri·ªÉn-taylor-b·∫≠c-hai&quot;&gt;Khai tri·ªÉn Taylor B·∫≠c Hai&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;X·∫•p x·ªâ b·∫≠c hai&lt;/strong&gt; bao g·ªìm th√¥ng tin v·ªÅ ƒë·ªô cong:&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \nabla^2 f(\mathbf{x}_0) (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;trong ƒë√≥ \(\nabla^2 f(\mathbf{x}_0)\) l√† ma tr·∫≠n Hessian t·∫°i \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;d·∫°ng-t·ªïng-qu√°t&quot;&gt;D·∫°ng T·ªïng Qu√°t&lt;/h3&gt;

&lt;p&gt;Chu·ªói Taylor ƒëa bi·∫øn ho√†n ch·ªânh li√™n quan ƒë·∫øn c√°c tensor b·∫≠c cao:&lt;/p&gt;

\[f(\mathbf{x}) = \sum_{|\alpha|=0}^{\infty} \frac{D^{\alpha} f(\mathbf{x}_0)}{\alpha!} (\mathbf{x} - \mathbf{x}_0)^{\alpha}\]

&lt;p&gt;trong ƒë√≥ \(\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_n)\) l√† ch·ªâ s·ªë ƒëa chi·ªÅu.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;·ª©ng-d·ª•ng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;·ª®ng d·ª•ng trong T·ªëi ∆∞u h√≥a&lt;/h2&gt;

&lt;p&gt;Chu·ªói Taylor l√† n·ªÅn t·∫£ng c·ªßa l√Ω thuy·∫øt t·ªëi ∆∞u h√≥a v√† c√°c thu·∫≠t to√°n v√¨ m·ªôt s·ªë l√Ω do:&lt;/p&gt;

&lt;h3 id=&quot;1-x·∫•p-x·ªâ-h√†m-c·ª•c-b·ªô&quot;&gt;1. X·∫•p x·ªâ H√†m C·ª•c b·ªô&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;X·∫•p x·ªâ Tuy·∫øn t√≠nh (Ph∆∞∆°ng ph√°p B·∫≠c Nh·∫•t):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ƒê∆∞·ª£c s·ª≠ d·ª•ng trong c√°c thu·∫≠t to√°n gradient descent&lt;/li&gt;
  &lt;li&gt;Gi·∫£ ƒë·ªãnh h√†m x·∫•p x·ªâ tuy·∫øn t√≠nh trong m·ªôt v√πng l√¢n c·∫≠n nh·ªè&lt;/li&gt;
  &lt;li&gt;K√≠ch th∆∞·ªõc b∆∞·ªõc ph·∫£i ƒë·ªß nh·ªè ƒë·ªÉ x·∫•p x·ªâ c√≥ hi·ªáu l·ª±c&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;X·∫•p x·ªâ B·∫≠c Hai (Ph∆∞∆°ng ph√°p B·∫≠c Hai):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ƒê∆∞·ª£c s·ª≠ d·ª•ng trong ph∆∞∆°ng ph√°p Newton v√† quasi-Newton&lt;/li&gt;
  &lt;li&gt;N·∫Øm b·∫Øt th√¥ng tin ƒë·ªô cong th√¥ng qua Hessian&lt;/li&gt;
  &lt;li&gt;Th∆∞·ªùng cung c·∫•p h·ªôi t·ª• nhanh h∆°n so v·ªõi ph∆∞∆°ng ph√°p b·∫≠c nh·∫•t&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-ƒëi·ªÅu-ki·ªán-t·ªëi-∆∞u&quot;&gt;2. ƒêi·ªÅu ki·ªán T·ªëi ∆∞u&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ƒêi·ªÅu ki·ªán C·∫ßn Thi·∫øt B·∫≠c Nh·∫•t:&lt;/strong&gt;
T·∫°i c·ª±c ti·ªÉu ƒë·ªãa ph∆∞∆°ng \(\mathbf{x}^*\), ta ph·∫£i c√≥ \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).&lt;/p&gt;

&lt;p&gt;ƒêi·ªÅu n√†y xu·∫•t ph√°t t·ª´ khai tri·ªÉn Taylor b·∫≠c nh·∫•t: n·∫øu \(\nabla f(\mathbf{x}^*) \neq \mathbf{0}\), ta c√≥ th·ªÉ di chuy·ªÉn theo h∆∞·ªõng \(-\nabla f(\mathbf{x}^*)\) ƒë·ªÉ gi·∫£m gi√° tr·ªã h√†m.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;ƒêi·ªÅu ki·ªán ƒê·ªß B·∫≠c Hai:&lt;/strong&gt;
N·∫øu \(\nabla f(\mathbf{x}^*) = \mathbf{0}\) v√† \(\nabla^2 f(\mathbf{x}^*)\) l√† x√°c ƒë·ªãnh d∆∞∆°ng, th√¨ \(\mathbf{x}^*\) l√† c·ª±c ti·ªÉu ƒë·ªãa ph∆∞∆°ng.&lt;/p&gt;

&lt;p&gt;ƒêi·ªÅu n√†y xu·∫•t ph√°t t·ª´ khai tri·ªÉn Taylor b·∫≠c hai: s·ªë h·∫°ng b·∫≠c hai chi·∫øm ∆∞u th·∫ø g·∫ßn \(\mathbf{x}^*\).&lt;/p&gt;

&lt;h3 id=&quot;3-thi·∫øt-k·∫ø-thu·∫≠t-to√°n&quot;&gt;3. Thi·∫øt k·∫ø Thu·∫≠t to√°n&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p Newton:&lt;/strong&gt;
S·ª≠ d·ª•ng x·∫•p x·ªâ Taylor b·∫≠c hai ƒë·ªÉ t√¨m c·ª±c ti·ªÉu c·ªßa m√¥ h√¨nh b·∫≠c hai:&lt;/p&gt;

\[\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\]

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p Trust Region:&lt;/strong&gt;
S·ª≠ d·ª•ng x·∫•p x·ªâ Taylor trong v√πng tin c·∫≠y n∆°i x·∫•p x·ªâ ƒë∆∞·ª£c cho l√† ch√≠nh x√°c.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p Line Search:&lt;/strong&gt;
S·ª≠ d·ª•ng khai tri·ªÉn Taylor ƒë·ªÉ x√°c ƒë·ªãnh k√≠ch th∆∞·ªõc b∆∞·ªõc ph√π h·ª£p d·ªçc theo h∆∞·ªõng t√¨m ki·∫øm.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;v√≠-d·ª•-ph√¢n-t√≠ch-h√†m-b·∫≠c-hai&quot;&gt;V√≠ d·ª•: Ph√¢n t√≠ch H√†m B·∫≠c Hai&lt;/h2&gt;

&lt;p&gt;X√©t \(f(x, y) = x^2 + 2xy + 3y^2\) t·∫°i ƒëi·ªÉm \((0, 0)\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt;
\(\nabla f = \begin{pmatrix} 2x + 2y \\ 2x + 6y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;T·∫°i \((0, 0)\): \(\nabla f(0, 0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hessian:&lt;/strong&gt;
\(\nabla^2 f = \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Khai tri·ªÉn Taylor B·∫≠c Hai t·∫°i \((0, 0)\):&lt;/strong&gt;
\(f(x, y) \approx f(0, 0) + 0 + \frac{1}{2} \begin{pmatrix} x &amp;amp; y \end{pmatrix} \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}\)&lt;/p&gt;

\[= 0 + \frac{1}{2}(2x^2 + 4xy + 6y^2) = x^2 + 2xy + 3y^2\]

&lt;p&gt;Trong tr∆∞·ªùng h·ª£p n√†y, h√†m l√† ch√≠nh x√°c b·∫≠c hai, n√™n khai tri·ªÉn Taylor b·∫≠c hai l√† ch√≠nh x√°c.&lt;/p&gt;

&lt;p&gt;V√¨ Hessian c√≥ c√°c gi√° tr·ªã ri√™ng \(\lambda_1 = 2 + 2\sqrt{2} &amp;gt; 0\) v√† \(\lambda_2 = 2 - 2\sqrt{2} &amp;lt; 0\), ƒëi·ªÉm \((0, 0)\) l√† ƒëi·ªÉm y√™n ng·ª±a, kh√¥ng ph·∫£i c·ª±c ti·ªÉu.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;c√°c-xem-x√©t-th·ª±c-t·∫ø&quot;&gt;C√°c Xem x√©t Th·ª±c t·∫ø&lt;/h2&gt;

&lt;h3 id=&quot;h·ªôi-t·ª•-v√†-ƒë·ªô-ch√≠nh-x√°c&quot;&gt;H·ªôi t·ª• v√† ƒê·ªô ch√≠nh x√°c&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;B√°n k√≠nh H·ªôi t·ª•&lt;/strong&gt;: Chu·ªói Taylor ch·ªâ h·ªôi t·ª• trong m·ªôt b√°n k√≠nh nh·∫•t ƒë·ªãnh t·ª´ ƒëi·ªÉm khai tri·ªÉn&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sai s·ªë C·∫Øt b·ªè&lt;/strong&gt;: S·ª≠ d·ª•ng s·ªë h·∫°ng h·ªØu h·∫°n ƒë∆∞a v√†o sai s·ªë x·∫•p x·ªâ&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Chi ph√≠ T√≠nh to√°n&lt;/strong&gt;: C√°c s·ªë h·∫°ng b·∫≠c cao y√™u c·∫ßu t√≠nh to√°n nhi·ªÅu ƒë·∫°o h√†m h∆°n&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;l·ª±a-ch·ªçn-thu·∫≠t-to√°n-t·ªëi-∆∞u-h√≥a&quot;&gt;L·ª±a ch·ªçn Thu·∫≠t to√°n T·ªëi ∆∞u h√≥a&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p b·∫≠c nh·∫•t&lt;/strong&gt; (gradient descent): Ch·ªâ s·ª≠ d·ª•ng th√¥ng tin gradient, ch·∫≠m h∆°n nh∆∞ng r·∫ª h∆°n m·ªói l·∫ßn l·∫∑p&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p b·∫≠c hai&lt;/strong&gt; (Newton): S·ª≠ d·ª•ng th√¥ng tin Hessian, h·ªôi t·ª• nhanh h∆°n nh∆∞ng ƒë·∫Øt m·ªói l·∫ßn l·∫∑p&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ph∆∞∆°ng ph√°p quasi-Newton&lt;/strong&gt;: X·∫•p x·ªâ Hessian, c√¢n b·∫±ng gi·ªØa t·ªëc ƒë·ªô v√† chi ph√≠ t√≠nh to√°n&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Khai tri·ªÉn chu·ªói Taylor gi√∫p ch√∫ng ta x·∫•p x·ªâ c√°c h√†m ph·ª©c t·∫°p v·ªõi c√°c h√†m ƒëa th·ª©c ƒë∆°n gi·∫£n h∆°n xung quanh m·ªôt ƒëi·ªÉm c·ª• th·ªÉ, ƒëi·ªÅu n√†y r·∫•t quan tr·ªçng cho c√°c thu·∫≠t to√°n t·ªëi ∆∞u h√≥a v√† hi·ªÉu h√†nh vi c·ª•c b·ªô c·ªßa c√°c h√†m.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-03 Gradient v√† ƒê·∫°o H√†m Theo H∆∞·ªõng</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_01_03_Gradient_and_Directional_Derivatives</id>
   <content type="html">&lt;p&gt;This lesson explores the gradient vector and directional derivatives, which are central concepts in deep-learning for understanding how functions change in different directions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gradient-vector&quot;&gt;Gradient Vector&lt;/h2&gt;

&lt;p&gt;The gradient \(\nabla f\) is a vector composed of the partial derivatives of the function \(f\) with respect to each of its variables. It indicates the direction of the steepest ascent of the function at a given point.&lt;/p&gt;

&lt;h3 id=&quot;definition-and-computation&quot;&gt;Definition and Computation&lt;/h3&gt;

&lt;p&gt;For a function of two variables, \(f(x, y)\), its gradient is:&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{pmatrix}\]

&lt;p&gt;For a function of \(n\) variables, \(f(x_1, x_2, \ldots, x_n)\):&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;h3 id=&quot;example-computing-a-gradient&quot;&gt;Example: Computing a Gradient&lt;/h3&gt;

&lt;p&gt;For \(f(x, y) = x^2 + 3xy + y^2\):&lt;/p&gt;

&lt;p&gt;\(\frac{\partial f}{\partial x} = 2x + 3y\)
\(\frac{\partial f}{\partial y} = 3x + 2y\)&lt;/p&gt;

&lt;p&gt;Therefore: \(\nabla f = \begin{pmatrix} 2x + 3y \\ 3x + 2y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;At the point \((1, 2)\): \(\nabla f(1, 2) = \begin{pmatrix} 2(1) + 3(2) \\ 3(1) + 2(2) \end{pmatrix} = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;directional-derivatives&quot;&gt;Directional Derivatives&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;directional derivative&lt;/strong&gt; measures the rate of change of \(f\) when we move in any chosen direction \(\mathbf{u}\). Here \(\mathbf{u}\) must be a unit vector (length 1).&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) and unit vector \(\mathbf{u} = \langle u_1, u_2, \ldots, u_n \rangle\):&lt;/p&gt;

\[D_{\mathbf{u}}f(\mathbf{x}) = \nabla f(\mathbf{x}) \cdot \mathbf{u} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} u_i\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;The directional derivative can be written as:&lt;/p&gt;

\[D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\]

&lt;p&gt;where \(\theta\) is the angle between \(\nabla f\) and \(\mathbf{u}\), and \(\lvert \nabla f \rvert\) is the magnitude of the gradient.&lt;/p&gt;

&lt;h3 id=&quot;example-computing-directional-derivatives&quot;&gt;Example: Computing Directional Derivatives&lt;/h3&gt;

&lt;p&gt;Using our previous example \(f(x, y) = x^2 + 3xy + y^2\) at point \((1, 2)\) where \(\nabla f(1, 2) = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 1:&lt;/strong&gt; \(\mathbf{u}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (positive x-direction)
\(D_{\mathbf{u}_1}f(1, 2) = 8 \cdot 1 + 7 \cdot 0 = 8\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 2:&lt;/strong&gt; \(\mathbf{u}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) (positive y-direction)
\(D_{\mathbf{u}_2}f(1, 2) = 8 \cdot 0 + 7 \cdot 1 = 7\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 3:&lt;/strong&gt; \(\mathbf{u}_3 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\) (45¬∞ diagonal)
\(D_{\mathbf{u}_3}f(1, 2) = 8 \cdot \frac{1}{\sqrt{2}} + 7 \cdot \frac{1}{\sqrt{2}} = \frac{15}{\sqrt{2}} \approx 10.61\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;maximum-and-minimum-rates-of-change&quot;&gt;Maximum and Minimum Rates of Change&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;p&gt;From the formula \(D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\), we can determine:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Maximum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 1\) (i.e., \(\theta = 0¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = \frac{\nabla f}{\lvert \nabla f \rvert}\) (same direction as gradient)&lt;/li&gt;
      &lt;li&gt;Maximum rate: \(D_{\max}f = \lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Minimum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = -1\) (i.e., \(\theta = 180¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = -\frac{\nabla f}{\lvert \nabla f \rvert}\) (opposite to gradient)&lt;/li&gt;
      &lt;li&gt;Minimum rate: \(D_{\min}f = -\lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 0\) (i.e., \(\theta = 90¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: Any vector perpendicular to \(\nabla f\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;summary-of-gradient-properties&quot;&gt;Summary of Gradient Properties&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The gradient \(\nabla f\) points in the direction of &lt;strong&gt;steepest increase&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The direction \(-\nabla f\) points in the direction of &lt;strong&gt;steepest decrease&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The magnitude \(\lvert \nabla f \rvert\) gives the &lt;strong&gt;maximum rate of change&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;When \(\nabla f = \mathbf{0}\), the point is a &lt;strong&gt;critical point&lt;/strong&gt; (potential optimum)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;relation-to-level-curves&quot;&gt;Relation to Level Curves&lt;/h2&gt;

&lt;p&gt;At any point on a level curve \(f(x, y) = c\), the gradient vector \(\nabla f\) is &lt;strong&gt;orthogonal (perpendicular)&lt;/strong&gt; to the tangent line of the level curve at that point.&lt;/p&gt;

&lt;h3 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h3&gt;

&lt;p&gt;This orthogonality property is fundamental because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Level curves represent constant function values&lt;/strong&gt;: Moving along a level curve doesn‚Äôt change the function value, so the directional derivative is zero.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient points to steepest increase&lt;/strong&gt;: The direction that increases the function value most rapidly must be perpendicular to the direction that doesn‚Äôt change it at all.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Deep Learning insight&lt;/strong&gt;: To find extrema, we look for points where the gradient is zero (critical points) or where the gradient is perpendicular to the constraint boundary.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h3&gt;

&lt;p&gt;Understanding gradients and directional derivatives is crucial for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: Moving in the direction \(-\nabla f\) to minimize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Ascent&lt;/strong&gt;: Moving in the direction \(+\nabla f\) to maximize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constrained Deep Learning&lt;/strong&gt;: Using the relationship between gradients and level curves&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convergence Analysis&lt;/strong&gt;: Understanding when algorithms will converge to optimal solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step Size Selection&lt;/strong&gt;: Determining how far to move in the gradient direction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The gradient provides both the direction to move and information about how quickly the function is changing, making it the foundation for most deep-learning algorithms.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-02 ƒê·∫°o h√†m v√† Gi·∫£i t√≠ch ƒëa bi·∫øn</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y bao g·ªìm ƒë·∫°o h√†m v√† c√°c kh√°i ni·ªám gi·∫£i t√≠ch ƒëa bi·∫øn thi·∫øt y·∫øu t·∫°o n·ªÅn t·∫£ng cho l√Ω thuy·∫øt v√† thu·∫≠t to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;ƒë·∫°o-h√†m-v√†-t·ªëc-ƒë·ªô-thay-ƒë·ªïi&quot;&gt;ƒê·∫°o h√†m v√† T·ªëc ƒë·ªô Thay ƒë·ªïi&lt;/h2&gt;

&lt;p&gt;ƒê·∫°o h√†m c·ªßa m·ªôt h√†m m·ªôt bi·∫øn th·ªÉ hi·ªán t·ªëc ƒë·ªô thay ƒë·ªïi t·ª©c th·ªùi c·ªßa n√≥, ƒëi·ªÅu n√†y r·∫•t c∆° b·∫£n ƒë·ªÉ hi·ªÉu c√°ch c√°c h√†m s·ªë ho·∫°t ƒë·ªông c·ª•c b·ªô.&lt;/p&gt;

&lt;h3 id=&quot;c√°c-kh√°i-ni·ªám-ƒë·∫°o-h√†m-c∆°-b·∫£n&quot;&gt;C√°c Kh√°i ni·ªám ƒê·∫°o h√†m C∆° b·∫£n&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;ƒê·ªô d·ªëc gi·ªØa hai ƒëi·ªÉm:&lt;/strong&gt;&lt;/p&gt;

\[\text{ƒê·ªô d·ªëc} = \frac{y_2 - y_1}{x_2 - x_1}\]

&lt;p&gt;&lt;strong&gt;ƒê·∫°o h√†m (t·ªëc ƒë·ªô thay ƒë·ªïi t·ª©c th·ªùi):&lt;/strong&gt;&lt;/p&gt;

\[f&apos;(x_0) = \lim_{x_1 \to x_0} \frac{f(x_1) - f(x_0)}{x_1 - x_0} = \lim_{\Delta x \to 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}\]

&lt;p&gt;ƒê·∫°o h√†m cho ch√∫ng ta bi·∫øt h√†m s·ªë thay ƒë·ªïi nhanh nh∆∞ th·∫ø n√†o t·∫°i b·∫•t k·ª≥ ƒëi·ªÉm n√†o, ƒëi·ªÅu n√†y r·∫•t quan tr·ªçng ƒë·ªÉ t√¨m c√°c ƒëi·ªÉm t·ªëi ∆∞u n∆°i t·ªëc ƒë·ªô thay ƒë·ªïi b·∫±ng kh√¥ng.&lt;/p&gt;

&lt;h3 id=&quot;ƒë∆∞·ªùng-m·ª©c-c·ªßa-h√†m-s·ªë&quot;&gt;ƒê∆∞·ªùng m·ª©c c·ªßa H√†m s·ªë&lt;/h3&gt;

&lt;p&gt;ƒê∆∞·ªùng m·ª©c l√† m·ªôt kh√°i ni·ªám c∆° b·∫£n trong gi·∫£i t√≠ch ƒëa bi·∫øn ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ tr·ª±c quan h√≥a c√°c h√†m hai bi·∫øn, th∆∞·ªùng ƒë∆∞·ª£c k√Ω hi·ªáu l√† \(f(x, y)\). Ch√∫ng cung c·∫•p c√°ch bi·ªÉu di·ªÖn m·ªôt b·ªÅ m·∫∑t 3D trong m·∫∑t ph·∫≥ng 2D.&lt;/p&gt;

&lt;p&gt;M·ªôt &lt;strong&gt;ƒë∆∞·ªùng m·ª©c&lt;/strong&gt; c·ªßa h√†m s·ªë \(f(x, y)\) l√† t·∫≠p h·ª£p t·∫•t c·∫£ c√°c ƒëi·ªÉm \((x, y)\) trong mi·ªÅn x√°c ƒë·ªãnh c·ªßa \(f\) n∆°i h√†m s·ªë nh·∫≠n gi√° tr·ªã h·∫±ng s·ªë:&lt;/p&gt;

\[f(x, y) = c\]

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;V·ªõi \(f(x, y) = x^2 + y^2\), c√°c ƒë∆∞·ªùng m·ª©c l√† c√°c h√¨nh tr√≤n: \(x^2 + y^2 = c\)&lt;/li&gt;
  &lt;li&gt;V·ªõi \(f(x, y) = x + y\), c√°c ƒë∆∞·ªùng m·ª©c l√† c√°c ƒë∆∞·ªùng th·∫≥ng song song: \(x + y = c\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;ƒê∆∞·ªùng m·ª©c gi√∫p ch√∫ng ta hi·ªÉu:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;ƒê·ªãa h√¨nh c·ªßa h√†m s·ªë&lt;/li&gt;
  &lt;li&gt;H∆∞·ªõng tƒÉng v√† gi·∫£m d·ªëc nh·∫•t&lt;/li&gt;
  &lt;li&gt;V·ªã tr√≠ c·ªßa c√°c ƒëi·ªÉm t·ªëi ∆∞u ti·ªÅm nƒÉng&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;c√°c-kh√°i-ni·ªám-ch√≠nh-c·ªßa-gi·∫£i-t√≠ch-ƒëa-bi·∫øn&quot;&gt;C√°c Kh√°i ni·ªám Ch√≠nh c·ªßa Gi·∫£i t√≠ch ƒêa bi·∫øn&lt;/h2&gt;

&lt;h3 id=&quot;ƒë·∫°o-h√†m-ri√™ng&quot;&gt;ƒê·∫°o h√†m Ri√™ng&lt;/h3&gt;

&lt;p&gt;V·ªõi m·ªôt h√†m s·ªë \(f(x_1, x_2, \ldots, x_n)\), &lt;strong&gt;ƒë·∫°o h√†m ri√™ng&lt;/strong&gt; theo \(x_i\) l√†:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, \ldots, x_i + h, \ldots, x_n) - f(x_1, \ldots, x_i, \ldots, x_n)}{h}\]

&lt;p&gt;ƒêi·ªÅu n√†y ƒëo l∆∞·ªùng c√°ch \(f\) thay ƒë·ªïi khi ch·ªâ c√≥ \(x_i\) bi·∫øn thi√™n trong khi t·∫•t c·∫£ c√°c bi·∫øn kh√°c gi·ªØ c·ªë ƒë·ªãnh.&lt;/p&gt;

&lt;h3 id=&quot;vector-gradient&quot;&gt;Vector Gradient&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Gradient&lt;/strong&gt; l√† m·ªôt vector g·ªìm t·∫•t c·∫£ c√°c ƒë·∫°o h√†m ri√™ng:&lt;/p&gt;

\[\nabla f(\mathbf{x}) = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;p&gt;Gradient ch·ªâ theo h∆∞·ªõng tƒÉng d·ªëc nh·∫•t c·ªßa h√†m s·ªë v√† vu√¥ng g√≥c v·ªõi c√°c ƒë∆∞·ªùng m·ª©c.&lt;/p&gt;

&lt;h3 id=&quot;ma-tr·∫≠n-hessian&quot;&gt;Ma tr·∫≠n Hessian&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Ma tr·∫≠n Hessian&lt;/strong&gt; ch·ª©a t·∫•t c·∫£ c√°c ƒë·∫°o h√†m ri√™ng b·∫≠c hai:&lt;/p&gt;

\[\nabla^2 f(\mathbf{x}) = \mathbf{H} = \begin{pmatrix} 
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}\]

&lt;p&gt;Hessian cung c·∫•p th√¥ng tin v·ªÅ ƒë·ªô cong c·ªßa h√†m s·ªë v√† r·∫•t quan tr·ªçng cho:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;X√°c ƒë·ªãnh b·∫£n ch·∫•t c·ªßa c√°c ƒëi·ªÉm t·ªõi h·∫°n (c·ª±c ti·ªÉu, c·ª±c ƒë·∫°i, ho·∫∑c ƒëi·ªÉm y√™n ng·ª±a)&lt;/li&gt;
  &lt;li&gt;C√°c ph∆∞∆°ng ph√°p t·ªëi ∆∞u h√≥a b·∫≠c hai nh∆∞ ph∆∞∆°ng ph√°p Newton&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;quy-t·∫Øc-d√¢y-chuy·ªÅn-cho-h√†m-ƒëa-bi·∫øn&quot;&gt;Quy t·∫Øc D√¢y chuy·ªÅn cho H√†m ƒêa bi·∫øn&lt;/h2&gt;

&lt;p&gt;Quy t·∫Øc d√¢y chuy·ªÅn l√† c∆° b·∫£n ƒë·ªÉ t√≠nh ƒë·∫°o h√†m c·ªßa c√°c h√†m h·ª£p th√†nh, th∆∞·ªùng xu·∫•t hi·ªán trong c√°c b√†i to√°n t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;h3 id=&quot;quy-t·∫Øc-d√¢y-chuy·ªÅn-c∆°-b·∫£n&quot;&gt;Quy t·∫Øc D√¢y chuy·ªÅn C∆° b·∫£n&lt;/h3&gt;

&lt;p&gt;V·ªõi h√†m s·ªë \(z = f(x, y)\) n∆°i \(x = g(t)\) v√† \(y = h(t)\):&lt;/p&gt;

\[\frac{dz}{dt} = \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}\]

&lt;h3 id=&quot;quy-t·∫Øc-d√¢y-chuy·ªÅn-t·ªïng-qu√°t&quot;&gt;Quy t·∫Øc D√¢y chuy·ªÅn T·ªïng qu√°t&lt;/h3&gt;

&lt;p&gt;V·ªõi \(z = f(x_1, x_2, \ldots, x_n)\) n∆°i m·ªói \(x_i = x_i(t_1, t_2, \ldots, t_m)\):&lt;/p&gt;

\[\frac{\partial z}{\partial t_j} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} \frac{\partial x_i}{\partial t_j}\]

&lt;h3 id=&quot;·ª©ng-d·ª•ng-trong-t·ªëi-∆∞u-h√≥a&quot;&gt;·ª®ng d·ª•ng trong T·ªëi ∆∞u h√≥a&lt;/h3&gt;

&lt;p&gt;Quy t·∫Øc d√¢y chuy·ªÅn r·∫•t thi·∫øt y·∫øu cho:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;T√≠nh to√°n Gradient&lt;/strong&gt;: T√≠nh gradient c·ªßa c√°c h√†m m·ª•c ti√™u h·ª£p th√†nh&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;X·ª≠ l√Ω R√†ng bu·ªôc&lt;/strong&gt;: X·ª≠ l√Ω c√°c r√†ng bu·ªôc l√† h√†m c·ªßa c√°c bi·∫øn kh√°c&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tri·ªÉn khai Thu·∫≠t to√°n&lt;/strong&gt;: Lan truy·ªÅn ng∆∞·ª£c trong m·∫°ng n∆°-ron v√† vi ph√¢n t·ª± ƒë·ªông&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ph√¢n t√≠ch ƒê·ªô nh·∫°y&lt;/strong&gt;: Hi·ªÉu c√°ch thay ƒë·ªïi tham s·ªë ·∫£nh h∆∞·ªüng ƒë·∫øn c√°c nghi·ªám t·ªëi ∆∞u&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;v√≠-d·ª•-t·ªëi-∆∞u-h√≥a-v·ªõi-r√†ng-bu·ªôc&quot;&gt;V√≠ d·ª•: T·ªëi ∆∞u h√≥a v·ªõi R√†ng bu·ªôc&lt;/h3&gt;

&lt;p&gt;Xem x√©t vi·ªác t·ªëi thi·ªÉu h√≥a \(f(x, y) = x^2 + y^2\) v·ªõi ƒëi·ªÅu ki·ªán \(g(x, y) = x + y - 1 = 0\).&lt;/p&gt;

&lt;p&gt;S·ª≠ d·ª•ng r√†ng bu·ªôc ƒë·ªÉ lo·∫°i b·ªè m·ªôt bi·∫øn: \(y = 1 - x\), v·∫≠y ch√∫ng ta t·ªëi thi·ªÉu h√≥a:
\(h(x) = f(x, 1-x) = x^2 + (1-x)^2\)&lt;/p&gt;

&lt;p&gt;S·ª≠ d·ª•ng quy t·∫Øc d√¢y chuy·ªÅn:
\(h&apos;(x) = \frac{\partial f}{\partial x} \cdot 1 + \frac{\partial f}{\partial y} \cdot \frac{d(1-x)}{dx} = 2x + 2(1-x)(-1) = 4x - 2\)&lt;/p&gt;

&lt;p&gt;ƒê·∫∑t \(h&apos;(x) = 0\) cho \(x = 1/2\), v·∫≠y ƒëi·ªÉm t·ªëi ∆∞u l√† \((1/2, 1/2)\).&lt;/p&gt;

&lt;p&gt;ƒêi·ªÅu n√†y minh h·ªça c√°ch c√°c kh√°i ni·ªám gi·∫£i t√≠ch ƒëa bi·∫øn l√†m vi·ªác c√πng nhau ƒë·ªÉ gi·∫£i quy·∫øt c√°c b√†i to√°n t·ªëi ∆∞u h√≥a m·ªôt c√°ch h·ªá th·ªëng.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-01 T√≠nh li√™n t·ª•c v√† T√≠nh li√™n t·ª•c ƒë·ªÅu</title>
   <link href="http://localhost:4000/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/vi/chapter00/00_01_01_Continuity_and_Uniform_Continuity</id>
   <content type="html">&lt;p&gt;B√†i h·ªçc n√†y gi·ªõi thi·ªáu c√°c kh√°i ni·ªám c∆° b·∫£n v·ªÅ t√≠nh li√™n t·ª•c v√† t√≠nh li√™n t·ª•c ƒë·ªÅu, nh·ªØng kh√°i ni·ªám quan tr·ªçng ƒë·ªÉ hi·ªÉu h√†nh vi c·ªßa c√°c h√†m s·ªë trong t·ªëi ∆∞u h√≥a.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;t√≠nh-li√™n-t·ª•c-v√†-t√≠nh-li√™n-t·ª•c-ƒë·ªÅu&quot;&gt;T√≠nh li√™n t·ª•c v√† T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c&lt;/strong&gt; v√† &lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt; l√† nh·ªØng kh√°i ni·ªám c∆° b·∫£n m√¥ t·∫£ h√†nh vi c·ªßa c√°c h√†m s·ªë, ƒë·∫∑c bi·ªát li√™n quan ƒë·∫øn t√≠nh ‚Äúm∆∞·ª£t m√†‚Äù ho·∫∑c ‚Äúc√≥ th·ªÉ d·ª± ƒëo√°n ƒë∆∞·ª£c‚Äù c·ªßa ch√∫ng. M·∫∑c d√π c√≥ li√™n quan ch·∫∑t ch·∫Ω, ch√∫ng th·ªÉ hi·ªán c√°c t√≠nh ch·∫•t kh√°c bi·ªát, v·ªõi t√≠nh li√™n t·ª•c ƒë·ªÅu l√† ƒëi·ªÅu ki·ªán m·∫°nh h∆°n so v·ªõi t√≠nh li√™n t·ª•c th√¥ng th∆∞·ªùng.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a-t√≠nh-li√™n-t·ª•c&quot;&gt;ƒê·ªãnh nghƒ©a T√≠nh li√™n t·ª•c&lt;/h3&gt;

&lt;p&gt;M·ªôt h√†m s·ªë \(f: A \to \mathbb{R}\) ƒë∆∞·ª£c g·ªçi l√† &lt;strong&gt;li√™n t·ª•c t·∫°i m·ªôt ƒëi·ªÉm&lt;/strong&gt; \(c \in A\) n·∫øu, v·ªõi m·ªçi s·ªë th·ª±c d∆∞∆°ng \(\varepsilon &amp;gt; 0\), t·ªìn t·∫°i m·ªôt s·ªë th·ª±c d∆∞∆°ng \(\delta &amp;gt; 0\) sao cho v·ªõi m·ªçi \(x \in A\), n·∫øu&lt;/p&gt;

\[\lvert x - c \rvert &amp;lt; \delta\]

&lt;p&gt;th√¨&lt;/p&gt;

\[\lvert f(x) - f(c) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;M·ªôt c√°ch tr·ª±c quan, ƒëi·ªÅu n√†y c√≥ nghƒ©a l√† v·ªõi b·∫•t k·ª≥ m·ª©c ƒë·ªô ch√≠nh x√°c mong mu·ªën \(\varepsilon\) n√†o trong ƒë·∫ßu ra \(f(x)\), ch√∫ng ta c√≥ th·ªÉ t√¨m ƒë∆∞·ª£c m·ªôt kho·∫£ng ƒë·ªß nh·ªè xung quanh \(c\) (c√≥ ƒë·ªô r·ªông \(2\delta\)) sao cho t·∫•t c·∫£ c√°c gi√° tr·ªã \(x\) trong kho·∫£ng n√†y √°nh x·∫° t·ªõi c√°c gi√° tr·ªã \(f(x)\) n·∫±m trong kho·∫£ng \(\varepsilon\) xung quanh \(f(c)\). Kh√≠a c·∫°nh quan tr·ªçng ·ªü ƒë√¢y l√† vi·ªác ch·ªçn \(\delta\) th∆∞·ªùng ph·ª• thu·ªôc kh√¥ng ch·ªâ v√†o \(\varepsilon\) m√† c√≤n v√†o ƒëi·ªÉm c·ª• th·ªÉ \(c\).&lt;/p&gt;

&lt;p&gt;M·ªôt h√†m s·ªë &lt;strong&gt;li√™n t·ª•c tr√™n m·ªôt t·∫≠p h·ª£p&lt;/strong&gt; \(A\) n·∫øu n√≥ li√™n t·ª•c t·∫°i m·ªçi ƒëi·ªÉm \(c \in A\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• v·ªÅ c√°c h√†m li√™n t·ª•c&lt;/strong&gt; bao g·ªìm t·∫•t c·∫£ ƒëa th·ª©c (v√≠ d·ª•: \(f(x) = x^2 + 3x - 1\)), c√°c h√†m l∆∞·ª£ng gi√°c nh∆∞ \(\sin(x)\) v√† \(\cos(x)\), v√† c√°c h√†m m≈© \(e^x\) tr√™n mi·ªÅn x√°c ƒë·ªãnh t∆∞∆°ng ·ª©ng c·ªßa ch√∫ng.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a-t√≠nh-li√™n-t·ª•c-ƒë·ªÅu&quot;&gt;ƒê·ªãnh nghƒ©a T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt;, m·∫∑t kh√°c, √°p ƒë·∫∑t m·ªôt ƒëi·ªÅu ki·ªán nghi√™m ng·∫∑t h∆°n. M·ªôt h√†m s·ªë \(f: A \to \mathbb{R}\) ƒë∆∞·ª£c g·ªçi l√† &lt;strong&gt;li√™n t·ª•c ƒë·ªÅu tr√™n m·ªôt t·∫≠p h·ª£p&lt;/strong&gt; \(A\) n·∫øu, v·ªõi m·ªçi s·ªë th·ª±c d∆∞∆°ng \(\varepsilon &amp;gt; 0\), t·ªìn t·∫°i m·ªôt s·ªë th·ª±c d∆∞∆°ng \(\delta &amp;gt; 0\) sao cho v·ªõi m·ªçi \(x, y \in A\), n·∫øu&lt;/p&gt;

\[\lvert x - y \rvert &amp;lt; \delta\]

&lt;p&gt;th√¨&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;S·ª± kh√°c bi·ªát ch√≠nh&lt;/strong&gt; so v·ªõi t√≠nh li√™n t·ª•c theo ƒëi·ªÉm n·∫±m ·ªü th·ª© t·ª± c·ªßa c√°c l∆∞·ª£ng t·ª´: ƒë·ªëi v·ªõi t√≠nh li√™n t·ª•c &lt;strong&gt;ƒë·ªÅu&lt;/strong&gt;, \(\delta\) ch·ªâ ph·ª• thu·ªôc v√†o \(\varepsilon\) v√† ƒë·ªôc l·∫≠p v·ªõi c√°c ƒëi·ªÉm c·ª• th·ªÉ \(x\) v√† \(y\) trong mi·ªÅn x√°c ƒë·ªãnh.&lt;/p&gt;

&lt;h3 id=&quot;ƒë·ªãnh-nghƒ©a-t√≠nh-li√™n-t·ª•c-lipschitz&quot;&gt;ƒê·ªãnh nghƒ©a T√≠nh li√™n t·ª•c Lipschitz&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c Lipschitz&lt;/strong&gt; cung c·∫•p m·ªôt kh√°i ni·ªám c·ª• th·ªÉ v√† ƒë·ªãnh l∆∞·ª£ng h∆°n v·ªÅ t√≠nh li√™n t·ª•c. M·ªôt h√†m s·ªë \(f: A \to \mathbb{R}\) ƒë∆∞·ª£c g·ªçi l√† &lt;strong&gt;li√™n t·ª•c Lipschitz&lt;/strong&gt; (ho·∫∑c &lt;strong&gt;L-Lipschitz&lt;/strong&gt;) tr√™n m·ªôt t·∫≠p h·ª£p \(A\) n·∫øu t·ªìn t·∫°i m·ªôt h·∫±ng s·ªë \(L \geq 0\) sao cho v·ªõi m·ªçi \(x, y \in A\):&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert\]

&lt;p&gt;H·∫±ng s·ªë nh·ªè nh·∫•t \(L\) nh∆∞ v·∫≠y ƒë∆∞·ª£c g·ªçi l√† &lt;strong&gt;h·∫±ng s·ªë Lipschitz&lt;/strong&gt; ho·∫∑c &lt;strong&gt;m√¥-ƒëun Lipschitz&lt;/strong&gt; c·ªßa \(f\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;C√°c t√≠nh ch·∫•t ch√≠nh c·ªßa T√≠nh li√™n t·ª•c Lipschitz:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T·ªëc ƒë·ªô thay ƒë·ªïi b·ªã ch·∫∑n&lt;/strong&gt;: ƒêi·ªÅu ki·ªán Lipschitz ƒë·∫£m b·∫£o r·∫±ng h√†m s·ªë kh√¥ng th·ªÉ thay ƒë·ªïi nhanh h∆°n m·ªôt t·ªëc ƒë·ªô tuy·∫øn t√≠nh ƒë∆∞·ª£c x√°c ƒë·ªãnh b·ªüi \(L\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt;: M·ªçi h√†m li√™n t·ª•c Lipschitz ƒë·ªÅu l√† li√™n t·ª•c ƒë·ªÅu (ch·ªçn \(\delta = \varepsilon/L\) v·ªõi \(L &amp;gt; 0\)).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Kh·∫£ vi h·∫ßu kh·∫Øp n∆°i&lt;/strong&gt;: C√°c h√†m li√™n t·ª•c Lipschitz kh·∫£ vi h·∫ßu kh·∫Øp n∆°i, v√† t·∫°i n∆°i ƒë·∫°o h√†m t·ªìn t·∫°i, \(\lvert f&apos;(x) \rvert \leq L\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª•:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = \lvert x \rvert\) l√† 1-Lipschitz tr√™n \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;\(f(x) = \sin(x)\) l√† 1-Lipschitz tr√™n \(\mathbb{R}\) (v√¨ \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) kh√¥ng ph·∫£i Lipschitz tr√™n \(\mathbb{R}\) nh∆∞ng l√† Lipschitz tr√™n b·∫•t k·ª≥ kho·∫£ng b·ªã ch·∫∑n n√†o&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;s·ª±-kh√°c-bi·ªát-ch√≠nh-v√†-th·ª©-b·∫≠c&quot;&gt;S·ª± kh√°c bi·ªát ch√≠nh v√† Th·ª© b·∫≠c&lt;/h3&gt;

&lt;p&gt;Ba lo·∫°i t√≠nh li√™n t·ª•c t·∫°o th√†nh m·ªôt th·ª© b·∫≠c c·ªßa c√°c ƒëi·ªÅu ki·ªán ng√†y c√†ng m·∫°nh:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ‚äÜ T√≠nh li√™n t·ª•c ƒë·ªÅu ‚äÜ T√≠nh li√™n t·ª•c Lipschitz&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Theo ƒëi·ªÉm so v·ªõi To√†n c·ª•c&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c&lt;/strong&gt;: T√≠nh ch·∫•t c·ª•c b·ªô (ki·ªÉm tra t·∫°i m·ªói ƒëi·ªÉm)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt;: T√≠nh ch·∫•t to√†n c·ª•c c·ªßa to√†n b·ªô h√†m s·ªë&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c Lipschitz&lt;/strong&gt;: T√≠nh ch·∫•t to√†n c·ª•c v·ªõi c√°c r√†ng bu·ªôc ƒë·ªãnh l∆∞·ª£ng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;L·ª±a ch·ªçn \(\delta\)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c&lt;/strong&gt;: \(\delta\) c√≥ th·ªÉ ph·ª• thu·ªôc v√†o c·∫£ \(\varepsilon\) v√† ƒëi·ªÉm c·ª• th·ªÉ \(c\)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt;: \(\delta\) ch·ªâ ph·ª• thu·ªôc v√†o \(\varepsilon\), ho·∫°t ƒë·ªông cho t·∫•t c·∫£ c√°c ƒëi·ªÉm ƒë·ªìng th·ªùi&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c Lipschitz&lt;/strong&gt;: \(\delta = \varepsilon/L\) cung c·∫•p m·ªëi quan h·ªá r√µ r√†ng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ki·ªÉm so√°t T·ªëc ƒë·ªô Thay ƒë·ªïi&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c&lt;/strong&gt;: Kh√¥ng ki·ªÉm so√°t t·ªëc ƒë·ªô thay ƒë·ªïi&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c ƒë·ªÅu&lt;/strong&gt;: ƒê·∫£m b·∫£o bi·∫øn thi√™n b·ªã ch·∫∑n tr√™n c√°c kho·∫£ng nh·ªè&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;T√≠nh li√™n t·ª•c Lipschitz&lt;/strong&gt;: Cung c·∫•p r√†ng bu·ªôc tuy·∫øn t√≠nh r√µ r√†ng cho t·ªëc ƒë·ªô thay ƒë·ªïi&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;M·ªëi quan h·ªá ƒê·ªô m·∫°nh&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;M·ªçi h√†m li√™n t·ª•c Lipschitz ƒë·ªÅu l√† li√™n t·ª•c ƒë·ªÅu&lt;/li&gt;
      &lt;li&gt;M·ªçi h√†m li√™n t·ª•c ƒë·ªÅu ƒë·ªÅu l√† li√™n t·ª•c&lt;/li&gt;
      &lt;li&gt;C√°c m·ªánh ƒë·ªÅ ng∆∞·ª£c l·∫°i n√≥i chung kh√¥ng ƒë√∫ng&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;v√≠-d·ª•-chi-ti·∫øt-v√†-so-s√°nh&quot;&gt;V√≠ d·ª• Chi ti·∫øt v√† So s√°nh&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• 1: \(f(x) = x^2\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \(\mathbb{R}\)&lt;/strong&gt;: Li√™n t·ª•c nh∆∞ng kh√¥ng li√™n t·ª•c ƒë·ªÅu (t·ªëc ƒë·ªô thay ƒë·ªïi \(\lvert f&apos;(x) \rvert = 2\lvert x \rvert\) kh√¥ng b·ªã ch·∫∑n)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \([0,1]\)&lt;/strong&gt;: Li√™n t·ª•c, li√™n t·ª•c ƒë·ªÅu, v√† Lipschitz v·ªõi \(L = 2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• 2: \(f(x) = \sin(x)\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \(\mathbb{R}\)&lt;/strong&gt;: Li√™n t·ª•c, li√™n t·ª•c ƒë·ªÅu, v√† 1-Lipschitz (v√¨ \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• 3: \(f(x) = \lvert x \rvert\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \(\mathbb{R}\)&lt;/strong&gt;: Li√™n t·ª•c, li√™n t·ª•c ƒë·ªÅu, v√† 1-Lipschitz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;L∆∞u √Ω&lt;/strong&gt;: Kh√¥ng kh·∫£ vi t·∫°i \(x = 0\), nh∆∞ng v·∫´n l√† Lipschitz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;V√≠ d·ª• 4: \(f(x) = \sqrt{x}\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \([0,1]\)&lt;/strong&gt;: Li√™n t·ª•c v√† li√™n t·ª•c ƒë·ªÅu, nh∆∞ng kh√¥ng ph·∫£i Lipschitz (ƒë·∫°o h√†m kh√¥ng b·ªã ch·∫∑n g·∫ßn \(x = 0\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Tr√™n \([a,1]\) v·ªõi \(a &amp;gt; 0\)&lt;/strong&gt;: Lipschitz v·ªõi \(L = 1/(2\sqrt{a})\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 
 <entry>
   <title>25-01 Future Directions in Deep Learning</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_01_Future_Directions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter25/25_01_Future_Directions</id>
   <content type="html">&lt;h1 id=&quot;the-future-of-deep-learning-emerging-trends-and-open-challenges&quot;&gt;The Future of Deep Learning: Emerging Trends and Open Challenges&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Deep learning has achieved remarkable success over the past decade, yet we stand at the beginning rather than the end of its potential impact. While current systems excel at specific tasks with abundant data and computation, numerous fundamental challenges remain unsolved and exciting directions are emerging. Understanding these frontiers‚Äîboth technical challenges and promising approaches‚Äîprepares practitioners and researchers to contribute to the field‚Äôs continued evolution and helps anticipate how AI capabilities will expand in coming years.&lt;/p&gt;

&lt;p&gt;The scaling hypothesis has driven much recent progress: larger models trained on more data with more compute consistently improve performance, with no clear ceiling yet observed. GPT-3‚Äôs 175 billion parameters exceeded GPT-2‚Äôs 1.5 billion by 100√ó, producing qualitatively new capabilities like few-shot learning. Yet scaling raises critical questions: Is this trend sustainable given energy costs and data availability? Do we hit fundamental limits or discover emergent capabilities? How do we train and serve models orders of magnitude larger? Understanding scaling‚Äôs promises and limitations shapes expectations for AI‚Äôs trajectory.&lt;/p&gt;

&lt;p&gt;Multimodal learning‚Äîsystems processing multiple modalities (vision, language, audio) together‚Äîrepresents a crucial frontier because human intelligence is inherently multimodal. Models like CLIP (learning from image-text pairs) and GPT-4 (processing both text and images) demonstrate that multimodal pre-training enables rich cross-modal understanding: describing images, answering visual questions, generating images from text descriptions. Future systems will likely be inherently multimodal, learning unified representations spanning modalities much as humans seamlessly integrate sight, sound, and language.&lt;/p&gt;

&lt;p&gt;Efficiency and sustainability emerge as critical concerns as models grow. Training GPT-3 reportedly consumed hundreds of thousands of dollars in compute and substantial carbon emissions. Democratizing AI requires techniques making advanced capabilities accessible beyond tech giants: efficient architectures, better algorithms requiring less data or compute, knowledge distillation from large to small models, and specialized hardware. Understanding the efficiency frontier‚Äîhow to maximize capabilities per unit computation‚Äîwill increasingly matter as AI deployment scales.&lt;/p&gt;

&lt;p&gt;Safety, robustness, and alignment represent perhaps the most important challenges. Current systems can be brittle (failing unpredictably on out-of-distribution inputs), biased (reflecting and amplifying societal biases in training data), and misaligned (optimizing objectives that don‚Äôt match true human values). As AI systems become more capable and deployed in critical applications, ensuring they behave reliably and beneficially becomes paramount. Research on adversarial robustness, fairness, interpretability, and value alignment will be crucial for responsible AI development.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;scaling-laws&quot;&gt;Scaling Laws&lt;/h3&gt;

&lt;p&gt;Empirical observations suggest power-law relationships between model performance and scale:&lt;/p&gt;

\[L \propto N^{-\alpha}\]

&lt;p&gt;where \(L\) is loss, \(N\) is number of parameters (or data size, or compute), and \(\alpha\) is a constant (typically 0.05-0.1). This implies diminishing returns: doubling parameters might reduce loss by 5-10%, requiring exponentially more parameters for linear loss improvements. Yet the relationship is surprisingly consistent across architectures and domains, suggesting fundamental regularities in how neural networks learn.&lt;/p&gt;

&lt;p&gt;The compute-optimal frontier trades off model size and training data:&lt;/p&gt;

\[N_{\text{optimal}} \propto C^{0.5}, \quad D_{\text{optimal}} \propto C^{0.5}\]

&lt;p&gt;where \(C\) is compute budget, \(N\) is parameters, \(D\) is training tokens. This suggests optimal use of compute equally balances model size and data quantity, informing how to allocate resources when scaling.&lt;/p&gt;

&lt;h3 id=&quot;few-shot-learning&quot;&gt;Few-Shot Learning&lt;/h3&gt;

&lt;p&gt;Meta-learning formalizes learning from few examples. Given task distribution \(p(\mathcal{T})\), learn initialization \(\theta_0\) that adapts quickly:&lt;/p&gt;

\[\theta_0 = \arg\min_\theta \mathbb{E}_{\mathcal{T} \sim p(\mathcal{T})}\left[\mathcal{L}_\mathcal{T}(\theta - \alpha \nabla_\theta \mathcal{L}_\mathcal{T}(\theta))\right]\]

&lt;p&gt;MAML learns \(\theta_0\) such that one gradient step on new task yields good performance. This enables rapid adaptation with minimal data.&lt;/p&gt;

&lt;h3 id=&quot;continual-learning&quot;&gt;Continual Learning&lt;/h3&gt;

&lt;p&gt;Learning new tasks without forgetting old ones requires balancing plasticity (learning new) and stability (retaining old). Elastic Weight Consolidation penalizes changes to parameters important for previous tasks:&lt;/p&gt;

\[\mathcal{L}_{\text{EWC}} = \mathcal{L}_{\text{new}} + \sum_i \frac{\lambda}{2} F_i (\theta_i - \theta_i^*)^2\]

&lt;p&gt;where \(F_i\) is Fisher information (second derivative of old task loss), \(\theta_i^*\) are parameters after learning old tasks. This allows learning new tasks while protecting parameters critical for old tasks.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider the progression from GPT-2 (1.5B parameters) to GPT-3 (175B parameters) to GPT-4 (rumored 1.7T parameters). Each scaling step enabled new capabilities:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GPT-2&lt;/strong&gt;: Coherent text generation, basic completion&lt;br /&gt;
&lt;strong&gt;GPT-3&lt;/strong&gt;: Few-shot learning, simple reasoning, basic coding&lt;br /&gt;
&lt;strong&gt;GPT-4&lt;/strong&gt;: Complex reasoning, multimodal understanding, sophisticated coding&lt;/p&gt;

&lt;p&gt;These aren‚Äôt just quantitative improvements but qualitative capability changes. GPT-3 could follow instructions it wasn‚Äôt explicitly trained on. GPT-4 can reason about images. These emergent abilities‚Äîcapabilities that appear suddenly at certain scales‚Äîsuggest scaling might continue yielding surprises.&lt;/p&gt;

&lt;p&gt;Multimodal learning enables novel applications. DALL-E generates images from text: ‚Äúan astronaut riding a horse in photorealistic style.‚Äù The model must understand both language (parsing the description) and vision (what astronauts and horses look like, what photorealistic means) and the mapping between them (how linguistic concepts translate to visual features). Future systems might seamlessly process video, audio, and text together, much closer to human-like perception.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Few-shot learning example
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FewShotLearner&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Meta-learning for few-shot classification.
    
    Learns from episodes: each episode has support set (few examples)
    and query set (test examples). Model learns to adapt quickly
    to new classes from few examples.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Feature extractor
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Classifier (dynamically created for each episode)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;classifier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Placeholder
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;adapt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;support_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;support_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Adapt to new task from support set.
        
        Creates and trains task-specific classifier on few examples.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Extract features from support set
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;support_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;support_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Create and train task-specific classifier
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;support_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;task_classifier&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;support_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;task_classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Quick adaptation
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;task_classifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;support_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;support_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;task_classifier&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Few-Shot Learning: Rapid Adaptation to New Tasks&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Meta-learning enables learning from few examples (5-10 per class)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;by learning how to learn quickly across many related tasks.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This is crucial for data-scarce domains!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Neuromorphic computing and brain-inspired architectures suggest radically different approaches. Spiking neural networks process discrete events (spikes) rather than continuous values, potentially more efficient and biologically plausible. Hardware specialized for neural computation (TPUs, neuromorphic chips) co-designs algorithms and hardware for efficiency.&lt;/p&gt;

&lt;p&gt;Quantum machine learning explores quantum computing for ML, potentially offering exponential speedups for certain operations. While mostly theoretical currently, quantum advantage for specific ML tasks might emerge as quantum hardware matures.&lt;/p&gt;

&lt;p&gt;Neural architecture search automated architecture design, discovering novel architectures (EfficientNet, NAS-derived networks) that humans might not conceive. Future: AI designing AI systems, co-evolving architectures and training procedures.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;‚ÄúAttention is All You Need‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
Transformers‚Äô impact continues growing‚Äîfoundation for GPT, BERT, essentially all modern LLMs. Understanding Transformers is understanding the future of deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2103.00020&quot;&gt;‚ÄúCLIP: Learning Transferable Visual Models From Natural Language Supervision‚Äù (2021)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alec Radford, Jong Wook Kim, et al. (OpenAI)&lt;br /&gt;
CLIP learned vision-language representations from 400M image-text pairs, enabling zero-shot image classification through text prompts. Demonstrated multimodal pre-training‚Äôs power and flexible task specification through natural language.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2010.11929&quot;&gt;‚ÄúAn Image is Worth 16x16 Words: Transformers for Image Recognition at Scale‚Äù (2021)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
Vision Transformers showed attention-based architectures can match or exceed CNNs on vision, suggesting Transformers might become universal architecture across modalities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2203.15556&quot;&gt;‚ÄúTraining Compute-Optimal Large Language Models‚Äù (2022)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jordan Hoffmann, Sebastian Borgeaud, et al. (DeepMind)&lt;br /&gt;
Chinchilla paper showed most LLMs undertrained‚Äîoptimal scaling balances model size and data. Influenced how we think about scaling laws and resource allocation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2303.12712&quot;&gt;‚ÄúSparks of Artificial General Intelligence: Early experiments with GPT-4‚Äù (2023)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Microsoft Research&lt;br /&gt;
Analyzed GPT-4‚Äôs capabilities across diverse tasks, documenting emergent abilities suggesting progress toward more general intelligence. While controversial, highlights rapid capability advancement.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Overhyping near-term capabilities while underestimating long-term potential is common. Current systems have significant limitations (no common sense, brittle reasoning, data inefficiency) that won‚Äôt be solved next year. Yet long-term progress (10-20 years) might be more dramatic than currently imaginable.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Deep learning‚Äôs future involves scaling to larger models discovering emergent capabilities, multimodal systems integrating vision-language-audio for richer understanding, efficiency innovations enabling democratized access despite growing model size, few-shot and meta-learning reducing data requirements, continual learning enabling lifelong learning without forgetting, and fundamental research on robustness, fairness, and alignment ensuring beneficial deployment. Open challenges include sample efficiency (learning from less data), reasoning and common sense (beyond pattern matching), interpretability (understanding decisions), robustness (handling distribution shift), and scalability (training and serving ever-larger models). The field progresses through parallel advances in architectures (Transformers), training techniques (self-supervised learning), applications (multimodal models), and theory (understanding why deep learning works), with breakthrough innovations often coming from unexpected directions. Understanding current frontiers and open problems prepares practitioners to contribute to deep learning‚Äôs continued evolution while maintaining realistic expectations about near-term capabilities and long-term potential.&lt;/p&gt;

&lt;p&gt;The future of deep learning will be shaped by technical innovations, computational advances, and thoughtful consideration of societal impacts, requiring both ambitious research pushing capabilities forward and careful work ensuring systems benefit humanity.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>25 Advanced Topics and Future Directions</title>
   <link href="http://localhost:4000/contents/en/chapter25/25_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter25/25_00_Introduction</id>
   <content type="html">&lt;p&gt;This final chapter explores cutting-edge research and future directions in deep learning: multimodal models (CLIP, Flamingo), neural architecture search, meta-learning (learning to learn), continual learning, federated learning, neuromorphic computing, quantum machine learning, and emerging challenges like AI safety, fairness, and sustainability. We look at where deep learning is heading and open research problems.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>24-01 Neural Network Interpretability and Explainability</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_01_Model_Interpretability/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter24/24_01_Model_Interpretability</id>
   <content type="html">&lt;h1 id=&quot;model-interpretability-understanding-the-black-box&quot;&gt;Model Interpretability: Understanding the Black Box&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Neural network interpretability addresses one of deep learning‚Äôs most significant challenges: understanding why models make particular predictions. While neural networks achieve remarkable performance on diverse tasks, their decision-making process often appears opaque‚Äîmillions of parameters interacting through nonlinear transformations make it difficult to trace how inputs map to outputs. This ‚Äúblack box‚Äù nature creates problems in high-stakes domains like medicine (why did the model diagnose this condition?), law (why was this defendant classified as high-risk?), and autonomous vehicles (why did the car brake suddenly?), where we need not just accurate predictions but justifications we can audit, trust, and debug.&lt;/p&gt;

&lt;p&gt;Understanding the distinction between interpretability and explainability clarifies what we‚Äôre seeking. Interpretability means the model‚Äôs internal workings are transparent‚Äîwe can understand the computation from inspection. Simple models like linear regression or decision trees are inherently interpretable; we can see exactly how features combine to produce predictions. Explainability means we can provide post-hoc explanations of why a model made specific predictions, even if the model itself isn‚Äôt inherently transparent. Deep neural networks are rarely interpretable (understanding millions of parameters is infeasible) but can be made explainable through techniques that highlight relevant inputs, visualize learned features, or approximate decisions with interpretable surrogates.&lt;/p&gt;

&lt;p&gt;The motivation for interpretability extends beyond satisfying curiosity. In scientific applications, understanding what features models use can generate new hypotheses‚Äîif a medical imaging model identifies a subtle pattern doctors missed, investigating this pattern might reveal new diagnostic markers. In debugging, interpretability reveals when models exploit spurious correlations (detecting huskies by snow in background rather than dog features) or fail to use relevant features. In safety-critical applications, interpretability enables verification that models behave reasonably across diverse scenarios. In regulated industries, explainability may be legally required for decisions affecting individuals. Understanding these diverse motivations helps appreciate that interpretability isn‚Äôt a single goal but multiple related objectives requiring different techniques.&lt;/p&gt;

&lt;p&gt;The landscape of interpretability methods is vast, reflecting the multiple ways we might understand neural networks. Saliency methods highlight which input regions most influenced a prediction, answering ‚Äúwhat did the model look at?‚Äù Activation visualization shows what patterns activate neurons, revealing ‚Äúwhat features has the network learned?‚Äù Attribution methods decompose predictions into feature contributions, explaining ‚Äúhow much did each input feature matter?‚Äù Concept-based explanations identify high-level concepts the model uses, moving beyond pixel or word-level attributions to semantic understanding. Each approach provides different insights, and comprehensive interpretability often requires multiple complementary techniques.&lt;/p&gt;

&lt;p&gt;Yet interpretability has fundamental tensions. More interpretable models are often less accurate (linear models vs deep networks). Faithful explanations (accurately describing model behavior) might be complex and hard to understand. Simple explanations might be understandable but unfaithful to actual model behavior. Perfect interpretability might require understanding millions of parameters‚Äîas complex as understanding the phenomenon the model learned. These tensions mean interpretability research involves careful tradeoffs between fidelity, simplicity, and utility, without universal solutions that satisfy all desiderata simultaneously.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Interpretability methods often formalize the question ‚Äúwhich inputs matter most for this prediction?‚Äù through attribution. Given input \(\mathbf{x}\) and model \(f\), compute attribution \(\mathbf{a}\) where \(a_i\) indicates importance of input dimension \(i\) for the prediction \(f(\mathbf{x})\).&lt;/p&gt;

&lt;h3 id=&quot;gradient-based-saliency&quot;&gt;Gradient-Based Saliency&lt;/h3&gt;

&lt;p&gt;The simplest attribution uses gradients:&lt;/p&gt;

\[\mathbf{a} = \left|\frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}\right|\]

&lt;p&gt;This measures how much the output would change for small changes in each input dimension. Large gradient indicates high sensitivity‚Äîthat input dimension strongly influences the output. For images, this produces saliency maps highlighting important pixels.&lt;/p&gt;

&lt;p&gt;However, gradient can saturate in ReLU networks (gradient is zero or one, not informative about magnitude of change) and doesn‚Äôt account for baseline (what are we comparing against?). Improvements address these issues:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Integrated Gradients&lt;/strong&gt; accumulates gradients along path from baseline \(\mathbf{x}&apos;\) to input \(\mathbf{x}\):&lt;/p&gt;

\[\mathbf{a}_i = (x_i - x_i&apos;) \int_{\alpha=0}^1 \frac{\partial f(\mathbf{x}&apos; + \alpha(\mathbf{x} - \mathbf{x}&apos;))}{\partial x_i} d\alpha\]

&lt;p&gt;This satisfies desirable axioms: sensitivity (if input doesn‚Äôt affect output, attribution is zero) and implementation invariance (equivalent networks give same attributions).&lt;/p&gt;

&lt;h3 id=&quot;shap-shapley-additive-explanations&quot;&gt;SHAP: Shapley Additive Explanations&lt;/h3&gt;

&lt;p&gt;SHAP uses Shapley values from cooperative game theory. The contribution of feature \(i\) is:&lt;/p&gt;

\[\phi_i = \sum_{S \subseteq \mathcal{F} \backslash \{i\}} \frac{|S|!(|\mathcal{F}|-|S|-1)!}{|\mathcal{F}|!} [f(S \cup \{i\}) - f(S)]\]

&lt;p&gt;where \(\mathcal{F}\) is all features, \(S\) are feature subsets, \(f(S)\) is model output with only features in \(S\) present (others set to baseline). This computes the average marginal contribution of feature \(i\) across all possible feature coalitions‚Äîa fair allocation of prediction among features.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Computing exact Shapley values requires $$2^{&lt;/td&gt;
      &lt;td&gt;\mathcal{F}&lt;/td&gt;
      &lt;td&gt;}$$ model evaluations (exponential in features), so approximations are used. Kernel SHAP approximates through weighted linear regression. For tree-based models, TreeSHAP computes exactly in polynomial time.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;layer-wise-relevance-propagation-lrp&quot;&gt;Layer-wise Relevance Propagation (LRP)&lt;/h3&gt;

&lt;p&gt;LRP backpropagates relevance from output to input:&lt;/p&gt;

\[R_i^{(l)} = \sum_j \frac{z_{ij}}{\sum_k z_{kj}} R_j^{(l+1)}\]

&lt;p&gt;where \(z_{ij} = a_i^{(l)} w_{ij}\) is contribution of neuron \(i\) in layer \(l\) to neuron \(j\) in layer \(l+1\). Starting with \(R_{\text{out}} = f(\mathbf{x})\) at output, relevance propagates backward, decomposing prediction into input contributions satisfying \(\sum_i R_i^{(0)} = f(\mathbf{x})\) (conservation).&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider a CNN classifying an image as ‚Äúdog‚Äù with 95% confidence. Without interpretability, we don‚Äôt know why. Was it the dog‚Äôs face, body shape, background context, or spurious patterns like grass (if all dogs in training had grass backgrounds)?&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient saliency&lt;/strong&gt; computes \(\partial p_{\text{dog}}/\partial \text{pixels}\). Large gradients highlight pixels that, if changed slightly, would most affect the dog probability. Visualized as a heatmap overlay on the image, we might see high values around the dog‚Äôs face and ears‚Äîgood, the model uses actual dog features. If high values appear in background, the model might be exploiting spurious correlations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Class Activation Mapping (CAM)&lt;/strong&gt; for CNNs with global average pooling shows which regions the final convolutional layer found important. For ‚Äúdog‚Äù class, we compute weighted combination of final conv layer‚Äôs feature maps using the classification weights:&lt;/p&gt;

\[\text{CAM} = \sum_k w_k^{\text{dog}} \cdot \text{FeatureMap}_k\]

&lt;p&gt;This produces a heatmap at feature map resolution showing which spatial regions contributed to the ‚Äúdog‚Äù prediction. Upsampling to input resolution and overlaying on the image reveals the model focused on the dog‚Äôs head and body‚Äîinterpretable and reassuring.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SHAP values&lt;/strong&gt; for a particular prediction might show:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Pixel region containing dog face: +0.35 (strong positive contribution)&lt;/li&gt;
  &lt;li&gt;Pixel region with dog body: +0.28&lt;/li&gt;
  &lt;li&gt;Background grass: +0.08 (small contribution - concerning if high)&lt;/li&gt;
  &lt;li&gt;Sky region: -0.02 (slight negative - expected for irrelevant regions)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;If grass has high SHAP value, we‚Äôve discovered the model uses spurious correlation (dogs often photographed on grass). We can then collect more diverse training data or use data augmentation to fix this.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adversarial examples&lt;/strong&gt; provide another interpretability lens. By finding minimal input perturbations that change predictions, we reveal model vulnerabilities. If adding imperceptible noise to dog image causes ‚Äúcat‚Äù prediction, the model‚Äôs representation is fragile‚Äîit hasn‚Äôt learned robust features. Studying these adversarial perturbations reveals what features matter: perturbations often add patterns the model strongly associates with target class, revealing learned (but perhaps spurious) class indicators.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GradCAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Gradient-weighted Class Activation Mapping.
    
    Visualizes which regions of image are important for prediction
    by computing gradients of class score with respect to final
    convolutional layer activations.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        model: CNN model
        target_layer: name of convolutional layer to visualize
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_layer&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Storage for forward activations and backward gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Register hooks
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;_register_hooks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_register_hooks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Register forward and backward hooks on target layer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Find target layer
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;named_modules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_forward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;forward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_full_backward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Generate CAM for target class.
        
        input_image: (1, 3, H, W)
        target_class: index of class to explain
        
        Returns: (H, W) heatmap
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass for target class
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;class_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get activations and gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1, C, H, W)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1, C, H, W)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Global average pool gradients to get weights
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1, C, 1, 1)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Weighted combination of activation maps
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1, 1, H, W)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# ReLU (only positive contributions)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Normalize to [0, 1]
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Grad-CAM: Visualizing CNN Decisions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load pre-trained model
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PIL&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resnet50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;DEFAULT&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create Grad-CAM
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradcam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GradCAM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_layer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;layer4&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load and preprocess image (simulated here)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generating Grad-CAM for sample image...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;input_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Get prediction
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predicted_class&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predicted class: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predicted_class&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; with confidence &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate CAM for predicted class
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradcam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;generate_cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted_class&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;CAM shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;CAM range: [&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;CAM highlights image regions important for prediction!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;High values = important regions, low values = irrelevant&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# SHAP approximation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleSHAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Simplified SHAP for neural networks&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        model: neural network
        background_data: reference dataset for baselines
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;background&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background_data&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Approximate SHAP values for input x.
        
        Uses sampling to approximate Shapley values:
        repeatedly mask random subsets of features,
        measure prediction changes.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Get baseline prediction (average over background)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;baseline_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;background&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Generate random feature masks
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute predictions with different feature subsets
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;masks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Mask some features (use background average)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x_masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;bg_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;background&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bg_avg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute prediction
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Marginal contribution of each feature
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;pred_diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;baseline_output&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred_diff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SHAP: Feature Attribution&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simple example with a linear model (for verification)
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;simple_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;background&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Reference data
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;shap&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleSHAP&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;simple_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;background&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Explain a prediction
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shap&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;explain&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Feature attributions (SHAP values):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attributions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Positive = feature increased prediction&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Negative = feature decreased prediction&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Magnitude = importance&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Adversarial examples for probing robustness:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fgsm_attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Fast Gradient Sign Method: minimal perturbation to fool model.
    
    Reveals model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s decision boundaries and vulnerabilities.
    Shows what patterns strongly influence predictions.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward to get gradients
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Create adversarial example
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Move in direction that increases loss (fools model)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;perturbation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sign&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;adversarial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perturbation&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adversarial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adversarial Examples: Probing Model Robustness&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simple classifier
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;toy_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyClassifier&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;toy_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Original image (random for demo)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;true_label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Get original prediction
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;orig_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;toy_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;orig_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orig_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;orig_conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orig_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Original prediction: class &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_pred&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;orig_conf&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; confidence)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate adversarial example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adversarial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fgsm_attack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;toy_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test adversarial
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;adv_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;toy_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adversarial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;adv_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adv_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;adv_conf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adv_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adv_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adversarial prediction: class &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adv_pred&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adv_conf&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; confidence)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Measure perturbation
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perturbation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adversarial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;original&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Average perturbation: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perturbation&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adv_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;orig_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úó Model fooled by imperceptible perturbation!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This reveals model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s decision boundary is fragile&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úì Model robust to this perturbation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Interpretability connects to causality through attempts to move beyond correlation to understanding causal mechanisms. Attribution methods identify correlations between inputs and outputs, but correlation doesn‚Äôt imply causation. Causal interpretability seeks to answer ‚Äúwould changing this input feature actually cause the prediction to change?‚Äù requiring interventions and counterfactual reasoning beyond standard attribution.&lt;/p&gt;

&lt;p&gt;The relationship to uncertainty quantification provides complementary understanding. Interpretability shows why a prediction was made. Uncertainty quantification shows how confident the model is. Together, they provide comprehensive understanding: ‚Äúthe model predicts class A because of feature X, with confidence Y.‚Äù Bayesian deep learning, dropout for uncertainty, and ensemble methods complement interpretability by quantifying prediction reliability.&lt;/p&gt;

&lt;p&gt;Interpretability relates to fairness and bias detection. If a hiring model uses gender or race features (directly or through proxies), interpretability methods reveal this, enabling auditing for discriminatory behavior. Understanding what features drive predictions is prerequisite for ensuring fairness, though interpretability alone doesn‚Äôt guarantee fairness‚Äîwe must also determine whether identified features are legitimate or biased.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6034&quot;&gt;‚ÄúDeep Inside Convolutional Networks: Visualising Image Classification Models and Saliency Maps‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Karen Simonyan, Andrea Vedaldi, Andrew Zisserman&lt;br /&gt;
Introduced gradient-based saliency maps for CNNs, showing derivatives reveal which pixels matter for predictions. Established visualization as key interpretability tool.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1311.2901&quot;&gt;‚ÄúVisualizing and Understanding Convolutional Networks‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Matthew Zeiler, Rob Fergus&lt;br /&gt;
Deconvolution networks visualized what features CNN layers learn. Showed early layers detect edges/colors, middle layers detect textures/patterns, deep layers detect object parts. Foundational for understanding CNN hierarchical features.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1610.02391&quot;&gt;‚ÄúGrad-CAM: Visual Explanations from Deep Networks via Gradient-based Localization‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ramprasaath Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna Vedantam, Devi Parikh, Dhruv Batra&lt;br /&gt;
Grad-CAM generates visual explanations by using gradients to weight feature maps, producing class-discriminative localization without modifying architecture. Became standard for CNN interpretability.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1705.07874&quot;&gt;‚ÄúA Unified Approach to Interpreting Model Predictions‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Scott Lundberg, Su-In Lee&lt;br /&gt;
SHAP unified multiple attribution methods under Shapley value framework from game theory, providing theoretically grounded explanations with desirable properties. Became standard for tabular data and model-agnostic explanations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1703.01365&quot;&gt;‚ÄúAxiomatic Attribution for Deep Networks‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Mukund Sundararajan, Ankur Taly, Qiqi Yan&lt;br /&gt;
Integrated Gradients satisfied attribution axioms (sensitivity, implementation invariance) that gradient-based methods violate. Provided principled attribution method with theoretical guarantees.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Saliency maps can be misleading. High gradient doesn‚Äôt always mean high importance‚Äîcould be artifact of network architecture (batch norm, ReLU) or optimization. Always verify interpretations with ablation (actually remove features and measure impact) or by checking if explanations align with domain knowledge.&lt;/p&gt;

&lt;p&gt;Adversarial examples don‚Äôt necessarily indicate poor models. All models have adversarial vulnerabilities‚Äîit‚Äôs a fundamental property of high-dimensional spaces. Focus on robustness to natural perturbations (noise, blur) rather than adversarially crafted worst-cases unless security is critical.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Neural network interpretability enables understanding why models make predictions through attribution methods (which inputs mattered), visualization techniques (what features were learned), and explanation frameworks (how decisions decompose). Gradient-based saliency highlights input regions with high sensitivity to prediction changes. Grad-CAM visualizes spatial importance in CNNs through gradient-weighted feature maps. SHAP provides theoretically grounded attributions through Shapley values from game theory. Adversarial examples reveal model robustness by finding minimal perturbations changing predictions. Different interpretability methods provide complementary insights‚Äîsaliency for input importance, activation visualization for learned features, SHAP for faithful attribution‚Äîoften requiring multiple techniques for comprehensive understanding. Interpretability enables debugging spurious correlations, building trust in high-stakes applications, satisfying regulatory requirements, and generating scientific insights from learned patterns, making it increasingly important as deep learning deployment expands to critical domains requiring explainability beyond accuracy.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>24 Interpretability and Explainability</title>
   <link href="http://localhost:4000/contents/en/chapter24/24_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter24/24_00_Introduction</id>
   <content type="html">&lt;p&gt;Understanding why deep learning models make certain predictions is crucial for trust, debugging, and compliance. This chapter covers visualization techniques (saliency maps, activation visualization), attention analysis, feature importance, LIME, SHAP, counterfactual explanations, and adversarial examples. We explore methods to make black-box models more interpretable.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>23-01 Model Compression and Efficiency</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_01_Model_Compression/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter23/23_01_Model_Compression</id>
   <content type="html">&lt;h1 id=&quot;efficient-deep-learning-compression-and-acceleration&quot;&gt;Efficient Deep Learning: Compression and Acceleration&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;As deep learning models have grown to billions of parameters, deploying them on resource-constrained devices (mobile phones, embedded systems, edge devices) or serving them at scale (millions of queries) has become challenging. Model compression techniques reduce model size, memory footprint, and computational requirements while maintaining accuracy, enabling deployment in scenarios where full models are impractical. These techniques‚Äîpruning, quantization, knowledge distillation, and efficient architectures‚Äîrepresent crucial engineering innovations making deep learning accessible beyond cloud servers with powerful GPUs.&lt;/p&gt;

&lt;p&gt;Pruning removes unnecessary parameters or connections, exploiting the observation that many neural network weights contribute minimally to outputs. Studies show networks remain effective after removing 50-90% of weights, suggesting significant redundancy. Structured pruning removes entire filters or layers, providing hardware-friendly speedups. Unstructured pruning removes individual weights, achieving higher compression but requiring specialized hardware for acceleration.&lt;/p&gt;

&lt;p&gt;Quantization reduces numerical precision, representing weights and activations with fewer bits (8-bit integers instead of 32-bit floats), reducing memory by 4√ó and enabling faster integer arithmetic on many processors. Post-training quantization applies to trained models without retraining. Quantization-aware training includes quantization in the training loop, allowing the network to adapt to reduced precision.&lt;/p&gt;

&lt;p&gt;Knowledge distillation transfers knowledge from large ‚Äúteacher‚Äù networks to small ‚Äústudent‚Äù networks by training students to match teacher predictions (soft targets) rather than just hard labels. Students learn from teacher‚Äôs uncertainty and similarities between classes, often achieving better performance than training on labels alone despite being much smaller.&lt;/p&gt;

&lt;p&gt;Efficient architectures like MobileNet and EfficientNet are designed for efficiency from the start through depthwise separable convolutions, neural architecture search, and careful scaling. These achieve competitive accuracy with fraction of computation/parameters compared to standard architectures.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;pruning&quot;&gt;Pruning&lt;/h3&gt;

&lt;p&gt;Define importance score for parameter \(w\):&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$I(w) =&lt;/td&gt;
      &lt;td&gt;\frac{\partial \mathcal{L}}{\partial w}&lt;/td&gt;
      &lt;td&gt;$$ (magnitude pruning)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$I(w) =&lt;/td&gt;
      &lt;td&gt;w \cdot \frac{\partial \mathcal{L}}{\partial w}&lt;/td&gt;
      &lt;td&gt;$$ (Taylor expansion approximation)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Remove weights with \(I(w) &amp;lt; \tau\) (threshold). After pruning, fine-tune remaining weights.&lt;/p&gt;

&lt;h3 id=&quot;quantization&quot;&gt;Quantization&lt;/h3&gt;

&lt;p&gt;Map continuous values to discrete levels. For 8-bit quantization:&lt;/p&gt;

\[w_{\text{quant}} = \text{round}\left(\frac{w - w_{\min}}{w_{\max} - w_{\min}} \cdot 255\right)\]

&lt;p&gt;Dequantize for computation:&lt;/p&gt;

\[w \approx w_{\min} + w_{\text{quant}} \cdot \frac{w_{\max} - w_{\min}}{255}\]

&lt;h3 id=&quot;knowledge-distillation&quot;&gt;Knowledge Distillation&lt;/h3&gt;

&lt;p&gt;Student network trained on soft targets from teacher:&lt;/p&gt;

\[\mathcal{L} = \alpha \mathcal{L}_{\text{hard}}(y, \hat{y}_{\text{student}}) + (1-\alpha) \mathcal{L}_{\text{soft}}(\hat{y}_{\text{teacher}}, \hat{y}_{\text{student}})\]

&lt;p&gt;Soft targets use temperature \(T\):&lt;/p&gt;

\[p_i = \frac{\exp(z_i/T)}{\sum_j \exp(z_j/T)}\]

&lt;p&gt;Higher \(T\) creates softer distributions revealing teacher‚Äôs uncertainty.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Imagine compressing a ResNet-50 (25M parameters, 4GB memory). Pruning might find that 60% of weights have magnitude &amp;lt; 0.001 and contribute negligibly. Removing these yields 10M parameters, 1.6GB‚Äî60% reduction with minimal accuracy loss.&lt;/p&gt;

&lt;p&gt;Quantization to INT8 (8-bit integers) from FP32 (32-bit floats) gives 4√ó memory reduction: 10M parameters now only 10MB vs 40MB. Combined with pruning: 2.5GB ‚Üí 1GB ‚Üí 250MB‚Äî10√ó total compression.&lt;/p&gt;

&lt;p&gt;Knowledge distillation transfers this compressed model‚Äôs knowledge to a MobileNet (4M parameters). The MobileNet learns from ResNet‚Äôs soft predictions, achieving 75% accuracy versus 70% training on labels alone‚Äîthe extra 5% comes from learning what ResNet thinks about hard examples.&lt;/p&gt;

&lt;p&gt;Final: 4M parameters, 40MB INT8 model achieving 75% accuracy versus original 25M parameters, 4GB FP32 achieving 78% accuracy. 100√ó smaller, 10√ó faster inference, only 3% accuracy loss‚Äîenabling mobile deployment!&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Pruning example
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;magnitude_prune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sparsity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Remove smallest magnitude weights&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;modules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;isinstance&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;quantile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sparsity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Quantization
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;quantize_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_bits&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Quantize tensor to num_bits&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;qmin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;qmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_bits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;min_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;qmin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;qmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_val&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Knowledge distillation
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;distillation_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;student_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;teacher_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Combine hard and soft targets&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;hard_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;student_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;soft_student&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;student_logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;soft_teacher&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;teacher_logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;soft_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;kl_div&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;soft_student&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft_teacher&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;batchmean&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hard_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soft_loss&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Model compression connects to neural architecture search (NAS), which discovers efficient architectures automatically. NAS explores architecture space, evaluating candidates by accuracy-efficiency tradeoffs.&lt;/p&gt;

&lt;p&gt;Compression relates to lottery ticket hypothesis: random networks contain subnetworks that, when trained, match full network performance. Finding these ‚Äúwinning tickets‚Äù provides alternative to post-training pruning.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.02626&quot;&gt;‚ÄúLearning both Weights and Connections for Efficient Neural Networks‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Song Han, Jeff Pool, John Tran, William Dally&lt;br /&gt;
Introduced magnitude-based pruning achieving 9-13√ó compression on AlexNet and VGGNet with minimal accuracy loss.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1503.02531&quot;&gt;‚ÄúDistilling the Knowledge in a Neural Network‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Geoffrey Hinton, Oriol Vinyals, Jeff Dean&lt;br /&gt;
Knowledge distillation paper showing student networks learn better from teacher predictions than from labels alone.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;&gt;‚ÄúMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Andrew Howard et al.&lt;br /&gt;
MobileNets use depthwise separable convolutions, reducing computation 8-9√ó versus standard convolutions while maintaining accuracy.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Model compression makes deep learning practical on resource-constrained devices through pruning (removing unnecessary parameters), quantization (reducing numerical precision), knowledge distillation (transferring large model knowledge to small models), and efficient architectures (designed for efficiency from scratch). These techniques enable 10-100√ó compression with minimal accuracy loss, democratizing deep learning deployment beyond cloud servers to edge devices, enabling real-time inference, and reducing environmental impact through lower computational requirements.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>23 Efficient Deep Learning</title>
   <link href="http://localhost:4000/contents/en/chapter23/23_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter23/23_00_Introduction</id>
   <content type="html">&lt;p&gt;Efficient deep learning makes models faster, smaller, and more deployable. This chapter covers model compression (pruning, quantization, knowledge distillation), efficient architectures (MobileNet, EfficientNet), hardware acceleration (GPUs, TPUs), mixed-precision training, and deployment strategies for edge devices and production systems.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>22-01 Graph Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_01_GNN_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter22/22_01_GNN_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;graph-neural-networks-deep-learning-on-graphs&quot;&gt;Graph Neural Networks: Deep Learning on Graphs&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://distill.pub/2021/gnn-intro/graph_neural_network.png&quot; alt=&quot;Graph Neural Network&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c Graph Neural Network v·ªõi message passing. Ngu·ªìn: Distill.pub&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Graph Neural Networks extend deep learning to graph-structured data, enabling neural networks to process networks of entities and relationships that pervade real-world data: social networks connecting people, molecular graphs connecting atoms, knowledge graphs linking concepts, citation networks relating papers, and recommendation systems connecting users and items. Unlike images (regular 2D grids) or sequences (1D chains), graphs have arbitrary structure‚Äîvariable numbers of neighbors, no spatial ordering, complex connectivity patterns‚Äîrequiring specialized neural architectures that can leverage this structure while remaining differentiable and trainable via backpropagation.&lt;/p&gt;

&lt;p&gt;The fundamental challenge graphs present is permutation invariance: a graph‚Äôs representation shouldn‚Äôt depend on how we order its nodes. If nodes are numbered 1,2,3 versus 3,2,1, the graph is identical, so representations should be too. This rules out naive approaches like feeding adjacency matrices to standard neural networks (which treat different orderings as different inputs). GNNs solve this through message passing: nodes iteratively aggregate information from neighbors through learned transformations, with aggregation functions (sum, mean, max) that are permutation-invariant. After several iterations, each node‚Äôs representation incorporates information from its neighborhood, with larger neighborhoods accessible through more iterations.&lt;/p&gt;

&lt;p&gt;Understanding GNNs requires appreciating that different graph learning tasks require different outputs. Node classification predicts labels for nodes (categorizing users in social networks). Link prediction predicts missing or future edges (recommending friendships or products). Graph classification predicts labels for entire graphs (classifying molecules as active/inactive for drugs). Each task uses the same message passing framework but differs in how node representations are aggregated and what predictions are made.&lt;/p&gt;

&lt;p&gt;The applications of GNNs span diverse domains. In chemistry, molecular graphs (atoms as nodes, bonds as edges) are processed by GNNs to predict properties like solubility or toxicity. In social networks, GNNs detect communities, predict friendships, or identify influential users. In recommender systems, bipartite graphs (users and items) are processed to predict preferences. In protein structure prediction, GNNs model amino acid interactions. In traffic prediction, road networks inform forecasting. This versatility demonstrates that graph structure is ubiquitous, and GNNs provide a general framework for learning from it.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;A graph \(\mathcal{G} = (\mathcal{V}, \mathcal{E})\) consists of nodes \(\mathcal{V} = \{v_1, \ldots, v_n\}\) and edges \(\mathcal{E} \subseteq \mathcal{V} \times \mathcal{V}\). Nodes have features \(\mathbf{x}_i \in \mathbb{R}^d\), and edges may have features \(\mathbf{e}_{ij}\). The adjacency matrix \(\mathbf{A} \in \{0,1\}^{n \times n}\) encodes structure: \(A_{ij} = 1\) if edge \((v_i, v_j) \in \mathcal{E}\), else 0.&lt;/p&gt;

&lt;h3 id=&quot;message-passing-framework&quot;&gt;Message Passing Framework&lt;/h3&gt;

&lt;p&gt;GNNs update node representations through iterative message passing. At layer \(k\), node \(i\)‚Äôs representation \(\mathbf{h}_i^{(k)}\) is updated based on neighbors:&lt;/p&gt;

\[\mathbf{h}_i^{(k)} = \text{UPDATE}^{(k)}\left(\mathbf{h}_i^{(k-1)}, \text{AGGREGATE}^{(k)}\left(\{\mathbf{h}_j^{(k-1)} : j \in \mathcal{N}(i)\}\right)\right)\]

&lt;p&gt;where \(\mathcal{N}(i)\) are neighbors of \(i\). AGGREGATE combines neighbor features (must be permutation-invariant), UPDATE combines node‚Äôs own features with aggregated neighbor information.&lt;/p&gt;

&lt;h3 id=&quot;graph-convolutional-networks-gcn&quot;&gt;Graph Convolutional Networks (GCN)&lt;/h3&gt;

&lt;p&gt;GCN uses spectral graph theory, defining convolution through graph Laplacian. The practical form:&lt;/p&gt;

\[\mathbf{H}^{(k+1)} = \sigma(\tilde{\mathbf{D}}^{-1/2}\tilde{\mathbf{A}}\tilde{\mathbf{D}}^{-1/2}\mathbf{H}^{(k)}\mathbf{W}^{(k)})\]

&lt;p&gt;where \(\tilde{\mathbf{A}} = \mathbf{A} + \mathbf{I}\) (adjacency plus self-loops), \(\tilde{\mathbf{D}}\) is degree matrix, \(\mathbf{H}^{(k)}\) are node representations at layer \(k\), \(\mathbf{W}^{(k)}\) are learned weights.&lt;/p&gt;

&lt;p&gt;This performs weighted aggregation of neighbors followed by linear transformation and nonlinearity, with weights inversely proportional to node degrees (high-degree nodes contribute less per neighbor).&lt;/p&gt;

&lt;h3 id=&quot;graphsage&quot;&gt;GraphSAGE&lt;/h3&gt;

&lt;p&gt;GraphSAGE samples fixed-size neighborhoods and uses learned aggregation:&lt;/p&gt;

\[\mathbf{h}_{\mathcal{N}(i)}^{(k)} = \text{AGGREGATE}(\{\mathbf{h}_j^{(k-1)} : j \in \mathcal{N}(i)\})\]

\[\mathbf{h}_i^{(k)} = \sigma(\mathbf{W}^{(k)} \cdot [\mathbf{h}_i^{(k-1)}, \mathbf{h}_{\mathcal{N}(i)}^{(k)}])\]

&lt;p&gt;AGGREGATE can be mean, max, or LSTM over neighborhood. This enables mini-batch training and handles variable-size neighborhoods.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider a social network: nodes are people, edges are friendships, node features include age, location, interests. We want to predict which users will like a new product (node classification).&lt;/p&gt;

&lt;p&gt;A 2-layer GNN works as follows. Initially, each user‚Äôs representation \(\mathbf{h}_i^{(0)}\) is their raw features. After layer 1, \(\mathbf{h}_i^{(1)}\) incorporates information from immediate friends (1-hop neighbors). User A‚Äôs representation now includes ‚Äúmy friends are ages 25-30, mostly in urban areas, interested in tech‚Äù‚Äîaggregated neighbor information. After layer 2, \(\mathbf{h}_i^{(2)}\) incorporates friends-of-friends (2-hop neighborhood). User A‚Äôs representation captures broader social context.&lt;/p&gt;

&lt;p&gt;For prediction, the network learns that users whose neighborhoods have certain patterns (many tech-interested friends, urban clustering) are likely to like tech products. The GNN provides features capturing both individual attributes and social context for classification.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCNLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Single Graph Convolutional Layer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xavier_uniform_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (num_nodes, in_features)
        adj: (num_nodes, num_nodes) adjacency matrix
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Add self-loops
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;adj_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Normalize
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;deg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;deg_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;deg_inv_sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deg_inv_sqrt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;inf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;diag&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deg_inv_sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;adj_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;norm&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply convolution
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;support&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2-layer Graph Convolutional Network&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCNLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCNLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_nodes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gcn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GCN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Random graph
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_nodes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Symmetric
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gcn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GCN output: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (100, 7)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each node gets class predictions using graph structure!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;GNNs connect to spectral graph theory through their mathematical foundations. Graph Laplacians and eigendecompositions provide theoretical basis for defining convolution on graphs, generalizing CNNs‚Äô convolution from regular grids to arbitrary graphs.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1609.02907&quot;&gt;‚ÄúSemi-Supervised Classification with Graph Convolutional Networks‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Thomas Kipf, Max Welling&lt;br /&gt;
Introduced GCN, establishing message passing on graphs as effective deep learning approach. Demonstrated semi-supervised node classification using graph structure plus limited labels.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.02216&quot;&gt;‚ÄúInductive Representation Learning on Large Graphs‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: William Hamilton, Rex Ying, Jure Leskovec&lt;br /&gt;
GraphSAGE enabled learning on large graphs through neighborhood sampling, allowing mini-batch training. Extended GNNs from transductive (fixed graph) to inductive (generalizing to new nodes/graphs).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.10903&quot;&gt;‚ÄúGraph Attention Networks‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Petar Veliƒçkoviƒá, Guilermo Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li√≤, Yoshua Bengio&lt;br /&gt;
GAT used attention mechanisms to weight neighbor contributions, learning importance of different neighbors. More flexible than fixed aggregation.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Oversmoothing occurs with many GNN layers‚Äînode representations become indistinguishable as they aggregate from increasingly large neighborhoods. Use skip connections, batch normalization, or careful depth selection (2-3 layers often sufficient).&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Graph Neural Networks process graph-structured data through message passing, iteratively updating node representations by aggregating information from neighbors through learned, permutation-invariant functions. GCNs use normalized adjacency matrices for spectral graph convolution. GraphSAGE samples neighborhoods for scalability. Graph attention networks learn neighbor importance through attention. Applications span social networks, molecules, knowledge graphs, and recommendation systems. GNNs enable deep learning on irregular, relational data where CNNs and RNNs don‚Äôt apply, opening graph-structured domains to modern AI.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>22 Graph Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter22/22_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter22/22_00_Introduction</id>
   <content type="html">&lt;p&gt;Graph Neural Networks (GNNs) extend deep learning to graph-structured data: social networks, molecules, knowledge graphs, and recommendation systems. This chapter covers graph representations, message passing, Graph Convolutional Networks (GCN), GraphSAGE, Graph Attention Networks (GAT), and applications in node classification, link prediction, and graph generation.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>21-01 Deep Reinforcement Learning</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_01_Deep_RL/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter21/21_01_Deep_RL</id>
   <content type="html">&lt;h1 id=&quot;deep-reinforcement-learning-neural-networks-meet-sequential-decision-making&quot;&gt;Deep Reinforcement Learning: Neural Networks Meet Sequential Decision Making&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Deep Reinforcement Learning combines the representation learning power of deep neural networks with the sequential decision-making framework of reinforcement learning, enabling agents to learn complex behaviors directly from high-dimensional sensory inputs like images or raw sensor data. While classical RL required hand-crafted feature representations and could only handle low-dimensional state spaces, deep RL learns both the representation and the policy end-to-end, scaling to problems previously intractable: playing video games from pixels, controlling robots from camera inputs, mastering chess and Go at superhuman levels, and learning complex manipulation skills through trial and error.&lt;/p&gt;

&lt;p&gt;The key insight making deep RL work is using neural networks as function approximators for value functions or policies. Instead of maintaining explicit tables \(Q(s,a)\) for every state-action pair (impossible for high-dimensional states like 84√ó84√ó4 Atari frames with \(256^{84 \times 84 \times 4} \approx 10^{67000}\) possible states), we approximate \(Q(s,a) \approx Q(s,a;\theta)\) with a neural network parameterized by \(\theta\). The network learns to generalize across similar states‚Äîhaving learned to recognize enemies in one game location, it applies this knowledge to other locations‚Äîenabling learning from feasible amounts of experience rather than requiring exhaustive exploration.&lt;/p&gt;

&lt;p&gt;However, combining deep learning with RL introduces unique challenges absent in either field individually. RL generates its own training data through interaction, creating correlations between sequential samples that violate the i.i.d. assumption underlying standard neural network training. The target values in Q-learning are non-stationary‚Äîthey depend on the current Q-network which is constantly updating, creating a moving target that can cause instability. The exploration-exploitation tradeoff becomes more critical when actions affect what data the agent sees, potentially causing the agent to get stuck in sub-optimal behaviors that prevent discovering better alternatives.&lt;/p&gt;

&lt;p&gt;Deep Q-Networks (DQN), introduced by DeepMind in 2013, solved these challenges through two key innovations: experience replay and target networks. Experience replay stores past experiences in a buffer and samples uniformly for training, breaking temporal correlations and allowing reuse of rare experiences. Target networks provide stable targets by updating slowly, preventing the oscillations that occur when chasing a constantly moving target. These techniques, combined with careful architecture design and training procedures, enabled learning to play Atari games directly from pixels at human or superhuman levels‚Äîa watershed moment demonstrating deep learning could tackle sequential decision-making at scale.&lt;/p&gt;

&lt;p&gt;The success of deep RL extends far beyond games. AlphaGo combined deep neural networks with Monte Carlo tree search to defeat world champions at Go, a game previously thought to require decades more progress. Robotic systems learn manipulation skills through deep RL, discovering strategies humans never explicitly programmed. Language models are fine-tuned through reinforcement learning from human feedback (RLHF), aligning them with human preferences for helpfulness and safety. Autonomous vehicles learn driving policies through simulation and real-world interaction. Understanding deep RL opens this vast application space while providing insights into how systems can learn complex behaviors through interaction rather than passive observation.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Deep Q-Networks extend Q-learning to continuous state spaces through neural function approximation. The Q-function is approximated as \(Q(s,a;\theta)\) where \(\theta\) are neural network parameters. Given transition \((s_t, a_t, r_t, s_{t+1})\), standard Q-learning updates:&lt;/p&gt;

\[Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_t + \gamma \max_{a&apos;} Q(s_{t+1}, a&apos;) - Q(s_t, a_t)]\]

&lt;p&gt;With neural networks, this becomes a gradient descent update minimizing squared TD error:&lt;/p&gt;

\[\mathcal{L}(\theta) = \mathbb{E}_{(s,a,r,s&apos;) \sim \mathcal{D}}\left[\left(r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;; \theta^-) - Q(s,a;\theta)\right)^2\right]\]

&lt;p&gt;where \(\mathcal{D}\) is experience replay buffer and \(\theta^-\) are target network parameters (updated periodically from \(\theta\)).&lt;/p&gt;

&lt;p&gt;The gradient with respect to \(\theta\) is:&lt;/p&gt;

\[\nabla_\theta \mathcal{L}(\theta) = \mathbb{E}\left[\left(r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;; \theta^-) - Q(s,a;\theta)\right) \nabla_\theta Q(s,a;\theta)\right]\]

&lt;p&gt;Notice the target \(r + \gamma \max_{a&apos;} Q(s&apos;, a&apos;; \theta^-)\) is treated as constant (no gradient through \(\theta^-\)), preventing unstable feedback loops that would occur if targets depended on parameters being optimized.&lt;/p&gt;

&lt;h3 id=&quot;experience-replay&quot;&gt;Experience Replay&lt;/h3&gt;

&lt;p&gt;The replay buffer \(\mathcal{D}\) stores recent transitions: \(\mathcal{D} = \{(s_i, a_i, r_i, s_i&apos;)\}_{i=1}^N\) with capacity \(N\) (typically 100K-1M). Each training iteration:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Agent takes action, observes transition, adds to \(\mathcal{D}\)&lt;/li&gt;
  &lt;li&gt;Sample mini-batch uniformly from \(\mathcal{D}\)&lt;/li&gt;
  &lt;li&gt;Compute loss and gradient on mini-batch&lt;/li&gt;
  &lt;li&gt;Update \(\theta\) via gradient descent&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Uniform sampling breaks temporal correlations (adjacent experiences are correlated, but random samples from buffer aren‚Äôt), stabilizing training. Reusing experiences improves sample efficiency‚Äîeach experience can be used in multiple updates rather than once.&lt;/p&gt;

&lt;h3 id=&quot;target-network&quot;&gt;Target Network&lt;/h3&gt;

&lt;p&gt;Maintain two networks: online network \(Q(s,a;\theta)\) updated every step, and target network \(Q(s,a;\theta^-)\) updated periodically (every \(C\) steps):&lt;/p&gt;

\[\theta^- \leftarrow \theta \quad \text{every } C \text{ steps}\]

&lt;p&gt;This provides stable targets for \(C\) steps, preventing the moving target problem where both the prediction and target change simultaneously, causing oscillations. Typical \(C = 10,000\) steps.&lt;/p&gt;

&lt;h3 id=&quot;policy-gradient-methods&quot;&gt;Policy Gradient Methods&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;An alternative to value-based RL directly parameterizes the policy $$\pi(a&lt;/td&gt;
      &lt;td&gt;s;\theta)$$. The objective is expected return:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta}\left[\sum_{t=0}^T \gamma^t r_t\right]\]

&lt;p&gt;The policy gradient theorem gives:&lt;/p&gt;

\[\nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta}\left[\sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t|s_t) \cdot G_t\right]\]

&lt;p&gt;where \(G_t = \sum_{k=t}^T \gamma^{k-t} r_k\) is return from time \(t\). This remarkable result says we can estimate the gradient by sampling trajectories, computing returns, and weighting log-probabilities of actions by returns. High-return actions get positive weight (increase probability), low-return actions get negative weight (decrease probability).&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Actor-Critic methods combine value and policy learning. The actor (policy $$\pi(a&lt;/td&gt;
      &lt;td&gt;s;\theta)\() selects actions, the critic (value function\)V(s;\phi)$$) evaluates them. The actor updates using policy gradient with advantage:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\nabla_\theta J(\theta) \propto \nabla_\theta \log \pi_\theta(a_t|s_t) \cdot A(s_t, a_t)\]

&lt;p&gt;where \(A(s_t, a_t) = Q(s_t, a_t) - V(s_t)\) is advantage (how much better than average this action is). The critic updates to better estimate values, providing better advantage estimates for the actor.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Imagine teaching an agent to play Pong from pixel inputs. The state is an 84√ó84 grayscale image showing paddles and ball. Actions are {up, down, stay}. The agent must learn to move the paddle to hit the ball‚Äîa simple task for humans but challenging for RL.&lt;/p&gt;

&lt;p&gt;Initially, the agent takes random actions. Occasionally it hits the ball by chance, receiving +1 reward. The DQN updates Q-values for states/actions leading to this reward. For the state ‚Äúball approaching my paddle from upper-left,‚Äù action ‚Äúmove up‚Äù gets higher Q-value. Through thousands of games, patterns emerge:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Ball high, paddle low ‚Üí move up has high Q-value&lt;/li&gt;
  &lt;li&gt;Ball low, paddle high ‚Üí move down has high Q-value&lt;/li&gt;
  &lt;li&gt;Ball middle, paddle middle ‚Üí stay has high Q-value&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The neural network learns these patterns not through explicit rules but by associating visual patterns (ball position relative to paddle) with action values. Crucially, it learns the dynamics: where the ball will be, not just where it is now, enabling anticipatory control.&lt;/p&gt;

&lt;p&gt;The experience replay buffer contains diverse situations: paddle at top with ball approaching, paddle at bottom with ball far away, etc. Uniformly sampling this buffer prevents the network from forgetting how to handle situations it hasn‚Äôt seen recently‚Äîa problem called catastrophic forgetting that would occur if training only on the current game state.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Complete DQN implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;deque&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Deep Q-Network for Atari-style games.
    
    Architecture: Conv layers extract features from frames,
    fully connected layers output Q-values for each action.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Input: (batch, 4, 84, 84) - 4 stacked frames
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Calculate conv output size
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;conv_output_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Fully connected layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Q-value per action
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;x: (batch, 4, 84, 84) stacked frames&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReplayBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Experience replay buffer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;deque&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;push&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DQNAgent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Complete DQN agent with experience replay and target network&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Online and target networks
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DQN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.00025&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ReplayBuffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;capacity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.99&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon_decay&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.995&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_update_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;select_action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Œµ-greedy action selection&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randrange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;state_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;q_values&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Single training step on mini-batch from replay buffer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Sample mini-batch
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dones&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Convert to tensors
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;next_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dones&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute current Q-values
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;current_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gather&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute target Q-values using target network
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;target_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;target_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rewards&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_q&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute loss
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Optimize
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Gradient clipping for stability
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip_grad_norm_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Update target network periodically
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_update_freq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decay epsilon
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon_decay&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Deep Q-Network (DQN) Agent&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate DQN components
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_shape&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;84&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 4 stacked frames
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DQNAgent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;DQN Components:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Policy network: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;policy_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Target network: Same architecture, updated every &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_update_freq&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; steps&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Replay buffer: Capacity &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;memory&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;maxlen&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Batch size: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Discount Œ≥: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Initial Œµ: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (decays to &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;agent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon_min&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate training loop structure
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;DQN Training Loop:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  1. Select action using Œµ-greedy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  2. Execute in environment, observe reward and next state&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  3. Store transition in replay buffer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  4. Sample mini-batch from buffer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  5. Compute Q-learning loss with target network&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  6. Update policy network via gradient descent&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  7. Periodically copy policy ‚Üí target network&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This combination of techniques enables stable deep RL training!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Deep RL connects to supervised learning through imitation learning. Instead of learning from rewards, agents can learn from expert demonstrations‚Äîsupervised learning on (state, action) pairs. This often provides better initialization than random policies, with subsequent RL fine-tuning adapting to the specific environment.&lt;/p&gt;

&lt;p&gt;The relationship to evolutionary strategies shows alternative optimization approaches. Instead of gradient-based policy improvement, evolve population of policies through selection and mutation. Deep neuroevolution has achieved competitive results, particularly for tasks where gradients are unreliable.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;‚ÄúPlaying Atari with Deep Reinforcement Learning‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Volodymyr Mnih et al. (DeepMind)&lt;br /&gt;
DQN paper showed deep networks could learn control policies from pixels, combining Q-learning with deep CNN function approximation, experience replay, and target networks. Achieved human-level performance on multiple Atari games, launching deep RL revolution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.nature.com/articles/nature14236&quot;&gt;‚ÄúHuman-level control through deep reinforcement learning‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Volodymyr Mnih et al. (DeepMind)&lt;br /&gt;
Nature publication demonstrating DQN achieving human-level performance across 49 Atari games with single architecture and hyperparameters. Established deep RL as viable approach for complex control from high-dimensional inputs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1602.01783&quot;&gt;‚ÄúAsynchronous Methods for Deep Reinforcement Learning‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Volodymyr Mnih et al.&lt;br /&gt;
A3C parallelized RL across multiple agents, removing need for experience replay through asynchronous updates. Achieved better performance with less training time, establishing actor-critic methods as alternative to value-based approaches.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1707.06347&quot;&gt;‚ÄúProximal Policy Optimization Algorithms‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov&lt;br /&gt;
PPO simplified policy gradient methods while maintaining performance through clipped surrogate objective preventing excessively large policy updates. Became de facto standard for policy gradient RL due to simplicity and robustness.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.nature.com/articles/nature24270&quot;&gt;‚ÄúMastering the game of Go without human knowledge‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: David Silver et al. (DeepMind)&lt;br /&gt;
AlphaGo Zero achieved superhuman Go performance through pure self-play without human data, using deep RL with MCTS. Demonstrated RL‚Äôs potential for discovering novel strategies surpassing human knowledge.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Reward shaping can help or hurt. Providing intermediate rewards for subgoals speeds learning but might create unintended behaviors (agent learns to maximize shaped rewards instead of true objective). Use carefully and validate final behavior on true rewards.&lt;/p&gt;

&lt;p&gt;Hyperparameter sensitivity in deep RL exceeds supervised learning. Learning rate, replay buffer size, update frequency, exploration schedule‚Äîall significantly affect performance. Extensive tuning often necessary. Start with published hyperparameters for similar tasks.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Deep reinforcement learning combines neural networks with RL, using networks as function approximators for value functions or policies, enabling learning from high-dimensional inputs like images. DQN uses experience replay to break temporal correlations and target networks for stable Q-learning targets, achieving human-level Atari game performance. Policy gradient methods directly optimize policy networks through REINFORCE or actor-critic approaches, often more stable than value methods for continuous actions. Deep RL has achieved remarkable successes including mastering Go, robotic control, and game playing, while remaining challenging due to sample inefficiency, hyperparameter sensitivity, and training instability. Understanding deep RL requires appreciating both RL foundations (MDPs, value functions, exploration) and deep learning techniques (CNNs for vision, gradient descent, architecture design), combining both fields‚Äô insights to create agents that learn complex behaviors through interaction.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>21 Deep Reinforcement Learning</title>
   <link href="http://localhost:4000/contents/en/chapter21/21_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter21/21_00_Introduction</id>
   <content type="html">&lt;p&gt;Deep Reinforcement Learning combines deep neural networks with RL to handle high-dimensional state spaces. This chapter covers DQN (Deep Q-Network), policy gradient methods (REINFORCE, A3C), actor-critic methods (A2C, PPO), and applications like game playing (AlphaGo) and robotics. We explore how deep learning enables RL to solve complex real-world problems.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>20-01 Reinforcement Learning Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_01_RL_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter20/20_01_RL_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;reinforcement-learning-learning-from-interaction&quot;&gt;Reinforcement Learning: Learning from Interaction&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/1b/Reinforcement_learning_diagram.svg/800px-Reinforcement_learning_diagram.svg.png&quot; alt=&quot;Reinforcement Learning Diagram&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: S∆° ƒë·ªì Reinforcement Learning v·ªõi agent, environment, actions v√† rewards. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Reinforcement learning represents a fundamentally different learning paradigm than the supervised and unsupervised learning we‚Äôve studied. Instead of learning from labeled examples or discovering patterns in unlabeled data, RL agents learn by interacting with an environment, taking actions, observing outcomes, and receiving rewards. The agent‚Äôs goal is to discover a policy‚Äîa strategy for choosing actions‚Äîthat maximizes cumulative reward over time. This trial-and-error learning with delayed rewards mirrors how humans and animals learn many skills: we try actions, experience consequences, and gradually improve our behavior to achieve desired outcomes.&lt;/p&gt;

&lt;p&gt;Understanding RL requires appreciating what makes it challenging compared to supervised learning. In supervised learning, we have correct answers for every input‚Äîthe model learns from examples of optimal behavior. In RL, we only have rewards indicating how good outcomes were, not which specific actions were optimal. The agent must explore different actions to discover which lead to high rewards, creating an exploration-exploitation tradeoff: should we exploit known good actions or explore potentially better alternatives? Moreover, rewards are often delayed‚Äîan action‚Äôs consequences might not be apparent until many steps later (in chess, moves early in the game affect victory or defeat much later). Credit assignment becomes challenging: which of the many actions taken contributed to the final reward?&lt;/p&gt;

&lt;p&gt;The mathematical framework of Markov Decision Processes provides elegant formalization of sequential decision-making under uncertainty. States represent the environment‚Äôs configuration, actions are choices available to the agent, transitions describe how actions change states (potentially stochastically), and rewards provide learning signal. The Markov property‚Äîthat the future depends only on the present state, not the full history‚Äîsimplifies analysis while being approximately true for many real-world problems when states are chosen appropriately. Value functions quantify the expected future reward from states or state-action pairs, providing targets for learning. Policies map states to actions, with the optimal policy selecting actions maximizing expected cumulative reward.&lt;/p&gt;

&lt;p&gt;The connection to deep learning through Deep Reinforcement Learning enables RL to scale to high-dimensional state spaces like images and large action spaces. Neural networks approximate value functions or policies, learning from experience through gradient descent. This combination has achieved remarkable success: AlphaGo mastering Go through self-play, Atari game playing from pixels, robotic manipulation learning from trial and error, and sophisticated language model alignment through reinforcement learning from human feedback (RLHF). Understanding RL fundamentals provides foundation for these deep RL methods covered in the next chapter.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;A Markov Decision Process (MDP) is defined by the tuple \((\mathcal{S}, \mathcal{A}, \mathcal{P}, \mathcal{R}, \gamma)\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\mathcal{S}\): State space (all possible environment configurations)&lt;/li&gt;
  &lt;li&gt;\(\mathcal{A}\): Action space (choices available to agent)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;\(\mathcal{P}\): Transition function $$P(s_{t+1}&lt;/td&gt;
          &lt;td&gt;s_t, a_t)$$ (dynamics)&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;\(\mathcal{R}\): Reward function \(R(s_t, a_t, s_{t+1})\) (feedback)&lt;/li&gt;
  &lt;li&gt;\(\gamma \in [0,1)\): Discount factor (balancing immediate vs future rewards)&lt;/li&gt;
&lt;/ul&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The agent follows a policy $$\pi(a&lt;/td&gt;
      &lt;td&gt;s)\(‚Äîprobability of action\)a\(in state\)s\(. The goal is finding optimal policy\)\pi^*$$ maximizing expected return:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[J(\pi) = \mathbb{E}_{\tau \sim \pi}\left[\sum_{t=0}^\infty \gamma^t r_t\right]\]

&lt;p&gt;where \(\tau = (s_0, a_0, r_0, s_1, a_1, r_1, \ldots)\) is a trajectory.&lt;/p&gt;

&lt;h3 id=&quot;value-functions&quot;&gt;Value Functions&lt;/h3&gt;

&lt;p&gt;The state value function quantifies expected return starting from state \(s\):&lt;/p&gt;

\[V^\pi(s) = \mathbb{E}_{\pi}\left[\sum_{t=0}^\infty \gamma^t r_t \mid s_0 = s\right]\]

&lt;p&gt;The action-value function (Q-function) includes the first action:&lt;/p&gt;

\[Q^\pi(s,a) = \mathbb{E}_{\pi}\left[\sum_{t=0}^\infty \gamma^t r_t \mid s_0 = s, a_0 = a\right]\]

&lt;p&gt;These satisfy Bellman equations expressing recursive relationships:&lt;/p&gt;

\[V^\pi(s) = \sum_a \pi(a|s) \sum_{s&apos;} P(s&apos;|s,a)[R(s,a,s&apos;) + \gamma V^\pi(s&apos;)]\]

\[Q^\pi(s,a) = \sum_{s&apos;} P(s&apos;|s,a)[R(s,a,s&apos;) + \gamma \sum_{a&apos;} \pi(a&apos;|s&apos;) Q^\pi(s&apos;, a&apos;)]\]

&lt;p&gt;The optimal value functions satisfy Bellman optimality equations:&lt;/p&gt;

\[V^*(s) = \max_a \sum_{s&apos;} P(s&apos;|s,a)[R(s,a,s&apos;) + \gamma V^*(s&apos;)]\]

\[Q^*(s,a) = \sum_{s&apos;} P(s&apos;|s,a)[R(s,a,s&apos;) + \gamma \max_{a&apos;} Q^*(s&apos;, a&apos;)]\]

&lt;p&gt;The optimal policy is greedy with respect to \(Q^*\): \(\pi^*(s) = \arg\max_a Q^*(s,a)\).&lt;/p&gt;

&lt;h3 id=&quot;q-learning&quot;&gt;Q-Learning&lt;/h3&gt;

&lt;p&gt;Q-learning learns \(Q^*\) without knowing transition probabilities through temporal difference learning:&lt;/p&gt;

\[Q(s_t, a_t) \leftarrow Q(s_t, a_t) + \alpha[r_t + \gamma \max_{a&apos;} Q(s_{t+1}, a&apos;) - Q(s_t, a_t)]\]

&lt;p&gt;The update uses observed reward \(r_t\) and estimated future value \(\max_{a&apos;} Q(s_{t+1}, a&apos;)\) to improve current estimate \(Q(s_t, a_t)\). This bootstrapping‚Äîusing one estimate to improve another‚Äîenables learning from experience without environment model.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider training an agent to play a simple game: navigate a 5√ó5 grid to reach a goal. States are positions (25 states), actions are {up, down, left, right}, reward is +10 at goal, -1 elsewhere (encouraging reaching goal quickly).&lt;/p&gt;

&lt;p&gt;Initially, Q-values are random. The agent starts at (0,0), takes random actions. After wandering, it accidentally reaches goal at (4,4), receiving +10 reward. Q-learning updates:&lt;/p&gt;

\[Q((4,3), \text{right}) \leftarrow Q((4,3), \text{right}) + \alpha[10 + 0 - Q((4,3), \text{right})]\]

&lt;p&gt;The Q-value for ‚Äúgo right from position next to goal‚Äù increases. Next time the agent reaches (4,3), it‚Äôs more likely to go right (if using Œµ-greedy policy based on Q-values).&lt;/p&gt;

&lt;p&gt;After more episodes, values propagate backward. Q((4,2), right) increases because it leads to (4,3) which now has high Q-value. Eventually, optimal Q-values form gradient pointing toward goal from every state, and the agent learns to navigate directly to goal from any starting position.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GridWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Simple grid environment for RL demonstration&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;goal&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Execute action, return (next_state, reward, done)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# up,down,left,right
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;actions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;new_y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;new_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;goal&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;goal&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Q-Learning
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;env&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GridWorld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Q(state, action)
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Learning rate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Discount
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Exploration
&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Q-Learning agent...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;episode&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Œµ-greedy action selection
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;env&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total_reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Q-learning update
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;best_next_action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reward&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_next_action&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;action&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_state&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;done&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;episode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Episode &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;episode&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Reward = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_reward&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Learned optimal policy!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;RL connects to control theory, operations research, and economics through optimal decision-making under uncertainty. Dynamic programming provides algorithms for computing optimal policies when environment dynamics are known. RL extends this to unknown dynamics, learning through interaction.&lt;/p&gt;

&lt;p&gt;RL relates to supervised learning through imitation learning and inverse RL. Rather than learning from rewards, agents can learn from demonstrations (supervised), or infer reward functions from expert behavior (inverse RL).&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://incompleteideas.net/book/the-book-2nd.html&quot;&gt;‚ÄúReinforcement Learning: An Introduction‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Richard Sutton, Andrew Barto&lt;br /&gt;
The definitive RL textbook, establishing mathematical foundations and core algorithms. Essential reading for anyone studying RL.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.5602&quot;&gt;‚ÄúPlaying Atari with Deep Reinforcement Learning‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Volodymyr Mnih et al.&lt;br /&gt;
DQN showed deep learning + RL could learn to play Atari games from pixels, launching deep RL revolution. Combined Q-learning with deep neural networks, experience replay, and target networks.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Exploration-exploitation tradeoff is crucial. Pure exploitation (always best known action) never discovers better alternatives. Pure exploration (random actions) doesn‚Äôt use learned knowledge. Œµ-greedy, softmax policies, or UCB-based methods balance both.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Reinforcement learning trains agents through interaction with environments, learning policies that maximize cumulative rewards through trial and error. MDPs formalize sequential decision-making with states, actions, transitions, and rewards. Value functions estimate expected future returns, providing targets for learning. Q-learning learns optimal action-values through temporal difference updates, enabling learning without environment model. The exploration-exploitation tradeoff requires balancing discovering new strategies versus using known good ones. RL‚Äôs delayed reward and credit assignment challenges make it harder than supervised learning but enable applications where supervision is unavailable or expensive.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>20 Reinforcement Learning Basics</title>
   <link href="http://localhost:4000/contents/en/chapter20/20_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter20/20_00_Introduction</id>
   <content type="html">&lt;p&gt;Reinforcement Learning (RL) trains agents to make sequential decisions by maximizing cumulative rewards. This chapter introduces the RL framework: agents, environments, states, actions, rewards, and policies. We cover Markov Decision Processes, value functions, Q-learning, and policy gradient methods. These fundamentals prepare you for deep RL in the next chapter.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>19 Speech and Audio Processing</title>
   <link href="http://localhost:4000/contents/en/chapter19/19_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter19/19_00_Introduction</id>
   <content type="html">&lt;p&gt;Deep learning has transformed audio processing, enabling speech recognition, speaker identification, music generation, and audio synthesis. This chapter covers audio representation (spectrograms, MFCCs), speech recognition architectures (DeepSpeech, Whisper), text-to-speech (WaveNet, Tacotron), and music generation models.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>18-01 Word Embeddings and Language Representation</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_01_Word_Embeddings/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter18/18_01_Word_Embeddings</id>
   <content type="html">&lt;h1 id=&quot;word-embeddings-representing-language-in-vector-space&quot;&gt;Word Embeddings: Representing Language in Vector Space&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/7/78/Word2vec.png/800px-Word2vec.png&quot; alt=&quot;Word2Vec Visualization&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça Word2Vec embeddings trong kh√¥ng gian vector. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Word embeddings represent one of the most fundamental innovations in natural language processing, transforming how we represent and process text in machine learning systems. The core idea is elegantly simple yet profoundly impactful: represent each word as a dense vector of real numbers (typically 100-300 dimensions) such that semantically similar words have similar vectors. This continuous vector representation replaces older sparse representations like one-hot encoding (vectors with thousands of dimensions, all zeros except one) with compact, meaningful embeddings that capture semantic relationships through geometric properties in vector space.&lt;/p&gt;

&lt;p&gt;Understanding why embeddings revolutionized NLP requires appreciating the limitations of discrete word representations. Traditional approaches treated words as atomic symbols‚Äî‚Äùking,‚Äù ‚Äúqueen,‚Äù and ‚Äúcar‚Äù were equally distant from each other, sharing no structure. One-hot encoding represents a 50,000-word vocabulary with 50,000-dimensional vectors that are all orthogonal, providing no notion of similarity. This makes learning difficult because the model cannot generalize from seeing ‚Äúking lives in palace‚Äù to understanding ‚Äúqueen lives in palace‚Äù‚Äîit must learn facts about ‚Äúqueen‚Äù independently despite semantic similarity to ‚Äúking.‚Äù&lt;/p&gt;

&lt;p&gt;Word embeddings solve this by learning continuous representations where similar words cluster together. The distance between ‚Äúking‚Äù and ‚Äúqueen‚Äù vectors is small (they‚Äôre both royalty), while ‚Äúking‚Äù and ‚Äúcar‚Äù are distant (semantically unrelated). More remarkably, embedding spaces exhibit analogical relationships through vector arithmetic: the vector from ‚Äúman‚Äù to ‚Äúwoman‚Äù is similar to the vector from ‚Äúking‚Äù to ‚Äúqueen,‚Äù capturing the gender relationship. We can solve analogies through simple vector math: king - man + woman ‚âà queen. This emergent structure wasn‚Äôt explicitly programmed but arose from training on text, demonstrating that embeddings capture deep semantic regularities.&lt;/p&gt;

&lt;p&gt;The training objective for learning embeddings is elegantly formulated through the distributional hypothesis from linguistics: words appearing in similar contexts have similar meanings. This simple principle enables unsupervised learning from massive text corpora. Models like Word2Vec and GloVe learn embeddings by predicting context words from target words or vice versa, or by factorizing co-occurrence statistics. The resulting vectors encode lexical semantics, syntactic patterns, and even some world knowledge, all discovered purely from word co-occurrence patterns in text without any labeled data.&lt;/p&gt;

&lt;p&gt;The impact of word embeddings on NLP cannot be overstated. They provided the foundation for the deep learning revolution in language processing, enabling neural networks to leverage vast unlabeled text for learning representations that then transfer to downstream tasks. Pre-trained embeddings like Word2Vec and GloVe became standard components in virtually all NLP systems from 2013-2018. While modern contextual embeddings from BERT and GPT have largely superseded static word embeddings for many tasks, understanding static embeddings remains crucial for appreciating how representation learning in NLP evolved and for applications where their simplicity and efficiency remain advantages.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Word embeddings map discrete symbols (words) to continuous vectors in a way that captures semantic similarity. Formally, we have a vocabulary \(V\) of size $$&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;\(and learn an embedding matrix\)\mathbf{E} \in \mathbb{R}^{d \times&lt;/td&gt;
      &lt;td&gt;V&lt;/td&gt;
      &lt;td&gt;}\(where column\)\mathbf{e}_w \in \mathbb{R}^d\(is the embedding for word\)w\(. Typical embedding dimension\)d = 100\text{-}300$$, much smaller than vocabulary size (10,000-100,000).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;word2vec-skip-gram-model&quot;&gt;Word2Vec: Skip-gram Model&lt;/h3&gt;

&lt;p&gt;The skip-gram model predicts context words given a target word, based on the distributional hypothesis. For a corpus with words \(w_1, w_2, \ldots, w_T\), the objective is:&lt;/p&gt;

\[\max_\theta \frac{1}{T}\sum_{t=1}^T \sum_{-c \leq j \leq c, j \neq 0} \log p(w_{t+j} | w_t; \theta)\]

&lt;p&gt;where \(c\) is context window size (typically 5), and \(\theta\) includes the embedding matrix and output weights. The conditional probability uses softmax:&lt;/p&gt;

\[p(w_O | w_I) = \frac{\exp(\mathbf{v}_{w_O}^T \mathbf{v}_{w_I})}{\sum_{w=1}^{|V|} \exp(\mathbf{v}_w^T \mathbf{v}_{w_I})}\]

&lt;p&gt;where \(\mathbf{v}_{w_I}\) is the input embedding of word \(w_I\) and \(\mathbf{v}_{w_O}\) is the output embedding of \(w_O\). Computing this softmax requires summing over the entire vocabulary (expensive!), motivating approximations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Negative sampling&lt;/strong&gt; approximates the softmax by sampling a few negative examples instead of summing over all words:&lt;/p&gt;

\[\log \sigma(\mathbf{v}_{w_O}^T \mathbf{v}_{w_I}) + \sum_{i=1}^k \mathbb{E}_{w_i \sim P_n(w)}[\log \sigma(-\mathbf{v}_{w_i}^T \mathbf{v}_{w_I})]\]

&lt;p&gt;where \(\sigma\) is sigmoid, \(k\) is number of negative samples (typically 5-20), and \(P_n(w)\) is noise distribution (often unigram raised to 3/4 power to oversample rare words). This transforms the multi-class problem into \(k+1\) binary classifications, tractable even for large vocabularies.&lt;/p&gt;

&lt;p&gt;The remarkable property of Word2Vec embeddings is that semantic relationships are encoded as linear translations in vector space:&lt;/p&gt;

\[\mathbf{e}_{\text{queen}} \approx \mathbf{e}_{\text{king}} - \mathbf{e}_{\text{man}} + \mathbf{e}_{\text{woman}}\]

\[\mathbf{e}_{\text{Paris}} \approx \mathbf{e}_{\text{France}} - \mathbf{e}_{\text{Germany}} + \mathbf{e}_{\text{Berlin}}\]

&lt;p&gt;These analogies weren‚Äôt explicitly trained but emerge from the distributional hypothesis: ‚Äúking‚Äù and ‚Äúqueen‚Äù appear in similar contexts (royal, throne, palace), as do ‚Äúking‚Äù and ‚Äúman‚Äù (gendered contexts), creating vector geometry that reflects these semantic patterns.&lt;/p&gt;

&lt;h3 id=&quot;glove-global-vectors&quot;&gt;GloVe: Global Vectors&lt;/h3&gt;

&lt;p&gt;GloVe takes a different approach, directly factorizing word co-occurrence statistics. Let \(X_{ij}\) be the number of times word \(j\) appears in word \(i\)‚Äôs context. GloVe minimizes:&lt;/p&gt;

\[J = \sum_{i,j=1}^{|V|} f(X_{ij})(\mathbf{w}_i^T \tilde{\mathbf{w}}_j + b_i + \tilde{b}_j - \log X_{ij})^2\]

&lt;p&gt;where \(\mathbf{w}_i\) and \(\tilde{\mathbf{w}}_j\) are word and context embeddings, \(b_i, \tilde{b}_j\) are biases, and \(f(X_{ij})\) is a weighting function:&lt;/p&gt;

\[f(x) = \begin{cases} (x/x_{\max})^\alpha &amp;amp; \text{if } x &amp;lt; x_{\max} \\ 1 &amp;amp; \text{otherwise} \end{cases}\]

&lt;p&gt;This weights frequent co-occurrences less heavily (they‚Äôre already well-represented) and caps influence of very frequent pairs. GloVe combines the benefits of global matrix factorization methods (leveraging entire corpus statistics) with local context window methods (Word2Vec), often producing embeddings competitive or superior to Word2Vec.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Imagine learning embeddings for a small vocabulary: {cat, dog, car, truck, animal, vehicle}. Initially, vectors are random. As we process text:&lt;/p&gt;

&lt;p&gt;‚ÄúThe cat is an animal‚Äù ‚Üí ‚Äúcat‚Äù and ‚Äúanimal‚Äù co-occur&lt;br /&gt;
‚ÄúThe dog is an animal‚Äù ‚Üí ‚Äúdog‚Äù and ‚Äúanimal‚Äù co-occur&lt;br /&gt;
‚ÄúThe car is a vehicle‚Äù ‚Üí ‚Äúcar‚Äù and ‚Äúvehicle‚Äù co-occur&lt;br /&gt;
‚ÄúThe truck is a vehicle‚Äù ‚Üí ‚Äútruck‚Äù and ‚Äúvehicle‚Äù co-occur&lt;/p&gt;

&lt;p&gt;The model adjusts vectors so:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;‚Äúcat‚Äù and ‚Äúdog‚Äù become close (both appear with ‚Äúanimal‚Äù)&lt;/li&gt;
  &lt;li&gt;‚Äúcar‚Äù and ‚Äútruck‚Äù become close (both appear with ‚Äúvehicle‚Äù)&lt;/li&gt;
  &lt;li&gt;‚Äúcat‚Äù and ‚Äúcar‚Äù stay distant (appear in different contexts)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After seeing enough text, the 2D embedding space might organize as:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;     animal
        ‚Üë
    dog ‚Ä¢ cat
        |
    ----+---- 
        |
  truck ‚Ä¢ car
        ‚Üì
     vehicle
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Semantic categories (animals vs vehicles) cluster, and within categories, similar items are nearby. We can compute:&lt;/p&gt;

&lt;p&gt;‚Äúcat‚Äù - ‚Äúanimal‚Äù ‚âà ‚Äúdog‚Äù - ‚Äúanimal‚Äù (both point from category to instance)&lt;br /&gt;
‚Äúcar‚Äù + ‚Äúvehicle‚Äù ‚âà ‚Äútruck‚Äù (category + similarity gives similar item)&lt;/p&gt;

&lt;p&gt;This geometric structure enables generalization: if the model learns facts about ‚Äúcat,‚Äù it can transfer to ‚Äúdog‚Äù through their vector similarity.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Complete Word2Vec implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collections&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Counter&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Word2VecSkipGram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Skip-gram Word2Vec with negative sampling.
    
    Learns word embeddings by predicting context words from target words.
    Uses negative sampling to make training efficient.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Input and output embeddings
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Input: embeddings used when word is target
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Output: embeddings used when word is context
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize with small random values
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;uniform_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                                   &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negative_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        target_words: (batch,) target word indices
        context_words: (batch,) context word indices (positive examples)
        negative_words: (batch, k) negative samples
        
        Returns negative log-likelihood
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Get embeddings
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;target_embeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;input_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, emb_dim)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context_embeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;output_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, emb_dim)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;neg_embeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;output_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;negative_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, k, emb_dim)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Positive scores (target-context similarity)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;pos_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_embeds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch,)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;pos_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Negative scores (target-negative dissimilarity)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;neg_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bmm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_embeds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;neg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pos_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;neg_loss&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Prepare training data
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Word2Vec Embeddings&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simple corpus for demonstration
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
the cat sat on the mat .
the dog sat on the rug .
the cat and the dog are animals .
the car is a vehicle .
the truck is a vehicle .
cats and dogs are pets .
cars and trucks are vehicles .
&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Build vocabulary
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx_to_word&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Corpus: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; words&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Vocabulary: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; unique words&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample vocab: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate training pairs
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_training_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generate (target, context) pairs&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get context (words within window)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context_start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Don&apos;t pair with self
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;context_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_training_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;corpus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;window_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; training pairs&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample pairs: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train Word2Vec
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Word2VecSkipGram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Small dim for demo
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training embeddings...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context_idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Sample negatives
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;neg_indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replace&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# To tensors
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;negatives&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neg_indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;negatives&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pairs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Analyze learned embeddings
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Analyzing Learned Embeddings&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Find nearest neighbors
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;find_nearest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_to_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Find k nearest words to query word&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;word_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;word_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute cosine similarities
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;similarities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_vec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word_vec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-10&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Get top k (excluding self)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argsort&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][::&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx_to_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;similarities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;top_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test semantic similarity
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dog&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;car&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;find_nearest&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_to_word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Nearest to &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;neighbors&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Embeddings learned semantic relationships from co-occurrence patterns!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Similar words (cat/dog, car/truck) have similar embeddings.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Word embeddings connect to distributional semantics, the linguistic theory that word meaning is determined by context. The computational implementation‚Äîlearning vectors such that words in similar contexts have similar representations‚Äîdirectly operationalizes this theory. Understanding this connection helps appreciate why embeddings work: they‚Äôre not arbitrary feature engineering but implementations of fundamental linguistic principles.&lt;/p&gt;

&lt;p&gt;Embeddings relate to dimensionality reduction techniques like PCA or autoencoders. We‚Äôre compressing high-dimensional one-hot vectors (vocab size) to low-dimensional dense vectors (embedding size) while preserving semantic information. The learned compression discovers that semantic relationships can be captured in far fewer dimensions than explicit symbol identity, revealing the intrinsic dimensionality of word semantics is much lower than vocabulary size.&lt;/p&gt;

&lt;p&gt;The evolution from static embeddings (Word2Vec, GloVe) to contextual embeddings (ELMo, BERT) reflects increasing sophistication. Static embeddings assign one vector per word type, so ‚Äúbank‚Äù (financial) and ‚Äúbank‚Äù (river) have identical representations despite different meanings. Contextual embeddings produce different vectors based on context, resolving polysemy. This evolution shows the field progressing from learning word-level representations to modeling language‚Äôs context-dependent nature.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1301.3781&quot;&gt;‚ÄúEfficient Estimation of Word Representations in Vector Space‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Tomas Mikolov, Kai Chen, Greg Corrado, Jeffrey Dean&lt;br /&gt;
Word2Vec introduced efficient methods (skip-gram and CBOW) for learning word embeddings at scale. The negative sampling training procedure enabled processing billions of words, making embeddings practical for large vocabularies. The paper demonstrated remarkable semantic properties‚Äîanalogies solved through vector arithmetic‚Äîshowing embeddings capture sophisticated language patterns. Word2Vec‚Äôs simplicity, efficiency, and quality made it widely adopted, establishing embeddings as fundamental to NLP.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://aclanthology.org/D14-1162/&quot;&gt;‚ÄúGloVe: Global Vectors for Word Representation‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jeffrey Pennington, Richard Socher, Christopher Manning&lt;br /&gt;
GloVe combined global matrix factorization with local context, factorizing word co-occurrence matrices to learn embeddings. The method achieved competitive or superior performance to Word2Vec while providing intuitive interpretation through co-occurrence statistics. GloVe demonstrated that different training objectives could produce similar high-quality embeddings, suggesting the representation itself matters more than specific training procedure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1802.05365&quot;&gt;‚ÄúDeep contextualized word representations‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer&lt;br /&gt;
ELMo introduced contextual embeddings from deep bidirectional LSTMs, representing each word differently based on sentence context. This addressed static embeddings‚Äô inability to handle polysemy and context-dependent meaning. ELMo showed that deep language models learn different types of information at different layers (syntax in lower, semantics in higher), and combining layers improves downstream tasks. ELMo represented transition from static to contextual representations, paving way for BERT and Transformers.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Using pre-trained embeddings without proper vocabulary alignment causes out-of-vocabulary issues. If your task vocabulary contains words not in the pre-trained embeddings, you need strategies: use subword embeddings (BPE, WordPiece), initialize missing words from similar words (if embeddings for ‚Äúcoronavirus‚Äù missing, average ‚Äúvirus‚Äù and ‚Äúcorona‚Äù), or fine-tune embeddings on domain-specific text.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Word embeddings represent words as dense continuous vectors where semantic similarity corresponds to geometric proximity, enabling neural networks to generalize across semantically related words through shared vector representations. Skip-gram Word2Vec predicts context from targets using negative sampling for efficiency, while GloVe factorizes co-occurrence matrices, both learning from unlabeled text through distributional hypothesis. The resulting embeddings exhibit remarkable properties including analogical reasoning through vector arithmetic (king - man + woman ‚âà queen) and semantic clustering (synonyms have similar vectors), all emerging from co-occurrence patterns without explicit supervision. Pre-trained embeddings like Word2Vec and GloVe transfer to downstream tasks, providing semantic representations that improve performance across NLP applications from sentiment analysis to machine translation. Modern contextual embeddings from BERT provide context-dependent representations addressing polysemy, though static embeddings remain useful for efficiency and interpretability. Understanding word embeddings provides foundation for all representation learning in NLP, demonstrating how neural networks can discover semantic structure purely from text patterns.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>18 Natural Language Processing</title>
   <link href="http://localhost:4000/contents/en/chapter18/18_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter18/18_00_Introduction</id>
   <content type="html">&lt;p&gt;NLP applies deep learning to understand and generate human language. This chapter covers word embeddings (Word2Vec, GloVe), language models (GPT, BERT), sequence tasks (NER, POS tagging), text classification, machine translation, question answering, and text generation. We explore modern NLP architectures and their practical applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17-01 Object Detection Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_01_Object_Detection/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter17/17_01_Object_Detection</id>
   <content type="html">&lt;h1 id=&quot;object-detection-localization-and-recognition&quot;&gt;Object Detection: Localization and Recognition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/38/Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg/800px-Detected-with-YOLO--Schreibtisch-mit-Objekten.jpg&quot; alt=&quot;Object Detection Example&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Object Detection v·ªõi YOLO - ph√°t hi·ªán v√† ƒë·ªãnh v·ªã nhi·ªÅu v·∫≠t th·ªÉ. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Object detection extends image classification from answering ‚Äúwhat objects are in this image?‚Äù to ‚Äúwhat objects are present and where are they located?‚Äù This seemingly small extension from classification to detection actually requires solving multiple interconnected problems simultaneously: proposing regions that might contain objects (region proposal), classifying what‚Äôs in each region (recognition), refining the boundaries of detections (localization), and handling multiple objects of different classes at different scales (multi-scale, multi-class detection). The complexity of coordinating these components while maintaining real-time performance has made object detection one of the most challenging and actively researched areas in computer vision.&lt;/p&gt;

&lt;p&gt;The evolution of object detection methods reveals a fascinating progression from traditional computer vision to modern deep learning approaches. Classical methods used hand-crafted features (SIFT, HOG) with sliding windows exhaustively searching every possible location and scale, then applying classifiers like SVMs. This was computationally expensive (evaluating millions of windows per image) and limited by feature quality. The deep learning revolution transformed object detection through learned features and end-to-end trainable systems, enabling dramatic improvements in both accuracy and speed.&lt;/p&gt;

&lt;p&gt;Modern object detection has branched into two major paradigms. Two-stage detectors like R-CNN, Fast R-CNN, and Faster R-CNN first propose regions likely to contain objects, then classify and refine these proposals. This explicit separation of region proposal and recognition enables high accuracy through focused computation on promising regions. Single-stage detectors like YOLO and SSD directly predict bounding boxes and class probabilities from regular grid positions, enabling real-time performance by avoiding the proposal stage at the cost of slightly lower accuracy on small objects.&lt;/p&gt;

&lt;p&gt;Understanding object detection deeply requires grasping several technical innovations that make modern systems work. Region Proposal Networks learn to generate object proposals rather than using hand-crafted rules, making the entire pipeline differentiable. Anchor boxes provide a way to handle objects of different aspect ratios and sizes through predefined box templates. Non-maximum suppression eliminates duplicate detections, addressing the fact that good detectors typically generate multiple overlapping boxes for each object. Feature pyramid networks enable detecting objects at multiple scales by building feature pyramies with rich semantics at all levels. These components, each solving a specific sub-problem, combine into systems that can detect and localize dozens of objects across multiple categories in milliseconds, enabling applications from autonomous driving to medical image analysis to augmented reality.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Object detection requires formalizing what we‚Äôre predicting and how we measure success. An object detection is a tuple \((\text{class}, x, y, w, h)\) specifying the object‚Äôs category and bounding box (center coordinates \(x,y\) and dimensions \(w,h\)). For an image with \(N\) objects, the ground truth is a set of such tuples: \(\{(\text{class}_i, x_i, y_i, w_i, h_i)\}_{i=1}^N\). Our detector must predict this set, which is challenging because \(N\) varies across images.&lt;/p&gt;

&lt;h3 id=&quot;intersection-over-union-iou&quot;&gt;Intersection over Union (IoU)&lt;/h3&gt;

&lt;p&gt;To measure localization quality, we use Intersection over Union between predicted and ground-truth boxes:&lt;/p&gt;

\[\text{IoU}(\text{box}_{\text{pred}}, \text{box}_{\text{gt}}) = \frac{\text{Area}(\text{box}_{\text{pred}} \cap \text{box}_{\text{gt}})}{\text{Area}(\text{box}_{\text{pred}} \cup \text{box}_{\text{gt}})}\]

&lt;p&gt;IoU ranges from 0 (no overlap) to 1 (perfect overlap). Typically, we consider a detection correct if IoU \(\geq 0.5\) and the predicted class matches ground truth. This threshold balances between requiring precise localization and allowing reasonable bounding box variations.&lt;/p&gt;

&lt;h3 id=&quot;bounding-box-regression&quot;&gt;Bounding Box Regression&lt;/h3&gt;

&lt;p&gt;Rather than directly predicting box coordinates, modern detectors predict offsets from anchor boxes (predefined reference boxes). Given anchor box \((\hat{x}, \hat{y}, \hat{w}, \hat{h})\) and ground truth \((\bar{x}, \bar{y}, \bar{w}, \bar{h})\), we parameterize targets as:&lt;/p&gt;

\[t_x = \frac{\bar{x} - \hat{x}}{\hat{w}}, \quad t_y = \frac{\bar{y} - \hat{y}}{\hat{h}}\]

\[t_w = \log\frac{\bar{w}}{\hat{w}}, \quad t_h = \log\frac{\bar{h}}{\hat{h}}\]

&lt;p&gt;The network predicts \((t_x, t_y, t_w, t_h)\), and we decode to absolute coordinates:&lt;/p&gt;

\[x = \hat{x} + \hat{w} \cdot t_x, \quad y = \hat{y} + \hat{h} \cdot t_y\]

\[w = \hat{w} \cdot \exp(t_w), \quad h = \hat{h} \cdot \exp(t_h)\]

&lt;p&gt;This parameterization is more learnable than direct coordinate prediction because offsets are typically small numbers with similar scales, while absolute coordinates span the entire image with very different scales for small versus large objects.&lt;/p&gt;

&lt;h3 id=&quot;multi-task-loss&quot;&gt;Multi-Task Loss&lt;/h3&gt;

&lt;p&gt;Object detectors optimize combined losses for classification and localization:&lt;/p&gt;

\[\mathcal{L} = \mathcal{L}_{\text{cls}} + \lambda \mathcal{L}_{\text{box}}\]

&lt;p&gt;where \(\mathcal{L}_{\text{cls}}\) is classification loss (cross-entropy) and \(\mathcal{L}_{\text{box}}\) is bounding box regression loss (smooth L1 or IoU loss). The weight \(\lambda\) balances these objectives‚Äîtoo high and the detector focuses on precise localization at the expense of correct classification; too low and classifications are accurate but boxes are poorly localized.&lt;/p&gt;

&lt;p&gt;For Faster R-CNN, the classification loss uses cross-entropy over classes plus background:&lt;/p&gt;

\[\mathcal{L}_{\text{cls}} = -\log p_{\text{class}}\]

&lt;p&gt;where \(\text{class}\) is the ground-truth class (or background if IoU &amp;lt; 0.5 with all ground-truth boxes).&lt;/p&gt;

&lt;p&gt;The box loss is smooth L1:&lt;/p&gt;

\[\mathcal{L}_{\text{box}} = \sum_{i \in \{x,y,w,h\}} \text{smooth}_{L1}(t_i - \hat{t}_i)\]

\[\text{smooth}_{L1}(x) = \begin{cases} 0.5x^2 &amp;amp; \text{if } |x| &amp;lt; 1 \\ |x| - 0.5 &amp;amp; \text{otherwise} \end{cases}\]

&lt;p&gt;Smooth L1 is less sensitive to outliers than L2 (quadratic becomes linear for large errors) while being differentiable everywhere (unlike pure L1).&lt;/p&gt;

&lt;h3 id=&quot;region-proposal-networks-rpn&quot;&gt;Region Proposal Networks (RPN)&lt;/h3&gt;

&lt;p&gt;Faster R-CNN introduced RPN, a fully convolutional network that predicts object proposals. At each position in the feature map, RPN predicts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Objectness scores: \(k\) anchors √ó 2 values (object vs background)&lt;/li&gt;
  &lt;li&gt;Box refinements: \(k\) anchors √ó 4 coordinates&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For a \(H \times W\) feature map with \(k=9\) anchors per position, RPN outputs:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Objectness: \(H \times W \times 9 \times 2\) scores&lt;/li&gt;
  &lt;li&gt;Box deltas: \(H \times W \times 9 \times 4\) values&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Total: \(HW \times 9\) proposals. Non-maximum suppression filters these to top \(\sim\)2000 based on objectness scores, which then go to the detection head.&lt;/p&gt;

&lt;p&gt;The RPN loss combines classification (objectness) and regression:&lt;/p&gt;

\[\mathcal{L}_{\text{RPN}} = \frac{1}{N_{\text{cls}}}\sum_i \mathcal{L}_{\text{cls}}(p_i, p_i^*) + \frac{\lambda}{N_{\text{box}}}\sum_i p_i^* \mathcal{L}_{\text{box}}(t_i, t_i^*)\]

&lt;p&gt;where \(p_i^* = 1\) if anchor \(i\) overlaps ground-truth with IoU &amp;gt; 0.7 (positive), \(p_i^* = 0\) if IoU &amp;lt; 0.3 (negative), and ignored if in between (to handle ambiguous cases).&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Imagine you‚Äôre trying to find and identify all people in a crowded photograph. Your strategy might be:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Quick scan&lt;/strong&gt; for regions likely to contain people (look for head shapes, body outlines)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closer examination&lt;/strong&gt; of promising regions (is this actually a person or a statue? Which person is it?)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Refinement&lt;/strong&gt; of boundaries (exactly where does this person‚Äôs bounding box start/end?)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;This three-stage process mirrors two-stage object detection. The Region Proposal Network does the quick scan, proposing ~2000 regions that might contain objects (people, cars, dogs, anything). The detection head examines each proposal, classifying what‚Äôs there and refining the bounding box. Non-maximum suppression eliminates duplicates (multiple overlapping boxes for the same person).&lt;/p&gt;

&lt;p&gt;Consider detecting cars in a street scene. The image might contain:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;3 cars at different distances (different sizes)&lt;/li&gt;
  &lt;li&gt;2 pedestrians&lt;/li&gt;
  &lt;li&gt;1 traffic sign&lt;/li&gt;
  &lt;li&gt;Complex background (buildings, trees)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A single-stage detector like YOLO divides the image into a grid (say 13√ó13). Each grid cell predicts:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Multiple bounding boxes (say 3, with different aspect ratios: tall, wide, square)&lt;/li&gt;
  &lt;li&gt;Class probabilities for each box&lt;/li&gt;
  &lt;li&gt;Confidence scores (is there an object here?)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For a grid cell at position (5, 8) near a car, it might predict:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Box 1: class=car, confidence=0.95, coordinates offset from cell center&lt;/li&gt;
  &lt;li&gt;Box 2: class=background, confidence=0.05&lt;/li&gt;
  &lt;li&gt;Box 3: class=background, confidence=0.02&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After processing all 13√ó13 cells, we have 13√ó13√ó3 = 507 predictions. Most are background (confidence near 0). NMS keeps only high-confidence, non-overlapping boxes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Car 1: confidence=0.95, box=[120, 200, 60, 40]&lt;/li&gt;
  &lt;li&gt;Car 2: confidence=0.89, box=[300, 180, 80, 50]&lt;/li&gt;
  &lt;li&gt;Car 3: confidence=0.76, box=[450, 220, 40, 25] (far car, smaller)&lt;/li&gt;
  &lt;li&gt;Person 1: confidence=0.92, box=[200, 150, 30, 80]&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The detector has identified all objects, classified them, and localized them with bounding boxes‚Äîexactly what object detection requires.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Complete Faster R-CNN style implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision.models.detection&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fasterrcnn_resnet50_fpn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision.models.detection.faster_rcnn&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;FastRCNNPredictor&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision.transforms&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Object Detection with Faster R-CNN&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load pre-trained Faster R-CNN
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Loading Pre-trained Faster R-CNN&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fasterrcnn_resnet50_fpn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;DEFAULT&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Faster R-CNN architecture:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Backbone: ResNet-50 + Feature Pyramid Network&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Region Proposal Network (RPN): Generates object proposals&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  RoI Pooling: Extracts features from proposals&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Detection Head: Classifies and refines boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Adapt for custom dataset (e.g., 10 classes + background)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 10 object classes + background
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Replace the classifier
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;roi_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_predictor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cls_score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;roi_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box_predictor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;FastRCNNPredictor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adapted for &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; object classes + background&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. Prepare custom dataset format
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Dataset Format for Object Detection&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CustomDetectionDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Object detection dataset format.
    
    Each sample returns:
    - image: (3, H, W) tensor
    - target: dictionary with:
        - boxes: (N, 4) tensor of [x1, y1, x2, y2] coordinates
        - labels: (N,) tensor of class indices
        - (optional) masks, keypoints, etc.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annotations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;annotations&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Load image (simulated here)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get annotations for this image
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [[x1,y1,x2,y2], ...]
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [class1, class2, ...]
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Convert to tensors
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;as_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;as_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;int64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create dummy data for demonstration
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Creating simulated detection dataset...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate 100 images with random objects
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dummy_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate annotations (random boxes and classes)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_annotations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_objects&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 1-4 objects per image
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Random boxes (x1, y1, x2, y2)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_objects&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;700&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Classes 1-10
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;dummy_annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;({&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;})&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CustomDetectionDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dummy_annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                         &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;collate_fn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tuple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dataset: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; images&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample annotation: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dummy_annotations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. Training
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3. Training Object Detector&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Move model to device
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;is_available&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Optimizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training for &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; epochs...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;(Using dummy data - in practice, use real annotated images)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()}&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward pass returns loss dict during training
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Combine losses
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training complete!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 4. Inference
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;4. Running Inference&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test on one image
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;600&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;800&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions for test image:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Boxes shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Labels shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Scores shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Filter by confidence threshold
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence_threshold&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;confidence_threshold&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Detections with confidence &amp;gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confidence_threshold&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; objects detected&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;boxes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keep&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;    Class &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: box=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, confidence=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Implement YOLO-style single-stage detector:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Single-Stage Detection (YOLO-style)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleSingleStageDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Simplified YOLO-style detector for educational purposes.
    
    Architecture:
    - Backbone CNN extracts features
    - Detection head predicts boxes + classes for grid cells
    - Each cell predicts B boxes with (x, y, w, h, confidence, class_probs)
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backbone (simplified - use any CNN)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;backbone&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Detection head
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each grid cell outputs: B boxes √ó (5 + num_classes)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 5 = (x, y, w, h, confidence)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output_channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;detection_head&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (B, 3, H, W) images
        
        Returns: (B, grid_size, grid_size, num_boxes, 5+num_classes)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Extract features
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backbone&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (B, 512, grid_size, grid_size)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Predict detections
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detection_head&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Reshape to (B, grid, grid, boxes, 5+classes)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;B&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;permute&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (B, grid, grid, boxes, ...)
&lt;/span&gt;        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;detections&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;detector&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleSingleStageDetector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_boxes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grid_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Single-stage detector architecture:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Grid size: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;√ó&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Boxes per cell: 3&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Classes: 10&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Total predictions: 13√ó13√ó3 = 507 boxes per image&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;416&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;416&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch of 2, 416√ó416 images
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;detector&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 13, 13, 3, 15)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dimensions: (batch, grid_y, grid_x, boxes, 5+classes)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each box prediction has:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 4 coordinates (x, y, w, h)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 1 confidence score&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 10 class probabilities&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Single forward pass produces all detections - very fast!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Object detection connects to image classification through its foundation in convolutional feature extraction. The backbone networks (ResNet, VGG, MobileNet) are typically classification networks adapted for detection by removing final classification layers and adding detection heads. The features learned for classification‚Äîedges, textures, object parts‚Äîtransfer naturally to detection because recognizing ‚Äúthis is a car‚Äù (classification) and ‚Äúthere‚Äôs a car at this location‚Äù (detection) both require understanding car appearance. However, detection requires additional capabilities: localizing precisely where objects are, handling multiple objects and scales, and distinguishing object from background. Understanding this connection helps appreciate why ImageNet pre-trained classifiers provide good starting points for detection but require architectural extensions (FPN for multi-scale, RPN for proposals) to reach full detection capability.&lt;/p&gt;

&lt;p&gt;The relationship to semantic segmentation illuminates different granularities of visual understanding. Classification assigns one label per image. Detection assigns labels and boxes to multiple objects per image. Semantic segmentation assigns labels to every pixel, delineating object boundaries exactly. Instance segmentation combines detection and segmentation, providing pixel-perfect masks for each object instance. This progression from coarse (image-level) to fine (pixel-level) understanding reflects different application requirements and computational tradeoffs. Detection provides a balance: more informative than classification (where are objects?) without the computational cost of pixel-level segmentation.&lt;/p&gt;

&lt;p&gt;Object detection‚Äôs connection to attention mechanisms is increasingly important in modern architectures. Transformers are replacing traditional detection heads through DETR (Detection Transformer), which treats object detection as set prediction using attention to directly predict all objects in parallel without anchors or NMS. The attention mechanism learns to attend to object locations and extents, providing an elegant end-to-end trainable alternative to the complex pipelines of traditional detectors. Understanding how attention can replace hand-crafted components like anchors and NMS helps appreciate Transformers‚Äô generality beyond NLP.&lt;/p&gt;

&lt;p&gt;The evolution from R-CNN to Fast R-CNN to Faster R-CNN demonstrates systematic optimization of computational bottlenecks. R-CNN ran CNN feature extraction separately for each proposal (2000 forward passes per image‚Äîvery slow). Fast R-CNN extracted features once for the whole image, then used RoI pooling to get proposal features (single forward pass‚Äîmuch faster). Faster R-CNN made proposal generation part of the network through RPN (fully differentiable, end-to-end trainable). Each innovation addressed a specific inefficiency while maintaining accuracy, showing how systems evolve through targeted improvements rather than complete redesigns.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1311.2524&quot;&gt;‚ÄúRich feature hierarchies for accurate object detection and semantic segmentation‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ross Girshick, Jeff Donahue, Trevor Darrell, Jitendra Malik&lt;br /&gt;
R-CNN revolutionized object detection by applying CNNs, previously successful for classification, to detection through region proposals. The approach was conceptually simple: use selective search to propose ~2000 regions per image, extract CNN features from each (forward passing each through AlexNet), then classify regions with SVMs and refine boxes with regression. While computationally expensive (2000 forward passes per image), R-CNN achieved dramatic improvements over traditional methods, demonstrating that learned features vastly outperform hand-crafted features for detection. The paper established the region-based detection paradigm and showed transfer learning (ImageNet pre-training for detection) was highly effective. R-CNN‚Äôs success sparked the deep learning revolution in object detection, leading to numerous improvements addressing its computational limitations while maintaining its core insight: detection can be solved through region classification with learned features.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1504.08083&quot;&gt;‚ÄúFast R-CNN‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Ross Girshick&lt;br /&gt;
Fast R-CNN addressed R-CNN‚Äôs computational bottleneck by sharing CNN computation across proposals through RoI (Region of Interest) pooling. Instead of running CNN separately for each proposal, extract features once for the whole image, then use RoI pooling to extract fixed-size feature vectors for each proposal from the shared feature map. This reduced forward passes from 2000 per image to 1, achieving ~10√ó speedup while improving accuracy through joint training of feature extraction, classification, and bounding box regression. The paper introduced multi-task loss combining classification and localization, showing that joint training improves both tasks compared to training separately. Fast R-CNN demonstrated that systematic analysis of computational bottlenecks and clever architectural innovations could dramatically improve efficiency without sacrificing accuracy, establishing principles for designing practical detection systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.01497&quot;&gt;‚ÄúFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Shaoqing Ren, Kaiming He, Ross Girshick, Jian Sun&lt;br /&gt;
Faster R-CNN completed the evolution to fully differentiable detection by replacing selective search with Region Proposal Networks, making the entire detection pipeline trainable end-to-end. RPN uses learned convolutional filters to predict objectness and box coordinates at every position in the feature map, generating proposals through learned mechanisms rather than hand-crafted algorithms. This innovation enabled sharing computation between proposal generation and detection, improved proposal quality through supervised training, and achieved near real-time speeds (5 FPS). The anchor box mechanism‚Äîpredicting offsets from predefined boxes of different aspect ratios and scales‚Äîbecame standard in subsequent detectors. Faster R-CNN set the template for two-stage detection and remained state-of-the-art for years, demonstrating that careful end-to-end design outperforms pipelined approaches with non-differentiable components.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.02640&quot;&gt;‚ÄúYou Only Look Once: Unified, Real-Time Object Detection‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi&lt;br /&gt;
YOLO fundamentally changed object detection by framing it as regression from image pixels directly to bounding box coordinates and class probabilities, enabling real-time detection (45 FPS) through a single forward pass. By dividing images into grids and having each cell predict boxes, YOLO eliminated region proposals and their associated computational cost. While initial accuracy was lower than Faster R-CNN (particularly for small objects), YOLO‚Äôs speed enabled real-time applications like autonomous driving and robotics. The paper showed that detection need not follow the two-stage paradigm, inspiring numerous single-stage detectors. YOLO‚Äôs end-to-end design philosophy‚Äîpredicting everything in one shot‚Äîdemonstrated that simple, unified approaches could compete with complex pipelines when properly designed.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1612.03144&quot;&gt;‚ÄúFeature Pyramid Networks for Object Detection‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Tsung-Yi Lin, Piotr Doll√°r, Ross Girshick, Kaiming He, Bharath Hariharan, Serge Belongie&lt;br /&gt;
FPN addressed multi-scale detection by building feature pyramids with strong semantics at all scales, combining high-resolution but semantically weak low-level features with low-resolution but semantically strong high-level features through top-down pathways and lateral connections. This enables detecting large objects using high-level features and small objects using low-level features enriched with semantic information from higher layers. FPN dramatically improved detection of objects at different scales, particularly small objects which previous methods struggled with. The architectural pattern‚Äîbuilding pyramids with both bottom-up (standard CNN) and top-down pathways‚Äîhas been widely adopted beyond detection to segmentation and other dense prediction tasks. FPN demonstrated that careful multi-scale architecture design addresses fundamental challenges in visual recognition.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Anchor box design significantly affects detection performance but is often overlooked. Anchors should match typical object aspect ratios and sizes in your dataset. For pedestrian detection (tall, narrow objects), use anchors like 1:3 and 1:4 aspect ratios. For cars (wider), use 2:1 or 3:2. The k-means clustering on training set bounding boxes can discover good anchor dimensions automatically. Having too many anchors wastes computation without improving accuracy, while too few miss important object types. Typical YOLO uses 9 anchors (3 scales √ó 3 aspect ratios), Faster R-CNN uses 9 (3 scales √ó 3 ratios) per position.&lt;/p&gt;

&lt;p&gt;Non-maximum suppression threshold selection involves precision-recall tradeoffs. Lower IoU threshold (0.3) suppresses more boxes, reducing duplicates but potentially eliminating valid detections of nearby objects. Higher threshold (0.7) keeps more boxes, detecting nearby objects well but producing duplicates. For crowded scenes (many nearby objects), use higher threshold. For sparse scenes, lower threshold. Understanding that NMS threshold controls this tradeoff allows tuning for specific applications.&lt;/p&gt;

&lt;p&gt;Class imbalance in object detection is severe and requires careful handling. Most anchor boxes are background (no object), creating extreme imbalance between background and object classes (often 1000:1 or more). Without handling, the detector learns to predict background for everything (trivial solution achieving 99.9% accuracy). Solutions include hard negative mining (train on hard background examples, ignore easy ones), focal loss (weight loss by difficulty, downweighting easy classifications), and balanced sampling (ensure batches contain similar numbers of object and background examples).&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Object detection extends classification to localizing and recognizing multiple objects per image, requiring simultaneous region proposal, classification, and bounding box regression. Two-stage detectors separate proposal generation from detection, using Region Proposal Networks to generate candidates and detection heads to classify and refine, achieving high accuracy through focused computation on object regions. Single-stage detectors directly predict boxes and classes from grid cells, enabling real-time performance through single forward pass at slight accuracy cost. Intersection over Union measures localization quality, with detections considered correct when IoU with ground-truth exceeds threshold (typically 0.5) and class matches. Anchor boxes provide reference boxes at different scales and aspect ratios, with networks predicting offsets rather than absolute coordinates, improving training stability. Feature pyramids enable multi-scale detection by combining high-level semantic features with high-resolution spatial features. Non-maximum suppression eliminates duplicate detections by keeping highest-confidence boxes and suppressing overlapping boxes. Multi-task training jointly optimizes classification and localization, with losses balanced to achieve both accurate recognition and precise localization. Understanding object detection requires appreciating how these components coordinate to handle variable numbers of objects at different scales, positions, and classes while maintaining real-time or near-real-time performance for practical applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>17 Computer Vision Applications</title>
   <link href="http://localhost:4000/contents/en/chapter17/17_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter17/17_00_Introduction</id>
   <content type="html">&lt;p&gt;This chapter applies deep learning to practical computer vision tasks: image classification, object detection (YOLO, Faster R-CNN), semantic segmentation (U-Net, DeepLab), instance segmentation (Mask R-CNN), pose estimation, and image generation. We cover architectures, datasets, metrics, and implementation details for real-world applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>16-01 Self-Supervised Learning</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_01_Self_Supervised_Learning/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter16/16_01_Self_Supervised_Learning</id>
   <content type="html">&lt;h1 id=&quot;self-supervised-learning-learning-from-data-itself&quot;&gt;Self-Supervised Learning: Learning from Data Itself&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Self-supervised learning represents a paradigm shift in how we leverage unlabeled data, creating supervision signals automatically from the data itself rather than requiring expensive human annotations. The key insight is that data contains inherent structure and relationships that can serve as learning signals: images have spatial structure allowing us to predict one part from others, text has sequential structure enabling prediction of masked words from context, videos have temporal coherence making frame ordering predictable. By formulating prediction tasks that exploit these structures, we can train neural networks on massive unlabeled datasets, learning representations that transfer effectively to downstream supervised tasks.&lt;/p&gt;

&lt;p&gt;The distinction between self-supervised and unsupervised learning is subtle but important. Traditional unsupervised learning (clustering, PCA) discovers structure without using it for prediction. Self-supervised learning formulates supervised prediction tasks using automatically generated labels from data structure, essentially converting unsupervised data into supervised learning problems through clever task design. Masked language modeling in BERT‚Äîpredicting masked words from context‚Äîis supervised learning where labels (the original words) come from the data itself rather than human annotators.&lt;/p&gt;

&lt;p&gt;Modern self-supervised learning has achieved remarkable success, particularly in NLP where pre-training on massive text through self-supervised objectives (masked language modeling, next sentence prediction) followed by fine-tuning on supervised tasks has become standard. BERT, GPT, and similar models learn rich language understanding from unlabeled text that transfers to diverse tasks. In computer vision, contrastive learning methods like SimCLR and MoCo learn visual representations by distinguishing augmented versions of the same image from different images, achieving representations competitive with supervised pre-training.&lt;/p&gt;

&lt;p&gt;Understanding self-supervised learning deeply requires appreciating the pretext tasks‚Äîthe automatically supervised objectives used during pre-training‚Äîand what representations they encourage. Good pretext tasks should be: (1) solvable from data alone without labels, (2) require understanding semantic structure to solve effectively, (3) produce representations useful for downstream tasks. The art is designing tasks where solving them necessitates learning general useful features rather than exploiting data shortcuts.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;contrastive-learning&quot;&gt;Contrastive Learning&lt;/h3&gt;

&lt;p&gt;Contrastive methods learn by distinguishing similar (positive) pairs from dissimilar (negative) pairs. Given anchor \(\mathbf{x}\), positive \(\mathbf{x}^+\) (augmented version of same image), and negatives \(\{\mathbf{x}_i^-\}\) (different images):&lt;/p&gt;

\[\mathcal{L}_{\text{contrastive}} = -\log \frac{\exp(\text{sim}(f(\mathbf{x}), f(\mathbf{x}^+))/\tau)}{\exp(\text{sim}(f(\mathbf{x}), f(\mathbf{x}^+))/\tau) + \sum_i \exp(\text{sim}(f(\mathbf{x}), f(\mathbf{x}_i^-))/\tau)}\]

&lt;p&gt;where \(f\) is encoder network, \(\text{sim}\) is similarity (typically cosine), \(\tau\) is temperature. This NT-Xent (normalized temperature-scaled cross-entropy) loss encourages representations where augmentations of same image are close while different images are far.&lt;/p&gt;

&lt;h3 id=&quot;masked-prediction&quot;&gt;Masked Prediction&lt;/h3&gt;

&lt;p&gt;BERT masks 15% of tokens and predicts them from context:&lt;/p&gt;

\[\mathcal{L}_{\text{MLM}} = -\mathbb{E}_{\mathbf{x}}\left[\sum_{i \in \mathcal{M}} \log p(x_i | \mathbf{x}_{\backslash \mathcal{M}})\right]\]

&lt;p&gt;where \(\mathcal{M}\) is set of masked positions. The model must use bidirectional context to predict masked words, learning deep language understanding.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider learning visual representations from unlabeled images. Take a photo of a cat. Create two augmented versions: one with random cropping and color jittering, another with different cropping and rotation. These are positive pairs‚Äîdifferent views of the same cat, should have similar representations.&lt;/p&gt;

&lt;p&gt;Sample photos of dogs, cars, trees as negatives. Contrastive learning pushes cat augmentations together in representation space while pushing cat apart from dogs/cars/trees. After training on millions of images, representations cluster by semantic content: all cats nearby, all dogs nearby, cats and dogs closer to each other (both animals) than to cars.&lt;/p&gt;

&lt;p&gt;These learned representations transfer to classification‚Äîeven though we never used labels during pre-training, the encoder learned to extract features distinguishing objects, which directly helps supervised classification with limited labels.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimCLR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Simplified SimCLR for contrastive learning&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;projection_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encoder (e.g., ResNet)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;base_encoder&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Projection head
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Maps encoder output to space where contrastive loss is computed
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projection&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;projection_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;projection&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# L2 normalize
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;nt_xent_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    NT-Xent loss for contrastive learning
    
    z1, z2: (batch, dim) representations of augmented pairs
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Concatenate augmentations
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2*batch, dim)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Compute similarity matrix
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2*batch, 2*batch)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Mask out self-similarity
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;~&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eye&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Positive pairs: (i, i+batch) and (i+batch, i)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;pos_sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)],&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# NT-Xent loss
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos_sim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sim_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Self-supervised learning enables learning from unlabeled data!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Self-supervised learning connects to transfer learning as pre-training strategy. Instead of ImageNet supervised pre-training, use self-supervised pre-training on unlabeled images, often learning representations that transfer even better.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1911.05722&quot;&gt;‚ÄúMomentum Contrast for Unsupervised Visual Representation Learning‚Äù (2020)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kaiming He, Haoqi Fan, Yuxin Wu, Saining Xie, Ross Girshick&lt;br /&gt;
MoCo maintained large dictionary of negative examples through momentum encoder, enabling effective contrastive learning. Achieved representations competitive with supervised pre-training.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2002.05709&quot;&gt;‚ÄúA Simple Framework for Contrastive Learning of Visual Representations‚Äù (2020)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton&lt;br /&gt;
SimCLR showed that simple contrastive learning with strong augmentations and large batches achieves excellent representations, outperforming many supervised pre-training approaches.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;‚ÄúBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
BERT‚Äôs masked language modeling is self-supervised learning, creating supervision from text itself.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Self-supervised learning creates supervision automatically from data structure, enabling learning from massive unlabeled datasets through pretext tasks like masked prediction or contrastive learning. Contrastive methods learn by distinguishing augmented views of same example from different examples, learning invariances to augmentations while capturing semantic content. Masked prediction tasks like BERT‚Äôs MLM learn to predict missing parts from context, requiring deep understanding of data structure. Self-supervised pre-training often matches or exceeds supervised pre-training for transfer learning, demonstrating that task-agnostic learning from unlabeled data produces versatile representations.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>16 Self-Supervised Learning</title>
   <link href="http://localhost:4000/contents/en/chapter16/16_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter16/16_00_Introduction</id>
   <content type="html">&lt;p&gt;Self-supervised learning trains models using automatically generated labels from the data itself, without manual annotation. This paradigm has revolutionized pre-training in NLP (masked language modeling) and computer vision (contrastive learning). This chapter covers contrastive learning, SimCLR, CLIP, MAE, and modern self-supervised approaches.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>15-01 Transfer Learning Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_01_Transfer_Learning_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter15/15_01_Transfer_Learning_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;transfer-learning-leveraging-pre-trained-knowledge&quot;&gt;Transfer Learning: Leveraging Pre-trained Knowledge&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Transfer learning represents one of the most practically important paradigms in modern deep learning, enabling us to build highly effective models with limited task-specific data by leveraging knowledge learned from related tasks. The core principle is deceptively simple: instead of training a neural network from scratch with randomly initialized weights, we start with weights pre-trained on a large dataset for a related task, then adapt these weights to our specific problem. This approach has democratized deep learning, making it accessible to practitioners who lack the massive datasets and computational resources required to train large models from scratch. A medical imaging application might leverage a network pre-trained on ImageNet. A sentiment analysis model might start from BERT pre-trained on web text. A speech recognition system might fine-tune Wav2Vec learned on unlabeled audio.&lt;/p&gt;

&lt;p&gt;Understanding why transfer learning works requires appreciating what neural networks learn during training. The layers of a deep network progressively build hierarchical representations. Early layers learn general, low-level features‚Äîedges, textures, simple shapes for images; basic phonemes for audio; common word patterns for text. These features are remarkably consistent across tasks and datasets. A network trained to classify cars versus trucks learns edge detectors nearly identical to a network classifying dogs versus cats, because edges are fundamental to visual understanding regardless of the specific objects. Middle layers learn mid-level features‚Äîobject parts, texture combinations, shape compositions‚Äîthat are somewhat task-specific but still broadly useful. Only the deepest layers learn highly task-specific features‚Äî‚Äùthis particular combination indicates a golden retriever‚Äù for dog breed classification.&lt;/p&gt;

&lt;p&gt;This feature reuse across tasks is what makes transfer learning possible. The early and middle layers, having learned general features on a large source dataset, provide a strong starting point for a target task. Even if the target task differs (classifying medical images instead of natural images), the fundamental visual features‚Äîedges, textures, shapes‚Äîremain relevant. We don‚Äôt need millions of medical images to learn these basics; we can transfer them from ImageNet and focus our limited medical data on learning the task-specific features in deeper layers. This is analogous to how humans learn: having learned basic visual concepts from everyday experience, we can quickly learn to identify rare diseases from a few examples, transferring our general visual understanding rather than learning vision from scratch.&lt;/p&gt;

&lt;p&gt;The practical impact cannot be overstated. Before transfer learning became standard practice, training good image classifiers required hundreds of thousands of labeled images. With transfer learning from ImageNet pre-trained models, competitive results are possible with thousands or even hundreds of images. In natural language processing, the impact was even more dramatic. Pre-trained language models like BERT, trained on billions of words of text, can be fine-tuned for specific tasks (sentiment analysis, named entity recognition, question answering) with datasets of just thousands of labeled examples, achieving performance that would require millions of labels if training from scratch. This has enabled applications of deep learning in domains where large labeled datasets don‚Äôt exist: medical diagnosis with limited patient data, rare language processing, specialized technical document understanding.&lt;/p&gt;

&lt;p&gt;Yet transfer learning is not magic, and understanding when it works versus when it fails is crucial for practitioners. Transfer learning assumes the source and target tasks share relevant structure‚Äîedges learned from ImageNet help with medical images because both involve natural images with edges, textures, and shapes. But ImageNet features might not transfer well to radar images (different data modality), satellite images (different scale and perspective), or abstract art (different statistical properties). The more similar the source and target distributions, the more effectively features transfer. This principle guides choice of pre-trained models: for medical imaging, networks pre-trained on chest X-rays transfer better than ImageNet, though ImageNet remains surprisingly effective due to the generality of low and mid-level visual features.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical framework for transfer learning connects to domain adaptation, multi-task learning, and meta-learning. Let‚Äôs formalize what we‚Äôre doing when we transfer knowledge and understand the theoretical foundations that explain why it works.&lt;/p&gt;

&lt;p&gt;Suppose we have a source domain with distribution \(p_S(\mathbf{x}, y)\) and abundant labeled data \(\mathcal{D}_S = \{(\mathbf{x}_i^S, y_i^S)\}_{i=1}^{N_S}\), and a target domain with distribution \(p_T(\mathbf{x}, y)\) and limited labeled data \(\mathcal{D}_T = \{(\mathbf{x}_j^T, y_j^T)\}_{j=1}^{N_T}\) where \(N_T \ll N_S\). We want to learn a predictor \(f_\theta(\mathbf{x})\) that performs well on the target domain.&lt;/p&gt;

&lt;p&gt;In standard supervised learning, we would minimize empirical risk on target data:&lt;/p&gt;

\[\theta^* = \arg\min_\theta \frac{1}{N_T}\sum_{j=1}^{N_T} \mathcal{L}(f_\theta(\mathbf{x}_j^T), y_j^T)\]

&lt;p&gt;But with small \(N_T\), this leads to severe overfitting‚Äîthe model memorizes training examples without learning generalizable patterns.&lt;/p&gt;

&lt;p&gt;Transfer learning instead performs two-stage optimization:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stage 1 (Pre-training)&lt;/strong&gt;: Train on source domain
\(\theta_S^* = \arg\min_\theta \frac{1}{N_S}\sum_{i=1}^{N_S} \mathcal{L}(f_\theta(\mathbf{x}_i^S), y_i^S)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Stage 2 (Fine-tuning)&lt;/strong&gt;: Initialize with \(\theta_S^*\), then train on target domain
\(\theta_T^* = \arg\min_\theta \frac{1}{N_T}\sum_{j=1}^{N_T} \mathcal{L}(f_\theta(\mathbf{x}_j^T), y_j^T), \quad \text{starting from } \theta_0 = \theta_S^*\)&lt;/p&gt;

&lt;p&gt;The initialization \(\theta_0 = \theta_S^*\) is crucial‚Äîit provides a starting point already close to a good solution for the target task (assuming domains are related), allowing fine-tuning to converge quickly with limited data.&lt;/p&gt;

&lt;p&gt;We can decompose the model as \(f_\theta = h_{\theta_h} \circ g_{\theta_g}\) where \(g_{\theta_g}\) is the feature extractor (early/middle layers) and \(h_{\theta_h}\) is the task-specific head (final layers). Transfer learning strategies differ in what they transfer and what they adapt:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Feature extraction&lt;/strong&gt;: Freeze \(\theta_g = \theta_g^S\) (use pre-trained features), only train \(\theta_h\) on target data
\(\theta_h^* = \arg\min_{\theta_h} \frac{1}{N_T}\sum_{j=1}^{N_T} \mathcal{L}(h_{\theta_h}(g_{\theta_g^S}(\mathbf{x}_j^T)), y_j^T)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fine-tuning all layers&lt;/strong&gt;: Initialize both \(\theta_g\) and \(\theta_h\) from source, train both on target
\((\theta_g^*, \theta_h^*) = \arg\min_{\theta_g, \theta_h} \frac{1}{N_T}\sum_{j=1}^{N_T} \mathcal{L}(h_{\theta_h}(g_{\theta_g}(\mathbf{x}_j^T)), y_j^T)\)
starting from \((\theta_g^S, \theta_h^{\text{random}})\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Layer-wise differential learning rates&lt;/strong&gt;: Use different learning rates for different layers
\(\theta_g \leftarrow \theta_g - \eta_g \nabla_{\theta_g} \mathcal{L}, \quad \theta_h \leftarrow \theta_h - \eta_h \nabla_{\theta_h} \mathcal{L}\)
typically with \(\eta_g &amp;lt; \eta_h\) (smaller learning rate for pre-trained layers, larger for new head)&lt;/p&gt;

&lt;p&gt;The choice depends on dataset size and similarity. With very small target data (hundreds of examples) and similar domains, feature extraction often works best‚Äîfrozen pre-trained features provide robust representations, and we only need to learn the task-specific mapping. With moderate data (thousands) and moderate similarity, fine-tuning with small learning rates adapts features slightly while avoiding catastrophic forgetting. With large data (tens of thousands+), full fine-tuning or even training from scratch might be preferable.&lt;/p&gt;

&lt;h3 id=&quot;domain-adaptation-theory&quot;&gt;Domain Adaptation Theory&lt;/h3&gt;

&lt;p&gt;The theoretical analysis of when transfer works invokes domain adaptation theory. Define the hypothesis space \(\mathcal{H}\) (all functions representable by our architecture). The error on target domain for hypothesis \(h \in \mathcal{H}\) can be bounded:&lt;/p&gt;

\[\epsilon_T(h) \leq \epsilon_S(h) + \frac{1}{2}d_{\mathcal{H}}(D_S, D_T) + \lambda\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\epsilon_S(h)\): error on source domain (can be minimized with abundant source data)&lt;/li&gt;
  &lt;li&gt;\(d_{\mathcal{H}}(D_S, D_T)\): distance between source and target distributions (measures domain shift)&lt;/li&gt;
  &lt;li&gt;\(\lambda\): error of ideal joint hypothesis (minimum possible error on both domains)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This bound reveals what‚Äôs needed for successful transfer: (1) low source error (good pre-training), (2) small domain distance (similar source and target), (3) small \(\lambda\) (shared optimal hypothesis exists). When domains are very different, \(d_{\mathcal{H}}\) is large, and the bound becomes loose‚Äîno guarantee transfer helps. This formalizes the intuition that transfer works when domains share structure.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Consider a concrete scenario: building a bird species classifier with only 500 labeled images across 20 species (25 images per species). Training a ResNet-50 (25 million parameters) from scratch on this data would catastrophically overfit‚Äîwe have far more parameters than training examples.&lt;/p&gt;

&lt;p&gt;The transfer learning approach starts with ResNet-50 pre-trained on ImageNet (1.2 million images, 1000 classes). This network has already learned:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Layer 1&lt;/strong&gt;: Edge detectors (horizontal, vertical, diagonal, curved)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer 2&lt;/strong&gt;: Texture patterns (feathers, beaks, backgrounds)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer 3&lt;/strong&gt;: Object parts (wings, heads, feet)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer 4&lt;/strong&gt;: Object compositions (whole birds, though specific to ImageNet bird species)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For our bird classification task, we:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Option 1: Feature Extraction&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Remove final classification layer (1000 classes)&lt;/li&gt;
  &lt;li&gt;Freeze all conv layers (keep pre-trained features)&lt;/li&gt;
  &lt;li&gt;Add new classification head (20 bird species)&lt;/li&gt;
  &lt;li&gt;Train only this new head on our 500 images&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This works because the frozen layers provide rich 2048-dimensional feature vectors for each image, capturing edges, textures, and bird-like parts. We only need to learn which combinations of these features correspond to which of our 20 species‚Äîa much simpler problem requiring far less data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Option 2: Fine-Tuning&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Start with pre-trained weights everywhere&lt;/li&gt;
  &lt;li&gt;Replace final layer with 20-class head (random initialization)&lt;/li&gt;
  &lt;li&gt;Train entire network with small learning rate (0.0001 vs typical 0.1)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The small learning rate is crucial. Pre-trained features are already good; we want to adapt them slightly, not destroy them. Early layers might barely change (edges are universal). Middle layers adapt more (bird-specific textures). Deep layers change most (our specific species features).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Concrete numerical example&lt;/strong&gt;: Suppose a pre-trained conv filter in layer 3 has weights detecting ‚Äúcurved structures‚Äù (useful for any object with curves). For bird species, we might want to detect ‚Äúfeather curves‚Äù specifically. Fine-tuning adjusts this filter‚Äôs weights slightly:&lt;/p&gt;

&lt;p&gt;Original weight: \(w_{\text{pre}} = 0.523\)&lt;br /&gt;
Gradient on bird data: \(\nabla w = 0.015\) (indicates small adjustment needed)&lt;br /&gt;
Updated weight: \(w_{\text{fine}} = 0.523 - 0.0001 \times 0.015 = 0.5229985\)&lt;/p&gt;

&lt;p&gt;The tiny change (0.0001 learning rate) adapts the feature slightly without destroying the useful structure learned from ImageNet. Across thousands of weights, these small adaptations accumulate to specialize the network for birds while preserving general visual understanding.&lt;/p&gt;

&lt;p&gt;Results: With feature extraction, we might achieve 85% accuracy on bird classification. With fine-tuning, 92% accuracy. Training from scratch with our 500 images: perhaps 60% accuracy (severe overfitting). The transfer learning advantage is dramatic and practical.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Complete transfer learning implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random_split&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Transfer Learning: Fine-tuning Pre-trained ResNet for Custom Dataset&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load pre-trained ResNet18 (smaller than ResNet50 for demonstration)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Loading Pre-trained Model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# weights=&apos;IMAGENET1K_V1&apos; loads ImageNet pre-trained weights
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IMAGENET1K_V1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Loaded ResNet18 pre-trained on ImageNet&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Original output layer: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (1000 classes for ImageNet)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Examine what pre-trained model has learned
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Pre-trained features:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Layer 1 filters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (64, 3, 7, 7)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  These are edge/texture detectors learned from ImageNet&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. Adapt for new task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Adapting for Custom Task (10 Classes)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Replace final fully-connected layer for our task
# Everything else keeps pre-trained weights
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Our custom task has 10 classes
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_features&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Get input size of fc layer
&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Original FC input features: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Replacing final layer for &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; classes...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;New model output layer: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_pretrained&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (10 classes for our custom task)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create dummy dataset (in practice, use your real data)
# We&apos;ll simulate with CIFAR-10 as our &quot;custom&quot; task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3. Preparing Custom Dataset&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;transform_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Resize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# ResNet expects 224√ó224 (CIFAR is 32√ó32)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.485&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.456&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.229&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.225&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# ImageNet stats
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate limited data scenario: use only 1000 training images
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CIFAR10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Take subset to simulate limited data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limited_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;remaining&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;limited_size&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;random_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;full_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limited_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;remaining&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CIFAR10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training with only &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;limited_size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; images (simulating limited data)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Test set: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; images&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 3. Training Strategy: Feature Extraction vs Fine-Tuning
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;4. Strategy A: Feature Extraction (Freeze Pre-trained Layers)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create copy of model for feature extraction
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IMAGENET1K_V1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Freeze all layers except final FC
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Unfreeze final layer
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;trainable_params_fe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;total_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Total parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_params&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Trainable parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_params_fe&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_params_fe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Only training the final classification layer!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Optimizer for feature extraction (only fc layer parameters)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer_fe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training feature extraction model (5 epochs)...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_fe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward (conv layers frozen, only fc trains)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_fe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Train Acc = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Evaluate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_acc_fe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Feature Extraction Test Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_acc_fe&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 4. Strategy B: Fine-Tuning
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5. Strategy B: Fine-Tuning (Update All Layers)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;resnet18&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;IMAGENET1K_V1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# All parameters trainable
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_params_ft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Trainable parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trainable_params_ft&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (100%)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Use differential learning rates
# Lower LR for pre-trained layers, higher for new layer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer_ft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0005&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;},&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Highest for new layer
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Default for any params not specified
&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Using layer-wise differential learning rates:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Early layers: 0.0001 (barely change)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Middle layers: 0.0002&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Deep layers: 0.0005&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  New FC layer: 0.001 (change most)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training fine-tuning model (5 epochs)...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_ft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_ft&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Train Acc = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Evaluate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predicted&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_acc_ft&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Fine-Tuning Test Accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_acc_ft&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Compare results
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Transfer Learning Results Comparison&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Feature Extraction: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_acc_fe&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;% test accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Fine-Tuning:        &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_acc_ft&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;% test accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Both dramatically outperform training from scratch (~60% on 1000 images)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Transfer learning enabled competitive performance with limited data!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Demonstrate feature visualization:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Analyzing Transferred Features&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Extract features for analysis
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extract_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;layer4&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Extract features from a specific layer.
    
    This shows what representations the model uses for classification.
    Pre-trained features should be meaningful even for custom task.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;features_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Register hook to capture layer outputs
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;features_hook&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;hook_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;features_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Get the layer
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;named_modules&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_forward_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hook_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;features_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;labels_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;features_hook&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;handle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;remove&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Concatenate all batches
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Extract layer4 features (last conv layer before FC)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extract_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model_finetune&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;layer4&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Extracted features from layer4 (last conv layer)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Feature shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1000, 512, 7, 7)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Global average pool to get 512-dim vectors
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_pooled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;features_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1000, 512)
&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;After global average pooling: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features_pooled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;These 512-dimensional features encode:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Low-level: edges, textures (from ImageNet)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Mid-level: object parts, shapes (from ImageNet)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - High-level: bird-specific patterns (adapted during fine-tuning)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The pre-trained features provide strong starting point!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Transfer learning connects to multi-task learning, where we train a single model on multiple related tasks simultaneously rather than sequentially. Multi-task learning uses shared representations (early/middle layers) while maintaining task-specific heads (final layers), similar to transfer learning‚Äôs architecture but with joint training. The shared representation learns features useful across tasks, providing implicit regularization (a feature must help multiple tasks to be retained) that often improves generalization compared to single-task training. Understanding this connection helps appreciate that transfer learning and multi-task learning address similar problems‚Äîleveraging shared structure across related tasks‚Äîthrough different training procedures.&lt;/p&gt;

&lt;p&gt;The relationship to meta-learning (learning to learn) is more subtle but important. Meta-learning aims to learn an initialization or learning algorithm that enables fast adaptation to new tasks with minimal data. Model-Agnostic Meta-Learning (MAML), for instance, learns an initialization that‚Äôs a few gradient steps away from good performance on any task from a distribution. Transfer learning can be viewed as a simple form of meta-learning where the ‚Äúmeta-training‚Äù is pre-training on the source task and ‚Äúadaptation‚Äù is fine-tuning on the target. More sophisticated meta-learning approaches extend this idea to learn better adaptations or to handle more diverse task distributions.&lt;/p&gt;

&lt;p&gt;Transfer learning‚Äôs success in NLP through pre-trained language models exemplifies domain-specific evolution of the paradigm. Word2Vec and GloVe provided pre-trained word embeddings, transferring lexical knowledge. ELMo provided pre-trained contextual representations. BERT revolutionized the field by pre-training entire Transformer models on massive text corpora through masked language modeling, then fine-tuning for specific tasks. GPT took this further with models so large that fine-tuning isn‚Äôt always necessary‚Äîfew-shot learning through prompting can adapt the model without any parameter updates. This progression from transferring embeddings to transferring complete models to avoiding fine-tuning entirely shows how transfer learning evolved as models scaled.&lt;/p&gt;

&lt;p&gt;The connection to curriculum learning provides another perspective. Transfer learning can be viewed as a two-stage curriculum: first learn general features (easier task with abundant data), then learn task-specific features (harder task with limited data). This staged approach mirrors how humans learn‚Äîgeneral education before specialization‚Äîand often works better than jumping directly to the hardest problem. Understanding this connection suggests we might use multi-stage transfer: pre-train on general data (ImageNet), intermediate training on domain-specific data (medical images broadly), then fine-tune on specific task (lung cancer detection). Such staged transfer has proven effective in specialized domains.&lt;/p&gt;

&lt;p&gt;Finally, transfer learning connects to the broader question of sample efficiency in machine learning. Deep learning‚Äôs data hunger‚Äîrequiring millions of examples‚Äîlimits applications where data is expensive (medical imaging, rare events) or impossible to collect at scale (private data, unique scenarios). Transfer learning dramatically improves sample efficiency by amortizing the cost of learning general features across many downstream tasks. Understanding transfer learning‚Äôs sample efficiency provides insights into what makes learning difficult (learning general features requires lots of data) versus easier (learning task-specific mappings given good features needs less data), informing when to expect transfer to help most dramatically.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.1792&quot;&gt;‚ÄúHow transferable are features in deep neural networks?‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jason Yosinski, Jeff Clune, Yoshua Bengio, Hector Lipson&lt;br /&gt;
This paper systematically investigated transferability of neural network features across tasks, providing empirical evidence and theoretical understanding of when transfer works. The authors trained networks on ImageNet variants, freezing different numbers of layers when transferring to new tasks, measuring performance degradation versus full fine-tuning. Key findings: early layers learn general features that transfer almost universally; middle layers are more task-specific but still broadly useful; final layers are highly task-specific and benefit most from adaptation. The paper also showed that co-adapted features (features that work well together) can be disrupted by freezing some while training others, suggesting fine-tuning all layers often works better than freezing many. This work established the empirical foundations for transfer learning best practices and demonstrated that feature transferability isn‚Äôt universal but depends on layer depth and task similarity.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.cv-foundation.org/openaccess/content_cvpr_2014/papers/Oquab_Learning_and_Transferring_2014_CVPR_paper.pdf&quot;&gt;‚ÄúLearning and Transferring Mid-Level Image Representations using Convolutional Neural Networks‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Maxime Oquab, Leon Bottou, Ivan Laptev, Josef Sivic&lt;br /&gt;
This paper demonstrated that CNN features pre-trained on ImageNet transfer effectively to diverse visual recognition tasks including object detection, scene classification, and fine-grained recognition. The authors showed that simply using pre-trained conv layers as feature extractors and training a classifier on these features achieved strong performance across tasks, outperforming hand-engineered features. The work established transfer learning as practical standard practice in computer vision, showing the features learned on one large dataset (ImageNet) generalize to many other vision tasks. The paper‚Äôs experimental methodology‚Äîsystematic evaluation across multiple tasks with controlled comparisons‚Äîset standards for demonstrating transfer effectiveness and influenced the widespread adoption of pre-trained models in computer vision.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;‚ÄúBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova&lt;br /&gt;
While primarily introducing BERT, this paper revolutionized transfer learning in NLP by showing that pre-training Transformers on massive text through masked language modeling, then fine-tuning on specific tasks, achieved state-of-the-art results across eleven diverse NLP tasks including question answering, natural language inference, and named entity recognition. BERT demonstrated the power of transfer learning at scale: a single pre-trained model could be adapted to vastly different tasks with minimal architectural changes (just adding simple task-specific heads). The pre-train-then-fine-tune paradigm became dominant in NLP, showing that transfer learning isn‚Äôt vision-specific but a general principle applicable across modalities. The paper‚Äôs impact extended beyond BERT itself to establishing large-scale unsupervised pre-training as a standard first step in NLP model development.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://ieeexplore.ieee.org/document/5288526&quot;&gt;‚ÄúA Survey on Transfer Learning‚Äù (2010)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Sinno Jialin Pan, Qiang Yang&lt;br /&gt;
This comprehensive survey paper organized and taxonomized transfer learning approaches across machine learning, not just deep learning. Pan and Yang defined: inductive transfer (labeled target data), transductive transfer (no labeled target data), and unsupervised transfer. They analyzed when transfer works (source and target share marginal or conditional distributions) versus fails (large domain shift), providing theoretical frameworks for understanding transferability. While pre-dating the deep learning era‚Äôs dramatic transfer learning successes, the theoretical foundations remain relevant: understanding transfer as leveraging shared structure between source and target, analyzing domain shift quantitatively, and recognizing that negative transfer (where using source data hurts target performance) can occur when domains are too dissimilar. The survey connects deep transfer learning to broader machine learning traditions, providing theoretical context for why and when transfer is effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1811.08883&quot;&gt;‚ÄúRethinking ImageNet Pre-training‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kaiming He, Ross Girshick, Piotr Doll√°r&lt;br /&gt;
This paper challenged the conventional wisdom that ImageNet pre-training is always beneficial, showing that for tasks with sufficient data (tens of thousands of images), training from scratch can match or exceed fine-tuning pre-trained models, given enough training time. The key insight was that pre-training‚Äôs advantage is primarily in faster convergence and better performance with limited data, not in reaching fundamentally better solutions. With abundant task-specific data and proper regularization, random initialization can work well, though requiring much longer training. The paper refined understanding of when transfer helps most: in low-data regimes (hundreds to thousands of examples), pre-training provides massive advantages; in high-data regimes (hundreds of thousands+), advantages diminish. This nuanced view helps practitioners make informed decisions about whether to use pre-trained models or train from scratch based on data availability and computational budget.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most common mistake is using pre-trained models without matching preprocessing to the pre-training protocol. If a model was pre-trained on ImageNet with specific normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] for RGB channels), fine-tuning or feature extraction must use identical normalization. Mismatched preprocessing causes the model to receive inputs from a different distribution than it was trained on, degrading performance dramatically. Always check the pre-training protocol (input size, normalization statistics, preprocessing steps) and replicate it exactly for transfer.&lt;/p&gt;

&lt;p&gt;Using too high a learning rate when fine-tuning destroys pre-trained features before they can adapt to the new task. The pre-trained weights represent useful features; large updates can push them far from this useful region into random territory. A good rule: use 10-100√ó smaller learning rate for fine-tuning than for training from scratch. If normal training uses lr=0.1, fine-tuning should use lr=0.001-0.01. Even better: use differential learning rates with earlier layers getting smaller rates (they‚Äôre more general, should change less) and later layers getting larger rates (more task-specific, should adapt more).&lt;/p&gt;

&lt;p&gt;Forgetting to set the model to eval mode when extracting features is a subtle bug that causes inconsistent results. If the model contains batch normalization or dropout layers and remains in train mode during feature extraction, these layers behave differently on different calls (batch norm uses batch statistics, dropout drops random units), causing the same input to produce different features. Always call &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;model.eval()&lt;/code&gt; and use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;torch.no_grad()&lt;/code&gt; when extracting features or making predictions.&lt;/p&gt;

&lt;p&gt;When fine-tuning NLP models like BERT, a common issue is catastrophic forgetting on short sequences. BERT was pre-trained on sequences of 512 tokens. Fine-tuning on a task with short sequences (tweets, SMS messages of 20-50 tokens) can degrade the model‚Äôs ability to handle long sequences. If you need to preserve this capability, include long-sequence examples during fine-tuning or use a mixture of source and target data (partial fine-tuning).&lt;/p&gt;

&lt;p&gt;A powerful trick for better transfer is using cyclical learning rates during fine-tuning. Start with a low learning rate, gradually increase to a moderate peak, then decrease again. This allows gentle adaptation initially (not destroying pre-trained features), more aggressive updates at the peak (finding task-specific features), and refinement finally (fine-tuning the adapted features). Combined with gradual unfreezing (start by training only the head, then unfreeze top layers, then middle layers), this provides smooth adaptation from pre-trained to task-specific features.&lt;/p&gt;

&lt;p&gt;For tasks very different from the pre-training domain, partial fine-tuning often works better than full fine-tuning. Freeze early layers (most general, least likely to need adaptation), fine-tune middle and late layers. This preserves universal low-level features while adapting task-specific higher-level features. The choice of where to freeze involves experimentation but follows the principle: freeze what transfers well, adapt what needs task-specific learning.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Transfer learning leverages pre-trained models to achieve strong performance on target tasks with limited data by transferring learned features from related source tasks with abundant data. The hierarchical nature of deep network features‚Äîgeneral low-level features in early layers, task-specific high-level features in late layers‚Äîenables selective transfer where we keep useful general features and adapt task-specific components. Feature extraction freezes pre-trained weights and trains only a new task-specific head, working well with very limited data (hundreds of examples) and minimal computational cost. Fine-tuning adapts all or most layers with small learning rates, typically achieving better performance with moderate data (thousands of examples) by specializing pre-trained features to the target domain. Layer-wise differential learning rates control adaptation, with early layers changing minimally (preserving general features) and late layers changing more (learning task-specific features), preventing catastrophic forgetting while enabling effective specialization. Transfer learning‚Äôs effectiveness depends on source-target similarity‚Äîmore similar domains enable better transfer‚Äîand the quality of pre-training‚Äîbetter source task performance generally improves transfer. Modern practice in computer vision starts with ImageNet pre-training, in NLP with BERT/GPT pre-training, and in speech with Wav2Vec pre-training, making transfer learning a standard first step rather than advanced technique. Understanding transfer learning deeply means recognizing it as amortizing the cost of learning general representations across many tasks, democratizing deep learning by making high performance achievable without massive task-specific datasets, and embodying the principle that good representations learned on one task often help on related tasks‚Äîa form of knowledge reuse fundamental to efficient learning.&lt;/p&gt;

&lt;p&gt;Transfer learning exemplifies how deep learning matured from requiring massive datasets for every task to enabling strong performance with limited task-specific data through strategic reuse of learned knowledge.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>15 Transfer Learning</title>
   <link href="http://localhost:4000/contents/en/chapter15/15_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter15/15_00_Introduction</id>
   <content type="html">&lt;p&gt;Transfer learning leverages knowledge from pre-trained models to solve new tasks with limited data. Instead of training from scratch, we fine-tune existing models or use them as feature extractors. This chapter covers feature extraction, fine-tuning strategies, domain adaptation, and practical transfer learning with popular models like ResNet, BERT, and GPT.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>14-01 Generative Adversarial Networks</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_01_GAN_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter14/14_01_GAN_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;generative-adversarial-networks-learning-through-competition&quot;&gt;Generative Adversarial Networks: Learning Through Competition&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://developers.google.com/static/machine-learning/gan/images/gan_diagram.svg&quot; alt=&quot;GAN Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c GAN v·ªõi Generator v√† Discriminator. Ngu·ªìn: Google Developers&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Generative Adversarial Networks represent one of the most creative and impactful ideas in recent machine learning history. Introduced by Ian Goodfellow and colleagues in 2014, GANs approach generative modeling through an entirely novel paradigm: training two neural networks in competition with each other. A generator network learns to create fake data that looks real, while a discriminator network learns to distinguish real data from the generator‚Äôs fakes. As these networks improve through their adversarial game, the generator becomes increasingly skilled at creating realistic outputs, eventually producing samples indistinguishable from real data.&lt;/p&gt;

&lt;p&gt;The elegance and power of this idea is best appreciated by understanding what preceded it. Traditional generative models like Gaussian Mixture Models or Hidden Markov Models required explicit probabilistic formulations and often made restrictive assumptions about data distribution. Variational autoencoders used neural networks but required explicit density models and variational inference. GANs sidestep these complexities entirely. We never explicitly model the probability density \(p(x)\). Instead, we implicitly learn to sample from it through the generator network. This implicit density modeling enables generating high-dimensional, complex data (like realistic images) that would be intractable to model explicitly.&lt;/p&gt;

&lt;p&gt;The adversarial training framework is inspired by game theory, specifically zero-sum games where one player‚Äôs gain is another‚Äôs loss. The generator tries to fool the discriminator, while the discriminator tries not to be fooled. This creates a natural curriculum: as the discriminator improves at detecting fakes, it provides increasingly challenging training signal to the generator, pushing it to create better fakes. Conversely, as the generator improves, the discriminator must become more discerning. At equilibrium‚Äîwhen the discriminator cannot distinguish real from fake better than random guessing‚Äîthe generator has learned to perfectly model the data distribution.&lt;/p&gt;

&lt;p&gt;Understanding GANs deeply requires grappling with several conceptual challenges. Training two networks simultaneously in opposition is fundamentally different from standard supervised learning where we optimize a single network. The loss for one network depends on the other network‚Äôs parameters, creating a moving target that can lead to instability. Mode collapse‚Äîwhere the generator learns to produce only a few types of outputs rather than capturing the full data diversity‚Äîis a persistent challenge. Measuring GAN performance is non-trivial since we can‚Äôt simply evaluate likelihood (we don‚Äôt have an explicit density model). These challenges make GANs notoriously difficult to train, requiring careful architecture design, loss function choices, and training tricks accumulated through years of research.&lt;/p&gt;

&lt;p&gt;Yet the results speak for themselves. GANs can generate photorealistic faces that don‚Äôt exist, transform horses into zebras, create art in specific styles, upscale low-resolution images, and countless other applications. The quality of GAN-generated images often exceeds VAEs and other generative approaches. This practical success, despite training difficulties, has made GANs one of the most active research areas in deep learning, with hundreds of variants proposed to stabilize training, improve quality, or enable new applications. Understanding the original GAN framework provides foundation for appreciating this vast landscape of extensions and applications.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical framework of GANs is based on a minimax game between generator and discriminator. Let‚Äôs build this up carefully, understanding each component‚Äôs role and how they interact.&lt;/p&gt;

&lt;p&gt;The generator \(G\) is a neural network that maps random noise \(\mathbf{z}\) sampled from a simple distribution (typically \(\mathbf{z} \sim \mathcal{N}(0, I)\)) to fake data:&lt;/p&gt;

\[\mathbf{x}_{\text{fake}} = G(\mathbf{z}; \theta_G)\]

&lt;p&gt;where \(\theta_G\) represents generator parameters. The noise vector \(\mathbf{z}\) serves as the source of variation‚Äîdifferent noise vectors should produce different fake samples, and the generator learns to map the noise distribution to the data distribution.&lt;/p&gt;

&lt;p&gt;The discriminator \(D\) is a neural network that takes an input \(\mathbf{x}\) (either real data or generator output) and outputs a probability that it‚Äôs real:&lt;/p&gt;

\[D(\mathbf{x}; \theta_D) \in [0, 1]\]

&lt;p&gt;where \(\theta_D\) represents discriminator parameters. Typically \(D\) ends with a sigmoid activation: \(D(\mathbf{x}) = \sigma(f_{\theta_D}(\mathbf{x}))\) where \(f\) is the discriminator‚Äôs feature extractor (convolutional layers, etc.).&lt;/p&gt;

&lt;p&gt;The training objective is formulated as a minimax game:&lt;/p&gt;

\[\min_G \max_D V(D, G) = \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log D(\mathbf{x})] + \mathbb{E}_{\mathbf{z} \sim p_z}[\log(1 - D(G(\mathbf{z})))]\]

&lt;p&gt;Let‚Äôs parse this carefully. The discriminator wants to maximize \(V\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log D(\mathbf{x})]\): Assign high probability to real data (\(D(\mathbf{x}) \to 1\), so \(\log D(\mathbf{x}) \to 0\))&lt;/li&gt;
  &lt;li&gt;\(\mathbb{E}_{\mathbf{z} \sim p_z}[\log(1 - D(G(\mathbf{z})))]\): Assign low probability to fakes (\(D(G(\mathbf{z})) \to 0\), so \(\log(1-D(G(\mathbf{z}))) \to 0\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The generator wants to minimize \(V\), specifically minimize \(\mathbb{E}_{\mathbf{z}}[\log(1 - D(G(\mathbf{z})))]\), making the discriminator assign high probability to its fakes.&lt;/p&gt;

&lt;p&gt;However, in practice, minimizing \(\log(1-D(G(\mathbf{z})))\) causes problems early in training when the generator is poor and \(D(G(\mathbf{z})) \approx 0\). The gradient of \(\log(1-D(G(\mathbf{z})))\) with respect to generator parameters is very small when \(D(G(\mathbf{z}))\) is small, providing weak learning signal exactly when the generator needs to improve most. The solution is a non-saturating variant: instead of minimizing \(\log(1-D(G(\mathbf{z})))\), maximize \(\log D(G(\mathbf{z}))\). These aren‚Äôt equivalent‚Äîthe second provides much stronger gradients when \(D(G(\mathbf{z}))\) is small.&lt;/p&gt;

&lt;p&gt;The training alternates between discriminator and generator updates:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Discriminator update&lt;/strong&gt; (maximize \(V\) with respect to \(\theta_D\)):&lt;/p&gt;

\[\theta_D \leftarrow \theta_D + \eta_D \nabla_{\theta_D} \left[\frac{1}{m}\sum_{i=1}^m \log D(\mathbf{x}^{(i)}) + \log(1-D(G(\mathbf{z}^{(i)})))\right]\]

&lt;p&gt;&lt;strong&gt;Generator update&lt;/strong&gt; (minimize \(V\) with respect to \(\theta_G\), using non-saturating objective):&lt;/p&gt;

\[\theta_G \leftarrow \theta_G - \eta_G \nabla_{\theta_G} \left[\frac{1}{m}\sum_{i=1}^m \log D(G(\mathbf{z}^{(i)}))\right]\]

&lt;p&gt;The gradients for the generator pass through the discriminator: \(\nabla_{\theta_G} D(G(\mathbf{z}))\) requires backpropagating through both \(G\) and \(D\). This coupling means generator training depends critically on discriminator providing meaningful gradients‚Äîif the discriminator is too perfect (always correctly identifying fakes), gradients vanish; if too poor (can‚Äôt distinguish real from fake), gradients are misleading.&lt;/p&gt;

&lt;p&gt;This delicate balance motivates various training strategies. We might train the discriminator \(k\) times per generator update (typically \(k=1\) or \(5\)), ensuring it stays ahead of the generator. We might add instance noise to discriminator inputs early in training, making its task harder and preventing it from becoming too strong too quickly. We might use different learning rates for generator and discriminator (often \(\eta_G &amp;lt; \eta_D\)) to control their relative improvement rates.&lt;/p&gt;

&lt;p&gt;At the theoretical equilibrium where \(p_G = p_{\text{data}}\) (generator distribution equals data distribution), the optimal discriminator is \(D^*(\mathbf{x}) = \frac{p_{\text{data}}(\mathbf{x})}{p_{\text{data}}(\mathbf{x}) + p_G(\mathbf{x})} = 0.5\) everywhere‚Äîit cannot distinguish real from fake. At this point, both loss terms equal \(\log(0.5)\), and neither network can improve by changing. This equilibrium corresponds to the generator perfectly modeling the data distribution.&lt;/p&gt;

&lt;p&gt;However, reaching this equilibrium in practice is challenging. The training dynamics can cycle, oscillate, or diverge. Mode collapse occurs when the generator discovers it can fool the discriminator by generating only a subset of the data distribution (modes)‚Äîif producing only digit ‚Äú1‚Äù fools the discriminator, why bother learning to generate other digits? Various regularization techniques (minibatch discrimination, unrolled optimization, spectral normalization) address these instabilities, showing that successful GAN training requires understanding the adversarial dynamics deeply, not just implementing the basic algorithm.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build intuition for the adversarial training process, imagine a scenario with counterfeit money (generator) and bank inspector (discriminator). Initially, the counterfeiter produces poor fakes‚Äîperhaps using a home printer that makes obviously fake bills. The inspector easily identifies these as fake (discriminator outputs near 0 for generator samples). This clear signal tells the counterfeiter what‚Äôs wrong‚Äîthe texture is wrong, colors are off, security features are missing.&lt;/p&gt;

&lt;p&gt;The counterfeiter improves, using better equipment and studying real bills more carefully. Now fakes are harder to detect‚Äîmaybe they pass casual inspection but fail under UV light. The inspector learns to check UV features (discriminator learns more sophisticated detection). This pushes the counterfeiter to replicate UV features too.&lt;/p&gt;

&lt;p&gt;This arms race continues. Each improvement by one side forces the other to improve. Eventually, the counterfeiter creates bills so convincing that even expert inspection cannot reliably distinguish them from real bills‚Äîthe equilibrium where \(D(\mathbf{x}) = 0.5\). At this point, the counterfeiter has learned to generate perfect currency.&lt;/p&gt;

&lt;p&gt;The GAN training dynamic follows this pattern. Let‚Äôs trace through early training on generating MNIST digits:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1-10&lt;/strong&gt; (Generator is terrible):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Generator produces noise that vaguely resembles digit shapes&lt;/li&gt;
  &lt;li&gt;Discriminator easily detects fakes (outputs near 0)&lt;/li&gt;
  &lt;li&gt;Strong gradients tell generator: ‚Äúmake sharper edges,‚Äù ‚Äúcenter the digit,‚Äù ‚Äúuse correct aspect ratio‚Äù&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 100-500&lt;/strong&gt; (Generator is improving):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Generator produces digit-like shapes, but wrong proportions or artifacts&lt;/li&gt;
  &lt;li&gt;Discriminator learns subtle features distinguishing real from fake&lt;/li&gt;
  &lt;li&gt;Maybe real 3s have specific curve ratios that fakes miss&lt;/li&gt;
  &lt;li&gt;Generator learns to match these statistics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Iteration 1000+&lt;/strong&gt; (Approaching equilibrium):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Generator produces convincing digits&lt;/li&gt;
  &lt;li&gt;Discriminator performance approaches 50% accuracy&lt;/li&gt;
  &lt;li&gt;Each generated sample looks like it could be from MNIST&lt;/li&gt;
  &lt;li&gt;Latent space has structure: different \(\mathbf{z}\) produces different digits&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A concrete example with numbers: suppose at some training iteration, we generate a fake digit and the discriminator outputs \(D(G(\mathbf{z})) = 0.3\). The discriminator is somewhat confident this is fake (30% probability of real). The generator‚Äôs loss is \(-\log(0.3) = 1.20\). Gradients indicate how to change generator parameters to increase \(D(G(\mathbf{z}))\) toward 1. The generator learns to adjust its outputs to fool this particular discriminator configuration.&lt;/p&gt;

&lt;p&gt;Meanwhile, the discriminator sees both this fake (which it correctly identified with 70% confidence) and real digits (which it should assign high probability). Suppose on a real digit, it outputs \(D(\mathbf{x}_{\text{real}}) = 0.95\)‚Äîcorrectly identifying real data with 95% confidence. Its loss combines both: \(-\log(0.95) - \log(1-0.3) = 0.05 + 0.36 = 0.41\). Gradients tell it how to better separate real from fake distributions.&lt;/p&gt;

&lt;p&gt;The adversarial dynamic is that the generator‚Äôs improvement makes the discriminator‚Äôs task harder (fakes become more convincing), while the discriminator‚Äôs improvement makes the generator‚Äôs task harder (must create more realistic fakes to fool a better detector). This mutual improvement drives both toward high capability.&lt;/p&gt;

&lt;p&gt;Mode collapse manifests distinctly. Suppose the generator discovers that producing ‚Äú1‚Äùs consistently fools the discriminator (maybe because ‚Äú1‚Äù is simple and the discriminator hasn‚Äôt learned to detect fake ‚Äú1‚Äùs yet). The generator might converge to producing only ‚Äú1‚Äùs or a few ‚Äú1‚Äù-like outputs, ignoring the rest of the digit manifold. The discriminator eventually learns to detect these specific fake ‚Äú1‚Äùs, but by then the generator might have mode-collapsed to a different digit. The training never achieves the equilibrium where all modes are covered. Various techniques address this: minibatch discrimination lets the discriminator detect lack of diversity, unrolled optimization allows the generator to anticipate discriminator‚Äôs response, and architectural choices can encourage diversity.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement a complete GAN from scratch to understand the training dynamics:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision.utils&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;make_grid&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Generator: maps random noise to fake data.
    
    Architecture follows common pattern for image generation:
    - Start with low spatial resolution but many channels
    - Progressively upsample spatially while reducing channels
    - Final layer outputs image with correct dimensions
    
    For MNIST: noise (100) ‚Üí (256√ó7√ó7) ‚Üí (128√ó14√ó14) ‚Üí (1√ó28√ó28)
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Project and reshape noise
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Linear layer: 100 ‚Üí 256*7*7, then reshape to (256, 7, 7)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Upsample through transposed convolutions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;deconv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 256√ó7√ó7 ‚Üí 128√ó14√ó14
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Stabilizes training
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# 128√ó14√ó14 ‚Üí 1√ó28√ó28
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Output in [-1, 1] (we&apos;ll normalize real data to match)
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        z: (batch, latent_dim) random noise
        Returns: (batch, 1, 28, 28) generated images
        
        The forward pass transforms unstructured noise into structured
        images through learned transformations. Early in training, outputs
        are noise. As training progresses, digit-like structures emerge.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Reshape to feature maps
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;deconv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Discriminator: distinguishes real from fake.
    
    Architecture mirrors generator in reverse:
    - Input: (1√ó28√ó28) image
    - Conv layers progressively downsample while increasing channels
    - Final: scalar output (probability image is real)
    
    Uses LeakyReLU instead of ReLU to prevent dying units, and no pooling
    (stride for downsampling instead) following DCGAN best practices.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# 1√ó28√ó28 ‚Üí 64√ó14√ó14
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Negative slope 0.2
&lt;/span&gt;            
            &lt;span class=&quot;c1&quot;&gt;# 64√ó14√ó14 ‚Üí 128√ó7√ó7
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Flatten: 128√ó7√ó7 ‚Üí 6272
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Final classification
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Probability of being real
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, 1, 28, 28) images
        Returns: (batch, 1) probabilities of being real
        
        The discriminator learns hierarchical features for detection:
        - Early layers: edges, textures (distinguish fake textures from real)
        - Middle layers: shapes, patterns (detect anatomically incorrect digits)  
        - Late layers: holistic features (identify subtle statistical differences)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training GAN
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Generative Adversarial Network on MNIST&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Hyperparameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Adam beta1 (lower than default 0.9 for GAN stability)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Data loading (normalize to [-1, 1] to match generator&apos;s tanh output)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Normalize to [-1, 1]
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                          &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;drop_last&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize networks
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;discriminator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Optimizers (both use Adam with Œ≤1=0.5 for stability)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer_G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer_D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Loss function (binary cross-entropy)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Labels for real and fake (used in loss computation)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;fake_label&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generator parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Discriminator parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training for &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; epochs...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This demonstrates the adversarial training dynamics:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;G_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;D_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# ==================== Train Discriminator ====================
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Discriminator wants to maximize: log D(x) + log(1 - D(G(z)))
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Equivalently, minimize: -log D(x) - log(1 - D(G(z)))
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Train on real data: maximize log D(x)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Loss: -log D(x) (negated because we minimize)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;labels_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;real_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_D_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Train on fake data: maximize log(1 - D(G(z)))
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Loss: -log(1 - D(G(z)))
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fake_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;fake_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Detach! Don&apos;t backprop through G
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss_D_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Total discriminator loss
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss_D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_D_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_D_fake&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# ==================== Train Generator ====================
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Generator wants to minimize: -log D(G(z))
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Equivalently, maximize: log D(G(z)) (non-saturating objective)
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Generate fakes again (no detach this time - we need gradients through G!)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fake_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_fake_for_G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Generator tries to make discriminator output 1 (real) for its fakes
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;labels_real_for_G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;full&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;real_label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_G&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_fake_for_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_real_for_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;loss_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Track losses
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Once per epoch
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;G_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;D_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Print progress
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;if &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch [&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;]  &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;D_loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;G_loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_G&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;D(x): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;D(G(z)): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Complete! Analyzing Results&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate samples
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate 64 samples
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fake_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; fake MNIST digits&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (64, 1, 28, 28)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Check discriminator&apos;s opinion on generated samples
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;discriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Discriminator scores for generated samples:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (ideally ~0.5)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Std:  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# If mean is near 0.5, generator is successfully fooling discriminator
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  ‚úì Generator successfully fools discriminator!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  ‚úó Discriminator still easily detects fakes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  ~ Generator is somewhat convincing&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate latent space interpolation
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Latent Space Interpolation in GAN&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Two random latent codes
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Interpolate
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generating &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; images by interpolating latent codes:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Step &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (t=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): Generated image shape &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Interpolation should show smooth morphing between different digits.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Quality of interpolation indicates latent space structure.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GAN Training Insights&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Key observations from training:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Adversarial dynamics create natural curriculum&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Balance between D and G is crucial (neither should dominate)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3. Loss values don&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t directly indicate quality (check samples!)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;4. Mode collapse is a constant danger (monitor diversity)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;5. Generated samples can be realistic despite imperfect equilibrium&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The relationship between GANs and variational autoencoders illuminates different approaches to generative modeling. VAEs explicitly model the data distribution through a latent variable model $$p(\mathbf{x}) = \int p(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})p(\mathbf{z})d\mathbf{z}$$, training through maximizing a variational lower bound on likelihood. This probabilistic framework provides theoretical guarantees and enables principled Bayesian inference but requires choosing parametric forms for distributions and often produces blurrier samples due to the reconstruction loss. GANs implicitly model distributions through the generator‚Äôs learned mapping from noise to data, using adversarial training instead of likelihood. This enables generating sharper, more realistic samples (because the discriminator can learn perceptual similarity rather than pixel-wise reconstruction) but lacks VAE‚Äôs theoretical guarantees and density estimation capability. Understanding both approaches reveals different tradeoffs: VAEs for theoretical understanding and density modeling, GANs for sample quality and flexibility.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;GANs connect to game theory through the minimax formulation. The generator and discriminator play a two-player zero-sum game where one‚Äôs gain (discriminator correctly identifying fakes) is the other‚Äôs loss (generator‚Äôs fakes being detected). Nash equilibrium‚Äîwhere neither player can improve by unilaterally changing strategy‚Äîcorresponds to the generator matching the data distribution. However, reaching Nash equilibrium in practice is challenging because we‚Äôre using gradient-based optimization, which makes local moves, in a non-convex game where equilibria might not exist or be unstable. This connection to game theory helps understand why GAN training can be unstable (many games have no pure strategy Nash equilibrium or have multiple equilibria) and motivates algorithms from game theory like unrolled optimization.&lt;/p&gt;

&lt;p&gt;The relationship to adversarial examples and robustness provides an interesting perspective. In adversarial examples research, we perturb inputs slightly to fool classifiers. In GANs, we‚Äôre doing something similar but more ambitious: creating completely synthetic inputs that fool the discriminator. The discriminator trying to resist fooling is analogous to adversarial training for robust classifiers. This connection suggests techniques from adversarial robustness (like certified defenses) might apply to stabilizing GAN training, and conversely, that GAN discriminators might provide insights into what makes classifiers vulnerable to adversarial examples. The mathematical connection is deep: both involve optimizing over input space to maximize or minimize classifier outputs.&lt;/p&gt;

&lt;p&gt;GANs‚Äô impact on semi-supervised learning demonstrates how generative models can improve discriminative tasks. By adding an auxiliary task to the discriminator‚Äînot just real/fake but also classifying real images into categories‚Äîwe can leverage unlabeled data (used for adversarial training) to improve classification on limited labeled data. The discriminator learns representations through both tasks, with the generative task providing regularization and additional training signal. This semi-supervised GAN framework has been successful in low-data regimes, showing how generative and discriminative learning can be mutually beneficial.&lt;/p&gt;

&lt;p&gt;Finally, GANs connect to the broader theme of learning without direct supervision on the target task. We never show the generator example outputs‚Äîit learns purely from discriminator feedback. This is analogous to reinforcement learning where agents learn from reward signals rather than supervised examples. Indeed, GANs can be viewed as applying policy gradient methods (from RL) to generative modeling, with the discriminator providing rewards (high scores for good fakes) that guide generator improvement. This connection has led to hybrid approaches combining GAN training with reinforcement learning principles for improved stability and performance.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;‚ÄúGenerative Adversarial Networks‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio&lt;br /&gt;
This foundational paper introduced the GAN framework and remains one of the most influential papers in modern machine learning. Goodfellow conceived the basic idea‚Äîtraining generator and discriminator adversarially‚Äîreportedly in a single evening, though the paper‚Äôs development involved significant theoretical and empirical work. The paper formalized GANs as a minimax game, proved that at equilibrium the generator learns the data distribution, and demonstrated results on several datasets. What made GANs revolutionary was not just the results but the paradigm shift: generative modeling through competition rather than likelihood maximization or reconstruction. The paper acknowledged training challenges (instability, mode collapse) while showing the approach‚Äôs potential. Reading it today, one appreciates both the clarity of the core idea and the prescience about challenges that would occupy researchers for years. GANs demonstrated that sometimes the best way to solve a problem isn‚Äôt to attack it directly (modeling density explicitly) but indirectly (learning to generate through adversarial feedback).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.06434&quot;&gt;‚ÄúUnsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alec Radford, Luke Metz, Soumith Chintala&lt;br /&gt;
The DCGAN paper made GANs practical by identifying architectural guidelines that stabilize training and improve sample quality. The authors systematically explored design choices‚Äîconvolutional vs fully connected layers, batch normalization placement, activation functions‚Äîfinding combinations that consistently worked. Their guidelines: use strided convolutions instead of pooling, use batch norm in both networks (except generator output and discriminator input), use ReLU in generator except output (tanh), use LeakyReLU in discriminator. These weren‚Äôt theoretically motivated but empirically discovered through extensive experimentation, demonstrating that practical progress sometimes comes from systematic engineering rather than mathematical insight. DCGAN showed that GANs could generate high-quality images (64√ó64 faces) and that the learned latent space had meaningful structure‚Äîarithmetic in latent space (vector for ‚Äúsmiling woman‚Äù minus ‚Äúneutral woman‚Äù plus ‚Äúneutral man‚Äù) produced ‚Äúsmiling man.‚Äù This demonstrated GANs learn disentangled representations encoding semantic attributes, making them useful beyond generation for representation learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.03498&quot;&gt;‚ÄúImproved Techniques for Training GANs‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen&lt;br /&gt;
This paper addressed GAN training instabilities through several techniques: feature matching (train generator to match statistics of discriminator‚Äôs intermediate features rather than fool final output), minibatch discrimination (let discriminator compare examples within a batch to detect lack of diversity), historical averaging (penalize parameters for deviating from historical averages), one-sided label smoothing (use 0.9 instead of 1.0 for real labels to prevent discriminator overconfidence), and virtual batch normalization (normalize using statistics from a reference batch to reduce batch-to-batch variance). Each technique addresses a specific failure mode: feature matching reduces instability, minibatch discrimination combats mode collapse, label smoothing prevents discriminator saturation. The paper also introduced the Inception Score for quantifying sample quality, providing an automated metric (though imperfect) for evaluating GANs. This work established that successful GAN training requires multiple complementary tricks rather than just the basic algorithm, providing a toolkit that has become standard practice.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.10196&quot;&gt;‚ÄúProgressive Growing of GANs for Improved Quality, Stability, and Variation‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen (NVIDIA)&lt;br /&gt;
This paper introduced progressive training: start with low-resolution images (4√ó4) and progressively add layers to generator and discriminator, increasing resolution (8√ó8, 16√ó16, ‚Ä¶, up to 1024√ó1024). This approach stabilizes training (easier to learn low-resolution distributions first) and enables generating very high-resolution images that were previously impossible. The paper also introduced improved evaluation metrics and training techniques. The generated faces at 1024√ó1024 resolution were shockingly realistic, demonstrating GANs‚Äô capability for high-fidelity generation. Progressive growing has influenced subsequent work (StyleGAN builds on it) and demonstrated that training curriculum‚Äîgradually increasing task difficulty‚Äîapplies not just to data (easy examples first) but to architecture (simple generation first, complex later). The work showed that GAN training instability can be partially addressed through careful training procedures, not just architecture or loss modifications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1812.04948&quot;&gt;‚ÄúA Style-Based Generator Architecture for Generative Adversarial Networks‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Tero Karras, Samuli Laine, Timo Aila (NVIDIA)&lt;br /&gt;
StyleGAN redesigned the generator architecture to enable fine-grained control over generated images. Instead of feeding latent code directly into the generator, StyleGAN maps it through a mapping network to an intermediate latent space \(\mathcal{W}\), then uses this to control style at different resolution levels through adaptive instance normalization. This enables incredible control: changing coarse styles (pose, face shape) independently of fine styles (hair texture, skin pores). The paper demonstrated unprecedented image quality and introduced tools for analyzing and improving GANs (like perceptual path length metric). StyleGAN generated faces indistinguishable from real photographs, achieving a milestone in generative modeling. The architecture‚Äôs success showed that generator design matters enormously‚Äînot all ways of mapping noise to images are equally good. The disentanglement properties (ability to control attributes independently) made StyleGAN useful for semantic editing and style transfer, expanding GANs from pure generation to controllable synthesis.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Mode collapse is perhaps the most frustrating failure mode in GAN training. The generator discovers it can fool the discriminator by producing only a few types of outputs rather than the full data diversity. For MNIST, this might mean generating only 1s and 7s, ignoring other digits. For faces, generating only certain poses or expressions. Detection requires checking sample diversity, not just quality‚Äîgenerate many samples and verify they span the data distribution. Solutions include minibatch discrimination (let discriminator see multiple samples and detect homogeneity), unrolled optimization (let generator anticipate discriminator‚Äôs response), or using different loss functions like Wasserstein GAN that are less prone to mode collapse. Understanding that mode collapse stems from the generator finding local optima in the adversarial game helps recognize when it‚Äôs occurring and motivates these solutions.&lt;/p&gt;

&lt;p&gt;Discriminator overpowering the generator early in training is common and destructive. If the discriminator becomes too good too quickly, it assigns probability near 0 to all generator outputs, providing vanishing gradients to the generator which can‚Äôt learn. This happens when the discriminator is too large relative to the generator, learning rate is too high for discriminator, or real/fake distributions are easily separable initially (generator starts terrible). Solutions: train discriminator less frequently (every \(k\) generator updates), use lower learning rate for discriminator, add noise to discriminator inputs (blurring the real/fake distinction), or use one-sided label smoothing (real labels = 0.9 instead of 1.0, reducing discriminator overconfidence). Monitoring \(D(\mathbf{x}_{\text{real}})\) and \(D(G(\mathbf{z}))\) helps: if real is always near 1 and fake always near 0, discriminator is too strong.&lt;/p&gt;

&lt;p&gt;Using batch normalization in the discriminator can cause problems when batch sizes are small because batch statistics become unreliable. With batch size 1, batch norm fails entirely. Solutions include using larger batch sizes (at least 32-64), using layer normalization or instance normalization instead of batch norm, or using virtual batch normalization (normalize using statistics from a fixed reference batch). Understanding that discriminator‚Äôs normalization affects what features it learns helps debug training issues related to batch size.&lt;/p&gt;

&lt;p&gt;Evaluating GAN quality is challenging because we can‚Äôt compute likelihood. Inception Score measures both quality (samples should be confidently classified) and diversity (should cover all classes) using a pre-trained classifier, but has limitations (doesn‚Äôt detect memorization, biased toward ImageNet classes). Fr√©chet Inception Distance (FID) compares statistics of real and generated samples in feature space, providing a better metric but still imperfect. For practical work, visual inspection remains important‚Äîgenerate many samples and manually check quality and diversity. Quantitative metrics complement but don‚Äôt replace human evaluation.&lt;/p&gt;

&lt;p&gt;A powerful technique for stable training is spectral normalization, which constrains discriminator‚Äôs Lipschitz constant by normalizing weight matrices by their spectral norm (largest singular value). This prevents the discriminator from having arbitrarily large gradients, stabilizing training dynamics. The technique adds minimal computational cost (computing spectral norm via power iteration) while dramatically improving stability. Modern GANs often use spectral normalization in the discriminator as standard practice, showing how theoretical understanding of training dynamics (Lipschitz constraint improves stability) translates to practical techniques.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Generative Adversarial Networks learn to generate realistic data by training two networks adversarially: a generator creating fake samples from random noise and a discriminator distinguishing real from fake. The adversarial objective is formulated as a minimax game where the generator minimizes what the discriminator maximizes, creating competitive dynamics that drive both networks toward higher capability. At equilibrium, the generator‚Äôs distribution matches the data distribution and the discriminator cannot distinguish real from fake better than random guessing, though reaching this equilibrium in practice is challenging. Training alternates between discriminator updates (using real data and generator‚Äôs fakes) and generator updates (trying to fool the discriminator), requiring careful balancing to prevent either network from dominating. Mode collapse‚Äîthe generator producing limited diversity‚Äîremains a persistent challenge addressed through architectural choices, modified objectives, and training techniques. GANs excel at generating high-quality, realistic samples (often superior to VAEs) and learning latent spaces with semantic structure enabling interpolation and manipulation. The implicit density modeling approach enables generating complex high-dimensional data without explicit probabilistic formulations, though at the cost of training instability and difficulty in evaluation. Understanding GANs deeply means appreciating both their creative power in generating realistic data and the delicate training dynamics that make them challenging but rewarding to work with in practice.&lt;/p&gt;

&lt;p&gt;The GAN framework demonstrates that competition can be a powerful learning signal, a principle that has influenced deep learning far beyond generative modeling.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>14 Generative Adversarial Networks (GANs)</title>
   <link href="http://localhost:4000/contents/en/chapter14/14_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter14/14_00_Introduction</id>
   <content type="html">&lt;p&gt;Generative Adversarial Networks (GANs) pit two networks against each other: a generator creates fake data and a discriminator tries to distinguish real from fake. This adversarial training produces remarkably realistic images. This chapter covers GAN training, loss functions, common architectures (DCGAN, StyleGAN), training challenges, and applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13-01 Variational Autoencoders</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_01_VAE_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter13/13_01_VAE_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;variational-autoencoders-probabilistic-generative-models&quot;&gt;Variational Autoencoders: Probabilistic Generative Models&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://lilianweng.github.io/posts/2018-08-12-vae/vae-gaussian.png&quot; alt=&quot;VAE Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c VAE v·ªõi ph√¢n ph·ªëi x√°c su·∫•t. Ngu·ªìn: Lilian Weng‚Äôs Blog&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Variational Autoencoders represent a beautiful marriage of variational inference from statistics and neural networks from deep learning, creating a principled probabilistic framework for generative modeling. While standard autoencoders learn deterministic encodings and decodings optimized for reconstruction, VAEs learn probability distributions over latent codes and data, enabling them to generate novel samples by sampling from the learned latent distribution. This probabilistic perspective addresses a fundamental limitation of vanilla autoencoders: their latent spaces can have ‚Äúholes‚Äù where no training examples map, making random sampling produce unrealistic outputs. VAEs regularize the latent space to be continuous and complete, ensuring we can sample from any region and decode to realistic data.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The key insight that makes VAEs work is the Evidence Lower BOund (ELBO), a tractable objective that lower-bounds the intractable log-likelihood we actually want to maximize. Computing \(\log p(\mathbf{x})\) for a latent variable model requires integrating over all possible latent codes \(\mathbf{z}\), which is generally impossible for continuous latent spaces with neural network decoders. VAEs sidestep this by introducing a recognition network (encoder) that approximates the true posterior $$p(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})$$, then optimizing a lower bound that‚Äôs tractable. The tightness of this bound depends on how well the encoder approximates the true posterior‚Äîbetter approximation means tighter bound and better model.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Understanding VAEs requires appreciating several sophisticated ideas working together. The reparameterization trick enables backpropagation through stochastic sampling operations, turning an optimization problem that seems to require reinforcement learning into one solvable with standard gradient descent. The KL divergence between the approximate posterior and the prior acts as a regularizer, preventing the latent space from fragmenting into disconnected regions and encouraging smoothness that enables interpolation. The encoder and decoder are trained jointly, creating an architecture where the encoder learns to infer meaningful latent representations while the decoder learns to generate realistic data from these representations.&lt;/p&gt;

&lt;p&gt;The beauty of the VAE framework is its generality. The same basic structure‚Äîencoder, latent distribution, decoder, ELBO objective‚Äîworks for images, text, audio, and other data types, with appropriate choices of encoder/decoder architectures and output distributions. The latent space learned by VAEs has remarkable properties: it‚Äôs continuous (nearby latent codes decode to similar outputs), complete (every region contains valid codes), and often interpretable (different latent dimensions capture different factors of variation like pose, color, or shape). These properties make VAEs valuable not just for generation but for representation learning, interpolation, and manipulation of semantic attributes.&lt;/p&gt;

&lt;p&gt;Yet VAEs have characteristic limitations that motivate ongoing research. Samples are often somewhat blurry compared to GANs, a consequence of the reconstruction-based objective and Gaussian assumptions commonly used for the decoder. The prior distribution (typically standard Gaussian) might not match the true aggregate posterior, creating a gap between what the encoder produces and what we sample from during generation. The encoder-decoder architecture creates a potential bottleneck if the latent dimension is too small. Understanding these limitations alongside VAE strengths enables using them appropriately: when you need a principled probabilistic model with tractable training, smooth latent space for interpolation, or explicit density estimation, VAEs excel. When sample quality is paramount and training instability is acceptable, GANs might be preferable.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical framework of VAEs is rooted in variational inference, a powerful technique from Bayesian statistics for approximating intractable posterior distributions. Let‚Äôs build up the mathematics carefully, understanding why each component is necessary and how they combine to create a trainable generative model.&lt;/p&gt;

&lt;p&gt;We assume data \(\mathbf{x}\) is generated from latent variables \(\mathbf{z}\) through a probabilistic process:&lt;/p&gt;

&lt;p&gt;\(\mathbf{z} \sim p(\mathbf{z})\) (prior distribution, chosen to be simple)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;$$\mathbf{x} \sim p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})\((likelihood, parameterized by neural network\)\theta$$)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The marginal likelihood of data is:&lt;/p&gt;

\[p_\theta(\mathbf{x}) = \int p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z}) d\mathbf{z}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This integral is intractable for continuous \(\mathbf{z}\) with complex $$p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})$$ (neural network decoder). Direct maximum likelihood optimization is impossible because we cannot evaluate the objective we want to maximize.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Variational inference addresses this by introducing an approximate posterior $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\((the encoder, parameterized by\)\phi$$) and deriving a lower bound on log-likelihood. Starting from the log-likelihood and introducing the encoder:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\log p_\theta(\mathbf{x}) = \log \int p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z}) d\mathbf{z}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Multiply inside the integral by $$\frac{q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})}{q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})} = 1$$:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[= \log \int q_\phi(\mathbf{z}|\mathbf{x}) \frac{p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})} d\mathbf{z}\]

\[= \log \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})}\left[\frac{p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})}\right]\]

&lt;p&gt;By Jensen‚Äôs inequality (log is concave):&lt;/p&gt;

\[\geq \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})}\left[\log \frac{p_\theta(\mathbf{x}|\mathbf{z}) p(\mathbf{z})}{q_\phi(\mathbf{z}|\mathbf{x})}\right]\]

&lt;p&gt;Rearranging terms:&lt;/p&gt;

\[= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})] - \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})}\left[\log \frac{q_\phi(\mathbf{z}|\mathbf{x})}{p(\mathbf{z})}\right]\]

\[= \mathbb{E}_{\mathbf{z} \sim q_\phi(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})] - KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))\]

&lt;p&gt;This is the Evidence Lower BOund (ELBO). The first term is reconstruction: how well can we reconstruct \(\mathbf{x}\) from latent codes sampled from the encoder. The second term is a KL divergence between the approximate posterior and the prior, acting as regularization.&lt;/p&gt;

&lt;p&gt;The ELBO provides a tractable training objective. Unlike \(\log p_\theta(\mathbf{x})\) which requires intractable integration, we can estimate the ELBO through sampling:&lt;/p&gt;

\[\mathcal{L}(\theta, \phi; \mathbf{x}) \approx \frac{1}{L}\sum_{l=1}^L \log p_\theta(\mathbf{x}|\mathbf{z}^{(l)}) - KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;where $$\mathbf{z}^{(l)} \sim q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\(. Often\)L=1$$ suffices (single sample per datapoint).&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;the-reparameterization-trick&quot;&gt;The Reparameterization Trick&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The remaining challenge is computing gradients with respect to \(\phi\) when the objective involves sampling $$\mathbf{z} \sim q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})$$. Naively, sampling is a non-differentiable operation‚Äîwe cannot backpropagate through randomness. The reparameterization trick solves this elegantly.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;For Gaussian approximate posterior $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}&lt;em&gt;\phi(\mathbf{x}), \boldsymbol{\sigma}^2&lt;/em&gt;\phi(\mathbf{x}))$$, instead of sampling directly, we:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;ol&gt;
  &lt;li&gt;Sample \(\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)\) (fixed distribution, no parameters)&lt;/li&gt;
  &lt;li&gt;Compute \(\mathbf{z} = \boldsymbol{\mu}_\phi(\mathbf{x}) + \boldsymbol{\sigma}_\phi(\mathbf{x}) \odot \boldsymbol{\epsilon}\)&lt;/li&gt;
&lt;/ol&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This is equivalent to sampling from $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\(but expressed as a deterministic function of\)\phi\(and external randomness\)\boldsymbol{\epsilon}\(. Gradients with respect to\)\phi\(flow through\)\boldsymbol{\mu}&lt;em&gt;\phi\(and\)\boldsymbol{\sigma}&lt;/em&gt;\phi$$, enabling backpropagation.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;For the common case where both $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\(and\)p(\mathbf{z})$$ are Gaussian, the KL divergence has a closed form:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z})) = KL(\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma}^2) \| \mathcal{N}(0, I))\]

\[= \frac{1}{2}\sum_{j=1}^{J} \left(\mu_j^2 + \sigma_j^2 - \log \sigma_j^2 - 1\right)\]

&lt;p&gt;where \(J\) is latent dimension. This allows exact computation without sampling, making training more stable.&lt;/p&gt;

&lt;p&gt;The complete VAE loss for a single datapoint becomes:&lt;/p&gt;

\[\mathcal{L}_{\text{VAE}}(\theta, \phi; \mathbf{x}) = \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0,I)}[\log p_\theta(\mathbf{x}|\boldsymbol{\mu}_\phi(\mathbf{x}) + \boldsymbol{\sigma}_\phi(\mathbf{x}) \odot \boldsymbol{\epsilon})] - \frac{1}{2}\sum_{j=1}^{J} (\mu_j^2 + \sigma_j^2 - \log \sigma_j^2 - 1)\]

&lt;p&gt;Maximizing this (or equivalently minimizing the negative) trains the VAE. The reconstruction term encourages accurate reconstruction while the KL term regularizes the latent space.&lt;/p&gt;

&lt;h3 id=&quot;decoder-output-distribution&quot;&gt;Decoder Output Distribution&lt;/h3&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The choice of $$p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})$$ affects what reconstruction loss we use. For continuous data like images:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Gaussian likelihood&lt;/strong&gt;: $$p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z}) = \mathcal{N}(\mathbf{x}; \boldsymbol{\mu}_\theta(\mathbf{z}), \sigma^2 I)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The negative log-likelihood is proportional to MSE: $$-\log p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z}) \propto |\mathbf{x} - \boldsymbol{\mu}_\theta(\mathbf{z})|^2$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Bernoulli likelihood&lt;/strong&gt; (for binary images): Each pixel independent Bernoulli with probability \(\hat{x}_i\) from decoder.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The negative log-likelihood is binary cross-entropy: $$-\log p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z}) = -\sum_i [x_i \log \hat{x}_i + (1-x_i)\log(1-\hat{x}_i)]$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The decoder network outputs the parameters of these distributions (means for Gaussian, probabilities for Bernoulli), and we sample from them during generation but use the mean/mode during reconstruction for training.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To understand how VAEs work in practice, let‚Äôs trace through generating a new handwritten digit. Suppose we‚Äôve trained a VAE on MNIST with 20-dimensional latent space.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;During training, the VAE saw thousands of ‚Äú3‚Äùs. For each ‚Äú3‚Äù image \(\mathbf{x}\), the encoder computed a Gaussian distribution in latent space: $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x}) = \mathcal{N}(\boldsymbol{\mu}&lt;em&gt;\phi(\mathbf{x}), \boldsymbol{\sigma}^2&lt;/em&gt;\phi(\mathbf{x}))\(. The KL penalty in the loss encouraged these distributions to be close to\)\mathcal{N}(0, I)$$, preventing them from spreading arbitrarily far or collapsing to point masses. The result: all ‚Äú3‚Äùs map to overlapping Gaussian distributions in a region of latent space. Different ‚Äú3‚Äùs (thick, thin, slanted) map to slightly different means, but all are close to each other and to the origin.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Similarly, ‚Äú8‚Äùs map to a different but also origin-centered region, ‚Äú1‚Äùs to another, and so on. The latent space self-organizes: different digits occupy different regions, but all regions are near the origin (due to KL penalty), and transitions between regions are smooth (no holes).&lt;/p&gt;

&lt;p&gt;Now for generation. We sample \(\mathbf{z} \sim \mathcal{N}(0, I)\)‚Äîjust random numbers from a standard Gaussian. Suppose we get \(\mathbf{z} = [0.5, -0.3, 0.1, \ldots]\) (20 numbers). By chance, this \(\mathbf{z}\) falls in the ‚Äú3‚Äù region of latent space. We decode: \(\hat{\mathbf{x}} = \text{decoder}_\theta(\mathbf{z})\). The decoder, having seen many ‚Äú3‚Äùs during training whose latent codes were near this \(\mathbf{z}\), has learned to map this region to ‚Äú3‚Äù-like images. The output is a novel ‚Äú3‚Äù‚Äînot a copy of any training example but a new instance following the learned pattern.&lt;/p&gt;

&lt;p&gt;The probabilistic nature provides interesting capabilities. If we sample \(\mathbf{z}\) from exactly \(\mathcal{N}(0, I)\), we get a diverse mix of all digits. If we want only ‚Äú3‚Äùs, we can sample from the region where ‚Äú3‚Äùs tend to map‚Äîbut we don‚Äôt know this region exactly without examining the encoder on ‚Äú3‚Äù training examples. This is a limitation: VAEs don‚Äôt provide explicit control over what class to generate unless we condition on class labels or discover class regions post-hoc.&lt;/p&gt;

&lt;p&gt;Interpolation between images works beautifully. Encode two images to get \(\boldsymbol{\mu}_1\) and \(\boldsymbol{\mu}_2\) (using encoder‚Äôs means, ignoring variances for determinism). Linearly interpolate:&lt;/p&gt;

\[\mathbf{z}_t = (1-t)\boldsymbol{\mu}_1 + t\boldsymbol{\mu}_2, \quad t \in [0,1]\]

&lt;p&gt;Decode each \(\mathbf{z}_t\) to get interpolated images. Because the VAE regularized the latent space to be smooth (through KL penalty), this interpolation produces coherent images throughout‚Äîsmoothly morphing from one digit to another. This is unlike vanilla autoencoders where interpolation might produce unrealistic images in unexplored latent regions.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The KL divergence penalty‚Äôs role deserves deep understanding. It serves three purposes: (1) regularization preventing overfitting to training examples, (2) ensuring the latent space is continuous and complete for sampling, (3) encouraging disentanglement where different latent dimensions capture independent factors of variation. The KL term $$KL(q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x}) | p(\mathbf{z}))$$ can be decomposed:&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z})) = -H(q_\phi(\mathbf{z}|\mathbf{x})) + H(p(\mathbf{z}), q_\phi(\mathbf{z}|\mathbf{x}))\]

&lt;p&gt;The first term encourages high entropy in \(q_\phi\) (uncertainty), preventing the encoder from collapsing to deterministic encodings (which would make sampling impossible). The second term encourages closeness to the prior \(p(\mathbf{z})\), ensuring the latent space structure matches what we‚Äôll sample from during generation.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement a complete VAE with all mathematical components explicit:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Variational Autoencoder for MNIST.
    
    Architecture:
    - Encoder: maps images to latent distribution parameters (Œº, œÉ)
    - Sampler: reparameterization trick for backpropagation through sampling
    - Decoder: maps latent codes to reconstructed images
    
    Loss: ELBO = reconstruction + KL divergence
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encoder: outputs parameters of Gaussian distribution
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# We output both Œº and log(œÉ¬≤) rather than œÉ for numerical stability
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# (œÉ must be positive, easier to ensure with exp(log œÉ¬≤))
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Separate layers for mean and log-variance
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This allows encoder to learn both independently
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc_logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder: maps latent code to reconstruction
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Output in [0,1] for pixel values
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Encode input to latent distribution parameters.
        
        Returns:
            mu: mean of q(z|x)
            logvar: log variance of q(z|x)
        
        We return log variance instead of variance/std for numerical stability.
        Variance must be positive, so we can ensure this by exponentiating logvar.
        This is more stable than directly predicting œÉ and squaring it.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc_mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc_logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Reparameterization trick: z = Œº + œÉ‚äôŒµ where Œµ ~ N(0,I)
        
        This is THE key innovation making VAEs trainable with backprop.
        Instead of sampling z ~ N(Œº,œÉ¬≤) (not differentiable w.r.t. Œº,œÉ),
        we express z as a deterministic function of Œº,œÉ and external randomness Œµ.
        
        Gradients can flow through Œº and œÉ to encoder parameters, enabling
        end-to-end training via standard backpropagation.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute standard deviation from log variance
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# std = exp(log(œÉ¬≤) / 2) = exp(logvar / 2)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Sample epsilon from standard normal
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# During training: random. During generation: can use specific Œµ
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Reparameterized sample: z = Œº + œÉ * Œµ
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Map latent code to reconstruction&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Full VAE forward pass.
        
        Returns:
            recon: reconstructed input
            mu: latent mean (for KL computation)
            logvar: latent log-variance (for KL computation)
        
        We return mu and logvar separately because we need them to compute
        the KL divergence in the loss function.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reparameterize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Generate new samples by sampling from prior and decoding.
        
        This is how we use the trained VAE for generation:
        1. Sample z ~ N(0, I) (the prior)
        2. Decode to get x
        
        Because we regularized q(z|x) to be close to N(0,I) during training,
        samples from N(0,I) should decode to realistic outputs.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vae_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    VAE loss: negative ELBO = reconstruction loss + KL divergence
    
    Args:
        recon_x: reconstructed input
        x: original input
        mu: latent mean from encoder
        logvar: latent log-variance from encoder
        beta: weight for KL term (Œ≤-VAE uses Œ≤‚â†1 for disentanglement)
    
    The loss has two terms:
    1. Reconstruction: how well we reconstruct input
    2. KL: how much encoder distribution differs from prior
    
    We want to minimize both: good reconstruction AND latent distribution
    close to prior.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Reconstruction loss (binary cross-entropy for images in [0,1])
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Treating each pixel as independent Bernoulli
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;BCE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;binary_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reduction&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# KL divergence KL(N(Œº,œÉ¬≤) \| N(0,I))
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Has closed form: 0.5 * Œ£(Œº¬≤ + œÉ¬≤ - log(œÉ¬≤) - 1)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# We have logvar = log(œÉ¬≤), so œÉ¬≤ = exp(logvar)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;KLD&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Total loss (negative ELBO)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Minimizing this is equivalent to maximizing ELBO
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BCE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KLD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BCE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;KLD&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training VAE
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Variational Autoencoder on MNIST&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create VAE
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VAE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VAE Architecture:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Input dimension: 784 (28√ó28)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Latent dimension: 20 (compression factor: 39√ó)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Total parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training VAE...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_bce&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_kld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Flatten images
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute loss
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;vae_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_bce&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bce&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_kld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kld&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Average over batches
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Per sample
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;avg_bce&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_bce&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_kld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_kld&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;(Recon = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_bce&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, KL = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_kld&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VAE Training Complete - Analyzing Results&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test reconstruction
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Encode (using mean, ignoring variance for determinism)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Reconstruct
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Measure reconstruction error
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recon_error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Test reconstruction MSE: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_error&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Analyze latent space statistics
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Latent space statistics (should be ~N(0,1) due to KL penalty):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (first 5 dims)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Std:  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Overall mean magnitude: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Overall std: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logvar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate new samples
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generating New Samples from VAE&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Sample from prior N(0,I)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; samples by sampling z ~ N(0,I)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (64, 784)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Check sample statistics
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated sample mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (should be ~0.5)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated sample std: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Reshape for visualization
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;samples_img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Reshaped for visualization: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate interpolation
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Latent Space Interpolation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Take two test images
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;img1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Encode to latent means
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mu1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mu2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Interpolating between two images in latent space:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Interpolate
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;9&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mu2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Print every other step
&lt;/span&gt;            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  t=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Generated interpolation image &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Interpolation should be smooth due to latent space regularization!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This is a key advantage of VAE over vanilla autoencoders.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate Œ≤-VAE (varying KL weight)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Œ≤-VAE: Controlling Disentanglement&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;By varying Œ≤ (weight on KL term), we control tradeoffs:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Œ≤ &amp;lt; 1: Prioritize reconstruction (sharper but less disentangled)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Œ≤ = 1: Standard VAE (balanced)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Œ≤ &amp;gt; 1: Prioritize latent regularity (more disentangled, blurrier)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Œ≤-VAE with Œ≤=4-10 often learns more interpretable latent dimensions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;where each dimension captures one semantic factor (size, rotation, etc.)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The relationship between VAEs and standard autoencoders illuminates what the probabilistic framework adds. Both use encoder-decoder architectures and reconstruction losses, but VAEs add: (1) probabilistic encodings (distributions rather than points), (2) the KL divergence regularization term, (3) the ability to sample for generation. These differences stem from VAEs being principled probabilistic models optimizing a lower bound on likelihood, while autoencoders are simply dimensionality reduction with a bottleneck. The probabilistic perspective provides theoretical guarantees: VAEs are approximately maximizing data likelihood, ensuring generated samples should be realistic if training succeeds. Autoencoders have no such guarantee‚Äîthey minimize reconstruction error, which doesn‚Äôt directly translate to generating good samples.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;VAEs connect deeply to variational inference, a general technique in Bayesian statistics for approximating intractable posterior distributions. The idea is always the same: we have a model \(p(\mathbf{x}, \mathbf{z})\) but cannot compute $$p(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\(exactly, so we approximate it with a simpler distribution\)q(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})\(from a tractable family (here, factorized Gaussians). We optimize the approximation by maximizing the ELBO, which lower-bounds the quantity we actually care about (log-likelihood). VAEs made variational inference scalable to high-dimensional problems through: (1) using neural networks for\)q\(and\)p$$, providing enormous flexibility, (2) the reparameterization trick enabling gradient-based optimization, (3) stochastic optimization allowing mini-batch training. Understanding VAEs through the variational inference lens connects them to a rich statistical tradition and motivates extensions like importance-weighted VAEs or hierarchical VAEs.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The connection to information theory provides another perspective. The ELBO can be written:&lt;/p&gt;

\[\text{ELBO} = \mathbb{E}_{q_\phi(\mathbf{z}|\mathbf{x})}[\log p_\theta(\mathbf{x}|\mathbf{z})] - KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))\]

\[= -H_{q_\phi}(p_\theta(\mathbf{x}|\mathbf{z})) - KL(q_\phi(\mathbf{z}|\mathbf{x}) \| p(\mathbf{z}))\]

&lt;p&gt;The first term is negative conditional entropy‚Äîfavoring decoders that confidently reconstruct given latent codes (low uncertainty). The KL term measures information cost of using \(q_\phi\) instead of the prior \(p\). This information-theoretic view suggests VAEs trade off between reconstruction fidelity and compression (low information latent codes), a perspective formalized in the Œ≤-VAE framework where we explicitly control this tradeoff with \(\beta\).&lt;/p&gt;

&lt;p&gt;VAEs relate to normalizing flows through their treatment of latent variables. Both use latent variables \(\mathbf{z}\) and learn mappings to data \(\mathbf{x}\). However, flows use invertible, deterministic mappings with tractable Jacobians, enabling exact likelihood. VAEs use flexible neural networks for encoder/decoder but approximate the likelihood through ELBO. Flows provide exact inference but require constrained architectures. VAEs allow flexible architectures but provide approximate inference. This tradeoff shapes their respective application domains: flows for exact density modeling, VAEs for flexible generation with stable training.&lt;/p&gt;

&lt;p&gt;Finally, VAEs connect to representation learning and disentanglement. A disentangled representation has individual latent dimensions corresponding to independent factors of variation (for faces: one dimension for pose, another for lighting, another for identity). VAEs‚Äô factorized Gaussian posterior encourages independence between latent dimensions, and Œ≤-VAEs with \(\beta &amp;gt; 1\) further encourage disentanglement by more strongly penalizing KL divergence. Learning disentangled representations is valuable beyond generation: downstream tasks benefit from interpretable, factorized features where we can manipulate specific attributes independently. Understanding how VAE training encourages disentanglement connects to broader questions about what constitutes good representations and how to discover them through unsupervised learning.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;‚ÄúAuto-Encoding Variational Bayes‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Diederik P. Kingma, Max Welling&lt;br /&gt;
This foundational paper introduced VAEs and made variational inference practical for deep learning through the reparameterization trick. Kingma and Welling showed that by expressing sampling as \(\mathbf{z} = \boldsymbol{\mu} + \boldsymbol{\sigma} \odot \boldsymbol{\epsilon}\) where \(\boldsymbol{\epsilon} \sim \mathcal{N}(0,I)\), we can backpropagate through stochastic computation, enabling gradient-based optimization of the ELBO. The paper provided clear mathematical derivations, proposed practical implementation details (using Gaussian encoders/decoders, closed-form KL), and demonstrated results on images. VAEs offered several advantages over existing approaches: principled probabilistic framework (unlike autoencoders), stable training (unlike early GANs), and tractable lower bound on likelihood (unlike implicit models). The work influenced thousands of follow-up papers exploring VAE variants, applications, and theoretical properties. Reading this paper, one appreciates both the mathematical sophistication (connecting neural networks to variational inference) and the practical insight (the reparameterization trick) that made the method work.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1606.05908&quot;&gt;‚ÄúTutorial on Variational Autoencoders‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Carl Doersch&lt;br /&gt;
This tutorial paper provided accessible introduction to VAEs for readers without strong background in variational inference. Doersch carefully explained the intuition behind ELBO (why a lower bound is sufficient, what the terms mean), the reparameterization trick (with visual diagrams showing gradient flow), and practical training considerations. The tutorial addressed common confusions (why Gaussian posteriors, what latent space structure means, how to choose hyperparameters) and connected VAEs to related concepts (autoencoders, GANs, Bayesian inference). While not introducing new methods, this tutorial significantly helped VAE adoption by making the framework accessible to practitioners. It exemplifies how clear exposition‚Äîexplaining not just what equations are but why they make sense‚Äîcan have major impact on field by lowering barriers to understanding sophisticated techniques.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://openreview.net/forum?id=Sy2fzU9gl&quot;&gt;‚ÄúŒ≤-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, Alexander Lerchner&lt;br /&gt;
This paper introduced Œ≤-VAE, a simple modification where the KL term in the loss is weighted by \(\beta &amp;gt; 1\) instead of 1. This seemingly minor change has profound effects on the learned latent representations. Higher Œ≤ more strongly penalizes KL divergence, encouraging the latent dimensions to be independent (factorized), which often leads to disentangled representations where each dimension captures one interpretable factor of variation. The paper demonstrated that Œ≤-VAEs learn to separate factors like shape, size, rotation, and color into different latent dimensions, enabling controlled generation by manipulating specific dimensions. The work connected VAEs to the information bottleneck principle and showed that the right amount of compression (through Œ≤) can improve representation quality for downstream tasks. Œ≤-VAE has become a standard tool for learning disentangled representations and illustrates how hyperparameters (Œ≤) can control qualitative properties of learned representations, not just quantitative metrics like reconstruction error.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1509.00519&quot;&gt;‚ÄúImportance Weighted Autoencoders‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Yuri Burda, Roger Grosse, Ruslan Salakhutdinov&lt;br /&gt;
This paper improved VAE‚Äôs ELBO through importance sampling, creating a tighter lower bound on log-likelihood. Standard VAE uses a single sample from \(q_\phi(\mathbf{z}|\mathbf{x})\) to estimate the ELBO. IWAE uses multiple samples and importance weighting, giving:&lt;/p&gt;

\[\mathcal{L}_{\text{IWAE}} = \mathbb{E}\left[\log \frac{1}{K}\sum_{k=1}^K \frac{p_\theta(\mathbf{x}, \mathbf{z}^{(k)})}{q_\phi(\mathbf{z}^{(k)}|\mathbf{x})}\right]\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This is a tighter lower bound (approaches true log-likelihood as \(K \to \infty\)) and often generates better samples. The paper showed that the quality improvement comes from better training of the generative model $$p_\theta(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})\(, though the inference network\)q_\phi$$ might become less accurate. IWAE demonstrates that even with VAE‚Äôs solid theoretical foundation, there‚Äôs room for improvement through better variational approximations. The importance weighting idea has influenced subsequent work on improving variational bounds and shows how classical statistical techniques (importance sampling) can enhance neural approaches.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1906.00446&quot;&gt;‚ÄúGenerating Diverse High-Fidelity Images with VQ-VAE-2‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ali Razavi, Aaron van den Oord, Oriol Vinyals&lt;br /&gt;
This paper introduced VQ-VAE-2, achieving state-of-the-art sample quality for VAE-based models by using discrete latent representations and hierarchical priors. Instead of continuous Gaussian latents, VQ-VAE uses vector quantization‚Äîthe encoder outputs indices into a learned codebook, and the decoder receives the corresponding codebook vectors. This discreteness allows using powerful autoregressive priors over the latent codes, dramatically improving sample quality. The hierarchical structure (separate latent codes for global and local structure) enables generating high-resolution images. While more complex than standard VAEs, VQ-VAE-2 demonstrated that VAE-based models could compete with GANs in sample quality while maintaining VAE‚Äôs advantages of stable training and latent space structure. The work showed that the VAE framework is flexible enough to accommodate discrete latents, hierarchical structure, and sophisticated priors, pushing VAE performance to new levels.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The most common failure mode in VAE training is posterior collapse, where the encoder learns to ignore the input and output the prior distribution for all inputs: $$q_\phi(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x}) \approx p(\mathbf{z}) = \mathcal{N}(0,I)\(regardless of\)\mathbf{x}$$. The KL term becomes zero (good for that term!) but the reconstruction term cannot improve because latent codes contain no information about the input. The decoder learns to generate average images (the mean of the training distribution) regardless of latent code. Symptoms include very low KL divergence (approaching 0) and poor reconstructions. This happens when the decoder is too powerful‚Äîit can reconstruct reasonably well without using latent information, so the encoder takes the easy route of outputting the prior to minimize KL.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Solutions include: (1) weakening the decoder (fewer layers/parameters), forcing it to rely on latent codes; (2) KL annealing‚Äîstart training with Œ≤=0 (no KL penalty) and gradually increase to Œ≤=1, allowing the encoder to discover useful representations before regularization is applied; (3) free bits‚Äîonly penalize KL if it‚Äôs above a threshold, ensuring latent dimensions maintain minimum information content; (4) better optimization‚Äîusing higher learning rates for the encoder than decoder, giving it advantage in the competition for capacity. Understanding posterior collapse as an optimization pathology rather than fundamental VAE limitation helps implement these solutions appropriately.&lt;/p&gt;

&lt;p&gt;Choosing the latent dimension involves a tradeoff between expressiveness and disentanglement. Larger latent dimensions can capture more variation (good for reconstruction) but tend to be less disentangled (dimensions become correlated, harder to interpret). Smaller latent dimensions force more compression and often learn more disentangled representations but may not capture all data variation (poor reconstruction). For MNIST, 10-20 dimensions typically suffice. For CelebA faces, 64-256 dimensions are common. Always validate on both reconstruction quality (quantitative) and latent space interpretability (qualitative).&lt;/p&gt;

&lt;p&gt;The choice of Œ≤ in Œ≤-VAE significantly affects outcomes. Œ≤=1 is standard VAE, balancing reconstruction and regularization. Œ≤&amp;gt;1 (typically 2-10) prioritizes disentanglement, useful when interpretability matters more than perfect reconstruction. Œ≤&amp;lt;1 (typically 0.1-0.5) prioritizes reconstruction, useful when generation quality matters more than latent space structure. For representation learning (using VAE features for downstream tasks), Œ≤=1-2 often works well. For controllable generation (manipulating specific attributes), Œ≤=4-10 provides more disentangled latents. Understanding this knob allows tailoring VAEs to specific application requirements.&lt;/p&gt;

&lt;p&gt;A powerful technique for improving sample quality is using more sophisticated decoder distributions than Gaussian or Bernoulli. Mixture of discretized logistics (modeling pixel values as mixture of binned distributions) captures multi-modality better than single Gaussian. Autoregressive decoders (each pixel predicted conditionally on previous pixels) capture dependencies autoencoders‚Äô factorized assumptions miss. These more expressive decoders often generate sharper samples while maintaining VAE‚Äôs stable training. The tradeoff is computational cost‚Äîautoregressive decoding is slow. Understanding that decoder choice affects both sample quality and training/generation speed guides appropriate architectural decisions.&lt;/p&gt;

&lt;p&gt;When using VAE latent codes for downstream tasks (classification, clustering), a decision is whether to use the mean \(\boldsymbol{\mu}\) or sample from \(\mathcal{N}(\boldsymbol{\mu}, \boldsymbol{\sigma}^2)\). For deterministic tasks (classification), using mean provides stable features. For tasks requiring uncertainty (active learning, Bayesian inference), sampling reflects the encoder‚Äôs uncertainty. For most applications, the mean works well and is standard practice, but understanding that the full distribution is available enables more sophisticated uses when appropriate.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Variational Autoencoders combine neural networks with variational inference to create a principled probabilistic framework for generative modeling with latent variables, optimizing the Evidence Lower BOund on log-likelihood as a tractable surrogate for the intractable true likelihood. The encoder learns to map inputs to distributions over latent codes (parameterized as Gaussian with learned mean and variance), while the decoder learns to reconstruct inputs from latent samples, with both trained jointly through the ELBO objective combining reconstruction accuracy and latent distribution regularization. The reparameterization trick‚Äîexpressing stochastic sampling as deterministic function of parameters and external randomness‚Äîenables backpropagation through sampling, making end-to-end training possible with standard gradient descent. The KL divergence between approximate posterior and prior regularizes the latent space to be continuous, complete, and centered around the prior, ensuring samples from the prior decode to realistic outputs and enabling smooth interpolation between examples. Œ≤-VAE extends the framework by weighting the KL term, trading off reconstruction quality for latent disentanglement and enabling learned representations where individual dimensions capture interpretable factors of variation. VAEs provide stable training compared to GANs, explicit latent space structure enabling interpolation and manipulation, and a principled probabilistic framework supporting theoretical analysis, though often producing somewhat blurrier samples than adversarially trained models. Understanding VAEs requires appreciating the interplay between deep learning (neural encoders/decoders), probability theory (latent variable models), and optimization (variational bounds), making them both theoretically rich and practically valuable for generation, representation learning, and semi-supervised learning.&lt;/p&gt;

&lt;p&gt;Variational autoencoders exemplify how bringing together ideas from different fields‚Äîneural networks, variational inference, information theory‚Äîcan create methods more powerful than the sum of their parts.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>13 Variational Autoencoders (VAE)</title>
   <link href="http://localhost:4000/contents/en/chapter13/13_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter13/13_00_Introduction</id>
   <content type="html">&lt;p&gt;Variational Autoencoders (VAEs) are probabilistic generative models that learn structured latent representations. By combining variational inference with neural networks, VAEs can generate new samples and interpolate smoothly in latent space. This chapter covers the VAE architecture, ELBO objective, reparameterization trick, and applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>12-01 Autoencoder Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_01_Autoencoder_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter12/12_01_Autoencoder_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;autoencoders-learning-efficient-representations&quot;&gt;Autoencoders: Learning Efficient Representations&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/2/28/Autoencoder_structure.png/600px-Autoencoder_structure.png&quot; alt=&quot;Autoencoder Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c Autoencoder v·ªõi encoder v√† decoder. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Autoencoders represent a fundamentally different paradigm in neural network training compared to the supervised learning we‚Äôve studied so far. Instead of learning to map inputs to labeled outputs, autoencoders learn to reconstruct their inputs through an information bottleneck. This seemingly circular task‚Äîpredicting the input from itself‚Äîbecomes meaningful when we constrain the network to pass information through a lower-dimensional hidden layer called the latent space or code. By forcing the network to compress and then decompress the input, we compel it to learn efficient representations that capture the essential structure of the data while discarding noise and irrelevant details.&lt;/p&gt;

&lt;p&gt;The power of autoencoders lies not in the reconstruction itself but in what they learn during the process. The encoder learns to extract the most important features from high-dimensional data and compress them into a compact representation. The decoder learns to generate realistic data from these compressed representations. The latent space that emerges has remarkable properties: nearby points in latent space often correspond to semantically similar inputs, and we can interpolate smoothly between points to generate novel, realistic examples. These properties make autoencoders valuable for dimensionality reduction, denoising, anomaly detection, feature learning for downstream tasks, and as building blocks for more sophisticated generative models.&lt;/p&gt;

&lt;p&gt;Understanding autoencoders requires appreciating the interplay between capacity and constraint. If the latent dimension equals or exceeds the input dimension, the network can simply learn the identity function, copying inputs through unchanged‚Äîuseless for learning meaningful structure. The bottleneck‚Äîmaking the latent dimension smaller than the input‚Äîforces the network to make choices about what to preserve. With a 784-dimensional input image compressed to 32 latent dimensions, the network cannot possibly encode every pixel independently. It must discover higher-level features like edges, shapes, and textures that compactly represent the image‚Äôs essential content. This compression isn‚Äôt arbitrary but learned from data, adapting to the specific structure present in the training distribution.&lt;/p&gt;

&lt;p&gt;The historical significance of autoencoders extends beyond their practical applications. They were among the first successful unsupervised learning methods in deep learning, demonstrating that neural networks could learn meaningful representations without labeled data. This influenced the development of pre-training strategies that enabled training deeper networks in the pre-ReLU era. Modern self-supervised learning and contrastive methods can be seen as descendants of autoencoder ideas‚Äîlearning representations by predicting or reconstructing parts of the input from other parts. The autoencoder framework also introduced the encoder-decoder architecture pattern that has proven enormously influential, appearing in sequence-to-sequence models, variational autoencoders, and generative adversarial networks.&lt;/p&gt;

&lt;p&gt;Yet autoencoders have important limitations that motivate more sophisticated generative models. Standard autoencoders learn to compress and reconstruct training data but don‚Äôt necessarily learn a good generative model‚Äîthe latent space might have ‚Äúholes‚Äù where no training examples map, making random sampling produce unrealistic outputs. They don‚Äôt explicitly model the data distribution, limiting their theoretical guarantees. And the reconstruction loss, while intuitive, might not capture perceptual similarity (two images can be pixel-wise different yet perceptually similar, or pixel-wise similar yet perceptually different). These limitations led to variational autoencoders (which model distributions explicitly), generative adversarial networks (which use adversarial training instead of reconstruction loss), and perceptual losses (which measure similarity in feature space rather than pixel space). Understanding vanilla autoencoders provides the foundation for appreciating these more advanced techniques.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical framework of autoencoders is elegantly simple yet rich in implications. An autoencoder consists of two neural networks composed sequentially: an encoder \(f_\phi\) parameterized by \(\phi\) and a decoder \(g_\theta\) parameterized by \(\theta\). Given input \(\mathbf{x} \in \mathbb{R}^{d}\), the encoder produces a latent representation:&lt;/p&gt;

\[\mathbf{z} = f_\phi(\mathbf{x}) \in \mathbb{R}^{k}\]

&lt;p&gt;where \(k &amp;lt; d\) enforces the bottleneck (though we‚Äôll discuss cases where this isn‚Äôt strictly required). The decoder reconstructs from the latent representation:&lt;/p&gt;

\[\hat{\mathbf{x}} = g_\theta(\mathbf{z}) = g_\theta(f_\phi(\mathbf{x})) \in \mathbb{R}^{d}\]

&lt;p&gt;The training objective minimizes reconstruction error:&lt;/p&gt;

\[\mathcal{L}(\mathbf{x}, \hat{\mathbf{x}}) = \|\mathbf{x} - \hat{\mathbf{x}}\|^2\]

&lt;p&gt;for continuous data (mean squared error), or:&lt;/p&gt;

\[\mathcal{L}(\mathbf{x}, \hat{\mathbf{x}}) = -\sum_{i=1}^{d} [x_i \log(\hat{x}_i) + (1-x_i)\log(1-\hat{x}_i)]\]

&lt;p&gt;for binary data (binary cross-entropy, treating each dimension as independent Bernoulli).&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;The choice of loss function embodies assumptions about the data and noise model. MSE assumes Gaussian noise: we‚Äôre modeling $$p(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z}) = \mathcal{N}(\mathbf{x}; g_\theta(\mathbf{z}), \sigma^2 I)\(, and minimizing MSE is equivalent to maximum likelihood under this assumption. Binary cross-entropy assumes Bernoulli noise: each pixel is independently binary with probability\)\hat{x}_i$$. For images with continuous values in [0,1], this is actually modeling each pixel as a probability, which seems odd but works reasonably in practice. More sophisticated approaches use perceptual losses based on feature distances in pre-trained networks, better capturing perceptual similarity.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The bottleneck dimension \(k\) is the key hyperparameter controlling the compression-fidelity tradeoff. Very small \(k\) (like 2-3 dimensions) creates extreme compression, forcing the network to capture only the most essential variations in data. This is useful for visualization (we can plot the 2D latent space) but may lose important details. Moderate \(k\) (32-128 dimensions for image datasets) balances compression and reconstruction quality. Large \(k\) (approaching input dimension) reduces compression pressure but might not learn interesting structure.&lt;/p&gt;

&lt;p&gt;Interestingly, even with \(k \geq d\) (no dimensional bottleneck), we can force meaningful learning through other constraints. Sparse autoencoders add a sparsity penalty to the latent activations:&lt;/p&gt;

\[\mathcal{L}_{\text{sparse}} = \|\mathbf{x} - \hat{\mathbf{x}}\|^2 + \lambda \sum_{j=1}^{k} KL(\rho \| \hat{\rho}_j)\]

&lt;p&gt;where \(\rho\) is a target sparsity level (e.g., 0.05) and \(\hat{\rho}_j\) is the average activation of latent unit \(j\) over the training set. The KL divergence penalty encourages most latent units to be inactive (near zero) most of the time, forcing different units to specialize in different patterns. This creates a sparse, distributed representation even without dimensional bottleneck.&lt;/p&gt;

&lt;p&gt;Denoising autoencoders corrupt the input \(\mathbf{x}\) with noise to create \(\tilde{\mathbf{x}}\) but train to reconstruct the original:&lt;/p&gt;

\[\mathcal{L} = \|\mathbf{x} - g_\theta(f_\phi(\tilde{\mathbf{x}}))\|^2\]

&lt;p&gt;The corruption process might add Gaussian noise, mask random pixels, or add salt-and-pepper noise. This forces the encoder to learn robust features invariant to the noise type, and the decoder to learn to ‚Äúfill in‚Äù corrupted regions based on uncorrupted context. Denoising autoencoders often learn better features than vanilla autoencoders because the denoising task requires understanding data structure, not just memorizing training examples.&lt;/p&gt;

&lt;p&gt;The latent space geometry deserves careful analysis. In a well-trained autoencoder on image data, nearby points in latent space typically correspond to perceptually similar images. We can interpolate linearly between two latent codes \(\mathbf{z}_1\) and \(\mathbf{z}_2\):&lt;/p&gt;

\[\mathbf{z}_t = (1-t)\mathbf{z}_1 + t\mathbf{z}_2, \quad t \in [0,1]\]

&lt;p&gt;and decode \(g_\theta(\mathbf{z}_t)\) to generate intermediate images. For well-behaved autoencoders, this produces smooth transitions (morphing one face into another, for example). However, standard autoencoders don‚Äôt guarantee good interpolation‚Äîthere might be ‚Äúholes‚Äù in latent space where no training examples map, and interpolating through these holes produces unrealistic reconstructions. Variational autoencoders address this by explicitly regularizing the latent space to be continuous and well-behaved.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build concrete intuition for how autoencoders learn representations, let‚Äôs trace through training on MNIST digits. Suppose we compress 28√ó28=784 pixel images to 32-dimensional latent codes.&lt;/p&gt;

&lt;p&gt;Initially, with random weights, the encoder produces meaningless latent codes and the decoder generates random noise as reconstruction. The reconstruction error is enormous‚Äîwe‚Äôre trying to match 784 pixel values but getting essentially random outputs. Gradients via backpropagation indicate how to adjust encoder and decoder weights to reduce this error.&lt;/p&gt;

&lt;p&gt;As training progresses, the encoder learns to extract increasingly meaningful features. Early on, it might learn that certain pixels tend to be dark (in the background) versus light (in digit strokes), encoding this as latent dimensions representing average brightness in different regions. This primitive encoding already allows better reconstruction than random noise‚Äîthe decoder learns to generate images with appropriate overall brightness patterns.&lt;/p&gt;

&lt;p&gt;With more training, the encoder discovers edge patterns. Certain latent dimensions become active when the digit has vertical strokes (1, 4, 7), others for curves (0, 6, 8, 9), others for horizontal segments (2, 3, 5, 7). The decoder learns to reconstruct digit-like images from these edge indicators. Reconstructions now capture the general shape of digits, though details might be blurry.&lt;/p&gt;

&lt;p&gt;Eventually, the 32 latent dimensions self-organize into a meaningful representation space. Dimensions might encode: digit identity (roughly which digit), stroke thickness, slant, size, position in image. This learned representation emerges purely from the reconstruction objective‚Äîwe never told the network what features to learn, only to compress and reconstruct accurately.&lt;/p&gt;

&lt;p&gt;Consider what happens when we encode several ‚Äú3‚Äùs from the training set. Their latent codes cluster together in the 32D latent space because they share structure (similar edges, curves, topology). Different ‚Äú3‚Äùs (thick, thin, slanted) map to slightly different but nearby latent points. Meanwhile, ‚Äú8‚Äùs cluster in a different region of latent space‚Äîthey share the topological structure (two loops) that ‚Äú3‚Äùs lack. The latent space has self-organized to reflect digit categories and variations within categories, all without any labels.&lt;/p&gt;

&lt;p&gt;Now for the interpolation test. Encode a ‚Äú3‚Äù to get \(\mathbf{z}_3\) and encode an ‚Äú8‚Äù to get \(\mathbf{z}_8\). Decode intermediate points:&lt;/p&gt;

&lt;p&gt;\(\mathbf{z}_{0.0} = \mathbf{z}_3 \to\) decodes to ‚Äú3‚Äù&lt;br /&gt;
\(\mathbf{z}_{0.25} = 0.75\mathbf{z}_3 + 0.25\mathbf{z}_8 \to\) decodes to ‚Äú3 with hint of 8‚Äù&lt;br /&gt;
\(\mathbf{z}_{0.5} = 0.5\mathbf{z}_3 + 0.5\mathbf{z}_8 \to\) decodes to ambiguous digit&lt;br /&gt;
\(\mathbf{z}_{0.75} = 0.25\mathbf{z}_3 + 0.75\mathbf{z}_8 \to\) decodes to ‚Äú8 with hint of 3‚Äù&lt;br /&gt;
\(\mathbf{z}_{1.0} = \mathbf{z}_8 \to\) decodes to ‚Äú8‚Äù&lt;/p&gt;

&lt;p&gt;If interpolation is smooth, we see gradual morphing. If there are discontinuities, we might get unrealistic outputs at intermediate points. This interpolation quality is a diagnostic for whether the latent space is well-structured.&lt;/p&gt;

&lt;p&gt;Denoising autoencoders add an interesting twist. Suppose we corrupt a ‚Äú7‚Äù by randomly zeroing 20% of pixels. The corrupted image is ambiguous‚Äîit could be a damaged ‚Äú7‚Äù or possibly a ‚Äú1‚Äù. The denoising autoencoder must use context (uncorrupted pixels) to infer the most likely original digit. This requires understanding digit structure, not just memorizing pixel patterns. The encoder learns to extract robust features despite corruption, and the decoder learns to generate complete digits from partial evidence. The learned representations are often more useful for downstream tasks than those from vanilla autoencoders because they‚Äôre forced to capture semantic structure rather than low-level pixel statistics.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement autoencoders from scratch with complete training pipeline:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Autoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Standard autoencoder with fully connected layers.
    
    Architecture: Input ‚Üí Encoder ‚Üí Latent (bottleneck) ‚Üí Decoder ‚Üí Reconstruction
    
    The bottleneck forces compression - input dimensions &amp;gt; latent dimensions.
    The network must learn efficient encoding of data structure.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        input_dim: flattened input size (28*28=784 for MNIST)
        latent_dim: bottleneck dimension (compression factor = input_dim/latent_dim)
        
        We&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll use symmetric encoder-decoder architecture with progressively
        decreasing then increasing dimensions: 784 ‚Üí 256 ‚Üí 128 ‚Üí 32 ‚Üí 128 ‚Üí 256 ‚Üí 784
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Autoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encoder: progressively compress
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# No activation - let latent be unbounded
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder: progressively decompress
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Sigmoid for pixel values in [0,1]
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Map input to latent representation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Reconstruct from latent code&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Full autoencoder: encode then decode&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DenoisingAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Denoising autoencoder: trained to reconstruct clean data from corrupted input.
    
    The corruption process forces learning robust features that capture
    data structure rather than memorizing training examples. Results in
    better features for downstream tasks.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;DenoisingAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Same architecture as vanilla autoencoder
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Additional regularization
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;add_noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Corrupt input with noise.
        
        For MNIST, we&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll use Gaussian noise and clip to [0,1].
        Other corruption types: masking (zero out pixels),
        salt-and-pepper, or adversarial perturbations.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;noisy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clamp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;noisy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Training: corrupt input, encode corrupted, decode to clean.
        
        Key difference from vanilla: we add noise to input before encoding
        but compute loss against original clean input. This trains the
        network to denoise.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Corrupt input
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x_noisy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;add_noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encode corrupted input
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_noisy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decode (should reconstruct clean input, not noisy input!)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_noisy&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load MNIST for demonstration
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Autoencoders on MNIST&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Data loading
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train vanilla autoencoder
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Training Vanilla Autoencoder (latent_dim=32)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Autoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer_ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Flatten images: (batch, 1, 28, 28) ‚Üí (batch, 784)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Training Denoising Autoencoder (latent_dim=32, noise=0.3)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DenoisingAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noise_factor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer_dae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward pass (adds noise internally)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;noisy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Loss: reconstruct CLEAN data from NOISY input
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;reconstruction&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;optimizer_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test and visualize
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Testing Reconstructions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Get test batch
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;next&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;iter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Vanilla autoencoder
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;recon_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Denoising autoencoder (add noise for testing too)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_noisy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;add_noise&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;recon_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute reconstruction errors
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;mse_ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mse_dae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Vanilla AE reconstruction MSE: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_ae&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Denoising AE reconstruction MSE: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mse_dae&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Visualize some reconstructions
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_display&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Displaying first &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_display&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; test images with reconstructions...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Reshape for visualization
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;originals&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;recon_ae_imgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recon_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;recon_dae_imgs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;recon_dae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_display&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Print shapes (would display in actual notebook)
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Original shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;originals&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Reconstructions shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon_ae_imgs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate latent space interpolation
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Latent Space Interpolation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Take two different digits
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;idx1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Interpolate between first and sixth test image
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;img1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;img2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Encode both
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Interpolating between two test images:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Image 1 latent code mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, std: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Image 2 latent code mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, std: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Interpolate in latent space
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generating &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; intermediate images by interpolation:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;img_interp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Step &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (t=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): Decoded image shape &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img_interp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;In a visual display, you&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d see smooth morphing from digit to digit.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This demonstrates the latent space has learned meaningful structure!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate dimensionality reduction visualization (2D latent space)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training 2D Autoencoder for Visualization&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TinyAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Autoencoder with 2D latent space for visualization&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 2D latent for plotting!
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TinyAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer_2d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training 2D autoencoder (extreme compression: 784 ‚Üí 2)...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;optimizer_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Visualize latent space
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Encoding test set into 2D latent space...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;latent_codes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels_all&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;latent_codes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cpu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;latent_codes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_codes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;labels_all&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;concatenate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Latent space coordinates shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_codes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (10000, 2)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;In a scatter plot, different digits would cluster in 2D space.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This demonstrates autoencoders learn meaningful representations!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Digit 0s in one region, 1s in another, etc.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Implement convolutional autoencoder for images:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Convolutional autoencoder for images.
    
    Uses conv layers in encoder (spatial downsampling through striding)
    and transposed convolutions in decoder (upsampling).
    Much more parameter-efficient than fully connected for images.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encoder: downsample with conv layers
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# 28√ó28√ó1 ‚Üí 14√ó14√ó32 ‚Üí 7√ó7√ó64 ‚Üí flatten ‚Üí latent_dim
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 28‚Üí14
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 14‚Üí7
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder: upsample with transposed conv
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# latent_dim ‚Üí 7√ó7√ó64 ‚Üí 14√ó14√ó32 ‚Üí 28√ó28√ó1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 7‚Üí14
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ConvTranspose2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 14‚Üí28
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder_linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Reshape to feature maps
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Convolutional Autoencoder for Images&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;conv_ae&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvAutoencoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;total_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conv_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Total parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_params&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Quick training
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer_conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training convolutional autoencoder...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Keep 2D structure for conv layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv_ae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mse_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;recon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;optimizer_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;optimizer_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Convolutional autoencoder trained!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Benefits: Fewer parameters, better image reconstructions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The conv structure provides inductive bias for spatial data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Autoencoders connect deeply to principal component analysis (PCA), a classical dimensionality reduction technique. A linear autoencoder with MSE loss learns to project data onto the subspace spanned by the top \(k\) principal components‚Äîexactly what PCA does. This equivalence reveals that autoencoders generalize PCA by allowing nonlinear encoder and decoder functions. Where PCA finds the best linear \(k\)-dimensional subspace, autoencoders find the best nonlinear \(k\)-dimensional manifold. For data with nonlinear structure (like images where meaningful variations are rotations, scalings, deformations‚Äîall nonlinear), autoencoders can capture structure that PCA misses. Understanding this connection helps appreciate autoencoders as nonlinear dimension reduction and motivates their use when linear methods fail.&lt;/p&gt;

&lt;p&gt;The relationship to representation learning and transfer learning is profound. Autoencoders trained on large unlabeled datasets learn general features that often transfer well to supervised tasks. In the pre-ImageNet era, greedy layer-wise pre-training using stacked autoencoders was crucial for training deep networks. Each layer was trained as an autoencoder on features from the previous layer, progressively learning hierarchical representations. While ReLU, batch normalization, and better initialization have made this pre-training less necessary for supervised learning, the core idea‚Äîthat unsupervised learning on plentiful unlabeled data can provide useful initializations for supervised tasks with limited labels‚Äîremains important and has evolved into modern self-supervised learning approaches.&lt;/p&gt;

&lt;p&gt;Autoencoders connect to information theory through the information bottleneck principle. The latent representation \(\mathbf{z}\) should capture information about \(\mathbf{x}\) relevant for reconstruction while discarding irrelevant details. Information theory quantifies this through mutual information: maximize \(I(\mathbf{x}; \mathbf{z})\) (information about input preserved in latent) while minimizing \(I(\mathbf{z}; \text{noise})\) or constraining \(I(\mathbf{z})\) (complexity of latent representation). Variational autoencoders make this connection explicit by introducing a KL divergence term that regularizes the latent distribution. Understanding autoencoders through information theory provides principled ways to think about what makes a good representation.&lt;/p&gt;

&lt;p&gt;The evolution from autoencoders to variational autoencoders (VAEs) and generative adversarial networks (GANs) shows how addressing limitations drives innovation. Standard autoencoders learn to reconstruct but don‚Äôt explicitly model the data distribution, limiting their generative ability. VAEs add a probabilistic framework, treating the encoder as computing a distribution over latent codes and adding a regularization term that shapes this distribution to be well-behaved (typically standard Gaussian). This enables principled sampling and interpolation. GANs take a completely different approach, using adversarial training instead of reconstruction, often generating sharper, more realistic samples. Each approach has strengths: autoencoders are simple and stable to train, VAEs provide principled probabilistic framework, GANs generate highest quality samples. Understanding autoencoders provides the foundation for appreciating these more sophisticated generative models.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.science.org/doi/10.1126/science.1127647&quot;&gt;‚ÄúReducing the Dimensionality of Data with Neural Networks‚Äù (2006)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Geoffrey E. Hinton, Ruslan Salakhutdinov&lt;br /&gt;
This seminal Science paper demonstrated that deep autoencoders could learn much better dimensionality reduction than PCA or shallow autoencoders. Hinton and Salakhutdinov introduced greedy layer-wise pre-training: train each layer as an autoencoder (actually a restricted Boltzmann machine in their case) on features from the previous layer, stacking them to build deep representations. This pre-training followed by fine-tuning enabled training networks much deeper than was previously possible (this was before ReLU and modern initialization techniques). The paper showed impressive results on visualizing high-dimensional data and compressing images, demonstrating that deep learning could learn hierarchical representations through unsupervised learning. This work was influential in the deep learning renaissance of the late 2000s, showing that depth mattered and that unsupervised pre-training could unlock it. While modern supervised learning doesn‚Äôt require autoencoder pre-training (thanks to ReLU, batch norm, and better initialization), the insights about hierarchical representation learning and unsupervised feature extraction remain important.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.cs.toronto.edu/~larocheh/publications/icml-2008-denoising-autoencoders.pdf&quot;&gt;‚ÄúExtracting and Composing Robust Features with Denoising Autoencoders‚Äù (2008)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Pascal Vincent, Hugo Larochelle, Yoshua Bengio, Pierre-Antoine Manzagol&lt;br /&gt;
This paper introduced denoising autoencoders and provided theoretical justification for why they learn better representations than vanilla autoencoders. The key insight is that by corrupting inputs and training to reconstruct the clean originals, we force the network to learn the data manifold‚Äôs structure rather than merely memorizing examples. The corruption acts as regularization, preventing the network from learning the identity function even with large latent dimensions. The paper showed both theoretically and empirically that denoising autoencoders learn representations robust to input corruption, making features more useful for downstream tasks like classification. The denoising framework has influenced many subsequent methods‚Äîmasked language modeling in BERT can be viewed as denoising, and many self-supervised approaches corrupt inputs and train networks to predict or reconstruct the original. This paper established corruption-and-reconstruction as a powerful unsupervised learning paradigm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.iro.umontreal.ca/~lisa/pointeurs/ICML2011_explicit_invariance.pdf&quot;&gt;‚ÄúContractive Auto-Encoders: Explicit Invariance During Feature Extraction‚Äù (2011)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Salah Rifai, Pascal Vincent, Xavier Muller, Xavier Glorot, Yoshua Bengio&lt;br /&gt;
This paper proposed contractive autoencoders, which add a penalty on the Frobenius norm of the encoder‚Äôs Jacobian. The objective becomes:&lt;/p&gt;

\[\mathcal{L} = \|\mathbf{x} - \hat{\mathbf{x}}\|^2 + \lambda \|J_f(\mathbf{x})\|_F^2\]

&lt;p&gt;where \(J_f(\mathbf{x}) = \frac{\partial f(\mathbf{x})}{\partial \mathbf{x}}\) is the encoder‚Äôs Jacobian. This penalty encourages the encoder to be insensitive to small variations in input‚Äîthe latent representation should change slowly as we perturb the input slightly. The intuition is that meaningful features should be robust to small input changes (like slight translations or noise). The paper showed that contractive autoencoders learn representations with better invariance properties than vanilla or denoising autoencoders, though at computational cost of computing and regularizing the Jacobian. The work deepened theoretical understanding of what makes good representations and provided tools for encouraging specific desirable properties (invariance, sparsity, etc.) through regularization.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;‚ÄúAuto-Encoding Variational Bayes‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Diederik P. Kingma, Max Welling&lt;br /&gt;
While introducing VAEs (covered in next chapter), this paper fundamentally changed how we think about autoencoders by providing a probabilistic framework. The authors showed that autoencoders can be viewed as learning to maximize a lower bound on the data likelihood, connecting them to principled probabilistic modeling. The variational framework addresses standard autoencoders‚Äô limitation: the latent space might have holes where no training examples map, making sampling unreliable. VAEs regularize the latent space to follow a known distribution (typically standard Gaussian), ensuring we can sample anywhere and decode to realistic outputs. The paper‚Äôs reparameterization trick‚Äîsampling through a differentiable operation‚Äîenabled training via backpropagation. VAEs became enormously influential, spawning numerous variants and applications in generative modeling, semi-supervised learning, and representation learning. Understanding vanilla autoencoders is prerequisite to appreciating VAEs‚Äô probabilistic sophistication and the additional guarantees it provides.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1511.05644&quot;&gt;‚ÄúAdversarial Autoencoders‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alireza Makhzani, Jonathon Shlens, Navdeep Jaitly, Ian Goodfellow, Brendan Frey&lt;br /&gt;
This paper combined autoencoders with adversarial training, using a discriminator to enforce that the latent code distribution matches a prior (like standard Gaussian) rather than using a KL divergence penalty (as VAEs do). The adversarial training makes the latent space match the prior more closely than VAE‚Äôs KL penalty while maintaining autoencoder‚Äôs reconstruction objective. The paper demonstrated that this hybrid approach can generate high-quality samples while being more flexible than VAEs in choice of latent prior (not limited to factorized Gaussians). Adversarial autoencoders showed how ideas from different frameworks (autoencoders, VAEs, GANs) could be combined, leading to models with complementary strengths. The work exemplifies the productive cross-pollination of ideas in deep learning‚Äîtechniques developed for one purpose (adversarial training for GANs) proving useful when combined with other frameworks (autoencoders).&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most common failure mode in autoencoders is using too large a latent dimension, undermining the compression objective. With latent dimension approaching input dimension, the network can learn to pass information through nearly unchanged, discovering no meaningful structure. The symptom is perfect reconstructions but useless latent codes‚Äîthey‚Äôre overcomplete and redundant. The solution is to aggressively reduce latent dimension or add other constraints (sparsity, denoising, contractive penalty). A useful heuristic: start with latent dimension 10-20√ó smaller than input dimension, then experiment. For MNIST (784 dimensions), try 32-64 latent dimensions. For higher-resolution images, the compression factor can be larger.&lt;/p&gt;

&lt;p&gt;Forgetting to normalize inputs causes training instability and poor reconstructions. If pixel values span [0, 255], reconstruction errors are hundreds of times larger than for normalized [0,1] values, leading to huge gradients and exploding losses. Always normalize inputs to [0,1] (dividing by 255) or standardize to mean 0, std 1. Match the decoder‚Äôs output activation to the normalization scheme: sigmoid for [0,1], tanh for [-1,1], linear for standardized. This ensures the decoder can actually produce values in the correct range.&lt;/p&gt;

&lt;p&gt;Using MSE loss for images seems intuitive but has a subtle issue: MSE weights all pixels equally, but human perception doesn‚Äôt work this way. A single misaligned pixel can cause large MSE even if the reconstruction looks perfect to humans. Conversely, blurry reconstructions (averaging pixels) can have low MSE while looking poor perceptually. For applications where perceptual quality matters, consider perceptual losses‚Äîmeasure distance in feature space of a pre-trained network like VGG rather than pixel space. Features from deep layers capture high-level structure (shapes, objects) that correlate better with human perception than pixel-wise distances.&lt;/p&gt;

&lt;p&gt;A powerful trick for better latent spaces is adding explicit regularization beyond just dimensionality reduction. Sparse autoencoders add L1 penalty on latent activations, encouraging most dimensions to be zero most of the time. This forces specialization‚Äîeach latent dimension captures a specific aspect of variation. Variational autoencoders add KL divergence to a prior, ensuring smooth, continuous latent space. Contractive autoencoders penalize the encoder Jacobian, encouraging invariance to input perturbations. Understanding these regularization options allows tailoring autoencoders to specific desiderata‚Äîsparsity for interpretability, smoothness for interpolation, robustness for downstream tasks.&lt;/p&gt;

&lt;p&gt;When using autoencoders for pre-training (less common now but still useful in low-data regimes), a key decision is whether to fine-tune the encoder, decoder, or both. For classification, typically freeze the decoder (we only need encoder features) and add a classification head on the latent representation, fine-tuning only this head and optionally the encoder. For generation tasks, we might freeze the encoder (if we have good latent codes) and fine-tune only the decoder. For domain adaptation, fine-tuning both often works best. The choice depends on whether encoder features, decoder generation, or both need task-specific adaptation.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Autoencoders learn efficient data representations by training to reconstruct inputs through a lower-dimensional bottleneck, forcing compression of high-dimensional data into compact latent codes that capture essential structure. The encoder maps inputs to latent representations while the decoder reconstructs inputs from latent codes, with both trained jointly using reconstruction loss (MSE for continuous data, cross-entropy for binary). The bottleneck dimension controls the compression-fidelity tradeoff, with smaller latent dimensions forcing more aggressive compression and potentially more meaningful feature learning. Denoising autoencoders corrupt inputs before encoding but train to reconstruct clean originals, learning robust features that capture data structure rather than memorizing examples. The latent space in well-trained autoencoders has semantic structure, with nearby points corresponding to similar inputs and smooth interpolation enabling morphing between examples. Autoencoders serve multiple purposes: dimensionality reduction for visualization or downstream tasks, feature learning for transfer learning, denoising to remove corruption, and as foundations for more sophisticated generative models. Understanding autoencoders provides essential background for variational autoencoders and other generative approaches while demonstrating core principles of unsupervised representation learning that pervade modern self-supervised methods.&lt;/p&gt;

&lt;p&gt;The autoencoder framework exemplifies a recurring theme in machine learning: learning through reconstruction, where we force models to discover structure by requiring them to recreate data through constraints or transformations that make trivial solutions impossible.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>12 Autoencoders</title>
   <link href="http://localhost:4000/contents/en/chapter12/12_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter12/12_00_Introduction</id>
   <content type="html">&lt;p&gt;Autoencoders learn efficient data representations through unsupervised learning. They compress input data into a lower-dimensional latent space and reconstruct it. This chapter covers vanilla autoencoders, denoising autoencoders, sparse autoencoders, and applications in dimensionality reduction, denoising, and anomaly detection.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11-01 Generative Models - Core Concepts</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_01_Generative_Models_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter11/11_01_Generative_Models_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;generative-models-learning-to-create&quot;&gt;Generative Models: Learning to Create&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Generative models represent a fundamental shift in how we think about machine learning. While discriminative models learn to map inputs to outputs‚Äîclassifying images into categories, translating sentences between languages, or predicting stock prices from historical data‚Äîgenerative models learn to understand and reproduce the underlying structure of data itself. They ask a more ambitious question: given examples of some data distribution, can we learn to generate new, realistic samples from that distribution? This capability opens remarkable possibilities: creating photorealistic images of people who don‚Äôt exist, composing music in the style of Bach, designing molecules with desired properties, or augmenting limited datasets with synthetic examples.&lt;/p&gt;

&lt;p&gt;Understanding why generative modeling matters requires appreciating what‚Äôs fundamentally different about generation versus discrimination. A discriminative classifier for dog breeds learns features sufficient to distinguish breeds‚Äîthe shape of ears, coat patterns, size. It doesn‚Äôt need to understand how these features combine to form a coherent dog, or what makes a dog anatomically plausible versus impossible. A generative model must learn deeper structure: how pixels organize into textures, how textures form objects, how objects compose into scenes, and crucially, what combinations are realistic versus unrealistic. This deeper understanding means generative models often learn richer representations than discriminative models, making them valuable even when generation itself isn‚Äôt the end goal.&lt;/p&gt;

&lt;p&gt;The mathematical framework for generative models is rooted in probability theory and statistical modeling. We assume data \(\mathbf{x}\) comes from some unknown distribution \(p_{\text{data}}(\mathbf{x})\). Our goal is to learn a model distribution \(p_{\text{model}}(\mathbf{x}; \theta)\) parameterized by \(\theta\) (neural network weights) that approximates \(p_{\text{data}}\). If we succeed, sampling from \(p_{\text{model}}\) should produce data indistinguishable from samples from \(p_{\text{data}}\). This probabilistic framing connects generative models to maximum likelihood estimation, variational inference, and other foundational concepts in statistics, while the use of neural networks for the model provides unprecedented flexibility in the functional forms we can represent.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Different generative modeling approaches make different tradeoffs between sample quality, training stability, theoretical guarantees, and computational requirements. Autoregressive models like PixelCNN explicitly model $$p(\mathbf{x}) = \prod_i p(x_i&lt;/td&gt;
      &lt;td&gt;x_{&amp;lt;i})\(, decomposing generation into sequential conditional distributions. They provide exact likelihoods and stable training but generate slowly (one pixel at a time). Variational autoencoders introduce latent variables\)\mathbf{z}\(and model\)p(\mathbf{x}) = \int p(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})p(\mathbf{z})d\mathbf{z}\(, optimizing a tractable lower bound on likelihood. They enable fast sampling and provide a principled probabilistic framework but often generate somewhat blurry samples. Generative adversarial networks sidestep explicit density modeling entirely, using adversarial training to learn a generator that implicitly samples from\)p_{\text{data}}$$. They often produce the sharpest, most realistic samples but suffer from training instability and mode collapse.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The practical applications of generative models extend far beyond novelty. In computer vision, they enable data augmentation (generating additional training examples), super-resolution (upscaling low-resolution images), inpainting (filling missing regions), and style transfer (applying artistic styles to photographs). In natural language processing, they power text generation, machine translation through generative seq2seq models, and data augmentation for low-resource languages. In drug discovery, they generate molecular structures with desired properties. In creative applications, they assist artists and designers. In anomaly detection, they identify outliers by measuring how well they fit the learned distribution. Understanding generative models opens this vast application space while providing insights into data structure that benefit even purely discriminative tasks.&lt;/p&gt;

&lt;p&gt;Yet generative modeling is fundamentally harder than discriminative learning in several ways. The space of possible outputs is exponentially larger than the space of labels (\(2^{784}\) possible MNIST images vs 10 labels). The learned distribution must capture complex dependencies between output dimensions (pixels aren‚Äôt independent‚Äînearby pixels are correlated, object parts must be anatomically coherent). Evaluation is challenging‚Äîwe can‚Äôt simply compute accuracy as we can for classification. And generation requires understanding not just what separates classes but what makes examples realistic, a higher bar of understanding. These challenges make generative modeling an active research area where major innovations continue to emerge regularly.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical foundation of generative models rests on probability theory, likelihood estimation, and information theory. Let‚Äôs build these concepts systematically to understand what we‚Äôre optimizing when training generative models and why different approaches lead to different algorithms.&lt;/p&gt;

&lt;h3 id=&quot;probability-density-and-the-data-distribution&quot;&gt;Probability Density and the Data Distribution&lt;/h3&gt;

&lt;p&gt;We assume our training data \(\{\mathbf{x}^{(1)}, \ldots, \mathbf{x}^{(m)}\}\) consists of independent samples from some unknown distribution \(p_{\text{data}}(\mathbf{x})\). For images, \(\mathbf{x}\) might be \(28 \times 28 = 784\) dimensional (MNIST) or \(224 \times 224 \times 3 = 150,528\) dimensional (ImageNet). The distribution \(p_{\text{data}}\) assigns probability density to each possible \(\mathbf{x}\), with high density for realistic images (actual digits, photographs of objects) and low or zero density for unrealistic ones (random noise, anatomically impossible scenes).&lt;/p&gt;

&lt;p&gt;Our goal is to learn a parametric model \(p_{\text{model}}(\mathbf{x}; \theta)\) that approximates \(p_{\text{data}}\). The parameters \(\theta\) (neural network weights) should be set such that the model assigns high probability to training examples and, by generalization, to held-out examples from the same distribution. The standard approach is maximum likelihood estimation:&lt;/p&gt;

\[\theta^* = \arg\max_\theta \prod_{i=1}^{m} p_{\text{model}}(\mathbf{x}^{(i)}; \theta)\]

&lt;p&gt;Taking logarithms (for numerical stability and mathematical convenience):&lt;/p&gt;

\[\theta^* = \arg\max_\theta \sum_{i=1}^{m} \log p_{\text{model}}(\mathbf{x}^{(i)}; \theta) = \arg\max_\theta \frac{1}{m}\sum_{i=1}^{m} \log p_{\text{model}}(\mathbf{x}^{(i)}; \theta)\]

&lt;p&gt;The average log-likelihood \(\frac{1}{m}\sum_{i=1}^{m} \log p_{\text{model}}(\mathbf{x}^{(i)}; \theta)\) approximates the expected log-likelihood under the data distribution:&lt;/p&gt;

\[\mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log p_{\text{model}}(\mathbf{x}; \theta)]\]

&lt;p&gt;Maximizing this expectation is equivalent to minimizing the Kullback-Leibler divergence between data and model distributions:&lt;/p&gt;

\[KL(p_{\text{data}} \| p_{\text{model}}) = \mathbb{E}_{\mathbf{x} \sim p_{\text{data}}}[\log p_{\text{data}}(\mathbf{x}) - \log p_{\text{model}}(\mathbf{x}; \theta)]\]

&lt;p&gt;Since \(p_{\text{data}}\) is fixed, minimizing KL divergence is equivalent to maximizing expected log-likelihood. This connects maximum likelihood to information theory and provides a principled measure of how well our model approximates the true distribution.&lt;/p&gt;

&lt;h3 id=&quot;explicit-vs-implicit-density-models&quot;&gt;Explicit vs Implicit Density Models&lt;/h3&gt;

&lt;p&gt;The challenge in generative modeling is that for high-dimensional data, explicitly defining \(p_{\text{model}}(\mathbf{x}; \theta)\) that‚Äôs both flexible (can approximate complex distributions) and tractable (we can actually compute it and optimize it) is difficult.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Explicit density models&lt;/strong&gt; directly parameterize \(p_{\text{model}}(\mathbf{x}; \theta)\):&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Autoregressive models&lt;/em&gt; use the chain rule to factorize density:&lt;/p&gt;

\[p(\mathbf{x}) = p(x_1) p(x_2|x_1) p(x_3|x_1, x_2) \cdots p(x_d|x_1, \ldots, x_{d-1}) = \prod_{i=1}^{d} p(x_i|\mathbf{x}_{&amp;lt;i})\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Each conditional $$p(x_i&lt;/td&gt;
      &lt;td&gt;\mathbf{x}_{&amp;lt;i})\(is modeled with a neural network. This is exact‚Äîwe can compute\)p(\mathbf{x})\(for any\)\mathbf{x}$$‚Äîbut generation is slow (must generate dimensions sequentially) and the conditional independence assumptions might be restrictive.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;em&gt;Flow-based models&lt;/em&gt; use invertible transformations \(\mathbf{x} = f(\mathbf{z})\) where \(\mathbf{z} \sim p_{\mathbf{z}}\) is simple (Gaussian). The change of variables formula gives:&lt;/p&gt;

\[p_{\mathbf{x}}(\mathbf{x}) = p_{\mathbf{z}}(f^{-1}(\mathbf{x})) \left|\det \frac{\partial f^{-1}}{\partial \mathbf{x}}\right|\]

&lt;p&gt;This is exact and allows both density evaluation and fast sampling, but requires carefully designed architectures to ensure invertibility and tractable Jacobian determinants.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implicit density models&lt;/strong&gt; define a stochastic procedure for sampling without explicitly specifying \(p_{\text{model}}(\mathbf{x})\):&lt;/p&gt;

&lt;p&gt;&lt;em&gt;GANs&lt;/em&gt; learn a generator \(G: \mathcal{Z} \to \mathcal{X}\) such that if \(\mathbf{z} \sim p_{\mathbf{z}}\) then \(G(\mathbf{z})\) has distribution approximating \(p_{\text{data}}\). We never compute \(p_{\text{model}}\) but can sample efficiently. Training uses adversarial objective instead of likelihood.&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;em&gt;VAEs&lt;/em&gt; partially explicit: they model $$p(\mathbf{x}&lt;/td&gt;
      &lt;td&gt;\mathbf{z})\(explicitly but marginalize over latent\)\mathbf{z}$$ using variational approximation. They maximize a lower bound on log-likelihood (ELBO) instead of likelihood itself.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The choice between explicit and implicit, between different model families, depends on priorities: do we need exact likelihood (for anomaly detection, compression)? Do we need fast sampling (for real-time generation)? Do we prioritize sample quality over training stability? Understanding these tradeoffs guides model selection for specific applications.&lt;/p&gt;

&lt;h3 id=&quot;latent-variable-models&quot;&gt;Latent Variable Models&lt;/h3&gt;

&lt;p&gt;Many generative models introduce latent variables \(\mathbf{z}\) representing hidden factors of variation. The generative process becomes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Sample latent code: \(\mathbf{z} \sim p(\mathbf{z})\) (typically \(\mathcal{N}(0, I)\))&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Generate data: $$\mathbf{x} \sim p(\mathbf{x}&lt;/td&gt;
          &lt;td&gt;\mathbf{z}; \theta)$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The marginal distribution is:&lt;/p&gt;

\[p(\mathbf{x}; \theta) = \int p(\mathbf{x}|\mathbf{z}; \theta) p(\mathbf{z}) d\mathbf{z}\]

&lt;p&gt;This framework is powerful because latent variables can represent interpretable factors (for faces: pose, lighting, expression, identity) and low-dimensional latent spaces can capture high-dimensional data manifolds. The challenge is that computing the integral for exact likelihood requires integrating over all possible latent codes, which is intractable for continuous \(\mathbf{z}\). Different generative models address this differently:&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;VAEs use variational inference, introducing an encoder $$q(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x}; \phi)\(that approximates the posterior\)p(\mathbf{z}&lt;/td&gt;
      &lt;td&gt;\mathbf{x})$$ and optimizing the Evidence Lower BOund (ELBO):&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

\[\log p(\mathbf{x}; \theta) \geq \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z}|\mathbf{x}; \phi)}[\log p(\mathbf{x}|\mathbf{z}; \theta)] - KL(q(\mathbf{z}|\mathbf{x}; \phi) \| p(\mathbf{z}))\]

&lt;p&gt;This lower bound is tractable‚Äîwe can estimate it via sampling and optimize it via backpropagation through the reparameterization trick.&lt;/p&gt;

&lt;p&gt;GANs bypass the likelihood computation entirely, directly training the generator \(G(\mathbf{z}; \theta)\) to produce samples indistinguishable from data through adversarial training. We never compute \(p(\mathbf{x})\) but implicitly learn to sample from it.&lt;/p&gt;

&lt;h3 id=&quot;evaluation-metrics&quot;&gt;Evaluation Metrics&lt;/h3&gt;

&lt;p&gt;Evaluating generative models is challenging because we care about distribution matching, not just performance on specific examples. Several metrics have been proposed:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Log-likelihood&lt;/strong&gt; (when computable): Measures how well the model assigns probability to test data. Higher is better. However, high likelihood doesn‚Äôt guarantee good samples (a model memorizing training data has perfect likelihood on training set).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Inception Score&lt;/strong&gt; (IS): Generates samples, classifies them with Inception network, computes:&lt;/p&gt;

\[IS = \exp(\mathbb{E}_{\mathbf{x} \sim p_G}[KL(p(y|\mathbf{x}) \| p(y))])\]

&lt;p&gt;Measures both quality (samples should be confidently classified) and diversity (should cover all classes). Higher is better, but IS has issues (biased toward ImageNet classes, doesn‚Äôt detect memorization).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Fr√©chet Inception Distance&lt;/strong&gt; (FID): Compares statistics of real and generated samples in Inception feature space, treating them as Gaussians and computing:&lt;/p&gt;

\[FID = \|\mu_r - \mu_g\|^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})\]

&lt;p&gt;Lower FID indicates closer distributions. More reliable than IS but still imperfect (assumes Gaussian features).&lt;/p&gt;

&lt;p&gt;Understanding these metrics‚Äô limitations is as important as using them. They correlate with perceptual quality but aren‚Äôt perfect. Visual inspection remains crucial. For specific applications, domain-specific metrics (face identity preservation for face generation, molecular validity for drug design) often matter more than generic metrics.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build intuition for generative models, let‚Äôs think about learning to generate handwritten digits. Imagine you‚Äôve never seen the digit ‚Äú3‚Äù but have seen thousands of other digits. Could you invent a plausible ‚Äú3‚Äù? Probably not‚Äîyou lack understanding of what makes a valid digit, what ‚Äú3‚Äù specifically looks like, how strokes connect.&lt;/p&gt;

&lt;p&gt;Now suppose you see thousands of examples of each digit including ‚Äú3‚Äù. You could learn: ‚Äú3‚Äù has two rounded parts, typically connected, orientation upright, strokes smooth. With this understanding, you could generate novel ‚Äú3‚Äùs‚Äînot copies of training examples but new variations following the learned pattern. This is what generative models do, but discovered automatically from data rather than described verbally.&lt;/p&gt;

&lt;p&gt;Consider the different approaches to this task:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Autoregressive approach&lt;/strong&gt;: Generate the digit pixel by pixel, left-to-right, top-to-bottom. At each position, predict the pixel value conditioned on all previous pixels. This ensures each pixel is consistent with preceding ones (if the top already looks like ‚Äú3‚Äù, continue that pattern). The sequential generation provides strong guidance but is slow‚Äî784 sequential decisions for MNIST.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;VAE approach&lt;/strong&gt;: Learn a latent space where different regions correspond to different digits and variations. To generate a ‚Äú3‚Äù, sample a latent code from the ‚Äú3 region‚Äù (learned during training) and decode it through the decoder network. The latent space provides efficient generation (sample once, decode once) and enables interpolation (smoothly morph between digits). However, the reconstruction-based training might produce blurry samples because pixel-wise MSE doesn‚Äôt capture perceptual quality well.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GAN approach&lt;/strong&gt;: Train a generator to fool a discriminator that‚Äôs trying to detect fakes. The generator learns whatever mapping from noise to images makes the discriminator unable to detect fakes. This adversarial training doesn‚Äôt require explicit pixel-wise reconstruction, allowing the generator to prioritize perceptual realism over exact pixel matching. The result is often sharper, more realistic samples, though training can be unstable and mode collapse might occur (generator only learns to create certain types of ‚Äú3‚Äùs).&lt;/p&gt;

&lt;p&gt;Let‚Äôs trace through a concrete example with a simple toy dataset: 2D points forming two clusters (representing two modes of a distribution). The true distribution \(p_{\text{data}}\) is a mixture of two Gaussians:&lt;/p&gt;

\[p_{\text{data}}(\mathbf{x}) = 0.5 \mathcal{N}(\mathbf{x}; [2, 2], I) + 0.5 \mathcal{N}(\mathbf{x}; [-2, -2], I)\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;Autoregressive model&lt;/strong&gt;: Models $$p(x_2&lt;/td&gt;
      &lt;td&gt;x_1)p(x_1)\(. For the first mode centered at [2, 2], it learns\)p(x_1) \approx \mathcal{N}(2, 1)\(and\)p(x_2&lt;/td&gt;
      &lt;td&gt;x_1) \approx \mathcal{N}(2, 1)\((roughly independent since we&apos;re using Gaussians, but could learn correlations). Generation: sample\)x_1 \sim p(x_1)\(, then\)x_2 \sim p(x_2&lt;/td&gt;
      &lt;td&gt;x_1)$$.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;VAE&lt;/strong&gt;: Introduces latent \(z \in \mathbb{R}\). Learns that \(z &amp;lt; 0\) maps to mode at [-2, -2] and \(z &amp;gt; 0\) maps to mode at [2, 2]. To generate, sample \(z \sim \mathcal{N}(0, 1)\), decode to \(\mathbf{x}\). The latent space smoothly varies from one mode to another.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;GAN&lt;/strong&gt;: Generator learns to map 1D noise \(z\) to 2D points such that the discriminator (which sees both real samples from the two Gaussians and generated samples) cannot distinguish real from fake. The generator might learn a nonlinear function that maps \(z \in [-3, 0]\) to the first mode and \(z \in [0, 3]\) to the second mode.&lt;/p&gt;

&lt;p&gt;Each approach successfully generates from both modes if trained properly, but they differ in how they represent the distribution, training stability, and generation procedure. Understanding these differences through simple examples builds intuition for their behavior on complex data like images.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement different generative modeling approaches on a toy dataset to understand their mechanics:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate toy data: mixture of 8 Gaussians in a circle
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_mixture_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Generate 2D data from mixture of 8 Gaussians arranged in a circle.
    
    This toy dataset lets us visualize learned distributions and compare
    different generative modeling approaches. Each Gaussian represents a
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; - generative models should learn to generate from all modes.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;n_modes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;radius&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.02&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Angles for modes evenly spaced around circle
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;thetas&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_modes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;endpoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Centers of Gaussians
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;centers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;radius&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;radius&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;thetas&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Sample from mixture
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Choose mode uniformly
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;mode_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_modes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Sample from chosen Gaussian
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mode_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;centers&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate training data
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generative Models on Toy 2D Dataset&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_centers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_mixture_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; samples from 8 Gaussian modes&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Data shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (10000, 2)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Mode centers:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_centers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 1. Simple Autoregressive Model
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AutoregressiveModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Simple 2D autoregressive model: p(x) = p(x2|x1) * p(x1)
    
    Models p(x1) as mixture of logistics, p(x2|x1) as conditional mixture.
    Demonstrates explicit density modeling - we can compute p(x) exactly.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# p(x1): mixture of logistics
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_means&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Parameter&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# p(x2|x1): neural network outputting mixture parameters
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2_net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# logits, means, scales for mixture
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Compute log p(x) = log p(x1) + log p(x2|x1)
        
        This is what makes it an explicit density model - we can evaluate
        probability of any point, enabling maximum likelihood training.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# log p(x1): log mixture of logistics
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;logits_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (1, n_components)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;means_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_means&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scales_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Logistic log-prob for each component
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales_1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;log_probs_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scales_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Mixture log-prob using log-sum-exp
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;log_p_x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logsumexp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_probs_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; \
                   &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logsumexp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# log p(x2|x1): conditional mixture
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;x2_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;logits_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;means_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scales_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;z_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales_2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;log_probs_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;functional&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softplus&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scales_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;log_p_x2_given_x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logsumexp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_probs_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; \
                            &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;logsumexp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Total log-prob
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_p_x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_p_x2_given_x1&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Generate samples: first sample x1, then x2|x1
        
        Demonstrates sequential generation - characteristic of autoregressive.
        Exact sampling from learned distribution.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Sample x1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;probs_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;components&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;multinomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probs_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;replacement&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;means&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_means&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1_scales&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Logistic samples (approximately using Gaussian)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Sample x2|x1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;x2_net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Sample component for each x1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;logits_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;probs_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;components_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;multinomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probs_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;squeeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Get parameters for chosen components
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;means_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;components_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scales_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;components_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;means_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scales_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train autoregressive model
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Training Autoregressive Model (Explicit Density)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AutoregressiveModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_components&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;ar_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Shuffle data
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randperm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Mini-batch training
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute negative log-likelihood
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;log_probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Negative log-likelihood
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;ar_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;ar_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: NLL = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate samples
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;samples_ar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_ar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; samples&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sample mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_ar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Data mean:   &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# 2. Simple GAN for comparison
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Training GAN (Implicit Density)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Simple generator for 2D data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Output 2D points
&lt;/span&gt;        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyDiscriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Simple discriminator for 2D data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LeakyReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyGenerator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;latent_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;disc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ToyDiscriminator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gen_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;disc_optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0002&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;betas&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training GAN on mixture of Gaussians...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Train discriminator
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# k discriminator steps per generator step
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Real data
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;batch_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_d_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Fake data
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;labels_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_d_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;loss_d&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_d_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss_d_fake&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;disc_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Train generator
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;labels_real_for_g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss_g&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels_real_for_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;loss_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;gen_optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: D_loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;G_loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss_g&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;D(real) = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
              &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;D(fake) = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate samples
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;samples_gan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z_sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GAN generated &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_gan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; samples&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Checking mode coverage (samples should cluster around 8 centers)...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Check if GAN covers all modes (mode collapse detection)
# For each true center, count nearby generated samples
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;center&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_centers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_gan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;nearby&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;distances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Mode &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (center &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;center&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;): &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nearby&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; nearby samples&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_gan&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt; 
       &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_centers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úì GAN covers all modes successfully!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úó Mode collapse detected - some modes have few/no samples&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generative Modeling Comparison&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Autoregressive Model:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Exact likelihood computable&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Stable training&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Sequential generation (slow)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Strong ordering assumptions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GAN:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Fast parallel generation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Often high sample quality&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - No explicit likelihood&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Training can be unstable&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Mode collapse risk&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;VAE (next chapter):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Explicit latent space&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Stable training&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  + Fast generation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Samples sometimes blurry&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Demonstrate likelihood-based evaluation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Evaluating Generative Model Quality&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# For autoregressive model, we can compute exact likelihood
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Test set (held-out data from same distribution)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_mixture_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data_test_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute log-likelihood on test set
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_log_probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_test_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_test_ll&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Autoregressive Model Test Log-Likelihood: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_test_ll&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Higher is better - model assigns high probability to test data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Generate and evaluate (samples should have similar likelihood to real data)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;samples_ar_eval&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;samples_log_probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ar_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_ar_eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_sample_ll&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;samples_log_probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated Samples Log-Likelihood: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_sample_ll&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Should be similar to test LL if model is good&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_test_ll&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;avg_sample_ll&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úì Small difference (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;) indicates good model!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úó Large difference (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diff&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;) indicates issues&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# For GAN, we can&apos;t compute likelihood, so we use proxy metrics
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GAN Evaluation (without explicit likelihood):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Visual inspection (do samples look realistic?)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Mode coverage (do samples span all modes?)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Diversity (are samples varied or repetitive?)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Discriminator score (should be ~0.5 for good generator)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;disc_scores_real&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data_test_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;disc_scores_fake&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;disc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;samples_gan&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Discriminator scores:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Real data: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc_scores_real&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (should be ~1.0 if D is good)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Generated: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;disc_scores_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (should be ~0.5 at equilibrium)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_scores_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;and&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;disc_scores_fake&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;‚úì Generator successfully fools discriminator!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Generative models connect to density estimation, a classical problem in statistics where we try to estimate probability density functions from samples. Traditional methods like kernel density estimation or parametric fitting (Gaussian mixture models) work well in low dimensions but scale poorly to high dimensions due to the curse of dimensionality. Neural network-based generative models overcome this by learning hierarchical features that capture data structure rather than explicitly representing density in raw input space. A deep generative model effectively performs density estimation in a learned feature space where data structure is simpler, then maps back to input space. This perspective helps appreciate why deep generative models succeed where classical methods fail.&lt;/p&gt;

&lt;p&gt;The relationship to unsupervised and self-supervised learning is profound. Generative models learn representations without labels, discovering structure purely from data patterns. The features learned during generative modeling often transfer well to downstream supervised tasks‚Äîautoencoders provide good initializations, GAN discriminators learn useful features, VAE encoders create meaningful latent spaces. This connects to the broader theme that large-scale unsupervised pre-training (like BERT or GPT language modeling, which are generative tasks) followed by supervised fine-tuning often outperforms purely supervised learning, especially in limited-data regimes. Understanding generative models provides insight into why unsupervised learning works and what representations emerge from generative objectives.&lt;/p&gt;

&lt;p&gt;Generative models connect to data augmentation through their ability to generate synthetic training examples. For imbalanced datasets (many examples of common classes, few of rare classes), generative models can synthesize additional minority class examples. For expensive-to-label data (medical images requiring expert annotation), generated examples can augment limited labeled sets. However, care is required: if the generative model hasn‚Äôt learned the true distribution accurately, synthetic examples might introduce bias. Best practice is to validate that generated examples aid rather than hurt downstream task performance.&lt;/p&gt;

&lt;p&gt;The evolution of evaluation metrics for generative models reflects ongoing challenges in measuring quality and diversity. Early GANs used human evaluation (time-consuming, not reproducible) or binary classifier tests (can a classifier distinguish real from fake?). Inception Score and FID provided automated metrics but have known biases and failure modes. Recent work explores learned perceptual metrics (measuring distance in learned feature spaces), precision-recall tradeoffs (quantifying quality vs diversity separately), and likelihood-based methods (for models that provide likelihoods). Understanding that no single metric is perfect guides practitioners to use multiple complementary evaluations rather than optimizing for any single metric.&lt;/p&gt;

&lt;p&gt;Finally, generative models connect to the fundamental question of what neural networks learn. By training networks to generate complex data like images or text, we‚Äôre essentially asking: what patterns, structures, and regularities exist in this data, and can networks discover them automatically? The fact that neural networks can learn to generate photorealistic faces, coherent paragraphs, or valid molecular structures demonstrates they‚Äôre capturing deep statistical regularities, not just memorizing. This learning of latent structure has implications beyond generation‚Äîit suggests neural networks are discovering representations that reflect genuine structure in the world, not just fitting training data.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-06.pdf&quot;&gt;‚ÄúA tutorial on Energy-Based Learning‚Äù (2006)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Yann LeCun&lt;br /&gt;
While not specifically about modern generative models, this tutorial established the energy-based framework that underlies much generative modeling. LeCun showed how many learning problems can be formulated as learning energy functions that assign low energy to correct/realistic outputs and high energy to incorrect/unrealistic ones. Generative models fit this framework: they learn energy landscapes where data has low energy. The tutorial covered Boltzmann machines, contrastive divergence, and other techniques that influenced later work on deep generative models. Understanding energy-based models provides theoretical foundation for why certain training procedures (like contrastive divergence or score matching) work and connects generative modeling to statistical physics and probabilistic inference. While modern generative models often use different training procedures (backpropagation with reparameterization for VAEs, adversarial training for GANs), the energy-based perspective remains valuable for understanding what these models are fundamentally doing.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://proceedings.mlr.press/v15/larochelle11a.html&quot;&gt;‚ÄúNADE: The Neural Autoregressive Distribution Estimator‚Äù (2011)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Hugo Larochelle, Iain Murray&lt;br /&gt;
This paper introduced NADE, an efficient autoregressive model that tractably computes \(p(\mathbf{x}) = \prod_i p(x_i|\mathbf{x}_{&amp;lt;i})\) using neural networks for the conditionals. The key innovation was weight sharing: rather than training separate networks for each conditional, NADE uses a single neural network with shared parameters, making it efficient and preventing overfitting. The paper demonstrated that autoregressive models could compete with more complex approaches like restricted Boltzmann machines while providing exact likelihood computation and stable training. NADE influenced subsequent autoregressive models like PixelRNN/PixelCNN (for images) and WaveNet (for audio), establishing autoregressive modeling as a viable approach for complex, high-dimensional data. The work showed that explicit density modeling‚Äîdirectly parameterizing \(p(\mathbf{x})\)‚Äîwas practical for deep learning, not just classical statistics.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1312.6114&quot;&gt;‚ÄúAuto-Encoding Variational Bayes‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Diederik P. Kingma, Max Welling&lt;br /&gt;
This foundational paper introduced Variational Autoencoders, combining variational inference with neural networks to create a scalable framework for generative modeling with latent variables. The key contribution was the reparameterization trick: instead of sampling \(\mathbf{z} \sim q(\mathbf{z}|\mathbf{x})\) (which isn‚Äôt differentiable with respect to \(q\)‚Äôs parameters), rewrite sampling as \(\mathbf{z} = \mu + \sigma \odot \boldsymbol{\epsilon}\) where \(\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)\). This deterministic function of parameters (\(\mu, \sigma\)) and external randomness (\(\boldsymbol{\epsilon}\)) enables backpropagation through sampling, making variational inference trainable via gradient descent. The paper showed VAEs could learn meaningful latent representations and generate novel samples while providing a principled probabilistic framework (unlike GANs which were concurrent but more heuristic initially). VAEs influenced countless subsequent works and established that latent variable models could scale to complex data through careful algorithm design. The ELBO objective and reparameterization trick have become fundamental tools in probabilistic deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.2661&quot;&gt;‚ÄúGenerative Adversarial Networks‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ian Goodfellow et al.&lt;br /&gt;
The GAN paper revolutionized generative modeling by introducing adversarial training as an alternative to maximum likelihood. By framing generation as a game between generator and discriminator, GANs enabled learning implicit density models that generate high-quality samples without requiring explicit density computation or intractable integrals. The paper‚Äôs theoretical analysis‚Äîshowing that at Nash equilibrium, the generator recovers the data distribution‚Äîprovided foundation while empirical results demonstrated practical viability. GANs spawned enormous subsequent research addressing training stability, mode collapse, and architecture design, becoming one of the most influential ideas in modern machine learning. The adversarial framework has been applied beyond generation to domain adaptation, robust training, and semi-supervised learning, demonstrating how a novel training paradigm can impact the field broadly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1912.02762&quot;&gt;‚ÄúNormalizing Flows for Probabilistic Modeling and Inference‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: George Papamakarios, Eric Nalisnick, Danilo Jimenez Rezende, Shakir Mohamed, Balaji Lakshminarayanan&lt;br /&gt;
This comprehensive review unified normalizing flows‚Äîgenerative models based on invertible transformations‚Äîexplaining their theoretical foundations and practical implementations. Flows learn bijective mappings \(\mathbf{x} = f(\mathbf{z})\) where \(\mathbf{z}\) has simple density (Gaussian) and \(f\) is invertible with tractable Jacobian determinant. This enables exact likelihood computation (unlike GANs) and fast sampling (unlike autoregressive models). The paper covered the landscape of flow architectures (coupling flows, autoregressive flows, continuous flows), their theoretical properties, and applications. Flows are less commonly used than VAEs or GANs for image generation but excel in tasks requiring exact density (anomaly detection, compression) or specific structure (molecular generation where validity constraints matter). Understanding flows completes the generative modeling picture, showing the tradeoff space between likelihood tractability, sampling efficiency, and architectural flexibility.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most fundamental mistake in generative modeling is evaluating models solely on training set likelihood or reconstruction quality. A model that memorizes training examples achieves perfect training likelihood but generates no novel examples‚Äîit fails as a generative model despite optimizing the objective perfectly. Symptoms include generated samples being near-identical to training examples and poor test set likelihood. Detection requires checking nearest neighbors in training set for each generated sample (if always very close, likely memorization) and evaluating on held-out data. Prevention includes proper regularization (weight decay, dropout), using validation set for model selection, and architectures that encourage generalization (bottlenecks in autoencoders, discriminator in GANs forcing novelty).&lt;/p&gt;

&lt;p&gt;Choosing inappropriate reconstruction losses causes perceptual mismatches between what the model optimizes and what humans care about. Pixel-wise MSE treats all pixels equally, but human vision is non-uniform‚Äîwe‚Äôre more sensitive to structure and edges than to smooth regions. An MSE-optimal reconstruction might be blurry (averaging out details) while looking poor perceptually. Conversely, a reconstruction with slightly shifted edges (high MSE) might look perceptually similar. Solutions include perceptual losses (measuring distance in feature space of a pre-trained network like VGG), adversarial losses (using a discriminator to judge realism), or structured losses (measuring gradient similarity, not just pixel similarity). Understanding that loss functions embody assumptions about what‚Äôs important guides appropriate choices for specific applications.&lt;/p&gt;

&lt;p&gt;For latent variable models, choosing latent dimensionality involves subtle tradeoffs. Too small (2-3 dimensions) enables visualization but may not capture data complexity, causing poor reconstructions. Too large (approaching input dimension) enables perfect reconstruction but may not learn meaningful structure‚Äîthe model might use each latent dimension for one input dimension, learning identity mapping. The right size depends on data complexity and desired compression. A useful heuristic: start with 10-20√ó compression, adjust based on reconstruction quality and downstream task performance. For MNIST (784 dimensions), try 32-64 latent dimensions. For ImageNet (224√ó224√ó3), try 512-2048.&lt;/p&gt;

&lt;p&gt;When generating samples, the sampling temperature often significantly affects quality-diversity tradeoffs. For autoregressive models or VAEs where we sample from learned distributions, we can scale logits by temperature before softmax:&lt;/p&gt;

\[p(x_i | \mathbf{x}_{&amp;lt;i}) = \text{softmax}(\mathbf{z}_i / T)\]

&lt;p&gt;Low temperature (\(T &amp;lt; 1\)) makes the distribution sharper‚Äîmore confident, less diverse. High temperature (\(T &amp;gt; 1\)) makes it more uniform‚Äîmore diverse but potentially less realistic. Temperature provides a post-training knob for trading off quality and diversity without retraining. Understanding this tradeoff helps generate samples appropriate for different applications.&lt;/p&gt;

&lt;p&gt;A powerful technique for improving sample quality is rejection sampling: generate multiple samples, score them with a discriminator or classifier, keep only high-scoring ones. This filters generated samples for quality at the cost of efficiency (must generate more samples than needed). For applications where quality matters more than generation speed (creating artwork, designing molecules), rejection sampling provides an easy win. Understanding that we can post-process generated samples‚Äînot just use whatever the model produces‚Äîexpands the toolkit for practical applications.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Generative models learn to understand and reproduce data distributions, enabling creation of novel, realistic samples from learned patterns. The three main paradigms‚Äîautoregressive models providing explicit sequential density factorization, variational autoencoders using latent variables with variational inference, and generative adversarial networks training through adversarial competition‚Äîmake different tradeoffs between likelihood tractability, sampling efficiency, training stability, and sample quality. Maximum likelihood provides a principled training objective connecting to information theory through KL divergence, though it requires tractable density evaluation or lower bounds. Latent variable models introduce compressed representations capturing factors of variation, enabling fast sampling and interpretable manipulation, though requiring careful inference procedures. Evaluation of generative models is challenging, requiring multiple metrics (likelihood when available, Inception Score, FID, human evaluation) and domain-specific validation rather than single numbers. Applications span data augmentation, super-resolution, style transfer, drug discovery, and creative tools, with choice of approach depending on whether we need likelihood estimation, controlled generation, sample quality, or training stability. Understanding generative modeling deeply means appreciating both the statistical foundations (probability theory, density estimation, variational inference) and the deep learning implementations (neural architectures, training algorithms, practical tricks) that make learning complex distributions tractable.&lt;/p&gt;

&lt;p&gt;Generative models demonstrate that neural networks can discover and internalize the statistical structure underlying complex data, learning representations that enable not just recognition but creation‚Äîa capability that edges closer to what we might consider genuine understanding.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>11 Generative Models Introduction</title>
   <link href="http://localhost:4000/contents/en/chapter11/11_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter11/11_00_Introduction</id>
   <content type="html">&lt;p&gt;Generative models learn to create new data samples similar to training data. This chapter introduces the fundamentals of generative modeling, probability distributions, maximum likelihood estimation, and evaluation metrics. These concepts form the foundation for autoencoders, VAEs, and GANs.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>10-01 Advanced Optimization Algorithms</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_01_Advanced_Optimizers/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter10/10_01_Advanced_Optimizers</id>
   <content type="html">&lt;h1 id=&quot;advanced-optimization-beyond-vanilla-gradient-descent&quot;&gt;Advanced Optimization: Beyond Vanilla Gradient Descent&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;While gradient descent provides the fundamental principle for training neural networks‚Äîmove parameters in the direction that decreases loss‚Äîits vanilla form suffers from several critical limitations that make training deep networks impractical. The learning rate must be carefully tuned: too large causes oscillation or divergence, too small causes painfully slow convergence. The same learning rate is used for all parameters, despite different parameters having different gradient scales and optimal update frequencies. Gradient descent treats all directions in parameter space equally, even though some directions represent ravines (steep in one direction, gentle in another) where we should move carefully. And it has no memory of previous gradients, unable to build momentum to escape shallow local minima or saddle points.&lt;/p&gt;

&lt;p&gt;Advanced optimization algorithms address these limitations through various mechanisms: maintaining momentum to accelerate in consistent directions while dampening oscillations; adapting learning rates per parameter based on gradient history, allowing aggressive updates for sparse gradients and conservative updates for frequent large gradients; and incorporating second-order information about the curvature of the loss surface without the prohibitive cost of computing full Hessian matrices. These improvements aren‚Äôt minor tweaks but essential techniques that have enabled training increasingly large and complex models‚Äîmodern language models with billions of parameters simply couldn‚Äôt be trained with vanilla gradient descent.&lt;/p&gt;

&lt;p&gt;Understanding these optimizers deeply means recognizing that they‚Äôre not competing alternatives but tools suited for different scenarios. Stochastic Gradient Descent with momentum excels when the loss surface has clear, consistent gradient directions and is computationally efficient, making it popular for computer vision tasks with large batch sizes. RMSprop adapts learning rates based on recent gradient magnitudes, particularly useful for recurrent networks where gradient scales vary dramatically across time steps. Adam combines momentum and adaptive learning rates, providing good default performance across diverse tasks and becoming the de facto standard for many applications. AdamW improves Adam‚Äôs weight decay handling, crucial for training large Transformers. Each optimizer embodies different assumptions about the loss surface and gradient dynamics, and choosing appropriately can mean the difference between a model that trains in hours versus days, or that trains successfully versus not at all.&lt;/p&gt;

&lt;p&gt;The evolution of optimization algorithms parallels the evolution of neural architectures. As networks became deeper (requiring techniques to handle vanishing/exploding gradients), optimizers evolved to adapt learning rates and build momentum. As networks became larger (requiring training on smaller batches due to memory constraints), optimizers developed to work effectively with noisy gradient estimates. As tasks diversified (from vision to NLP to reinforcement learning), optimizers became more adaptive to different gradient landscapes. This co-evolution of architectures and optimizers is ongoing‚Äînew architectures often require optimizer innovations, and new optimizers enable new architectures.&lt;/p&gt;

&lt;p&gt;Yet with all these sophisticated algorithms, the fundamentals remain: we‚Äôre still computing gradients via backpropagation and taking steps opposite to these gradients. The advanced optimizers change how we determine step sizes and directions, leveraging gradient history and statistics, but the core principle‚Äîiterative refinement based on loss gradients‚Äîstays constant. This means that understanding vanilla gradient descent deeply provides the foundation for understanding all variants, which are best seen as sophisticated modifications addressing specific failure modes rather than entirely different approaches.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Let‚Äôs build up the mathematics of advanced optimizers systematically, understanding each component‚Äôs purpose and how they combine to improve upon vanilla gradient descent. We‚Äôll start with momentum and progress through increasingly sophisticated techniques.&lt;/p&gt;

&lt;h3 id=&quot;momentum-building-velocity&quot;&gt;Momentum: Building Velocity&lt;/h3&gt;

&lt;p&gt;Vanilla gradient descent updates parameters using only the current gradient:&lt;/p&gt;

\[\theta_t = \theta_{t-1} - \eta \nabla_\theta \mathcal{L}(\theta_{t-1})\]

&lt;p&gt;Momentum introduces a velocity term that accumulates gradients over time:&lt;/p&gt;

\[\mathbf{v}_t = \beta \mathbf{v}_{t-1} + \nabla_\theta \mathcal{L}(\theta_{t-1})\]

\[\theta_t = \theta_{t-1} - \eta \mathbf{v}_t\]

&lt;p&gt;where \(\beta \in [0, 1)\) is the momentum coefficient (typically 0.9). The velocity \(\mathbf{v}_t\) is an exponentially weighted moving average of gradients. Expanding the recursion reveals how past gradients influence current updates:&lt;/p&gt;

\[\mathbf{v}_t = \nabla_\theta \mathcal{L}(\theta_{t-1}) + \beta \nabla_\theta \mathcal{L}(\theta_{t-2}) + \beta^2 \nabla_\theta \mathcal{L}(\theta_{t-3}) + \ldots\]

&lt;p&gt;Recent gradients have full weight, while older gradients contribute with exponentially decaying weights \(\beta^k\). This creates several beneficial effects. First, if gradients consistently point in the same direction, the velocity builds up, accelerating progress‚Äîlike a ball rolling downhill gaining speed. Second, if gradients oscillate (positive then negative), the velocity dampens oscillations‚Äîopposing gradients partially cancel. Third, momentum can carry the optimization through shallow local minima or flat regions where current gradients are near zero but past gradients indicated a good direction.&lt;/p&gt;

&lt;p&gt;The geometric intuition is that momentum transforms the gradient from a force into a velocity. In physics, force (gradient) causes acceleration, leading to velocity changes. Here, the gradient directly contributes to velocity, which determines position updates. This physics analogy isn‚Äôt perfect but captures how momentum creates inertia‚Äîthe optimization continues moving in directions that were previously good even if the current gradient disagrees slightly.&lt;/p&gt;

&lt;h3 id=&quot;nesterov-accelerated-gradient-nag&quot;&gt;Nesterov Accelerated Gradient (NAG)&lt;/h3&gt;

&lt;p&gt;A clever modification of momentum computes gradients not at the current position but at the anticipated future position:&lt;/p&gt;

\[\mathbf{v}_t = \beta \mathbf{v}_{t-1} + \nabla_\theta \mathcal{L}(\theta_{t-1} - \beta \mathbf{v}_{t-1})\]

\[\theta_t = \theta_{t-1} - \eta \mathbf{v}_t\]

&lt;p&gt;The key difference is \(\nabla_\theta \mathcal{L}(\theta_{t-1} - \beta \mathbf{v}_{t-1})\) instead of \(\nabla_\theta \mathcal{L}(\theta_{t-1})\). We‚Äôre computing the gradient at where momentum would take us, then using that gradient to refine the update. This ‚Äúlook ahead‚Äù provides a form of correction: if momentum is carrying us toward a bad region, the gradient at the anticipated position will indicate this, allowing us to slow down or change direction.&lt;/p&gt;

&lt;p&gt;The improvement over standard momentum is subtle but consistent across many tasks. NAG typically converges faster and overshoots less at minima. The intuition is that standard momentum is reactive (respond to gradients at current position) while NAG is proactive (anticipate where we‚Äôre going and plan accordingly). In practice, the difference between momentum and NAG is often small, but NAG is theoretically better motivated and occasionally provides noticeable improvements.&lt;/p&gt;

&lt;h3 id=&quot;adagrad-adaptive-learning-rates&quot;&gt;AdaGrad: Adaptive Learning Rates&lt;/h3&gt;

&lt;p&gt;AdaGrad adapts learning rates per parameter based on accumulated squared gradients:&lt;/p&gt;

\[\mathbf{G}_t = \mathbf{G}_{t-1} + (\nabla_\theta \mathcal{L}(\theta_{t-1}))^2\]

\[\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\mathbf{G}_t + \epsilon}} \odot \nabla_\theta \mathcal{L}(\theta_{t-1})\]

&lt;p&gt;where the square and square root are element-wise, \(\mathbf{G}_t\) accumulates squared gradients, and \(\epsilon\) (typically \(10^{-8}\)) prevents division by zero. The division by \(\sqrt{\mathbf{G}_t}\) means parameters with large accumulated gradients receive smaller updates, while parameters with small accumulated gradients receive larger updates.&lt;/p&gt;

&lt;p&gt;This adaptive scaling addresses a key limitation of vanilla gradient descent. In sparse features (common in NLP where most words don‚Äôt appear in most documents), some parameters receive gradient updates rarely. AdaGrad gives these infrequent parameters larger updates when they do receive gradients, while frequently updated parameters (corresponding to common features) receive smaller updates. This is particularly valuable in tasks with sparse data or highly variable feature frequencies.&lt;/p&gt;

&lt;p&gt;However, AdaGrad has a fatal flaw for long training runs: \(\mathbf{G}_t\) only grows, never shrinks. As training progresses, \(\sqrt{\mathbf{G}_t}\) becomes very large, making effective learning rates approach zero, and learning stops. This aggressive learning rate decay is appropriate for convex optimization where we want to slow down as we approach the minimum, but neural network loss surfaces are non-convex with many local minima, plateaus, and saddle points. Stopping adaptation too early prevents escaping these suboptimal regions.&lt;/p&gt;

&lt;h3 id=&quot;rmsprop-exponential-moving-average&quot;&gt;RMSprop: Exponential Moving Average&lt;/h3&gt;

&lt;p&gt;RMSprop fixes AdaGrad‚Äôs aggressive decay by using an exponentially weighted moving average of squared gradients instead of accumulation:&lt;/p&gt;

\[\mathbf{E}[g^2]_t = \beta \mathbf{E}[g^2]_{t-1} + (1-\beta)(\nabla_\theta \mathcal{L}(\theta_{t-1}))^2\]

\[\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\mathbf{E}[g^2]_t + \epsilon}} \odot \nabla_\theta \mathcal{L}(\theta_{t-1})\]

&lt;p&gt;Typical \(\beta = 0.9\) means we consider roughly the last \(1/(1-\beta) = 10\) gradient updates. This allows the algorithm to forget old gradients, so if the gradient scale changes (as we move through different regions of the loss surface), the learning rate adaptation adjusts. RMSprop became particularly popular for training RNNs where gradient scales vary dramatically, and it remains a solid choice when gradient statistics change over training.&lt;/p&gt;

&lt;h3 id=&quot;adam-adaptive-moment-estimation&quot;&gt;Adam: Adaptive Moment Estimation&lt;/h3&gt;

&lt;p&gt;Adam combines momentum and RMSprop‚Äôs adaptive learning rates, maintaining both first moment (mean) and second moment (uncentered variance) estimates:&lt;/p&gt;

&lt;p&gt;\(\mathbf{m}_t = \beta_1 \mathbf{m}_{t-1} + (1-\beta_1) \nabla_\theta \mathcal{L}(\theta_{t-1})\) (momentum term)&lt;/p&gt;

&lt;p&gt;\(\mathbf{v}_t = \beta_2 \mathbf{v}_{t-1} + (1-\beta_2) (\nabla_\theta \mathcal{L}(\theta_{t-1}))^2\) (RMSprop term)&lt;/p&gt;

&lt;p&gt;These are biased toward zero initially (since \(\mathbf{m}_0 = \mathbf{v}_0 = 0\)). Adam corrects this bias:&lt;/p&gt;

\[\hat{\mathbf{m}}_t = \frac{\mathbf{m}_t}{1-\beta_1^t}, \quad \hat{\mathbf{v}}_t = \frac{\mathbf{v}_t}{1-\beta_2^t}\]

&lt;p&gt;The update rule combines both:&lt;/p&gt;

\[\theta_t = \theta_{t-1} - \frac{\eta}{\sqrt{\hat{\mathbf{v}}_t} + \epsilon} \odot \hat{\mathbf{m}}_t\]

&lt;p&gt;Default hyperparameters \(\beta_1 = 0.9, \beta_2 = 0.999, \epsilon = 10^{-8}\) work well across many tasks, making Adam popular as a ‚Äúlow-tuning‚Äù optimizer. The algorithm adapts to gradient statistics (through \(\mathbf{v}_t\)) while building momentum (through \(\mathbf{m}_t\)), combining benefits of both approaches.&lt;/p&gt;

&lt;p&gt;The bias correction deserves careful attention. Early in training, \(\mathbf{m}_t\) and \(\mathbf{v}_t\) are dominated by their initialization at zero, making them biased estimates of true moments. For example, \(\mathbf{m}_1 = (1-\beta_1)g_1\) significantly underestimates \(\mathbb{E}[g]\) when \(\beta_1 = 0.9\). Dividing by \(1-\beta_1^t\) corrects this: \(\hat{\mathbf{m}}_1 = \frac{(1-\beta_1)g_1}{1-\beta_1} = g_1\). As \(t \to \infty\), \(\beta_1^t \to 0\), so the correction factor approaches 1 and has no effect. This ensures good behavior from the first update while asymptotically behaving like uncorrected exponential averages.&lt;/p&gt;

&lt;h3 id=&quot;adamw-decoupled-weight-decay&quot;&gt;AdamW: Decoupled Weight Decay&lt;/h3&gt;

&lt;p&gt;A subtle issue with Adam is how it handles L2 regularization (weight decay). Standard practice adds \(\lambda \theta\) to gradients:&lt;/p&gt;

\[\nabla \mathcal{L}_{\text{reg}} = \nabla \mathcal{L} + \lambda \theta\]

&lt;p&gt;But in Adam, this regularized gradient gets processed through adaptive learning rates, which can dilute the regularization effect. AdamW decouples weight decay from gradient-based optimization:&lt;/p&gt;

\[\mathbf{m}_t = \beta_1 \mathbf{m}_{t-1} + (1-\beta_1) \nabla_\theta \mathcal{L}(\theta_{t-1})\]

\[\mathbf{v}_t = \beta_2 \mathbf{v}_{t-1} + (1-\beta_2) (\nabla_\theta \mathcal{L}(\theta_{t-1}))^2\]

\[\theta_t = \theta_{t-1} - \eta \left(\frac{\hat{\mathbf{m}}_t}{\sqrt{\hat{\mathbf{v}}_t} + \epsilon} + \lambda \theta_{t-1}\right)\]

&lt;p&gt;The weight decay term \(\lambda \theta_{t-1}\) is added after adaptive scaling, ensuring regularization strength is independent of gradient statistics. This seemingly minor change significantly improves generalization, particularly for Transformers and other large models where proper regularization is crucial.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To understand how different optimizers behave, imagine optimizing a function with a ravine: steep sides and a gentle slope along the bottom toward the minimum. Picture a 2D loss surface where one direction has high curvature (steep) and the perpendicular direction has low curvature (gentle). The minimum lies at the bottom of this ravine.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Vanilla Gradient Descent&lt;/strong&gt;: Steps perpendicular to contours of constant loss. In the ravine, gradients point mostly toward the ravine bottom (steep direction), barely along it (gentle direction). We take large steps toward the sides, bounce between them, and make slow progress along the ravine toward the minimum. It‚Äôs inefficient‚Äîmost gradient magnitude is in the wrong direction (perpendicular to the path to minimum) rather than the right direction (along the ravine).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SGD with Momentum&lt;/strong&gt;: Accumulates velocity along the ravine as consistent gradients in that direction build up momentum. When gradients oscillate perpendicular to the ravine (positive then negative as we bounce between sides), the velocity in that direction dampens. We accelerate along the ravine while oscillations perpendicular to it are suppressed. The ball rolling downhill analogy is apt‚Äîmomentum carries us through flat regions and helps escape shallow bowls.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;AdaGrad/RMSprop&lt;/strong&gt;: Notices that gradients in the steep direction are consistently large, while gradients in the gentle direction are small. It reduces learning rate in the steep direction (to prevent bouncing) and maintains it in the gentle direction (to make progress). This automatically does gradient rescaling based on the different curvatures, allowing larger effective steps along the ravine even with smaller steps perpendicular to it.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Adam&lt;/strong&gt;: Combines both mechanisms. Momentum accelerates along the ravine. Adaptive learning rates prevent excessive bouncing. The result is fast, stable progress toward the minimum. Adam also handles the fact that gradient statistics change as we move‚Äîearly in training, far from the minimum, gradients are large; near the minimum, they shrink. The adaptive scaling adjusts automatically.&lt;/p&gt;

&lt;p&gt;Consider a concrete scenario: training a neural network on a dataset with rare but important features. Vanilla SGD updates all parameters equally, so rare features get updated infrequently (only when examples containing them appear). AdaGrad/Adam give these parameters larger effective learning rates (because their \(\mathbf{v}_t\) is smaller, having accumulated fewer gradient updates), allowing them to learn quickly from the few examples they see. Common features, updated frequently, get smaller effective learning rates, preventing overreaction to individual examples. This adaptivity is why Adam often converges faster than SGD, particularly in NLP where vocabulary sparsity is extreme.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement optimizers from scratch to understand their mechanics:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SGDMomentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Stochastic Gradient Descent with Momentum.
    
    Maintains exponentially weighted average of gradients (velocity)
    and uses this for updates instead of raw gradients. Accelerates
    in consistent directions, dampens oscillations.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        params: list of parameter arrays to optimize
        lr: learning rate
        momentum: coefficient for velocity (Œ≤ in equations)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize velocities to zero
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each parameter gets its own velocity of same shape
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocities&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Update parameters using momentum.
        
        grads: list of gradients (same structure as params)
        
        The velocity update v_t = Œ≤*v_{t-1} + g_t creates exponential
        weighting: recent gradients contribute fully, older gradients
        contribute with weight Œ≤^k. Typical Œ≤=0.9 means we effectively
        average over ~10 recent gradients.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Update velocity: exponential moving average of gradients
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameter using velocity
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Note: some formulations use (1-Œ≤)*g instead of g
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# We follow PyTorch convention
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;velocities&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    RMSprop: Root Mean Square Propagation.
    
    Adapts learning rate per parameter based on exponential moving
    average of squared gradients. Parameters with consistently large
    gradients get smaller effective learning rate.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        beta: decay rate for gradient square average
        epsilon: small constant for numerical stability
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize squared gradient averages
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sq_grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Update using adaptive learning rates.
        
        The division by ‚àöE[g¬≤] means parameters with large typical gradients
        get smaller updates (to prevent instability), while parameters with
        small typical gradients get larger updates (to make progress).
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Update squared gradient moving average
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# E[g¬≤]_t = Œ≤*E[g¬≤]_{t-1} + (1-Œ≤)*g¬≤_t
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sq_grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sq_grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                               &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Adaptive learning rate: lr / ‚àöE[g¬≤]
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Adding epsilon prevents division by zero
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;adapted_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sq_grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameter
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;adapted_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Adam: Adaptive Moment Estimation.
    
    Combines momentum (first moment) and RMSprop (second moment).
    Includes bias correction for proper behavior early in training.
    The de facto standard optimizer for many deep learning tasks.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        beta1: decay rate for first moment (momentum)
        beta2: decay rate for second moment (RMSprop)
        
        Default values work well across many tasks - Adam&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s strength
        is robustness to hyperparameter choices.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize moments
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# First moment
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Second moment
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Time step (for bias correction)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Adam update with bias correction.
        
        The bias correction is crucial early in training when m_t and v_t
        are biased toward zero. Without correction, early updates are too
        small, slowing initial training. The correction factor 1/(1-Œ≤^t)
        grows as t increases, then approaches 1.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Increment timestep
&lt;/span&gt;        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Update biased first moment estimate (momentum)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update biased second moment estimate (RMSprop)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute bias-corrected moments
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# These corrections are largest early (when t is small)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# and approach 1 as t ‚Üí ‚àû
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;m_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;v_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameter
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Combines momentum direction (m_hat) with adaptive scaling (‚àöv_hat)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AdamW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    AdamW: Adam with decoupled weight decay.
    
    Separates L2 regularization from gradient-based optimization.
    Better generalization than Adam, especially for Transformers.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Adam update with decoupled weight decay.
        
        Key difference from Adam: weight decay is applied directly to
        parameters (Œ∏ ‚Üê Œ∏ - ŒªŒ∏) rather than being added to gradients.
        This ensures regularization strength is independent of adaptive
        learning rate scaling.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Update moments (same as Adam)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Bias correction
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;m_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;v_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update with decoupled weight decay
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Weight decay happens outside adaptive scaling
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m_hat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v_hat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;param&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate optimizer comparison on 2D optimization problem
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Comparing Optimizers on Rosenbrock Function&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Rosenbrock: f(x,y) = (1-x)¬≤ + 100(y-x¬≤)¬≤&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Minimum at (1, 1), but narrow curved valley makes optimization hard&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Classic optimization test function with narrow curved valley&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradient of Rosenbrock function&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;400&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize parameters (start far from minimum)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create optimizers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt_sgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]})()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SGDMomentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_rmsprop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;opt_adam&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.999&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Track trajectories
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trajectories&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Momentum&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()],&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Optimize for 500 steps
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;step&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Vanilla SGD
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;opt_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trajectories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Momentum
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trajectories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Momentum&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# RMSprop
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trajectories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Adam
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rosenbrock_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;opt_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;trajectories&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Compare final positions
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final positions after 500 steps:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  SGD:      (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_sgd&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Momentum: (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  RMSprop:  (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_rmsprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Adam:     (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  True min: (1.0000, 1.0000)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Observations:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Momentum accelerates along the valley&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- RMSprop adapts to different curvatures&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Adam combines benefits of both&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Vanilla SGD is slowest (gets stuck in oscillations)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now demonstrate on actual neural network training:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TensorDataset&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create simple classification task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Neural Network with Different Optimizers&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate synthetic data: XOR-like problem
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# XOR
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;FloatTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TensorDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simple network
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;net&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sequential&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train with different optimizers
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizers_to_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;SGD+Momentum&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; 
                                                   &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RMSprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;AdamW&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;AdamW&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                            &lt;span class=&quot;n&quot;&gt;weight_decay&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer_fn&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizers_to_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training with &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Create fresh model
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;optimizer_fn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Train
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Forward
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Backward
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataloader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;25&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Test accuracy
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;final_loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Compare results
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Optimizer Comparison Results&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Optimizer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;res&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;final_loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;12.4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;res&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10.2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Key observations:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Momentum accelerates convergence over vanilla SGD&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Adaptive methods (RMSprop, Adam) converge faster&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- AdamW often best generalization with weight decay&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Choice matters: 2-5x speed difference common&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Demonstrate learning rate scheduling:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CosineAnnealingSchedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Cosine annealing learning rate schedule.
    
    Gradually decreases learning rate following cosine curve.
    Often combined with warm restarts for improved performance.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        lr_max: maximum learning rate
        lr_min: minimum learning rate
        T_max: period of cosine cycle (iterations)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Get learning rate at iteration t&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; \
               &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CosineAnnealingSchedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_min&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T_max&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Learning Rate Scheduling&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lrs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Learning rate evolution (first 300 iterations):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Start: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  After 50 iters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  After 100 iters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (end of cycle, restarts)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  After 150 iters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lrs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;150&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Cosine annealing smoothly reduces LR, enabling fine-tuning near minima&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The relationship between optimization algorithms and the geometry of loss surfaces illuminates why different optimizers excel in different scenarios. Deep neural network loss surfaces are highly non-convex, featuring local minima, saddle points, and plateaus. Saddle points‚Äîwhere gradients are zero but we‚Äôre not at a minimum‚Äîare particularly common in high dimensions. Momentum helps escape saddle points by building velocity that carries through regions with zero gradient. Adaptive learning rates help when different directions have vastly different curvatures‚Äîcommon in neural networks where some parameters (like biases) receive consistently similar gradients while others (like weights) have highly variable gradient magnitudes.&lt;/p&gt;

&lt;p&gt;The connection to second-order optimization methods provides theoretical context. Newton‚Äôs method uses second derivatives (the Hessian matrix) to account for curvature, enabling faster convergence. However, computing and inverting the Hessian for networks with millions of parameters is computationally prohibitive‚Äî\(O(n^2)\) memory and \(O(n^3)\) computation. Adaptive learning rate methods like Adam approximate second-order information through gradient statistics (the second moment \(\mathbf{v}_t\) is related to diagonal Hessian entries) without the prohibitive cost. This approximate curvature information, while cruder than full Newton methods, provides enough benefit to significantly accelerate training while remaining computationally practical.&lt;/p&gt;

&lt;p&gt;Optimizers interact intimately with batch normalization and other normalization techniques. Batch normalization changes the loss surface geometry, making it smoother and reducing sensitivity to learning rates. This interaction can be subtle: some optimizers that work well without normalization may be less advantageous with it. Adam with batch normalization sometimes converges to worse minima than SGD with momentum, a phenomenon called ‚Äúgeneralization gap.‚Äù Understanding these interactions guides optimizer choice based on architecture‚ÄîTransformers (which use layer normalization) often work best with AdamW, while ResNets (with batch normalization) might prefer SGD with momentum for final performance.&lt;/p&gt;

&lt;p&gt;The evolution from hand-tuned learning rates to adaptive methods represents a broader trend in deep learning: automating hyperparameter choices. Early neural network training required extensive tuning of learning rates, schedules, and momentum coefficients. Modern adaptive optimizers reduce this burden‚ÄîAdam‚Äôs default hyperparameters work reasonably across diverse tasks. This democratization of deep learning made the field more accessible, though it also created a risk: using black-box optimizers without understanding their assumptions can lead to poor performance in edge cases. The best practitioners understand both the algorithms and when their assumptions break down.&lt;/p&gt;

&lt;p&gt;Learning rate schedules connect to the exploration-exploitation tradeoff in optimization. Early in training, we want to explore broadly, taking larger steps to find good regions of parameter space. Later, we want to exploit, taking smaller steps to fine-tune parameters near a minimum. Schedules like cosine annealing or step decay formalize this, reducing learning rate as training progresses. Warm-up schedules do the opposite initially‚Äîstart with very small learning rate and gradually increase‚Äîwhich helps when using very large batches or when parameters are randomly initialized and initial gradients might be misleading. The Transformer paper‚Äôs warm-up schedule \(\eta_t = d_{\text{model}}^{-0.5} \min(t^{-0.5}, t \cdot \text{warmup}^{-1.5})\) has become standard for training large models.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/sutskever13.html&quot;&gt;‚ÄúOn the importance of initialization and momentum in deep learning‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ilya Sutskever, James Martens, George Dahl, Geoffrey Hinton&lt;br /&gt;
This paper rigorously analyzed momentum‚Äôs benefits for deep learning, showing it‚Äôs not just a minor improvement but essential for training deep networks effectively. The authors demonstrated that momentum combined with proper initialization (they used specific schemes for different layer types) enables training much deeper networks than vanilla SGD. They showed momentum helps escape saddle points and reduces the impact of noisy gradients from mini-batch sampling. Importantly, they provided theoretical analysis of momentum‚Äôs dynamics, connecting it to classical optimization theory while demonstrating its specific advantages for non-convex neural network loss surfaces. The paper established Nesterov momentum as particularly effective, slightly but consistently outperforming standard momentum. This work influenced the field‚Äôs understanding that optimization algorithms must be tailored to deep learning‚Äôs unique challenges‚Äîhigh dimensionality, non-convexity, noisy gradients‚Äîrather than simply applying classical optimization methods.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.6980&quot;&gt;‚ÄúAdam: A Method for Stochastic Optimization‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Diederik P. Kingma, Jimmy Ba&lt;br /&gt;
This paper introduced Adam and demonstrated its effectiveness across diverse tasks including image classification, language modeling, and variational inference. The key contribution was combining adaptive learning rates (like RMSprop) with momentum, while including bias correction to ensure good behavior from the first update. Kingma and Ba showed that Adam requires minimal hyperparameter tuning‚Äîdefault values \(\beta_1=0.9, \beta_2=0.999\) work well across problems‚Äîmaking it accessible to practitioners who can‚Äôt afford extensive tuning. The paper‚Äôs empirical comparisons showed Adam consistently matching or exceeding other optimizers while being robust to learning rate choice. Adam became the default optimizer for many applications, particularly in NLP where its adaptation to gradient statistics helps with sparse vocabularies. The paper also introduced AdaMax (a variant using \(L_\infty\) norm instead of \(L_2\)) and provided regret bound analysis connecting Adam to online convex optimization theory, though these theoretical aspects are less commonly used than the practical algorithm.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1711.05101&quot;&gt;‚ÄúDecoupled Weight Decay Regularization‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ilya Loshchilov, Frank Hutter&lt;br /&gt;
This paper identified a subtle but important flaw in how Adam handles L2 regularization and proposed AdamW as the solution. The authors showed that adding weight decay to gradients (standard practice) and then applying adaptive learning rates (as Adam does) causes the effective weight decay to vary across parameters based on their gradient statistics. This coupling undermines regularization‚Äîparameters with large gradients receive less weight decay, opposite of what‚Äôs desirable. AdamW decouples weight decay from gradient-based updates, applying it directly to parameters after the adaptive update. The paper demonstrated improved generalization across multiple benchmarks, particularly for Transformers where proper regularization is crucial. AdamW has largely replaced Adam for training large language models and other Transformer-based systems. The work exemplifies how understanding the interaction between different training components (optimization + regularization) reveals subtle issues that significantly impact practical performance.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1908.03265&quot;&gt;‚ÄúOn the Variance of the Adaptive Learning Rate and Beyond‚Äù (2020)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Liyuan Liu, Haoming Jiang, Pengcheng He, Weizhu Chen, Xiaodong Liu, Jianfeng Gao, Jiawei Han&lt;br /&gt;
This paper analyzed why Adam sometimes generalizes worse than SGD despite converging faster, a phenomenon called the ‚Äúgeneralization gap.‚Äù The authors showed that Adam‚Äôs adaptive learning rates can lead to sharp minima (low training loss but poor generalization) while SGD with momentum tends to find flatter minima (better generalization). They proposed RAdam (Rectified Adam), which modifies the bias correction to be more conservative early in training when gradient statistics are unreliable. The paper deepened understanding of the optimization-generalization tradeoff: faster convergence doesn‚Äôt always mean better final performance. It showed that variance in adaptive learning rates can be harmful and proposed variance reduction techniques. This work has influenced how practitioners use Adam‚Äîrecognizing when its adaptive mechanism helps (sparse gradients, varying scales) versus when simpler methods with better generalization properties (SGD+momentum) are preferable.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1907.08610&quot;&gt;‚ÄúLookahead Optimizer: k steps forward, 1 step back‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Michael R. Zhang, James Lucas, Geoffrey Hinton, Jimmy Ba&lt;br /&gt;
This paper introduced a meta-optimization algorithm that wraps around any base optimizer (SGD, Adam, etc.). Lookahead maintains two sets of weights: fast weights updated by the base optimizer and slow weights that periodically synchronize with fast weights. The algorithm runs the base optimizer for \(k\) steps (typically 5-10), then updates slow weights toward the fast weights, then resets fast weights to the slow weights. This reduces variance in optimization trajectory and improves convergence. The paper showed that Lookahead improves performance of base optimizers consistently across tasks, providing more stable training and often better generalization. While less commonly used than Adam or SGD+momentum, Lookahead demonstrates that optimization algorithms can be composed‚Äîwe can build meta-algorithms that enhance existing optimizers. The paper‚Äôs empirical analysis across vision and language tasks established that optimizer design remains an active research area with room for innovation beyond the classics.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most common mistake when using adaptive optimizers like Adam is forgetting to adjust hyperparameters when changing batch size. With vanilla SGD, doubling batch size roughly requires doubling learning rate to maintain equivalent parameter updates (since gradients are averaged over batch). But for Adam, the relationship is more complex because adaptive learning rates already account for gradient magnitudes. A practical rule: when increasing batch size, increase learning rate proportionally but less aggressively (perhaps by \(\sqrt{2}\) instead of \(2\)), and monitor validation performance carefully. Very large batch sizes (thousands) may require learning rate warm-up to prevent early instability.&lt;/p&gt;

&lt;p&gt;A subtle issue is optimizer state accumulation when fine-tuning pre-trained models. If you load a pre-trained model and continue training with Adam, the momentum and variance estimates start from zero, not from values appropriate for a nearly-converged model. This can cause instability or prevent fine-tuning from improving the model. The solution: either use a lower learning rate for fine-tuning (allowing gradients to build up optimizer state safely) or reset the optimizer state when loading checkpoints, starting fresh. Understanding that optimizers maintain internal state beyond just parameters helps debug unexpected fine-tuning behavior.&lt;/p&gt;

&lt;p&gt;Weight decay in AdamW requires calibration differently than in SGD. For SGD, weight decay around 0.0001-0.001 is typical. For AdamW, values around 0.01-0.1 often work better because the decoupling changes its effective strength. When migrating from Adam to AdamW, don‚Äôt just enable weight decay with values tuned for SGD‚Äîyou‚Äôll likely over-regularize. Start with 0.01 and tune based on train-test gap. This illustrates a broader principle: hyperparameters are not architecture-agnostic but must be tuned within the context of the full training configuration.&lt;/p&gt;

&lt;p&gt;Gradient clipping interacts with optimizers in non-obvious ways. For Adam, clipping gradients before the optimizer sees them affects both momentum and variance estimates. If gradients are clipped to norm 5, the maximum second moment becomes 25, bounding the adaptive scaling. This can be beneficial (prevents extremely small effective learning rates) or harmful (prevents adaptation to true gradient scales). For stability, clip gradients for RNNs and Transformers. For maximum Adam adaptivity on well-behaved networks, skip clipping. Understanding this tradeoff helps choose appropriate configurations.&lt;/p&gt;

&lt;p&gt;A powerful technique for hyperparameter tuning is cyclical learning rates‚Äîvarying learning rate between bounds during training. This allows the model to periodically escape local minima it might settle into, potentially finding better solutions. Combined with snapshot ensembling (saving models at different points in the cycle and ensembling their predictions), this can improve performance beyond single-model training with fixed learning rates. The computational cost is minimal (just scheduling) while benefits can be substantial, making it an underutilized trick in the practitioner‚Äôs toolkit.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Advanced optimization algorithms improve upon vanilla gradient descent by incorporating momentum to accelerate in consistent directions and dampen oscillations, and by adapting learning rates per parameter based on gradient history. SGD with momentum builds velocity from exponentially weighted gradient averages, helping traverse ravines and escape plateaus. RMSprop adapts learning rates using exponential averages of squared gradients, automatically scaling updates based on typical gradient magnitudes per parameter. Adam combines both mechanisms while including bias correction for proper early-iteration behavior, becoming the de facto standard for many applications due to robust performance with minimal tuning. AdamW improves Adam by decoupling weight decay from gradient-based updates, ensuring regularization strength is independent of adaptive scaling, crucial for training large Transformers. The choice of optimizer involves tradeoffs between convergence speed, final performance, computational cost, and hyperparameter sensitivity, with no single optimizer dominating all scenarios. Understanding each optimizer‚Äôs assumptions‚Äîwhat loss surface geometry it handles well, what gradient statistics it expects‚Äîenables matching algorithms to problems effectively. Modern practice often uses Adam or AdamW for initial experimentation due to robustness, potentially switching to SGD with momentum for final training if better generalization is needed. The sophistication of these algorithms shouldn‚Äôt obscure the fundamental principle: they‚Äôre all using gradients computed via backpropagation to iteratively improve parameters, differing only in how they process gradients into parameter updates.&lt;/p&gt;

&lt;p&gt;The evolution of optimization algorithms from vanilla gradient descent to modern adaptive methods represents the field learning to automate aspects of training that previously required expert tuning, democratizing deep learning while also introducing new subtleties that practitioners must understand to train models effectively.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>10 Deep Learning Algorithms</title>
   <link href="http://localhost:4000/contents/en/chapter10/10_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter10/10_00_Introduction</id>
   <content type="html">&lt;p&gt;Advanced deep-learning algorithms improve training speed and convergence. This chapter covers momentum, RMSprop, Adam, AdamW, and learning rate schedules. Understanding these optimizers is essential for efficiently training deep neural networks and achieving state-of-the-art results.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>09-02 Batch Normalization</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_02_Batch_Normalization/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter09/09_02_Batch_Normalization</id>
   <content type="html">&lt;h2 id=&quot;what-is-batch-normalization&quot;&gt;What is Batch Normalization?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Batch Normalization&lt;/strong&gt; (BatchNorm or BN), introduced by Ioffe and Szegedy (2015), normalizes the inputs of each layer to have zero mean and unit variance. It has become one of the most important techniques in modern deep learning.&lt;/p&gt;

&lt;h3 id=&quot;the-problem-internal-covariate-shift&quot;&gt;The Problem: Internal Covariate Shift&lt;/h3&gt;

&lt;p&gt;As network trains:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Distribution of layer inputs changes&lt;/li&gt;
  &lt;li&gt;Each layer must adapt to new input distribution&lt;/li&gt;
  &lt;li&gt;Slows down training significantly&lt;/li&gt;
  &lt;li&gt;Makes networks sensitive to initialization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Batch Norm solution&lt;/strong&gt;: Normalize layer inputs to stable distribution.&lt;/p&gt;

&lt;h2 id=&quot;how-batch-normalization-works&quot;&gt;How Batch Normalization Works&lt;/h2&gt;

&lt;h3 id=&quot;forward-pass-training&quot;&gt;Forward Pass (Training)&lt;/h3&gt;

&lt;p&gt;For a mini-batch of activations \(\mathbf{x} = \{x_1, x_2, \ldots, x_m\}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Compute batch statistics&lt;/strong&gt;&lt;/p&gt;

\[\mu_{\mathcal{B}} = \frac{1}{m} \sum_{i=1}^{m} x_i\]

\[\sigma^2_{\mathcal{B}} = \frac{1}{m} \sum_{i=1}^{m} (x_i - \mu_{\mathcal{B}})^2\]

&lt;p&gt;&lt;strong&gt;Step 2: Normalize&lt;/strong&gt;&lt;/p&gt;

\[\hat{x}_i = \frac{x_i - \mu_{\mathcal{B}}}{\sqrt{\sigma^2_{\mathcal{B}} + \epsilon}}\]

&lt;p&gt;where \(\epsilon\) (e.g., \(10^{-5}\)) prevents division by zero.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Scale and shift (learnable parameters)&lt;/strong&gt;&lt;/p&gt;

\[y_i = \gamma \hat{x}_i + \beta\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\gamma\): scale parameter (learned)&lt;/li&gt;
  &lt;li&gt;\(\beta\): shift parameter (learned)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;inference-testing&quot;&gt;Inference (Testing)&lt;/h3&gt;

&lt;p&gt;Use population statistics (moving averages from training):&lt;/p&gt;

\[\hat{x} = \frac{x - \mu_{\text{pop}}}{\sqrt{\sigma^2_{\text{pop}} + \epsilon}}\]

\[y = \gamma \hat{x} + \beta\]

&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm1D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        num_features: number of features/channels
        eps: small constant for numerical stability
        momentum: for running mean/var updates
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Learnable parameters
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Running statistics (for inference)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Cache for backprop
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: input of shape (batch_size, num_features)
        training: whether in training mode
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Compute batch statistics
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;batch_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Normalize
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Scale and shift
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update running statistics
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                               &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_mean&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                              &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_var&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Cache for backward pass
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Use running statistics
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; \
                          &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Backpropagate through batch normalization
        dout: gradient from next layer
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;D&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradients of parameters
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dgamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_normalized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dbeta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradient of normalized x
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dx_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradient of variance
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; \
                     &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradient of mean
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dmean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dx_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                &lt;span class=&quot;n&quot;&gt;dvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradient of x
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx_normalized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
             &lt;span class=&quot;n&quot;&gt;dvar&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
             &lt;span class=&quot;n&quot;&gt;dmean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dx&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm1D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;out_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Train output mean: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Train output std: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Testing
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;out_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Test uses running statistics&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;why-batch-normalization-works&quot;&gt;Why Batch Normalization Works&lt;/h2&gt;

&lt;h3 id=&quot;1-reduces-internal-covariate-shift&quot;&gt;1. Reduces Internal Covariate Shift&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Stabilizes distribution of layer inputs&lt;/li&gt;
  &lt;li&gt;Each layer sees more consistent inputs&lt;/li&gt;
  &lt;li&gt;Easier to learn&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-allows-higher-learning-rates&quot;&gt;2. Allows Higher Learning Rates&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;More stable gradient flow&lt;/li&gt;
  &lt;li&gt;Can train 10-100x faster&lt;/li&gt;
  &lt;li&gt;Less sensitive to initialization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-acts-as-regularization&quot;&gt;3. Acts as Regularization&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Adds noise to activations (from batch statistics)&lt;/li&gt;
  &lt;li&gt;Similar effect to dropout&lt;/li&gt;
  &lt;li&gt;Can reduce need for dropout&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-smooths-optimization-landscape&quot;&gt;4. Smooths Optimization Landscape&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Makes loss surface smoother&lt;/li&gt;
  &lt;li&gt;Gradients more predictable&lt;/li&gt;
  &lt;li&gt;Easier optimization&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;where-to-place-batch-norm&quot;&gt;Where to Place Batch Norm&lt;/h2&gt;

&lt;h3 id=&quot;before-or-after-activation&quot;&gt;Before or After Activation?&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Original paper (before activation)&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Modern practice (after activation)&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Both work, but ‚Äúafter‚Äù is more common now.&lt;/p&gt;

&lt;h3 id=&quot;complete-network-example&quot;&gt;Complete Network Example&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvNetWithBatchNorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Convolution + BatchNorm + Activation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Conv2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm1D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Block 1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bn1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Block 2
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bn2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Block 3
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bn3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Fully connected
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bn4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;batch-normalization-for-cnns&quot;&gt;Batch Normalization for CNNs&lt;/h2&gt;

&lt;p&gt;For convolutional layers, normalize across spatial dimensions:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BatchNorm2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Parameters: one per channel
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Running statistics
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: shape (batch, channels, height, width)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Compute mean and var across batch and spatial dims
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Keep channel dimension
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Normalize
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Scale and shift
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update running stats
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                               &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; \
                              &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; \
                    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;running_var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;variants-and-alternatives&quot;&gt;Variants and Alternatives&lt;/h2&gt;

&lt;h3 id=&quot;1-layer-normalization&quot;&gt;1. Layer Normalization&lt;/h3&gt;

&lt;p&gt;Normalize across features instead of batch:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;layer_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    x: shape (batch, features)
    Normalize each sample independently
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: RNNs, Transformers (where batch size varies or is 1)&lt;/p&gt;

&lt;h3 id=&quot;2-instance-normalization&quot;&gt;2. Instance Normalization&lt;/h3&gt;

&lt;p&gt;Normalize each sample and each channel independently:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;instance_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    x: shape (batch, channels, height, width)
    Normalize each instance and channel
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: Style transfer, GANs&lt;/p&gt;

&lt;h3 id=&quot;3-group-normalization&quot;&gt;3. Group Normalization&lt;/h3&gt;

&lt;p&gt;Compromise between Layer and Instance norm:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;group_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_groups&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    x: shape (batch, channels, height, width)
    Split channels into groups and normalize
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_groups&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;N&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gamma&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;beta&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: Small batch sizes, object detection&lt;/p&gt;

&lt;h2 id=&quot;common-issues-and-solutions&quot;&gt;Common Issues and Solutions&lt;/h2&gt;

&lt;h3 id=&quot;issue-1-small-batch-sizes&quot;&gt;Issue 1: Small Batch Sizes&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Unreliable batch statistics with small batches&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use Group Normalization or Layer Normalization&lt;/li&gt;
  &lt;li&gt;Increase batch size if possible&lt;/li&gt;
  &lt;li&gt;Use larger momentum for running statistics&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;issue-2-train-test-discrepancy&quot;&gt;Issue 2: Train-Test Discrepancy&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Different behavior between training and testing&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Always remember to set training mode correctly&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Training
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# or training=True
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Testing
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# or training=False
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;evaluate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;issue-3-batch-norm--dropout&quot;&gt;Issue 3: Batch Norm + Dropout&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Can interact poorly&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Usually don‚Äôt need dropout with batch norm&lt;/li&gt;
  &lt;li&gt;If using both: dropout after batch norm&lt;/li&gt;
  &lt;li&gt;Or use only one of them&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-tips&quot;&gt;Practical Tips&lt;/h2&gt;

&lt;h3 id=&quot;1-initialization-with-batch-norm&quot;&gt;1. Initialization with Batch Norm&lt;/h3&gt;

&lt;p&gt;Can use larger initial weights:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Without BatchNorm: careful initialization
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# With BatchNorm: can be more aggressive
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.05&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Larger variance OK
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-learning-rates&quot;&gt;2. Learning Rates&lt;/h3&gt;

&lt;p&gt;Can use much higher learning rates:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Without BatchNorm
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# With BatchNorm
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 10x higher!
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-momentum-for-running-stats&quot;&gt;3. Momentum for Running Stats&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Fast adaptation (small datasets)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Stable statistics (large datasets)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Default
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Very stable (production)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;momentum&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;batch-norm-in-modern-architectures&quot;&gt;Batch Norm in Modern Architectures&lt;/h2&gt;

&lt;h3 id=&quot;resnet&quot;&gt;ResNet&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;resnet_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;identity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Conv -&amp;gt; BN -&amp;gt; ReLU
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Conv -&amp;gt; BN
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Add skip connection before final ReLU
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;mobilenet&quot;&gt;MobileNet&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;depthwise_separable_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Depthwise conv
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;depthwise_conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Pointwise conv
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv_1x1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Batch Normalization&lt;/strong&gt; normalizes layer inputs to stable distribution&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Reduces internal covariate shift&lt;/strong&gt;, enables faster training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Allows higher learning rates&lt;/strong&gt; (10-100x speedup)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Acts as regularization&lt;/strong&gt;, reduces need for dropout&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Variants&lt;/strong&gt;: Layer Norm (RNNs), Instance Norm (style transfer), Group Norm (small batches)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modern practice&lt;/strong&gt;: Essential in almost all deep networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key&lt;/strong&gt;: Remember training vs. inference modes!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Batch Normalization revolutionized deep learning by making networks much easier to train. It‚Äôs now a standard component in almost every modern architecture.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;: We‚Äôll explore L1/L2 regularization, early stopping, and data augmentation to complete our regularization toolkit!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>09-01 Dropout Regularization</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_01_Dropout/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter09/09_01_Dropout</id>
   <content type="html">&lt;h1 id=&quot;dropout-preventing-overfitting-through-random-deactivation&quot;&gt;Dropout: Preventing Overfitting Through Random Deactivation&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/0/04/Dropout_Neural_Net_Model.svg/800px-Dropout_Neural_Net_Model.svg.png&quot; alt=&quot;Dropout Visualization&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça k·ªπ thu·∫≠t Dropout trong m·∫°ng neural. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Dropout&lt;/strong&gt; is a powerful regularization technique that randomly ‚Äúdrops out‚Äù (sets to zero) a fraction of neurons during training. This simple yet effective method prevents overfitting and has become one of the most widely used regularization techniques in deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why Dropout matters&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Prevents co-adaptation&lt;/strong&gt;: Forces neurons to learn independently&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ensemble effect&lt;/strong&gt;: Like training many sub-networks simultaneously&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Simple to implement&lt;/strong&gt;: Just a few lines of code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effective&lt;/strong&gt;: Significantly improves generalization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: By randomly removing neurons during training, we prevent the network from relying too heavily on any single neuron, forcing it to learn robust, distributed representations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analogy&lt;/strong&gt;: Like a team where members randomly don‚Äôt show up to practice. Each member must learn to perform well independently rather than relying on specific teammates, making the team more robust overall.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;dropout-during-training&quot;&gt;Dropout During Training&lt;/h3&gt;

&lt;p&gt;For layer with activation \(\mathbf{a}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Generate binary mask&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{m}_i \sim \text{Bernoulli}(1-p)\]

&lt;p&gt;where \(p\) is dropout rate (probability of dropping).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: Apply mask and scale&lt;/strong&gt; (inverted dropout):&lt;/p&gt;

\[\mathbf{a}_{\text{dropout}} = \frac{\mathbf{m} \odot \mathbf{a}}{1-p}\]

&lt;p&gt;where \(\odot\) is element-wise multiplication.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why scale by \(\frac{1}{1-p}\)?&lt;/strong&gt; To maintain expected value:&lt;/p&gt;

\[\mathbb{E}[\mathbf{a}_{\text{dropout}}] = \mathbb{E}\left[\frac{\mathbf{m} \odot \mathbf{a}}{1-p}\right] = \mathbf{a}\]

&lt;h3 id=&quot;dropout-during-inference&quot;&gt;Dropout During Inference&lt;/h3&gt;

&lt;p&gt;At test time, use all neurons:&lt;/p&gt;

\[\mathbf{a}_{\text{test}} = \mathbf{a}\]

&lt;p&gt;No dropping, no scaling needed (due to scaling during training).&lt;/p&gt;

&lt;h3 id=&quot;mathematical-interpretation&quot;&gt;Mathematical Interpretation&lt;/h3&gt;

&lt;p&gt;Dropout approximates training an ensemble of \(2^n\) different networks (where \(n\) is number of neurons):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each training step uses a different sub-network&lt;/li&gt;
  &lt;li&gt;Final network approximates averaging all sub-networks&lt;/li&gt;
  &lt;li&gt;Ensemble learning without training multiple models!&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;expected-behavior&quot;&gt;Expected Behavior&lt;/h3&gt;

&lt;p&gt;For dropout rate \(p\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Fraction of zeros during training: \(p\)&lt;/li&gt;
  &lt;li&gt;Remaining activations scaled by: \(\frac{1}{1-p}\)&lt;/li&gt;
  &lt;li&gt;Expected output: Same as without dropout&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;h3 id=&quot;concrete-example&quot;&gt;Concrete Example&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Network&lt;/strong&gt;: Hidden layer with 4 neurons&lt;br /&gt;
&lt;strong&gt;Dropout rate&lt;/strong&gt;: \(p = 0.5\) (50%)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Training iteration 1&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Activations: \([2.0, 3.5, 1.2, 4.1]\)&lt;/li&gt;
  &lt;li&gt;Random mask: \([0, 1, 1, 0]\)&lt;/li&gt;
  &lt;li&gt;After dropout: \([0, 7.0, 2.4, 0]\) (scaled by 2)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Training iteration 2&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Activations: \([2.0, 3.5, 1.2, 4.1]\)&lt;/li&gt;
  &lt;li&gt;Random mask: \([1, 0, 1, 1]\)&lt;/li&gt;
  &lt;li&gt;After dropout: \([4.0, 0, 2.4, 8.2]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Testing&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Activations: \([2.0, 3.5, 1.2, 4.1]\)&lt;/li&gt;
  &lt;li&gt;No mask: \([2.0, 3.5, 1.2, 4.1]\) (all neurons active)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;visual-intuition&quot;&gt;Visual Intuition&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Training (dropout=0.5):
    Input ‚Üí [X  ‚úì  ‚úì  X] ‚Üí Output
            ‚Üì  ‚Üì  ‚Üì  ‚Üì
         (dropped) (scaled)

Testing (no dropout):
    Input ‚Üí [‚úì  ‚úì  ‚úì  ‚úì] ‚Üí Output
            ‚Üì  ‚Üì  ‚Üì  ‚Üì
           (all active)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;why-it-works-preventing-co-adaptation&quot;&gt;Why It Works: Preventing Co-Adaptation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Without dropout&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Neuron A becomes expert at ‚Äúeyes‚Äù&lt;/li&gt;
  &lt;li&gt;Neuron B always relies on Neuron A&lt;/li&gt;
  &lt;li&gt;If A makes mistake, B fails too&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;With dropout&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Sometimes A is dropped&lt;/li&gt;
  &lt;li&gt;B must learn to work without A&lt;/li&gt;
  &lt;li&gt;Both learn robust, independent features&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;h3 id=&quot;pytorch-implementation&quot;&gt;PyTorch Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLPWithDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;MLPWithDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Layer 1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Dropout after activation
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Layer 2
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer (no dropout)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MLPWithDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Enable dropout
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch of 32
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (32, 10)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Testing
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Disable dropout
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Test output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (10, 10)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Check dropout effect
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Same input
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training (with dropout) - outputs vary:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;outputs_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Same input
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;outputs_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Testing (no dropout) - outputs identical:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;manual-dropout-implementation&quot;&gt;Manual Dropout Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DropoutManual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        X: (batch, features)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Generate mask: 1 with prob (1-p), 0 with prob p
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;binomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Apply mask and scale
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradient only flows through kept neurons&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keep_prob&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DropoutManual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dropped units: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Testing  
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dropped units at test: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;spatial-dropout-for-cnns&quot;&gt;Spatial Dropout for CNNs&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpatialDropout2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, channels, height, width)
        Drop entire feature maps
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;training&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Mask shape: (batch, channels, 1, 1)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Same mask for all spatial positions in a channel
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bernoulli&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
                              &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;spatial_dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SpatialDropout2D&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch=2, 64 channels, 32√ó32
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;spatial_dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Entire channels dropped: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Also provides regularization&lt;/li&gt;
  &lt;li&gt;Often reduces need for dropout&lt;/li&gt;
  &lt;li&gt;Modern architectures: BN instead of dropout in many cases&lt;/li&gt;
  &lt;li&gt;If using both: dropout after batch norm&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;data-augmentation&quot;&gt;Data Augmentation&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Another form of regularization&lt;/li&gt;
  &lt;li&gt;Adds noise/variation to training data&lt;/li&gt;
  &lt;li&gt;Complementary to dropout&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;early-stopping&quot;&gt;Early Stopping&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Stop training when validation loss increases&lt;/li&gt;
  &lt;li&gt;Prevents overfitting&lt;/li&gt;
  &lt;li&gt;Used together with dropout&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;ensemble-methods&quot;&gt;Ensemble Methods&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Train multiple independent models&lt;/li&gt;
  &lt;li&gt;Average predictions&lt;/li&gt;
  &lt;li&gt;Dropout approximates this with single model&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;dropconnect&quot;&gt;DropConnect&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Drop connections instead of neurons&lt;/li&gt;
  &lt;li&gt;Similar effect, different implementation&lt;/li&gt;
  &lt;li&gt;Less commonly used&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://jmlr.org/papers/v15/srivastava14a.html&quot;&gt;‚ÄúDropout: A Simple Way to Prevent Neural Networks from Overfitting‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov&lt;br /&gt;
&lt;strong&gt;THE foundational dropout paper&lt;/strong&gt;. Introduced dropout and provided theoretical analysis showing it prevents co-adaptation of neurons. Demonstrated dramatic improvements on multiple benchmarks including MNIST, CIFAR, and ImageNet. Became standard regularization technique in deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1207.0580&quot;&gt;‚ÄúImproving neural networks by preventing co-adaptation of feature detectors‚Äù (2012)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Geoffrey E. Hinton, Nitish Srivastava, Alex Krizhevsky, et al.&lt;br /&gt;
Early dropout paper introducing the concept. Explained how dropout creates an ensemble of exponentially many thinned networks that share parameters. Showed empirical improvements and provided intuition for why random deactivation helps.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://proceedings.mlr.press/v28/wan13.html&quot;&gt;‚ÄúRegularization of Neural Networks using DropConnect‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Li Wan, Matthew Zeiler, Sixin Zhang, Yann LeCun, Rob Fergus&lt;br /&gt;
Introduced DropConnect - dropping connections instead of neurons. Showed this variant can sometimes outperform dropout. Generalized the concept of random dropping beyond individual units.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1411.4280&quot;&gt;‚ÄúSpatial Dropout‚Äù (2015) - part of ‚ÄúEfficient Object Localization Using CNNs‚Äù&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jonathan Tompson, Ross Goroshin, Arjun Jain, Yann LeCun, Christoph Bregler&lt;br /&gt;
Introduced spatial dropout for convolutional layers - dropping entire feature maps instead of individual activations. Showed this is more effective for CNNs where nearby pixels are correlated.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.05287&quot;&gt;‚ÄúA Theoretically Grounded Application of Dropout in RNNs‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Yarin Gal, Zoubin Ghahramani&lt;br /&gt;
Analyzed dropout in RNNs and introduced variational dropout - using same mask across time steps. Provided theoretical foundation connecting dropout to Bayesian inference, showing dropout approximates uncertainty estimation.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-1-forgetting-to-disable-during-testing&quot;&gt;‚ö†Ô∏è Pitfall 1: Forgetting to Disable During Testing&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Dropout still active at test time ‚Üí inconsistent predictions&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: Always set model.eval()&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Wrong
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Dropout still active if model in train mode!
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Correct
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-2-too-high-dropout-rate&quot;&gt;‚ö†Ô∏è Pitfall 2: Too High Dropout Rate&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Network loses too much capacity&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: Start with 0.5, reduce if performance drops&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Too aggressive - may hurt performance
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Dropping 90%!
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Better starting points
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# Fully connected
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Convolutional
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# Input layer
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-3-using-with-batch-normalization&quot;&gt;‚ö†Ô∏è Pitfall 3: Using with Batch Normalization&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Both provide regularization, can interact poorly&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: Usually choose one or the other&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Modern practice: Use BN, skip dropout
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# No dropout needed!
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# If using both: dropout after BN
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# After activation
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-1-different-rates-for-different-layers&quot;&gt;‚úÖ Trick 1: Different Rates for Different Layers&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SmartDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Conservative
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Standard
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout_deep&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Lower for deep layers
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-2-monte-carlo-dropout-uncertainty-estimation&quot;&gt;‚úÖ Trick 2: Monte Carlo Dropout (Uncertainty Estimation)&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mc_dropout_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Multiple stochastic forward passes for uncertainty
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Keep dropout ON
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mean_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;uncertainty&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;uncertainty&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Get prediction with uncertainty
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mc_dropout_predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Prediction: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Uncertainty: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-3-scheduled-dropout&quot;&gt;‚úÖ Trick 3: Scheduled Dropout&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScheduledDropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradually increase dropout during training&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;final_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;final_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_epochs&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;progress&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;progress&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Dropout&lt;/strong&gt; randomly deactivates neurons during training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rate&lt;/strong&gt;: 0.5 for FC layers, 0.1-0.3 for conv, 0.2 for input&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scaling&lt;/strong&gt;: Multiply by \(\frac{1}{1-p}\) during training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inference&lt;/strong&gt;: Use all neurons, no dropout&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Effect&lt;/strong&gt;: Ensemble learning, prevents co-adaptation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modern use&lt;/strong&gt;: Less common with batch normalization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key&lt;/strong&gt;: Remember train vs eval modes!&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Dropout remains one of the simplest yet most effective regularization techniques in deep learning!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;: Batch Normalization - another powerful technique that revolutionized training!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>09 Regularization Techniques</title>
   <link href="http://localhost:4000/contents/en/chapter09/09_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter09/09_00_Introduction</id>
   <content type="html">&lt;p&gt;Regularization prevents overfitting by constraining model complexity. This chapter covers essential techniques: L1/L2 regularization, dropout, batch normalization, data augmentation, and early stopping. These methods are crucial for building models that generalize well to unseen data.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>08-01 The Transformer Architecture</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_01_Transformer_Architecture/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter08/08_01_Transformer_Architecture</id>
   <content type="html">&lt;h1 id=&quot;the-transformer-revolutionizing-sequence-processing&quot;&gt;The Transformer: Revolutionizing Sequence Processing&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://machinelearningmastery.com/wp-content/uploads/2021/08/attention_research_1.png&quot; alt=&quot;Transformer Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c Transformer t·ª´ paper ‚ÄúAttention Is All You Need‚Äù. Ngu·ªìn: Google Research&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;The Transformer represents one of the most significant architectural innovations in the history of deep learning. When Vaswani and colleagues at Google introduced it in their 2017 paper ‚ÄúAttention Is All You Need,‚Äù they made a bold claim that seemed almost heretical: recurrent layers, which had been the foundation of sequence modeling for decades, were unnecessary. Instead, they proposed an architecture built entirely on attention mechanisms, enabling parallel processing of sequences and fundamentally changing how we approach natural language processing, and increasingly, many other domains.&lt;/p&gt;

&lt;p&gt;To understand why the Transformer was revolutionary, we must first appreciate the limitations it overcame. Recurrent Neural Networks, including their sophisticated variants LSTMs and GRUs, process sequences one element at a time, maintaining a hidden state that theoretically encodes all previous context. This sequential processing is inherently slow‚Äîwe cannot process timestep \(t\) until we‚Äôve processed timestep \(t-1\), preventing parallelization across the sequence length. Moreover, information from early in the sequence must pass through many recurrent steps to influence predictions about later elements, and with each step, gradients can vanish or the information can degrade. While LSTMs mitigated this through gating mechanisms, they didn‚Äôt eliminate the fundamental sequential bottleneck.&lt;/p&gt;

&lt;p&gt;The Transformer‚Äôs key insight is that we can replace sequential processing with attention mechanisms that directly compute relationships between all positions in a sequence simultaneously. Instead of information flowing through hidden states across time, every position can directly attend to every other position in a single operation. This enables full parallelization across sequence length‚Äîwe can process all positions simultaneously using matrix operations that GPUs excel at. The model can learn arbitrary dependencies without the constraint that information must flow sequentially through hidden states.&lt;/p&gt;

&lt;p&gt;Beyond computational efficiency, the Transformer‚Äôs attention mechanisms provide something qualitatively different from RNNs: explicit, interpretable relationships between sequence elements. When translating ‚ÄúThe animal didn‚Äôt cross the street because it was too tired,‚Äù the model can directly compute that ‚Äúit‚Äù strongly attends to ‚Äúanimal‚Äù (not ‚Äústreet‚Äù), making the representation more interpretable and debuggable. These attention weights, which we can visualize, show what the model is ‚Äúfocusing on,‚Äù providing insight impossible with RNN hidden states.&lt;/p&gt;

&lt;p&gt;The impact of Transformers extends far beyond their original application to machine translation. They‚Äôve become the foundation of modern NLP through models like BERT (which uses Transformer encoders for understanding) and GPT (which uses Transformer decoders for generation). The architecture has proven remarkably versatile, succeeding not just in NLP but in computer vision (Vision Transformers), speech processing, protein folding (AlphaFold), and even multimodal tasks combining vision and language (CLIP, GPT-4). This versatility suggests the Transformer captures something fundamental about how to process structured data, not just sequences.&lt;/p&gt;

&lt;p&gt;Understanding Transformers deeply requires grasping several interconnected ideas: how self-attention computes relationships between all positions, why we need multiple attention heads, how positional encodings inject sequence order into an otherwise position-agnostic model, and how the encoder-decoder architecture enables sequence-to-sequence tasks. Each component serves a specific purpose, and their combination creates an architecture that‚Äôs both powerful and elegant.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical elegance of the Transformer lies in how it decomposes sequence processing into simple, parallelizable operations. Let‚Äôs build up the mathematics systematically, starting with the core attention mechanism and then showing how complete Transformer layers are constructed.&lt;/p&gt;

&lt;h3 id=&quot;self-attention-the-core-mechanism&quot;&gt;Self-Attention: The Core Mechanism&lt;/h3&gt;

&lt;p&gt;Given an input sequence \(\mathbf{X} = [\mathbf{x}_1, \mathbf{x}_2, \ldots, \mathbf{x}_n]\) where each \(\mathbf{x}_i \in \mathbb{R}^{d_{model}}\), self-attention computes a new representation where each position incorporates information from all other positions. The mechanism uses three learned projections of the input:&lt;/p&gt;

&lt;p&gt;\(\mathbf{Q} = \mathbf{X}\mathbf{W}^Q \in \mathbb{R}^{n \times d_k}\) (Queries: ‚Äúwhat am I looking for?‚Äù)&lt;/p&gt;

&lt;p&gt;\(\mathbf{K} = \mathbf{X}\mathbf{W}^K \in \mathbb{R}^{n \times d_k}\) (Keys: ‚Äúwhat do I offer?‚Äù)&lt;/p&gt;

&lt;p&gt;\(\mathbf{V} = \mathbf{X}\mathbf{W}^V \in \mathbb{R}^{n \times d_v}\) (Values: ‚Äúwhat is my actual content?‚Äù)&lt;/p&gt;

&lt;p&gt;The intuition behind this query-key-value paradigm comes from information retrieval. When searching a database, you have a query (what you‚Äôre looking for), items have keys (metadata describing them), and when you find matches, you retrieve values (the actual content). Self-attention works similarly: each position‚Äôs query determines what to look for, is compared against all positions‚Äô keys to find relevant matches, and then retrieves a weighted combination of their values.&lt;/p&gt;

&lt;p&gt;The attention computation itself is remarkably simple:&lt;/p&gt;

\[\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right) \mathbf{V}\]

&lt;p&gt;Let‚Äôs parse this step by step. The matrix product \(\mathbf{Q}\mathbf{K}^T\) produces an \(n \times n\) matrix of attention scores, where entry \((i,j)\) is the dot product between query \(i\) and key \(j\), measuring their similarity. High dot product means the query and key align well‚Äîthis position should attend strongly to that position.&lt;/p&gt;

&lt;p&gt;The scaling by \(\sqrt{d_k}\) prevents the dot products from growing too large as dimensionality increases. Without this scaling, when \(d_k\) is large, dot products can become very large in magnitude, pushing the softmax into regions where gradients vanish (the softmax saturates). The specific choice of \(\sqrt{d_k}\) comes from assuming query and key components are independent random variables with variance 1‚Äîthen the dot product has variance \(d_k\), so dividing by \(\sqrt{d_k}\) normalizes back to unit variance. This scaling is crucial for stable training.&lt;/p&gt;

&lt;p&gt;The softmax operation converts these scores into a probability distribution over positions for each query position. For position \(i\), the softmax over scores determines how much to attend to each other position, with weights summing to 1. This normalization is essential‚Äîit creates a weighted average rather than a weighted sum, making the output scale independent of sequence length.&lt;/p&gt;

&lt;p&gt;Finally, multiplying by \(\mathbf{V}\) computes the weighted average of values. Each output position is a weighted combination of all input values, where weights are determined by query-key similarities. This is where information actually flows between positions‚Äîthe attention weights determine which positions‚Äô information contributes to each output.&lt;/p&gt;

&lt;h3 id=&quot;multi-head-attention-multiple-perspectives&quot;&gt;Multi-Head Attention: Multiple Perspectives&lt;/h3&gt;

&lt;p&gt;A single attention mechanism can learn one type of relationship, but language (and many other domains) involves multiple types of relationships simultaneously. Multi-head attention addresses this by running multiple attention operations in parallel, each with different learned projection matrices:&lt;/p&gt;

\[\text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) \mathbf{W}^O\]

&lt;p&gt;where each head is:&lt;/p&gt;

\[\text{head}_i = \text{Attention}(\mathbf{Q}\mathbf{W}_i^Q, \mathbf{K}\mathbf{W}_i^K, \mathbf{V}\mathbf{W}_i^V)\]

&lt;p&gt;The typical configuration uses \(h=8\) heads with \(d_k = d_v = d_{model}/h = 64\) when \(d_{model}=512\). This design choice means the total computational cost of multi-head attention equals that of single-head attention with full dimensionality, but we get the representational advantage of multiple attention patterns.&lt;/p&gt;

&lt;p&gt;Different heads learn to capture different types of relationships. In machine translation, one head might focus on syntactic dependencies (subject-verb agreement), another on semantic relationships (coreference resolution), and another on positional biases (nearby words often relate). The model learns these specializations automatically through training‚Äîwe don‚Äôt specify what each head should do, we merely provide the capacity for specialization.&lt;/p&gt;

&lt;p&gt;The final linear projection \(\mathbf{W}^O\) integrates information from all heads. This projection is crucial‚Äîwithout it, we‚Äôd just have \(h\) independent attention mechanisms. The projection allows heads to collaborate, combining their different perspectives into a unified representation.&lt;/p&gt;

&lt;h3 id=&quot;positional-encoding-injecting-sequence-order&quot;&gt;Positional Encoding: Injecting Sequence Order&lt;/h3&gt;

&lt;p&gt;A fundamental property of attention is that it‚Äôs permutation-invariant: if we shuffle the input sequence, the attention outputs (before considering position) shuffle identically. This is because attention only looks at content similarity (dot products), not position. For language, where word order crucially affects meaning (‚Äúdog bites man‚Äù vs ‚Äúman bites dog‚Äù), this is a problem.&lt;/p&gt;

&lt;p&gt;The solution is to add positional information to the input embeddings. The original Transformer uses sinusoidal positional encodings:&lt;/p&gt;

\[PE_{(pos, 2i)} = \sin\left(\frac{pos}{10000^{2i/d_{model}}}\right)\]

\[PE_{(pos, 2i+1)} = \cos\left(\frac{pos}{10000^{2i/d_{model}}}\right)\]

&lt;p&gt;where \(pos\) is the position index and \(i\) is the dimension index. This might seem arbitrary, but it has elegant properties. Different dimensions use different frequencies, from wavelengths of \(2\pi\) to \(10000 \cdot 2\pi\). This creates a unique ‚Äúfingerprint‚Äù for each position. Moreover, the encoding is deterministic and works for sequences longer than those seen during training (unlike learned positional embeddings which have a maximum length).&lt;/p&gt;

&lt;p&gt;The trigonometric functions also enable the model to learn relative positions. For any fixed offset \(k\), \(PE_{pos+k}\) can be expressed as a linear function of \(PE_{pos}\). This means the model can learn to attend based on relative distances (‚Äúattend to the word 3 positions before‚Äù) rather than just absolute positions, making it more flexible.&lt;/p&gt;

&lt;h3 id=&quot;the-complete-transformer-layer&quot;&gt;The Complete Transformer Layer&lt;/h3&gt;

&lt;p&gt;A Transformer encoder layer combines self-attention with a position-wise feed-forward network, both wrapped in residual connections and layer normalization:&lt;/p&gt;

\[\mathbf{X}&apos; = \text{LayerNorm}(\mathbf{X} + \text{MultiHeadAttention}(\mathbf{X}, \mathbf{X}, \mathbf{X}))\]

\[\mathbf{X}&apos;&apos; = \text{LayerNorm}(\mathbf{X}&apos; + \text{FFN}(\mathbf{X}&apos;))\]

&lt;p&gt;The FFN is applied identically to each position:&lt;/p&gt;

\[\text{FFN}(x) = \max(0, x\mathbf{W}_1 + \mathbf{b}_1)\mathbf{W}_2 + \mathbf{b}_2\]

&lt;p&gt;Typically \(\mathbf{W}_1 \in \mathbb{R}^{d_{model} \times d_{ff}}\) with \(d_{ff} = 4 \times d_{model} = 2048\) (for \(d_{model}=512\)). This expansion and contraction pattern allows the network to compute complex functions of the attention output.&lt;/p&gt;

&lt;p&gt;The residual connections (adding input to output) and layer normalization are critical for training deep Transformers. Residual connections provide gradient highways‚Äîgradients can flow directly through the addition operation without passing through attention or FFN, mitigating vanishing gradients. Layer normalization stabilizes training by normalizing activations to have zero mean and unit variance within each sample, making the network less sensitive to parameter scale.&lt;/p&gt;

&lt;p&gt;The decoder architecture adds an additional cross-attention layer that attends to the encoder‚Äôs output:&lt;/p&gt;

\[\mathbf{X}&apos; = \text{LayerNorm}(\mathbf{X} + \text{MaskedSelfAttention}(\mathbf{X}, \mathbf{X}, \mathbf{X}))\]

\[\mathbf{X}&apos;&apos; = \text{LayerNorm}(\mathbf{X}&apos; + \text{CrossAttention}(\mathbf{X}&apos;, \text{EncoderOut}, \text{EncoderOut}))\]

\[\mathbf{X}&apos;&apos;&apos; = \text{LayerNorm}(\mathbf{X}&apos;&apos; + \text{FFN}(\mathbf{X}&apos;&apos;))\]

&lt;p&gt;The masked self-attention uses a causal mask preventing positions from attending to future positions, crucial for autoregressive generation where we generate one token at a time.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build intuition for how Transformers process sequences, let‚Äôs trace through a concrete example of translating ‚ÄúI love deep learning‚Äù to French ‚ÄúJ‚Äôaime l‚Äôapprentissage profond.‚Äù&lt;/p&gt;

&lt;p&gt;First, consider what happens in the encoder. The input sentence becomes a sequence of embeddings, one per word (or subword token). Let‚Äôs focus on how the word ‚Äúlearning‚Äù in position 4 builds its representation through self-attention.&lt;/p&gt;

&lt;p&gt;The query for ‚Äúlearning‚Äù asks: ‚ÄúWhat context is relevant for understanding me?‚Äù Its query vector gets compared (via dot products) against the key vectors of all positions:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚ÄúI‚Äù: Low similarity (grammatical subject, semantically distant)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúlove‚Äù: Medium similarity (verb governing the noun phrase)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúdeep‚Äù: High similarity (adjective modifying this noun)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúlearning‚Äù: High similarity (self-attention)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After softmax normalization, suppose we get attention weights [0.05, 0.15, 0.35, 0.45]. The output representation for ‚Äúlearning‚Äù is:&lt;/p&gt;

\[\text{output}_{\text{learning}} = 0.05 \cdot \mathbf{v}_{\text{I}} + 0.15 \cdot \mathbf{v}_{\text{love}} + 0.35 \cdot \mathbf{v}_{\text{deep}} + 0.45 \cdot \mathbf{v}_{\text{learning}}\]

&lt;p&gt;This output incorporates information from ‚Äúdeep‚Äù (the modifying adjective) and from the word itself, with smaller contributions from other positions. The representation has been contextualized‚Äîit now encodes not just ‚Äúlearning‚Äù in isolation but ‚Äúdeep learning‚Äù as a compound concept.&lt;/p&gt;

&lt;p&gt;Crucially, all four word positions compute their attention weights and outputs simultaneously in matrix form. This parallelization is what makes Transformers fast to train compared to RNNs, which would need four sequential steps.&lt;/p&gt;

&lt;p&gt;Now consider the decoder when generating ‚Äúprofond‚Äù (deep) in the French translation. The decoder performs masked self-attention over the French tokens generated so far: ‚ÄúJ‚Äô‚Äù (I), ‚Äúaime‚Äù (love), ‚Äúl‚Äôapprentissage‚Äù (learning). It cannot attend to ‚Äúprofond‚Äù itself because that would be ‚Äúcheating‚Äù‚Äîlooking at the answer we‚Äôre trying to predict. The causal mask enforces this.&lt;/p&gt;

&lt;p&gt;Then comes cross-attention, where the decoder attends to the encoder‚Äôs representation of the English sentence. The query for the position being generated asks: ‚ÄúWhat part of the source sentence should I focus on to generate the next French word?‚Äù The key-value pairs come from the encoder‚Äôs final representations:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Query from ‚Äúgenerate next word after ‚Äòl‚Äôapprentissage‚Äô‚Äù&lt;/li&gt;
  &lt;li&gt;Keys from [‚ÄúI‚Äù, ‚Äúlove‚Äù, ‚Äúdeep‚Äù, ‚Äúlearning‚Äù]&lt;/li&gt;
  &lt;li&gt;High attention to ‚Äúdeep‚Äù (the English word we‚Äôre translating)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The cross-attention mechanism has learned to align French positions with corresponding English positions, implementing a soft, learned alignment that‚Äôs more flexible than hard alignment rules.&lt;/p&gt;

&lt;p&gt;With multiple heads, different heads can attend to different aspects. Head 1 might focus on the direct translation source (‚Äúdeep‚Äù ‚Üí ‚Äúprofond‚Äù), Head 2 on syntactic context (adjective following noun in French), Head 3 on longer-range dependencies. The model learns these specializations through backpropagation, discovering that different types of attention are useful for translation.&lt;/p&gt;

&lt;p&gt;The position-wise feed-forward network after attention serves a different role. While attention computes relationships between positions, FFN processes each position‚Äôs representation independently, transforming it through nonlinear functions. This non-linearity is essential‚Äîattention is essentially a weighted average (a linear operation), so without FFN, stacking attention layers wouldn‚Äôt increase representational power. The FFN allows each position to compute complex functions of its attended representation.&lt;/p&gt;

&lt;p&gt;Think of the encoder-decoder flow like this: The encoder builds increasingly sophisticated representations of the input through stacked layers of self-attention. Each layer refines the representation by letting positions communicate, building up from surface features (word identity) to deep semantic understanding (meaning in context). The decoder then uses this rich representation to generate the output autoregressively, using masked self-attention to maintain coherence in what it‚Äôs generated so far and cross-attention to align with the source.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement a Transformer from scratch to understand every component deeply:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScaledDotProductAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Core attention mechanism: attention = softmax(QK^T / ‚àöd_k) V
    
    The scaling by ‚àöd_k is not optional‚Äîit&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s critical for training stability.
    Without it, dot products grow with dimensionality, pushing softmax into
    saturation regions where gradients vanish. This small detail was crucial
    to making Transformers work.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# ‚àöd_k for scaling
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        q: queries (batch, n_heads, seq_len_q, d_k)
        k: keys (batch, n_heads, seq_len_k, d_k)
        v: values (batch, n_heads, seq_len_v, d_v)
        mask: optional mask (batch, 1, seq_len_q, seq_len_k)
        
        The 4D tensors accommodate batching (dimension 0), multiple heads
        (dimension 1), and sequence processing (dimensions 2-3).
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute attention scores: how much should each query attend to each key?
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Shape: (batch, n_heads, seq_len_q, seq_len_k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply mask if provided (for padding or causal masking)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Set masked positions to -inf so softmax gives them weight 0
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Why -inf? Because e^(-inf) = 0, so softmax probability becomes 0
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;attn_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;masked_fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-inf&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Normalize scores to probabilities using softmax
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each query position gets a probability distribution over key positions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Weighted sum of values according to attention weights
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is where information actually flows between positions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Multi-head attention: parallel attention with different learned projections.
    
    Why multiple heads? Different heads can learn different types of relationships.
    One head might learn syntactic dependencies, another semantic similarities,
    another positional patterns. The model discovers these specializations
    through training.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d_model must be divisible by n_heads&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Dimension per head
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections for Q, K, V (all heads combined in one matrix)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Why combined? More efficient GPU computation than separate projections
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output projection to combine heads
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Attention mechanism with scaling
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScaledDotProductAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;temperature&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Dropout for regularization
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        q, k, v: (batch, seq_len, d_model)
        
        The same input X is typically used for q, k, v in self-attention,
        but they can differ for cross-attention (decoder attending to encoder).
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections for all heads at once
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Shape: (batch, seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Split into multiple heads
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Reshape (batch, seq_len, d_model) to (batch, seq_len, n_heads, d_k)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Then transpose to (batch, n_heads, seq_len, d_k) for head-wise processing
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply attention for all heads in parallel
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each head operates independently on its d_k dimensions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Concatenate heads back together
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# (batch, n_heads, seq_len, d_k) ‚Üí (batch, seq_len, n_heads, d_k) 
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# ‚Üí (batch, seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contiguous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Final linear projection integrates information from all heads
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PositionwiseFeedForward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Two-layer fully connected network applied to each position independently.
    
    Why position-wise? After attention computes interactions between positions,
    each position needs to process its aggregated information. The FFN provides
    this capacity for complex, nonlinear transformations.
    
    Why two layers? Single linear layer would be too limiting. Two layers with
    nonlinearity between them (forming a MLP) can approximate any function.
    The expansion (d_model ‚Üí d_ff) and contraction (d_ff ‚Üí d_model) pattern
    is similar to an autoencoder, creating a bottleneck that forces efficient
    representation.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Expansion layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Contraction layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w_2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, seq_len, d_model)
        
        Each position (each row in seq_len dimension) passes through
        the same two-layer network independently. This is equivalent to
        applying a 1D convolution with kernel size 1.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;w_2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;w_1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TransformerEncoderLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Complete Transformer encoder layer: self-attention + FFN + residuals + norms.
    
    The architecture follows a specific pattern that has been carefully designed:
    1. Multi-head self-attention for position interactions
    2. Residual connection + layer norm for stable training
    3. Position-wise FFN for nonlinear transformation
    4. Another residual connection + layer norm
    
    This pattern repeats for all encoder layers, building increasingly
    sophisticated representations through depth.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self_attn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ffn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;PositionwiseFeedForward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Layer normalization (normalizes across features for each sample/position)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LayerNorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;norm2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LayerNorm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, seq_len, d_model)
        mask: optional attention mask
        
        The forward pass implements the add &amp;amp; norm pattern:
        x = norm(x + sublayer(x))
        
        Why this order? Normalizing after adding (post-norm) was the original
        design. Modern variants use pre-norm (norm before sublayer) which can
        be more stable for very deep networks.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Self-attention block
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;self_attn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Feed-forward block  
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;ffn_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ffn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ffn_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_positional_encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Sinusoidal positional encoding as proposed in original paper.
    
    We create a matrix of shape (max_len, d_model) where row i contains
    the positional encoding for position i. Even dimensions use sine,
    odd dimensions use cosine, with frequencies decreasing as dimension increases.
    
    Why this specific pattern? It creates unique encodings for each position,
    allows the model to learn relative positions (PE(pos+k) is linear in PE(pos)),
    and generalizes to unseen sequence lengths.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (max_len, 1)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Compute frequencies for each dimension
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# div_term = 1 / (10000^(2i/d_model)) for i in [0, d_model/2)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;div_term&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;arange&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; 
                        &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;10000.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;pe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;pe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sin&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;div_term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Even dimensions
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;pe&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;position&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;div_term&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Odd dimensions
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pe&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TransformerEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Stack of N encoder layers that progressively refine representations.
    
    Each layer allows positions to communicate through attention, building
    up from surface-level features to deep semantic understanding. The stack
    of 6 layers in the original paper was empirically determined‚Äîdeeper can
    be better with enough data, but training becomes harder.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2048&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Token embeddings: convert token IDs to dense vectors
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Positional encoding (fixed, not learned in original Transformer)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;pos_encoding&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                           &lt;span class=&quot;nf&quot;&gt;create_positional_encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Stack of encoder layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;TransformerEncoderLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize embeddings (important for training stability)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;init&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src_mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        src: source token IDs (batch, seq_len)
        src_mask: optional mask for padding tokens
        
        Returns encoded representations after passing through all layers.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Embed tokens and scale (important: multiply by ‚àöd_model)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Why scale? To balance with positional encoding which has values ~1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Add positional encoding
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Broadcasting: (batch, seq_len, d_model) + (seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos_encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Pass through encoder layers sequentially
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each layer refines the representation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_weights_all&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;attn_weights_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights_all&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstration: Create and test encoder
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Transformer Encoder Example&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10000&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TransformerEncoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Random input tokens
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 15)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 15, 512)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Number of attention weight matrices: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 6 layers
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each attention weight shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 8, 15, 15)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Total parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Visualize attention for first head of first layer
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention Pattern (Layer 0, Head 0)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Take first sample, first head, first layer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_map&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights (each row shows what that position attends to):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Note: Each row sums to 1.0 (probability distribution over positions)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let‚Äôs implement a complete training loop showing how Transformers learn:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleTransformerLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Simple Transformer language model for demonstration.
    
    This implements a decoder-only architecture (like GPT) that predicts
    the next token given previous tokens. It&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s simpler than full encoder-decoder
    but demonstrates all key concepts.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                 &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1024&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;register_buffer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;pos_encoding&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;nf&quot;&gt;create_positional_encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder layers (with causal masking in attention)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ModuleList&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
            &lt;span class=&quot;nc&quot;&gt;TransformerEncoderLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_ff&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output projection to vocabulary
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_proj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Create mask preventing attention to future positions.
        
        For autoregressive generation, position i should only attend to
        positions 0...i, not i+1...n. This mask enforces causality.
        
        Returns upper triangular matrix of False (mask out future)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tril&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;x: (batch, seq_len) of token IDs&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Embedding + positional encoding
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;math&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pos_encoding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Create causal mask
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;causal_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;to&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;device&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Process through layers
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Project to vocabulary
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;output_proj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training example on toy data
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Transformer Language Model&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create simple sequence prediction task
# Task: predict next number in sequence [1,2,3,4,5,...]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size_small&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model_lm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleTransformerLM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size_small&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                               &lt;span class=&quot;n&quot;&gt;n_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate training data: sequences like [1,2,3,4] ‚Üí predict [2,3,4,5]
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_sequence_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generate simple sequential patterns for language model training&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Target is input shifted by 1
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:],&lt;/span&gt; 
                        &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train for a few iterations
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Generate batch
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_sequence_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                     &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size_small&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model_lm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, seq_len, vocab_size)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Compute loss (flatten for cross-entropy)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size_small&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward and optimize
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Backprop through Transformer!
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Transformer successfully trained to predict sequences!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The model learned to use attention to predict based on context.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The Transformer‚Äôs relationship to recurrent neural networks is both a contrast and a continuation. RNNs process sequences through time, maintaining a hidden state that theoretically summarizes all previous information. This recurrence enables temporal dependencies but creates several problems: sequential processing (can‚Äôt parallelize), vanishing gradients over long sequences, and fixed-size bottleneck (hidden state must compress everything). Transformers solve all three: attention allows full parallelization, gradients flow directly between any positions (no vanishing), and there‚Äôs no bottleneck‚Äîall positions remain active. However, this comes at a cost: \(O(n^2)\) complexity in sequence length for attention, compared to \(O(n)\) for RNNs. For very long sequences (thousands of tokens), this quadratic cost becomes prohibitive, motivating research into efficient attention variants.&lt;/p&gt;

&lt;p&gt;The connection between Transformers and convolutional networks is subtler but illuminating. Both process structured data (sequences for Transformers, images for CNNs) using specialized operations. Convolution uses local receptive fields and parameter sharing for translation invariance. Attention uses global receptive fields (every position attends to every other) and position-specific parameters. You can view self-attention as a learned, data-dependent, global convolution where the kernel (attention weights) changes based on input content rather than being fixed. This flexibility allows Transformers to capture long-range dependencies that would require many convolutional layers, but at higher computational cost.&lt;/p&gt;

&lt;p&gt;The encoder-decoder architecture of the original Transformer connects to earlier sequence-to-sequence models. The encoder-decoder paradigm‚Äîseparately encode the source into a representation, then decode into the target‚Äîpredates Transformers, appearing in RNN seq2seq models. The Transformer‚Äôs innovation was implementing this paradigm using only attention. The encoder builds a source representation through stacked self-attention, and the decoder uses this via cross-attention while maintaining causality through masked self-attention. This decomposition is powerful because encoder and decoder can have different depths and properties optimized for their specific roles.&lt;/p&gt;

&lt;p&gt;Positional encodings connect to a fundamental tension in Transformers: they‚Äôre designed to be permutation-invariant (for parallelization) but must process ordered sequences (where order matters). The positional encoding solution adds position information to content embeddings, allowing the model to distinguish positions. Learned positional embeddings (used in BERT and GPT) are an alternative that‚Äôs simpler but can‚Äôt extrapolate to longer sequences than seen in training. Recent research explores relative positional encodings (T5, Transformer-XL) that encode relative rather than absolute positions, potentially providing better inductive bias for certain tasks. Understanding these variants helps appreciate the tradeoffs in representing position.&lt;/p&gt;

&lt;p&gt;The Transformer‚Äôs influence on architecture search and neural network design more broadly cannot be overstated. The architecture‚Äôs success despite breaking with the conventional wisdom (that recurrence was necessary for sequences) encouraged researchers to question other assumptions. This led to Vision Transformers (questioning whether convolution was necessary for images), protein structure prediction with Transformers (AlphaFold), and countless other applications. The Transformer demonstrates that strong inductive biases (like convolution‚Äôs locality or recurrence‚Äôs temporal processing) can sometimes be replaced with more flexible learned mechanisms given sufficient data and computation.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;‚ÄúAttention Is All You Need‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, Illia Polosukhin (Google Brain/Research)&lt;br /&gt;
This is THE foundational paper that introduced the Transformer architecture and revolutionized deep learning. The authors demonstrated that multi-head self-attention alone, without any recurrence or convolution, could achieve state-of-the-art results on machine translation while being significantly more parallelizable. The paper is remarkably clear and comprehensive, describing every component of the architecture, the training details, and extensive experiments. The title itself‚Äî‚ÄùAttention Is All You Need‚Äù‚Äîwas provocative, suggesting that the attention mechanism introduced in earlier seq2seq papers was sufficient on its own. History proved this claim correct and then some: Transformers became the foundation not just of NLP but of modern AI broadly. The paper‚Äôs impact is measured not just in citations (tens of thousands) but in how thoroughly it changed the field‚Äîwithin five years, Transformers had largely replaced RNNs for sequence modeling.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1810.04805&quot;&gt;‚ÄúBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova (Google AI Language)&lt;br /&gt;
BERT took the Transformer encoder and introduced a new pre-training paradigm that revolutionized NLP. Instead of training on next-token prediction (like language models), BERT uses masked language modeling: randomly mask some tokens and predict them from bidirectional context. This forces the model to develop deep understanding of language since it must use both left and right context. BERT demonstrated that pre-training Transformers on massive unlabeled data, then fine-tuning on specific tasks, could achieve state-of-the-art results across a wide range of NLP tasks with minimal task-specific architecture changes. The paper established the pre-train-then-fine-tune paradigm now dominant in NLP and increasingly other domains. BERT‚Äôs success spawned numerous variants (RoBERTa, ALBERT, ELECTRA) and demonstrated the power of transfer learning with Transformers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf&quot;&gt;‚ÄúLanguage Models are Unsupervised Multitask Learners‚Äù (2019)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever (OpenAI)&lt;br /&gt;
The GPT-2 paper showed that large Transformer language models could perform multiple tasks zero-shot without any fine-tuning‚Äîsimply by framing tasks as language modeling problems. The model demonstrated reading comprehension, translation, summarization, and question-answering capabilities without being explicitly trained for these tasks. This ‚Äúprompting‚Äù paradigm, where we guide the model through natural language instructions rather than fine-tuning, would become even more important with GPT-3 and ChatGPT. The paper also demonstrated scaling laws: larger Transformers with more data generally perform better, with no clear ceiling yet observed. This observation drove the race toward ever-larger language models that continues today. GPT-2‚Äôs release was controversial (initially withheld due to concerns about misuse), raising important questions about AI safety and responsible research that remain relevant.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2010.11929&quot;&gt;‚ÄúAn Image is Worth 16√ó16 Words: Transformers for Image Recognition at Scale‚Äù (2021)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alexey Dosovitskiy, Lucas Beyer, Alexander Kolesnikov, et al. (Google Research, Brain Team)&lt;br /&gt;
Vision Transformer (ViT) demonstrated that Transformers could match or exceed CNNs on image classification, challenging the dominance of convolutional architectures in computer vision. The key insight was treating images as sequences of patches: split an image into 16√ó16 patches, linearly embed each patch, add positional encodings, and process with a standard Transformer encoder. Remarkably, this approach with minimal vision-specific inductive bias (no convolution, no pooling) achieved excellent results when pretrained on sufficient data. ViT showed that Transformers are not just for NLP but represent a more general architecture for processing structured data. The paper sparked rapid adoption of Transformers in vision, with variants like Swin Transformer and DeiT addressing ViT‚Äôs data hungriness and computational cost.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/2207.09238&quot;&gt;‚ÄúFormal Algorithms for Transformers‚Äù (2022)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Mary Phuong, Marcus Hutter (DeepMind)&lt;br /&gt;
This relatively recent paper provides a comprehensive mathematical formalization of Transformer architectures and their variants. While not introducing new models, it serves as the definitive technical reference, precisely defining all operations, analyzing computational complexity, and cataloging the many Transformer variants (encoder-only, decoder-only, encoder-decoder, sparse attention, etc.). The paper is invaluable for researchers implementing custom Transformers or analyzing their properties rigorously. It clarifies subtle details often glossed over in tutorials and papers (like exactly how masks work, how to handle variable-length sequences, and the precise order of operations). For anyone seeking to truly understand Transformers at a formal level or implement them correctly from scratch, this paper is essential reading.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;One of the most common mistakes when implementing Transformers is forgetting to add positional encodings or adding them incorrectly. Without positional information, the attention mechanism is permutation-invariant‚Äîshuffling the input tokens produces identically shuffled outputs. For language, where ‚Äúdog bites man‚Äù and ‚Äúman bites dog‚Äù have opposite meanings, this is catastrophic. The positional encoding must be added to the embeddings after embedding lookup but before the first encoder layer. A subtle error is adding positional encodings at every layer rather than just initially‚Äîthe original Transformer adds them only once, letting subsequent layers maintain or modify positional information through attention.&lt;/p&gt;

&lt;p&gt;Incorrect masking is another insidious bug. In decoder self-attention, the causal mask must prevent position \(i\) from attending to positions \(&amp;gt; i\). This requires setting attention scores to \(-\infty\) (not 0!) before softmax for masked positions. Setting masked scores to 0 before softmax means they still receive positive probability after softmax (since \(e^0 = 1\)), allowing information leakage from future tokens. The \(-\infty\) ensures \(e^{-\infty} = 0\), giving zero probability. Additionally, for padded sequences, we must mask attention to padding tokens in both encoder and decoder to prevent the model from attending to meaningless padding.&lt;/p&gt;

&lt;p&gt;Forgetting to scale attention scores by \(\sqrt{d_k}\) is surprisingly common and can severely impact training. As dimensionality increases, unscaled dot products grow in magnitude (assuming normalized inputs with unit variance, the variance of the dot product grows linearly with dimension). Large dot products push softmax into saturation‚Äîmost probability mass goes to a single position, and gradients become very small. The model fails to learn distributed attention patterns and may not train at all for large \(d_k\). The \(\sqrt{d_k}\) scaling keeps dot products at reasonable magnitude regardless of dimension.&lt;/p&gt;

&lt;p&gt;The learning rate schedule used in the original Transformer paper‚Äîwarmup followed by decay‚Äîis actually quite important for stable training, not just a minor detail. The schedule increases learning rate linearly for the first warmup_steps (typically 4000), then decays proportional to the inverse square root of step number. Why warmup? At initialization, parameters are random and gradients can be noisy. A high learning rate causes wild updates that can push the model into bad regions. Warmup allows the model to ‚Äúsettle in‚Äù with small, careful steps before accelerating. After warmup, the decay helps convergence by taking smaller steps as we approach a minimum. This schedule is now standard for training large Transformers.&lt;/p&gt;

&lt;p&gt;A powerful technique for Transformers is using mixed precision training (FP16 instead of FP32). Transformers have many matrix multiplications, which GPUs can perform much faster in FP16. However, naive FP16 training causes numerical issues (small gradients underflow to zero). The solution is mixed precision: compute in FP16 but maintain FP32 master copy of weights and use loss scaling to prevent gradient underflow. This can speed training by 2-3√ó and reduce memory usage, allowing larger batch sizes or models.&lt;/p&gt;

&lt;p&gt;For inference efficiency, key-value caching is essential in autoregressive generation (generating one token at a time). When generating token \(t\), we‚Äôve already computed keys and values for tokens \(1...t-1\). Rather than recomputing them (which requires processing the entire sequence again), cache them and only compute the new token‚Äôs keys/values. This transforms generation from \(O(n^2)\) complexity to \(O(n)\), making generation of long sequences practical.&lt;/p&gt;

&lt;p&gt;Finally, understanding that Transformer complexity is \(O(n^2 d)\) where \(n\) is sequence length motivates much recent research. For very long sequences (documents with thousands of tokens), the quadratic complexity becomes prohibitive. Various approaches address this: Sparse Transformers use local + strided attention patterns reducing to \(O(n \sqrt{n})\), Linformer uses low-rank approximations achieving \(O(n)\), and Reformer uses locality-sensitive hashing for efficient attention. Understanding why vanilla Transformers are expensive helps appreciate these innovations and choose appropriate variants for different sequence length regimes.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;The Transformer architecture revolutionized sequence processing by replacing recurrence with self-attention, enabling parallel training and better long-range dependencies. The core scaled dot-product attention computes relationships between all positions through query-key similarities, weighted value averaging. Multi-head attention allows learning multiple relationship types simultaneously. Positional encodings inject sequence order into the otherwise position-agnostic attention mechanism. The encoder-decoder architecture with masked self-attention and cross-attention enables sequence-to-sequence tasks like translation. Residual connections and layer normalization enable training deep Transformers (6+ layers). The architecture‚Äôs success extends far beyond NLP to vision, speech, and multimodal domains, establishing Transformers as perhaps the most important neural architecture of the modern era. Understanding Transformers deeply‚Äîtheir mathematical foundations, implementation details, and design rationale‚Äîis essential for anyone working in contemporary AI, as they underlie BERT, GPT, ChatGPT, and countless other systems transforming how we interact with technology.&lt;/p&gt;

&lt;p&gt;The Transformer‚Äôs elegance lies not in complex components but in how simple pieces‚Äîattention, residuals, normalization‚Äîcombine into an architecture that‚Äôs simultaneously powerful, efficient, and versatile. This is the hallmark of great design in any field.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>08 The Transformer Architecture</title>
   <link href="http://localhost:4000/contents/en/chapter08/08_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter08/08_00_Introduction</id>
   <content type="html">&lt;p&gt;Transformers revolutionized NLP and deep learning by replacing recurrent layers with self-attention. Introduced in ‚ÄúAttention Is All You Need‚Äù (2017), Transformers enable parallel processing, handle long-range dependencies better than RNNs, and have become the foundation of modern AI models like BERT, GPT, and beyond. This chapter covers the complete Transformer architecture and its variants.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key breakthroughs&lt;/strong&gt;: BERT, GPT-2/3/4, T5, Vision Transformers, and more - all based on this architecture!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>07-01 Attention Mechanisms</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_01_Attention_Mechanisms/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter07/07_01_Attention_Mechanisms</id>
   <content type="html">&lt;h1 id=&quot;attention-mechanisms-learning-where-to-focus&quot;&gt;Attention Mechanisms: Learning Where to Focus&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/tensorflow/nmt/master/nmt/g3doc/img/attention_mechanism.jpg&quot; alt=&quot;Attention Mechanism Visualization&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça c∆° ch·∫ø Attention trong d·ªãch m√°y. Ngu·ªìn: TensorFlow NMT&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Attention mechanisms represent one of the most transformative ideas in modern deep learning, fundamentally changing how neural networks process sequential and structured data. The core insight is deceptively simple yet profound: not all parts of the input are equally relevant for making a particular prediction, and the network should learn to focus on the most relevant parts dynamically based on context. This idea, first introduced to address limitations in sequence-to-sequence models for machine translation, has become so central to deep learning that it forms the foundation of Transformers, the dominant architecture in natural language processing and increasingly in computer vision and other domains.&lt;/p&gt;

&lt;p&gt;To understand why attention emerged and why it matters so profoundly, we must first appreciate the bottleneck problem it solves. In early encoder-decoder architectures for tasks like machine translation, the encoder processes the entire source sentence into a single fixed-size vector, which the decoder then uses to generate the translation. This fixed-size vector‚Äîregardless of whether the source is five words or fifty‚Äîmust encode all information about the source that might be relevant for generating the target. This is an extreme information bottleneck. Moreover, it violates an intuitive principle of translation: when generating each target word, we should focus primarily on the corresponding source words, not treat all source words equally.&lt;/p&gt;

&lt;p&gt;The attention mechanism solves this by allowing the decoder to directly access all encoder hidden states, not just the final one, and to compute a weighted average of these states where the weights reflect relevance to the current decoding step. When translating ‚ÄúThe black cat‚Äù to French, when generating ‚Äúnoir‚Äù (black), the attention mechanism learns to focus heavily on ‚Äúblack‚Äù in the source, largely ignoring ‚Äúthe‚Äù and ‚Äúcat.‚Äù This dynamic, learned focusing ability eliminates the fixed-size bottleneck and provides interpretability‚Äîwe can visualize attention weights to see what the model is focusing on, making the translation process more transparent.&lt;/p&gt;

&lt;p&gt;The mathematical elegance of attention lies in its generality. At its core, attention is a mechanism for computing weighted averages where the weights are determined by relevance or similarity, typically measured through learned functions. This abstraction applies far beyond machine translation. In image captioning, attention can focus on different image regions when generating different caption words. In reading comprehension, attention can focus on relevant passages when answering questions. In self-attention (used in Transformers), positions in a sequence can attend to each other to build contextualized representations. The same mathematical framework‚Äîqueries, keys, values, and similarity-based weighting‚Äîworks across all these domains.&lt;/p&gt;

&lt;p&gt;What makes attention particularly powerful is that it‚Äôs differentiable and can be trained end-to-end with backpropagation. The network learns what to attend to purely from the training objective, without explicit supervision about which source words correspond to which target words in translation, or which image regions correspond to which caption words. This learned attention often discovers alignments and relationships that match human intuitions, providing both performance gains and interpretability. The attention weights‚Äîvisualizable as heatmaps showing which inputs the model focused on for each output‚Äîgive us unprecedented insight into neural network decision-making.&lt;/p&gt;

&lt;p&gt;The evolution from simple attention in encoder-decoder models to self-attention in Transformers represents a conceptual leap. In encoder-decoder attention, the decoder (generating output) attends to the encoder (representing input)‚Äîa one-way relationship from source to target. Self-attention allows elements within the same sequence to attend to each other bidirectionally. Every word in a sentence can look at every other word to build its representation. This enables capturing complex linguistic relationships like coreference (‚ÄúThe cat‚Äù and ‚Äúit‚Äù referring to the same entity), syntactic dependencies, and semantic relationships, all learned automatically from data. Self-attention‚Äôs power comes from enabling direct communication between all positions in a sequence, creating \(O(1)\) path lengths for information flow compared to \(O(n)\) in RNNs where information must traverse the sequence linearly.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;To understand attention deeply, we must build up from first principles, starting with the simplest formulation and progressing to the sophisticated multi-head self-attention used in Transformers. The core idea is to compute outputs as weighted combinations of values, where weights are determined by the relevance of each value to the current query.&lt;/p&gt;

&lt;h3 id=&quot;the-general-attention-framework&quot;&gt;The General Attention Framework&lt;/h3&gt;

&lt;p&gt;Suppose we have a query \(\mathbf{q}\) representing what we‚Äôre looking for, a set of keys \(\{\mathbf{k}_1, \ldots, \mathbf{k}_n\}\) representing what each input offers, and corresponding values \(\{\mathbf{v}_1, \ldots, \mathbf{v}_n\}\) representing the actual content. The attention mechanism computes:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Similarity scores&lt;/strong&gt;: \(e_i = \text{score}(\mathbf{q}, \mathbf{k}_i)\) measuring relevance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Attention weights&lt;/strong&gt;: \(\alpha_i = \frac{\exp(e_i)}{\sum_{j=1}^n \exp(e_j)}\) (softmax normalization)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Context vector&lt;/strong&gt;: \(\mathbf{c} = \sum_{i=1}^n \alpha_i \mathbf{v}_i\) (weighted sum)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The choice of similarity function \(\text{score}(\mathbf{q}, \mathbf{k}_i)\) gives rise to different attention variants. Let‚Äôs examine the most important ones and understand why each design choice matters.&lt;/p&gt;

&lt;h3 id=&quot;additive-bahdanau-attention&quot;&gt;Additive (Bahdanau) Attention&lt;/h3&gt;

&lt;p&gt;The first widely successful attention mechanism, introduced for neural machine translation, uses:&lt;/p&gt;

\[\text{score}(\mathbf{q}, \mathbf{k}_i) = \mathbf{v}_a^T \tanh(\mathbf{W}_a \mathbf{q} + \mathbf{U}_a \mathbf{k}_i)\]

&lt;p&gt;This additive formulation has several properties worth examining. The query and key are first projected through learned weight matrices \(\mathbf{W}_a\) and \(\mathbf{U}_a\), allowing the model to learn what aspects of the query and key are relevant for computing similarity. These projections happen in the same space (both result in vectors of the same dimension), which are then added and passed through \(\tanh\) nonlinearity. The \(\tanh\) serves dual purposes: it provides nonlinearity (allowing the similarity function to capture complex relationships) and it bounds the pre-softmax scores (preventing extremely large values that would cause softmax saturation).&lt;/p&gt;

&lt;p&gt;The final projection through \(\mathbf{v}_a^T\) (a learned vector) combines the features from the tanh layer into a single scalar score. This vector \(\mathbf{v}_a\) can be seen as learning which feature combinations indicate high relevance. The entire similarity function is learned from data through backpropagation‚Äîinitially random, it adapts to discover what constitutes relevance for the specific task.&lt;/p&gt;

&lt;h3 id=&quot;multiplicative-luong-attention&quot;&gt;Multiplicative (Luong) Attention&lt;/h3&gt;

&lt;p&gt;A simpler formulation that often works as well or better:&lt;/p&gt;

\[\text{score}(\mathbf{q}, \mathbf{k}_i) = \mathbf{q}^T \mathbf{W}_a \mathbf{k}_i\]

&lt;p&gt;or even more simply (dot-product attention):&lt;/p&gt;

\[\text{score}(\mathbf{q}, \mathbf{k}_i) = \mathbf{q}^T \mathbf{k}_i\]

&lt;p&gt;The dot product measures similarity through alignment‚Äîhigh dot product means the query and key point in similar directions in the representation space. This is computationally efficient (just vector dot products) and works well when queries and keys are already in the same semantic space. The learned matrix \(\mathbf{W}_a\) in the general form allows transforming the key before comparison, giving more flexibility.&lt;/p&gt;

&lt;p&gt;The dot product formulation becomes particularly elegant when we consider batch processing. With query matrix \(\mathbf{Q} \in \mathbb{R}^{m \times d}\) (\(m\) queries) and key matrix \(\mathbf{K} \in \mathbb{R}^{n \times d}\) (\(n\) keys):&lt;/p&gt;

\[\mathbf{E} = \mathbf{Q}\mathbf{K}^T \in \mathbb{R}^{m \times n}\]

&lt;p&gt;This single matrix multiplication computes all \(m \times n\) pairwise similarities simultaneously, perfectly suited for GPU parallelization. This efficiency is one reason dot-product attention became standard in Transformers.&lt;/p&gt;

&lt;h3 id=&quot;scaled-dot-product-attention&quot;&gt;Scaled Dot-Product Attention&lt;/h3&gt;

&lt;p&gt;The Transformer uses dot-product attention with a crucial modification‚Äîscaling:&lt;/p&gt;

\[\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right) \mathbf{V}\]

&lt;p&gt;where \(d_k\) is the dimension of keys (and queries). Why this scaling? Consider what happens as \(d_k\) grows. If query and key components are independent random variables with mean 0 and variance 1, their dot product has variance \(d_k\). For \(d_k = 512\) (common in Transformers), unnormalized dot products have standard deviation \(\sqrt{512} \approx 22.6\). After softmax, such large magnitudes cause one probability to dominate (approaching 1) with others near 0, creating sharp attention distributions where gradients vanish.&lt;/p&gt;

&lt;p&gt;Dividing by \(\sqrt{d_k}\) normalizes the variance back to 1, regardless of dimension. This keeps dot products in a range where softmax has meaningful gradients, allowing the model to learn nuanced attention distributions‚Äîattending to multiple positions with varying weights rather than hard selection of a single position. This seemingly minor scaling factor was crucial to making Transformer attention work for large model dimensions.&lt;/p&gt;

&lt;h3 id=&quot;self-attention-the-key-innovation&quot;&gt;Self-Attention: The Key Innovation&lt;/h3&gt;

&lt;p&gt;Self-attention applies attention within a single sequence, allowing elements to attend to each other. For a sequence \(\mathbf{X} = [\mathbf{x}_1, \ldots, \mathbf{x}_n]\), we create queries, keys, and values through learned projections:&lt;/p&gt;

\[\mathbf{Q} = \mathbf{X}\mathbf{W}^Q, \quad \mathbf{K} = \mathbf{X}\mathbf{W}^K, \quad \mathbf{V} = \mathbf{X}\mathbf{W}^V\]

&lt;p&gt;Each position becomes a query asking ‚Äúwhat context is relevant to me?‚Äù Its query is compared against all positions‚Äô keys (including its own), producing attention weights that determine how much to incorporate from each position‚Äôs value. The output for position \(i\) is:&lt;/p&gt;

\[\mathbf{o}_i = \sum_{j=1}^n \alpha_{ij} \mathbf{v}_j, \quad \text{where} \quad \alpha_{ij} = \frac{\exp(\mathbf{q}_i^T \mathbf{k}_j / \sqrt{d_k})}{\sum_{j&apos;=1}^n \exp(\mathbf{q}_i^T \mathbf{k}_{j&apos;} / \sqrt{d_k})}\]

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;This creates an \(n \times n\) matrix of interactions between all position pairs. Position \(i\) can directly attend to position \(j\) regardless of how far apart they are in the sequence. This direct connectivity is what enables capturing long-range dependencies without the vanishing gradient issues of RNNs‚Äîinformation flows directly from position \(j\) to position \(i\) in one step, not through $$&lt;/td&gt;
      &lt;td&gt;i-j&lt;/td&gt;
      &lt;td&gt;$$ sequential transformations.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;multi-head-attention-multiple-perspectives&quot;&gt;Multi-Head Attention: Multiple Perspectives&lt;/h3&gt;

&lt;p&gt;A single attention mechanism can learn one type of relationship, but natural language (and many other structured domains) involves multiple simultaneous relationship types. Multi-head attention addresses this by computing attention multiple times in parallel with different learned projections:&lt;/p&gt;

\[\text{head}_h = \text{Attention}(\mathbf{X}\mathbf{W}_h^Q, \mathbf{X}\mathbf{W}_h^K, \mathbf{X}\mathbf{W}_h^V)\]

\[\text{MultiHead}(\mathbf{X}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_H) \mathbf{W}^O\]

&lt;p&gt;Each head has its own projection matrices \(\mathbf{W}_h^Q, \mathbf{W}_h^K, \mathbf{W}_h^V\), allowing it to learn different attention patterns. Empirically, different heads specialize: one might learn to attend to syntactically related words, another to semantically similar words, another to simply nearby words. The network discovers these specializations automatically through backpropagation‚Äîwe don‚Äôt specify what each head should do, we merely provide the capacity for specialization through separate parameters.&lt;/p&gt;

&lt;p&gt;The typical configuration uses 8 heads with \(d_k = d_v = d_{\text{model}}/8\), meaning each head operates in a lower-dimensional space (64 dimensions if \(d_{\text{model}} = 512\)). This design choice maintains the same total computational cost as single-head full-dimension attention while providing representational advantages of multiple perspectives. The final concatenation and projection through \(\mathbf{W}^O\) integrates information from all heads, allowing them to collaborate rather than operating independently.&lt;/p&gt;

&lt;h3 id=&quot;masking-in-attention&quot;&gt;Masking in Attention&lt;/h3&gt;

&lt;p&gt;For many applications, we need to prevent attention to certain positions. Two types of masking are crucial:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Padding mask&lt;/strong&gt;: When sequences in a batch have different lengths, we pad shorter sequences. The mask prevents attending to padding tokens:&lt;/p&gt;

\[\text{mask}_{ij} = \begin{cases} 1 &amp;amp; \text{if position } j \text{ is real content} \\ 0 &amp;amp; \text{if position } j \text{ is padding} \end{cases}\]

&lt;p&gt;&lt;strong&gt;Causal (look-ahead) mask&lt;/strong&gt;: For autoregressive generation, position \(i\) cannot attend to positions \(j &amp;gt; i\) (future positions):&lt;/p&gt;

\[\text{mask}_{ij} = \begin{cases} 1 &amp;amp; \text{if } j \leq i \\ 0 &amp;amp; \text{if } j &amp;gt; i \end{cases}\]

&lt;p&gt;These masks are applied before softmax by setting masked positions to \(-\infty\):&lt;/p&gt;

\[\text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}} + \mathbf{M}\right)\]

&lt;p&gt;where \(\mathbf{M}_{ij} = 0\) if allowed, \(-\infty\) if masked. Since \(\exp(-\infty) = 0\), masked positions receive zero attention weight after softmax.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build genuine intuition for how attention works, let‚Äôs trace through the mechanics of translating the sentence ‚ÄúI love deep learning‚Äù to French ‚ÄúJ‚Äôaime l‚Äôapprentissage profond‚Äù using encoder-decoder attention.&lt;/p&gt;

&lt;p&gt;The encoder processes the English sentence, producing hidden states \(\mathbf{h}_1^{enc}, \ldots, \mathbf{h}_4^{enc}\) for the four words. These hidden states contain rich representations of each word in context‚Äî‚Äùdeep‚Äù is represented not in isolation but as modifying ‚Äúlearning.‚Äù&lt;/p&gt;

&lt;p&gt;Now the decoder begins generating the French translation. At the first step, it must generate ‚ÄúJ‚Äô‚Äù (I). The decoder has its own hidden state \(\mathbf{s}_1\) representing ‚Äúabout to generate the first word.‚Äù This becomes the query: ‚ÄúWhat source information is relevant for generating the first word?‚Äù The encoder hidden states serve as keys and values.&lt;/p&gt;

&lt;p&gt;The attention mechanism computes similarities between the query \(\mathbf{s}_1\) and each encoder hidden state:&lt;/p&gt;

&lt;p&gt;\(e_{1,1} = \mathbf{s}_1^T \mathbf{W}_a \mathbf{h}_1^{enc}\) (similarity to ‚ÄúI‚Äù)
\(e_{1,2} = \mathbf{s}_1^T \mathbf{W}_a \mathbf{h}_2^{enc}\) (similarity to ‚Äúlove‚Äù)
\(e_{1,3} = \mathbf{s}_1^T \mathbf{W}_a \mathbf{h}_3^{enc}\) (similarity to ‚Äúdeep‚Äù)
\(e_{1,4} = \mathbf{s}_1^T \mathbf{W}_a \mathbf{h}_4^{enc}\) (similarity to ‚Äúlearning‚Äù)&lt;/p&gt;

&lt;p&gt;Suppose these scores are \([2.5, 0.8, 0.3, 0.2]\). After softmax normalization, we get attention weights approximately \([0.77, 0.14, 0.05, 0.04]\). The model has learned to focus primarily on ‚ÄúI‚Äù (0.77) when generating ‚ÄúJ‚Äô‚Äù, which aligns perfectly with the translation.&lt;/p&gt;

&lt;p&gt;The context vector is then:&lt;/p&gt;

\[\mathbf{c}_1 = 0.77 \cdot \mathbf{h}_1^{enc} + 0.14 \cdot \mathbf{h}_2^{enc} + 0.05 \cdot \mathbf{h}_3^{enc} + 0.04 \cdot \mathbf{h}_4^{enc}\]

&lt;p&gt;This context is heavily influenced by the representation of ‚ÄúI‚Äù but includes minor contributions from other words, capturing that even when translating ‚ÄúI‚Äù, other context matters (formal vs informal, sentence structure, etc.). The decoder then combines this context with its own state to generate ‚ÄúJ‚Äô‚Äù.&lt;/p&gt;

&lt;p&gt;Moving to the third French word ‚Äúl‚Äôapprentissage‚Äù (learning), the decoder state \(\mathbf{s}_3\) now asks: ‚ÄúWhat‚Äôs relevant for generating this word?‚Äù The attention mechanism might produce weights \([0.03, 0.05, 0.12, 0.80]\), focusing primarily on ‚Äúlearning‚Äù (0.80) with some attention to ‚Äúdeep‚Äù (0.12) since they form a compound in English. The context vector:&lt;/p&gt;

\[\mathbf{c}_3 = 0.03 \cdot \mathbf{h}_1^{enc} + 0.05 \cdot \mathbf{h}_2^{enc} + 0.12 \cdot \mathbf{h}_3^{enc} + 0.80 \cdot \mathbf{h}_4^{enc}\]

&lt;p&gt;This adaptive focus on different source parts for different target words is attention‚Äôs power‚Äîit solves the alignment problem in translation without explicit alignment annotations.&lt;/p&gt;

&lt;p&gt;Now consider self-attention within the English sentence itself. When building a representation for ‚Äúlearning,‚Äù we compute its similarity to all words including itself:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚ÄúI‚Äù: Low similarity (different parts of speech, distant semantically)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúlove‚Äù: Medium (syntactically related‚Äî‚Äùlove‚Äù governs ‚Äúlearning‚Äù)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúdeep‚Äù: High (forms compound noun phrase ‚Äúdeep learning‚Äù)&lt;/li&gt;
  &lt;li&gt;‚Äúlearning‚Äù ‚Üî ‚Äúlearning‚Äù: High (self-similarity)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After softmax, suppose we get weights \([0.08, 0.17, 0.40, 0.35]\). The contextualized representation becomes:&lt;/p&gt;

\[\mathbf{o}_{\text{learning}} = 0.08 \mathbf{v}_I + 0.17 \mathbf{v}_{\text{love}} + 0.40 \mathbf{v}_{\text{deep}} + 0.35 \mathbf{v}_{\text{learning}}\]

&lt;p&gt;This representation now encodes not just ‚Äúlearning‚Äù in isolation but ‚Äúdeep learning‚Äù as a concept, incorporating information from its modifier. This is how self-attention builds contextualized representations‚Äîevery word‚Äôs representation becomes a function of its relationships to all other words.&lt;/p&gt;

&lt;p&gt;The beauty of multi-head attention is that different heads can capture different aspects simultaneously. Head 1 might focus on syntactic dependencies (subject-verb, adjective-noun). Head 2 might focus on semantic relationships (coreference, similarity). Head 3 might use positional patterns (attending to adjacent words). Each head uses different projection matrices \(\mathbf{W}_h^Q, \mathbf{W}_h^K, \mathbf{W}_h^V\), allowing it to implement a different similarity function and thus discover different relationships.&lt;/p&gt;

&lt;p&gt;Mathematically, with \(H\) heads and \(d_k = d_v = d_{\text{model}}/H\):&lt;/p&gt;

\[\text{head}_h = \text{Attention}(\mathbf{X}\mathbf{W}_h^Q, \mathbf{X}\mathbf{W}_h^K, \mathbf{X}\mathbf{W}_h^V)\]

&lt;p&gt;where \(\mathbf{W}_h^Q, \mathbf{W}_h^K \in \mathbb{R}^{d_{\text{model}} \times d_k}\) and \(\mathbf{W}_h^V \in \mathbb{R}^{d_{\text{model}} \times d_v}\). Each head produces output of dimension \(d_v\), and concatenating \(H\) heads gives dimension \(H \cdot d_v = d_{\text{model}}\), which is then projected:&lt;/p&gt;

\[\text{MultiHead}(\mathbf{X}) = [\text{head}_1; \ldots; \text{head}_H] \mathbf{W}^O\]

&lt;p&gt;where \(\mathbf{W}^O \in \mathbb{R}^{d_{\text{model}} \times d_{\text{model}}}\). This final projection integrates information from all heads, allowing them to collaborate. Without it, heads would be completely independent, potentially learning redundant patterns.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement attention mechanisms from scratch to understand every detail:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BahdanauAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Additive (Bahdanau) attention for encoder-decoder models.
    
    This was the first successful attention mechanism for neural machine
    translation. While more complex than dot-product attention, it&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s
    instructive for understanding the general attention framework.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        hidden_dim: dimension of encoder/decoder hidden states
        
        We&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll learn to project both encoder states and decoder state
        into a common space where we measure similarity.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Projection matrices
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Wa projects encoder hidden states
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Ua projects decoder state (query)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wa&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ua&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# va projects combined features to scalar score
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;va&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Compute attention weights and context vector.
        
        decoder_state: (hidden_dim, 1) - current decoder state (query)
        encoder_states: list of (hidden_dim, 1) - all encoder states (keys/values)
        
        Returns:
            context: weighted average of encoder states
            attention_weights: what we attended to (for visualization)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute score for each encoder state
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_enc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Additive scoring: v^T tanh(Wa*h_enc + Ua*s_dec)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# This is more flexible than dot product but more expensive
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;projected_enc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wa&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_enc&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;projected_dec&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Ua&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Add and pass through tanh
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;projected_enc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;projected_dec&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Project to scalar score
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;score&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;va&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;score&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Softmax to get attention weights
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Subtract max for numerical stability
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp_scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute weighted average (context vector)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_enc&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weight&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_enc&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate attention on simple translation example
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Bahdanau Attention Example: Neural Machine Translation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate encoder states for &quot;I love deep learning&quot; (4 words)
# In practice, these come from running encoder RNN
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;source_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;I&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;love&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;deep&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;learning&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create attention mechanism
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;BahdanauAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate decoder states when generating &quot;J&apos;aime l&apos;apprentissage profond&quot;
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;J&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;aime&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;apprentissage&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;profond&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights when generating each French word:&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Target&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention to source words&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;72&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Simulate decoder state for this target word
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute attention
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;compute_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Display attention distribution
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;weight_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_word&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weight_str&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The model learns to focus on relevant source words for each target word!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;In a trained model, these alignments would be much sharper.&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now implement the Transformer‚Äôs scaled dot-product attention:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScaledDotProductAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Scaled dot-product attention as used in Transformers.
    
    This is simpler and more efficient than additive attention,
    while being equally or more effective. The scaling by ‚àöd_k
    is critical for training stability.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Q: queries (seq_len_q, d_k)
        K: keys (seq_len_k, d_k)
        V: values (seq_len_v, d_v) where seq_len_k == seq_len_v
        mask: optional (seq_len_q, seq_len_k), 1 where allowed, 0 where masked
        
        Returns:
            output: (seq_len_q, d_v)
            attention_weights: (seq_len_q, seq_len_k)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Compute attention scores: Q¬∑K^T / ‚àöd_k
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is a matrix of all pairwise similarities
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (seq_len_q, seq_len_k)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Apply mask if provided
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Set masked positions to very negative (will be ~0 after softmax)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Softmax along key dimension (each query gets probability distribution over keys)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Weighted sum of values
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (seq_len_q, d_v)
&lt;/span&gt;        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Numerically stable softmax&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp_x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate self-attention
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Self-Attention Example: Building Contextualized Representations&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulated word embeddings for &quot;The cat sat&quot;
# In practice, these come from an embedding layer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Creating contextualized representations using self-attention...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create Q, K, V through linear projections (simplified: use same embeddings)
# In Transformers, these would be learned projections
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Each word queries for relevant context
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Each word offers its representation as key
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embeddings&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Each word provides its content as value
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Apply attention
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_mechanism&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ScaledDotProductAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;contextualized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_mechanism&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights (each row shows what that word attended to):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Word&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;35&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;weights_str&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights_str&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Contextualized representations incorporate information from attended words.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; representation now includes context from &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; and &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sat&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Complete PyTorch multi-head attention implementation:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Multi-head attention as used in Transformers.
    
    This implementation shows all details: splitting into heads,
    computing attention for each head in parallel, and recombining.
    Modern frameworks optimize this heavily, but understanding the
    mechanics is crucial.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; \
            &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d_model (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;) must be divisible by num_heads (&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections for Q, K, V (for all heads combined)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Why combined? GPU efficiency - single matrix multiply vs H separate ones
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output projection to integrate heads
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Scale for dot-product attention
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Split last dimension into (num_heads, d_k).
        
        Input:  (batch, seq_len, d_model)
        Output: (batch, num_heads, seq_len, d_k)
        
        This reshaping allows each head to operate independently
        on its d_k dimensional subspace.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, num_heads, seq_len, d_k)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        query, key, value: (batch, seq_len, d_model)
        mask: optional (batch, 1, seq_len, seq_len) or (batch, 1, 1, seq_len)
        
        For self-attention: query = key = value = input sequence
        For encoder-decoder: query = decoder, key = value = encoder output
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections in batch
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each word gets projected to Q, K, V spaces
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Split into multiple heads
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each head works with d_k dimensions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, num_heads, seq_len, d_k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Scaled dot-product attention for all heads in parallel
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Q¬∑K^T gives (batch, num_heads, seq_len_q, seq_len_k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply mask if provided
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;masked_fill&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Softmax to get attention weights
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each query position gets probability distribution over key positions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply attention weights to values
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;matmul&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, num_heads, seq_len, d_k)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Recombine heads
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Transpose and reshape to (batch, seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;contiguous&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Final linear projection
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;W_o&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate multi-head attention
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Multi-Head Self-Attention Example&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create multi-head attention
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Random input (simulating embedded sequence)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Self-attention: query = key = value = x
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 6, 64)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 6, 64) - same as input
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 8, 6, 6)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights: (batch, num_heads, seq_len_q, seq_len_k)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 2 batches&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 8 heads (each learns different attention pattern)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - 6√ó6 attention matrix (each query attends to all keys)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Visualize attention pattern for first batch, first head
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention pattern (batch 0, head 0):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;attn_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each row shows what that position attends to:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each row sums to 1.0: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate masked attention (causal mask for autoregressive)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Masked Self-Attention (Causal Mask for Language Modeling)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Create lower triangular mask: position i can only attend to positions ‚â§ i
    
    This prevents information leakage from future tokens during training
    of autoregressive models like GPT.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tril&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 1 where allowed, 0 where masked
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;causal_mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Causal mask (1 = allowed, 0 = masked future):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Apply masked attention
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_masked&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Masked attention weights (batch 0, head 0):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;attn_masked_matrix&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_masked&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detach&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attn_masked_matrix&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;round&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Notice: Future positions (upper triangle) have zero attention weight!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Each position only attends to current and previous positions.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Complete example showing attention in sequence-to-sequence:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq2SeqWithAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Sequence-to-sequence model with attention mechanism.
    
    Demonstrates encoder-decoder attention (decoder attending to encoder)
    which is different from self-attention. This was the original
    use case for attention mechanisms.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Encoder: embedding + LSTM
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder_embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;encoder_lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder: embedding + LSTM + attention + output
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_embedding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoder_lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedding_dim&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                    &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Attention mechanism (decoder queries encoder)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output projection
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_proj&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_dim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Encode source sequence.
        src: (batch, src_len) token indices
        
        Returns all encoder hidden states for attention
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;embedded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encoder_lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;decode_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        One decoder step with attention.
        
        tgt_token: (batch, 1) current target token
        decoder_state: (h, c) decoder LSTM state
        encoder_outputs: (batch, src_len, hidden_dim) to attend to
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Embed target token
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;embedded&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder_embedding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tgt_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, 1, embedding_dim)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Compute attention over encoder outputs
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Query: current decoder state (use h from LSTM state)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Keys/Values: encoder outputs
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;query&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, 1, hidden_dim)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;query&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                               &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Combine embedded input with context from attention
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;lstm_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;embedded&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;context&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decoder LSTM step
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decoder_lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Project to vocabulary
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;output_proj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;new_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn_weights&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Full forward pass for training.
        Teacher forcing: use true target tokens as decoder inputs
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Encode source
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;encode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize decoder state with encoder&apos;s final state
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_state&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Decode target sequence (teacher forcing)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_proj&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_features&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tgt_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Use true target token at this step (teacher forcing)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;tgt_token&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Decoder step with attention
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;decode_step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;tgt_token&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoder_state&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;encoder_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sequence-to-Sequence with Attention&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;src_vocab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tgt_vocab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;120&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Seq2SeqWithAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simulate translation: source [12, 34, 56, 78] ‚Üí target [23, 45, 67]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;src_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch of 2, length 4
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch of 2, length 3
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Source shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;src&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 4)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Target shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 3)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 3, 120)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Model uses attention to focus on relevant source words for each target word!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The relationship between attention mechanisms and human cognitive attention provides useful but imperfect analogies. When humans read, we don‚Äôt process all words equally‚Äîwe focus on content-bearing words, skim over function words, and our eye movements reflect this selective attention. When listening, we focus on the speaker while filtering out background noise. Attention in neural networks captures this principle of selective processing, though the mechanism is quite different from biological attention. The neural attention is soft (weights sum to 1 rather than hard selection) and learned (discovered through backpropagation rather than evolved through biology). These differences matter: soft attention allows gradient flow through all paths (essential for learning), while hard attention would require reinforcement learning to train.&lt;/p&gt;

&lt;p&gt;The connection between attention and memory systems is profound. In computer architecture, attention is analogous to content-addressable memory: we query memory based on content similarity rather than fixed addresses. The keys serve as memory addresses, values as memory content, and queries specify what we‚Äôre looking for. This parallel extends to database systems where queries select relevant records based on key matching. Understanding attention through this lens helps clarify why the query-key-value decomposition is natural: it mirrors how we retrieve information from any indexed collection.&lt;/p&gt;

&lt;p&gt;Attention mechanisms have interesting relationships to traditional machine learning techniques. The attention weights, computed through softmax over similarities, resemble kernel methods in classical machine learning where we compute weighted combinations based on similarity kernels. The difference is that attention learns the similarity function (through the query and key projections) rather than using a fixed kernel like RBF. This learned similarity is more flexible, adapting to task-specific notions of relevance. Understanding this connection helps appreciate attention as part of a longer tradition of similarity-based learning, not an isolated invention.&lt;/p&gt;

&lt;p&gt;The evolution from basic attention to self-attention to multi-head self-attention shows progressive generalization. Basic encoder-decoder attention allows decoder to query encoder‚Äîa one-directional relationship. Self-attention allows all positions to query each other‚Äîany element can attend to any other. Multi-head self-attention computes multiple independent attention patterns‚Äîdifferent heads can specialize in different relationship types. This progression from specific to general made attention increasingly powerful and versatile, ultimately enabling its use as the sole mechanism for sequence processing in Transformers.&lt;/p&gt;

&lt;p&gt;Attention‚Äôs relationship to convolutional operations provides another perspective. Standard convolution uses fixed, learned kernels applied uniformly across the input. Attention can be viewed as dynamic, input-dependent convolution where the kernel (attention weights) changes based on content. A 1√ó1 convolution in CNNs is nearly equivalent to attention with query equal to keys (all positions attend equally), while attention with learned queries allows focus to vary by position and context. This connection helps understand why Vision Transformers work‚Äîattention generalizes convolution‚Äôs ability to process spatial structure while adding dynamic, context-dependent weighting.&lt;/p&gt;

&lt;p&gt;Finally, attention connects to the broader theme of routing information in neural networks. Skip connections in ResNets route information around layers. Gating in LSTMs routes information through or around the cell state update. Attention routes information from source positions to target positions with learned weights. This routing perspective suggests attention is part of a general pattern: neural networks need mechanisms to selectively pass information through different paths based on content, and learned gating (whether through attention weights, LSTM gates, or other mechanisms) is the standard solution. Understanding this pattern helps recognize when attention-like mechanisms might be useful in novel architectures.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.0473&quot;&gt;‚ÄúNeural Machine Translation by Jointly Learning to Align and Translate‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio&lt;br /&gt;
This is THE paper that introduced attention mechanisms to neural networks and transformed sequence-to-sequence learning. Bahdanau and colleagues identified the bottleneck problem in encoder-decoder models‚Äîcompressing the entire source sentence into a single fixed-size vector‚Äîand proposed attention as the solution. Their key insight was to let the decoder access all encoder hidden states and learn to weight them based on relevance to the current decoding step. The paper demonstrated dramatic improvements in machine translation, particularly for longer sentences where the bottleneck was most severe. What makes this paper historically significant is not just the performance gains but the general principle it established: neural networks can learn to selectively focus on relevant information through differentiable mechanisms. This principle has been applied far beyond translation to attention mechanisms in image captioning, reading comprehension, speech recognition, and ultimately to self-attention in Transformers. The attention visualization showing alignment between source and target words provided unprecedented interpretability, demonstrating that neural networks could discover linguistic correspondences without explicit supervision.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1508.04025&quot;&gt;‚ÄúEffective Approaches to Attention-based Neural Machine Translation‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Minh-Thang Luong, Hieu Pham, Christopher D. Manning&lt;br /&gt;
Introduced shortly after Bahdanau attention, this paper systematically explored attention mechanism design choices and proposed simpler alternatives. Luong attention uses dot-product similarity (\(\mathbf{q}^T \mathbf{k}\)) or general multiplicative (\(\mathbf{q}^T \mathbf{W} \mathbf{k}\)) instead of Bahdanau‚Äôs additive formulation, showing these simpler mechanisms often perform better while being more computationally efficient. The paper also distinguished between global attention (attending to all source positions) and local attention (attending to a window around an aligned position), providing options for different computation-accuracy tradeoffs. The careful empirical comparison methodology established best practices for evaluating attention variants. Luong‚Äôs dot-product attention, particularly the scaled version, became the foundation for Transformer attention, showing how systematic exploration of architectural choices leads to better designs. The paper also demonstrated that attention could be applied at different granularities (word-level, character-level) and in different configurations (input-feeding, where attention is fed back into the decoder), expanding understanding of attention‚Äôs versatility.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.03044&quot;&gt;‚ÄúShow, Attend and Tell: Neural Image Caption Generation with Visual Attention‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron Courville, Ruslan Salakhutdinov, Richard Zemel, Yoshua Bengio&lt;br /&gt;
This paper extended attention from NLP to computer vision, using attention to focus on different image regions when generating different caption words. When generating ‚Äúred‚Äù in ‚ÄúA red car is parked,‚Äù the model learns to attend to the car‚Äôs color; when generating ‚Äúparked,‚Äù it attends to the scene context. The paper introduced both soft attention (differentiable weighted average, trainable with backpropagation) and hard attention (stochastic selection of single position, requiring reinforcement learning). It demonstrated that attention mechanisms are not domain-specific but represent a general principle applicable wherever selective focus is beneficial. The visualizations showing attention maps overlaid on images provided compelling evidence that the model was learning meaningful correspondences between visual content and language. This work inspired attention applications across modalities and contributed to the eventual development of vision-and-language models like CLIP and multimodal Transformers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;‚ÄúAttention is All You Need‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, ≈Åukasz Kaiser, Illia Polosukhin&lt;br /&gt;
While primarily introducing the Transformer, this paper‚Äôs treatment of attention mechanisms themselves was transformative. The authors showed that self-attention‚Äîattention within a single sequence‚Äîcould replace recurrence entirely, not just augment it. The scaled dot-product attention formulation with the \(1/\sqrt{d_k}\) scaling became standard. Multi-head attention, allowing multiple attention patterns to be learned in parallel, addressed the limitation of single-head attention‚Äôs inability to capture multiple relationship types simultaneously. The paper demonstrated that attention‚Äôs computational properties (fully parallelizable, constant path length between any positions) could be advantages rather than just supplements to recurrent processing. The success of Transformers established attention not as a useful addition to RNNs but as a standalone mechanism sufficient for sequence processing, fundamentally changing how the field approaches sequential data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1803.02155&quot;&gt;‚ÄúSelf-Attention with Relative Position Representations‚Äù (2018)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Peter Shaw, Jakob Uszkoreit, Ashish Vaswani&lt;br /&gt;
This paper addressed a limitation of standard Transformer attention: the reliance on absolute positional encodings added before attention. Shaw and colleagues proposed incorporating relative position information directly into the attention mechanism itself, making attention weights depend not just on content but on the distance between positions. This allows the model to learn patterns like ‚Äúattend to the word 2 positions before‚Äù more naturally than with absolute positions. The paper showed improved performance on translation and other tasks, and relative position encodings have been adopted in many Transformer variants (T5, Transformer-XL). The work illustrates how even after a major architectural innovation (Transformers), refinements addressing subtle limitations continue to improve performance. It also demonstrates the principle that inductive biases (like position matters) should be incorporated where they‚Äôre most relevant (in the attention mechanism itself) rather than through separate mechanisms (positional encodings), when possible.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;A fundamental mistake when implementing attention is forgetting to apply softmax to the attention scores, using raw similarity scores as weights instead. Without softmax normalization, the weighted sum \(\sum_i e_i \mathbf{v}_i\) grows with the number of keys (since we‚Äôre summing more terms), making the context vector‚Äôs magnitude dependent on sequence length. Softmax ensures weights sum to 1, creating a weighted average rather than weighted sum, so context magnitude is independent of sequence length. This normalization is not optional‚Äîit‚Äôs essential for stable training and meaningful interpretation of attention weights as probabilities.&lt;/p&gt;

&lt;p&gt;Another common error is applying masking incorrectly. When using masks to prevent attention to certain positions (padding or future positions), we must set masked positions to \(-\infty\) (or a very large negative number like -1e9) before softmax, not to 0 after softmax. Setting post-softmax weights to 0 doesn‚Äôt affect the gradients properly during backpropagation because the softmax computation graph still includes the masked positions. Setting pre-softmax scores to \(-\infty\) ensures both that the position receives zero weight (since \(\exp(-\infty) = 0\)) and that gradients flow correctly during backpropagation.&lt;/p&gt;

&lt;p&gt;The scaling in scaled dot-product attention is frequently omitted in naive implementations, causing subtle training issues. Without dividing by \(\sqrt{d_k}\), dot products have variance proportional to \(d_k\). For large dimensions (512, 1024), this pushes values into softmax saturation regions where one position gets nearly all attention weight and gradients vanish. The model fails to learn distributed attention patterns and may not train at all. The \(\sqrt{d_k}\) scaling is not a minor detail but essential for stable training with high-dimensional representations.&lt;/p&gt;

&lt;p&gt;When implementing multi-head attention, a common bug is not properly splitting and recombining dimensions. The reshaping operations‚Äîsplitting \(d_{\text{model}}\) into \((\text{num\_heads}, d_k)\), computing attention, then concatenating back to \(d_{\text{model}}\)‚Äîmust preserve the batch and sequence dimensions while shuffling the feature dimension. Getting the transpose and reshape operations in the wrong order produces tensors of correct shape but with scrambled data. Always verify with small examples that information flows correctly: a simple test is checking that with query = key = value and no mask, the output equals the input (identity attention).&lt;/p&gt;

&lt;p&gt;A powerful technique for understanding what attention has learned is visualizing attention weights as heatmaps. For encoder-decoder attention in translation, plot source words on one axis, target words on the other, with heatmap intensity showing attention weight. This reveals learned alignments‚Äîwhich source words the model focuses on when generating each target word. For self-attention, the \(n \times n\) matrix shows which positions attend to which other positions. Patterns that emerge‚Äîattention to nearby words, attention from pronouns to their antecedents, attention across syntactic dependencies‚Äîprovide insight into what linguistic structure the model has discovered. This interpretability is one of attention‚Äôs major advantages over black-box RNN hidden states.&lt;/p&gt;

&lt;p&gt;For computational efficiency with very long sequences, consider sparse attention patterns. Full attention requires \(O(n^2)\) memory and computation where \(n\) is sequence length. For sequences of thousands of tokens (documents, long-form text), this becomes prohibitive. Sparse attention restricts each position to attend to only a subset of positions (e.g., local window plus strided positions), reducing complexity to \(O(n\sqrt{n})\) or even \(O(n)\) while maintaining ability to capture long-range dependencies through multiple layers. Understanding when full attention is necessary versus when sparse patterns suffice helps choose appropriate architectures for different sequence length regimes.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Attention mechanisms enable neural networks to selectively focus on relevant parts of the input when making predictions, solving the fixed-size bottleneck problem of encoder-decoder models and providing interpretability through visualizable attention weights. The core mathematical framework‚Äîcomputing queries, keys, and values, measuring similarity between queries and keys, using softmax to convert similarities to weights, and computing weighted averages of values‚Äîis general enough to apply across domains and tasks. Scaled dot-product attention combines simplicity, efficiency, and effectiveness, scaling similarity scores by \(\sqrt{d_k}\) to maintain reasonable magnitudes regardless of dimensionality. Multi-head attention allows learning multiple attention patterns simultaneously, with different heads discovering different types of relationships (syntactic, semantic, positional) through their separate learned projections. Self-attention applies attention within sequences rather than between encoder and decoder, enabling each position to build representations incorporating information from all other positions with constant path length for information flow. Masking controls which positions can be attended to, enabling both handling of variable-length sequences (padding masks) and autoregressive generation (causal masks). The transition from attention as an augmentation to RNNs to attention as the sole mechanism in Transformers demonstrates how an idea can evolve from useful addition to foundational principle, ultimately transforming an entire field by enabling architectures that are simultaneously more powerful, more interpretable, and more efficient to train than their predecessors.&lt;/p&gt;

&lt;p&gt;Attention is not just a technical mechanism but a paradigm shift in how we think about neural network architectures: from fixed processing pipelines to dynamic, learned routing of information based on relevance and context.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>07-01 Attention Mechanism Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_01_Attention_Basics/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter07/07_01_Attention_Basics</id>
   <content type="html">&lt;h2 id=&quot;motivation-the-bottleneck-problem&quot;&gt;Motivation: The Bottleneck Problem&lt;/h2&gt;

&lt;p&gt;In seq2seq models (encoder-decoder), the encoder compresses entire input into a fixed-size vector:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input: &quot;The cat sat on the mat&quot; ‚Üí Encoder ‚Üí [fixed vector] ‚Üí Decoder ‚Üí Output
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Fixed vector is a bottleneck for long sequences!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: &lt;strong&gt;Attention&lt;/strong&gt; - Let decoder ‚Äúlook at‚Äù all encoder outputs, focusing on relevant parts.&lt;/p&gt;

&lt;h2 id=&quot;attention-intuition&quot;&gt;Attention Intuition&lt;/h2&gt;

&lt;p&gt;When translating ‚ÄúThe cat sat on the mat‚Äù to French:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Translating ‚Äúchat‚Äù ‚Üí Focus on ‚Äúcat‚Äù&lt;/li&gt;
  &lt;li&gt;Translating ‚Äúassis‚Äù ‚Üí Focus on ‚Äúsat‚Äù&lt;/li&gt;
  &lt;li&gt;Translating ‚Äútapis‚Äù ‚Üí Focus on ‚Äúmat‚Äù&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Attention computes how much to focus on each input position.&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;bahdanau-attention-additive-attention&quot;&gt;Bahdanau Attention (Additive Attention)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Components&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Encoder outputs: \(\mathbf{h}_1, \mathbf{h}_2, \ldots, \mathbf{h}_T\)&lt;/li&gt;
  &lt;li&gt;Decoder state: \(\mathbf{s}_t\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Compute Alignment Scores&lt;/strong&gt; (how much attention to pay):&lt;/p&gt;

\[e_{t,i} = v_a^T \tanh(\mathbf{W}_a \mathbf{s}_t + \mathbf{U}_a \mathbf{h}_i)\]

&lt;p&gt;&lt;strong&gt;2. Compute Attention Weights&lt;/strong&gt; (normalize scores):&lt;/p&gt;

\[\alpha_{t,i} = \frac{\exp(e_{t,i})}{\sum_{j=1}^{T} \exp(e_{t,j})}\]

&lt;p&gt;Note: \(\sum_{i=1}^{T} \alpha_{t,i} = 1\) (probability distribution)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Compute Context Vector&lt;/strong&gt; (weighted sum):&lt;/p&gt;

\[\mathbf{c}_t = \sum_{i=1}^{T} \alpha_{t,i} \mathbf{h}_i\]

&lt;p&gt;&lt;strong&gt;4. Combine with Decoder State&lt;/strong&gt;:&lt;/p&gt;

\[\tilde{\mathbf{s}}_t = \tanh(\mathbf{W}_c [\mathbf{c}_t; \mathbf{s}_t])\]

&lt;h2 id=&quot;luong-attention-multiplicative-attention&quot;&gt;Luong Attention (Multiplicative Attention)&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Simpler scoring functions&lt;/strong&gt;:&lt;/p&gt;

&lt;h3 id=&quot;dot-product&quot;&gt;Dot Product:&lt;/h3&gt;
&lt;p&gt;\(e_{t,i} = \mathbf{s}_t^T \mathbf{h}_i\)&lt;/p&gt;

&lt;h3 id=&quot;general-with-weight-matrix&quot;&gt;General (with weight matrix):&lt;/h3&gt;
&lt;p&gt;\(e_{t,i} = \mathbf{s}_t^T \mathbf{W}_a \mathbf{h}_i\)&lt;/p&gt;

&lt;h3 id=&quot;concatenation&quot;&gt;Concatenation:&lt;/h3&gt;
&lt;p&gt;\(e_{t,i} = \mathbf{v}_a^T \tanh(\mathbf{W}_a [\mathbf{s}_t; \mathbf{h}_i])\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;More efficient&lt;/strong&gt; than Bahdanau for dot product version.&lt;/p&gt;

&lt;h2 id=&quot;self-attention&quot;&gt;Self-Attention&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Key innovation&lt;/strong&gt;: Attention within the same sequence!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For each position&lt;/strong&gt;, compute attention over all positions (including itself).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Understanding ‚Äúit‚Äù in ‚ÄúThe animal didn‚Äôt cross the street because it was too tired‚Äù&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;‚Äúit‚Äù attends to ‚Äúanimal‚Äù (high attention)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;scaled-dot-product-attention&quot;&gt;Scaled Dot-Product Attention&lt;/h3&gt;

&lt;p&gt;Given:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Query&lt;/strong&gt; \(\mathbf{Q}\): What I‚Äôm looking for&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key&lt;/strong&gt; \(\mathbf{K}\): What I have to offer&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Value&lt;/strong&gt; \(\mathbf{V}\): The actual content&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Formula&lt;/strong&gt;:&lt;/p&gt;

\[\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}}\right) \mathbf{V}\]

&lt;p&gt;where \(d_k\) is dimension of keys (for numerical stability).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Steps&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Compute similarity: \(\mathbf{Q}\mathbf{K}^T\) (query-key dot products)&lt;/li&gt;
  &lt;li&gt;Scale: divide by \(\sqrt{d_k}\)&lt;/li&gt;
  &lt;li&gt;Normalize: softmax to get attention weights&lt;/li&gt;
  &lt;li&gt;Weight values: multiply by \(\mathbf{V}\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Q: queries (seq_len_q, d_k)
    K: keys (seq_len_k, d_k)
    V: values (seq_len_v, d_v)  where seq_len_k = seq_len_v
    mask: optional mask for padding/future positions
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute attention scores
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Apply mask if provided (set masked positions to -inf)
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;not&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Softmax to get attention weights
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scores&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Weight the values
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;d_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (4, 64)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (4, 4)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention weights sum: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# [1, 1, 1, 1]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;multi-head-attention&quot;&gt;Multi-Head Attention&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Idea&lt;/strong&gt;: Multiple attention ‚Äúheads‚Äù learn different aspects of relationships.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Head 1: Syntactic relationships&lt;/li&gt;
  &lt;li&gt;Head 2: Semantic relationships&lt;/li&gt;
  &lt;li&gt;Head 3: Positional relationships&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Formula&lt;/strong&gt;:&lt;/p&gt;

\[\text{MultiHead}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h) \mathbf{W}^O\]

&lt;p&gt;where&lt;/p&gt;

\[\text{head}_i = \text{Attention}(\mathbf{Q}\mathbf{W}_i^Q, \mathbf{K}\mathbf{W}_i^K, \mathbf{V}\mathbf{W}_i^V)\]

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\mathbf{W}_i^Q, \mathbf{W}_i^K \in \mathbb{R}^{d_{model} \times d_k}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\mathbf{W}_i^V \in \mathbb{R}^{d_{model} \times d_v}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\mathbf{W}^O \in \mathbb{R}^{hd_v \times d_{model}}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Typically: \(d_k = d_v = d_{model} / h\)&lt;/p&gt;

&lt;h3 id=&quot;implementation-1&quot;&gt;Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_o&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Split last dimension into (num_heads, d_k)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, num_heads, seq_len, d_k)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Linear projections
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_q&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, seq_len, d_model)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_k&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_v&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Split into multiple heads
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, num_heads, seq_len, d_k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;split_heads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Scaled dot-product attention for each head
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;scaled_dot_product_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;K&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;V&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Concatenate heads
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;transpose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, seq_len, num_heads, d_k)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Final linear projection
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;attention_output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_o&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;MultiHeadAttention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d_model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_heads&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Self-attention
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (2, 10, 512)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;types-of-attention&quot;&gt;Types of Attention&lt;/h2&gt;

&lt;h3 id=&quot;1-self-attention&quot;&gt;1. Self-Attention&lt;/h3&gt;
&lt;p&gt;Q, K, V all from same source&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use&lt;/strong&gt;: Understanding relationships within a sequence&lt;/p&gt;

&lt;h3 id=&quot;2-cross-attention-encoder-decoder-attention&quot;&gt;2. Cross-Attention (Encoder-Decoder Attention)&lt;/h3&gt;
&lt;p&gt;Q from decoder, K and V from encoder&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use&lt;/strong&gt;: Machine translation, image captioning&lt;/p&gt;

&lt;h3 id=&quot;3-masked-attention&quot;&gt;3. Masked Attention&lt;/h3&gt;
&lt;p&gt;Prevent attending to future positions&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use&lt;/strong&gt;: Autoregressive generation (language modeling)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create mask that prevents attending to future positions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;triu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 1 where we should mask (future), 0 where we can attend
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;mask&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_causal_mask&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# [[0, 1, 1, 1],
#  [0, 0, 1, 1],
#  [0, 0, 0, 1],
#  [0, 0, 0, 0]]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;attention-visualization&quot;&gt;Attention Visualization&lt;/h2&gt;

&lt;p&gt;Attention weights can be visualized as heatmaps:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;visualize_attention&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    attention_weights: (target_len, source_len)
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;figure&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;imshow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;attention_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cmap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;viridis&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;aspect&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;auto&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;colorbar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;source_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;source_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rotation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;yticks&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target_words&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Source&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Target&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attention Weights&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;advantages-of-attention&quot;&gt;Advantages of Attention&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;No fixed-length bottleneck&lt;/strong&gt;: Can attend to entire input&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Long-range dependencies&lt;/strong&gt;: Direct connections between any positions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpretability&lt;/strong&gt;: Can visualize what model focuses on&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parallelization&lt;/strong&gt;: Unlike RNNs, can compute all attentions in parallel&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Performance&lt;/strong&gt;: State-of-the-art results on many tasks&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Attention&lt;/strong&gt; allows models to focus on relevant parts of input&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scaled dot-product attention&lt;/strong&gt;: Core mechanism using Q, K, V&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self-attention&lt;/strong&gt;: Attention within same sequence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multi-head attention&lt;/strong&gt;: Multiple attention heads for different aspects&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Types&lt;/strong&gt;: Self-attention, cross-attention, masked attention&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Benefits&lt;/strong&gt;: Better long-range dependencies, parallelizable, interpretable&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Foundation&lt;/strong&gt; for Transformers (next chapter)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Attention is the key breakthrough that led to modern NLP models like BERT and GPT!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>07 Attention Mechanisms</title>
   <link href="http://localhost:4000/contents/en/chapter07/07_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter07/07_00_Introduction</id>
   <content type="html">&lt;p&gt;Attention mechanisms allow models to focus on relevant parts of the input when making predictions. Originally developed for sequence-to-sequence tasks like machine translation, attention has become fundamental to modern deep learning, especially in Transformers. This chapter covers attention basics, self-attention, and multi-head attention.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>06-01 Long Short-Term Memory Networks</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_01_LSTM_Architecture/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter06/06_01_LSTM_Architecture</id>
   <content type="html">&lt;h1 id=&quot;long-short-term-memory-conquering-the-vanishing-gradient&quot;&gt;Long Short-Term Memory: Conquering the Vanishing Gradient&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/9/93/LSTM_Cell.svg/800px-LSTM_Cell.svg.png&quot; alt=&quot;LSTM Cell Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: C·∫•u tr√∫c chi ti·∫øt c·ªßa m·ªôt LSTM cell v·ªõi c√°c c·ªïng ƒëi·ªÅu khi·ªÉn. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;The Long Short-Term Memory (LSTM) network represents one of the most important architectural innovations in the history of recurrent neural networks. Introduced by Hochreiter and Schmidhuber in 1997, LSTMs were specifically designed to solve the vanishing gradient problem that plagued vanilla RNNs, enabling neural networks to learn dependencies spanning hundreds or even thousands of time steps. While the architecture might seem complex at first glance with its multiple gates and cell state, each component serves a specific, carefully designed purpose in managing the flow of information through time.&lt;/p&gt;

&lt;p&gt;Understanding why LSTMs were necessary requires appreciating the fundamental challenge they address. As we saw with vanilla RNNs, gradients during backpropagation through time must pass through repeated matrix multiplications by the recurrent weight matrix and activation function derivatives. When these operations consistently suppress signals (as tanh derivatives do when activations saturate), gradients vanish exponentially with the number of time steps. This makes learning long-range dependencies‚Äîunderstanding that a word at the beginning of a paragraph influences interpretation of a sentence at the end‚Äînearly impossible for vanilla RNNs in practice.&lt;/p&gt;

&lt;p&gt;The LSTM‚Äôs solution is elegant in its core idea, though complex in execution: create explicit pathways for information to flow unchanged through time. The key innovation is the cell state, a separate pathway that runs parallel to the hidden state. The cell state can maintain information across many time steps with only minor linear interactions, avoiding the repeated nonlinear transformations that cause vanishing gradients in vanilla RNNs. Think of the cell state as a highway for information transmission through time, while the hidden state handles moment-to-moment processing.&lt;/p&gt;

&lt;p&gt;But simply having a separate cell state isn‚Äôt sufficient‚Äîwe need mechanisms to control what information enters the cell state, what information is retained or forgotten, and what information is exposed to the rest of the network. This is where gates come in. LSTMs use three types of gates‚Äîforget gates, input gates, and output gates‚Äîeach implemented as a sigmoid neural network layer that outputs values between 0 and 1. These gates act as learnable switches, determining how much information flows through different paths. The sigmoid is crucial here: it provides smooth gradients (unlike hard thresholds) while its output range [0,1] makes it interpretable as a probability or proportion‚Äîhow much to forget, how much to add, how much to output.&lt;/p&gt;

&lt;p&gt;The genius of the LSTM architecture lies in how these gates work together to create flexible, learnable memory dynamics. The forget gate can clear outdated information from the cell state. The input gate can selectively add new information. The output gate can control what parts of the cell state are exposed to the downstream network. All of this happens through learned parameters that adapt to the specific patterns in the training data. The network learns not just what to remember but when to remember, when to forget, and when to act on its memory‚Äîmeta-cognitive skills that emerge from the architecture‚Äôs inductive bias.&lt;/p&gt;

&lt;p&gt;LSTMs became enormously successful, dominating sequence modeling from the late 1990s through the mid-2010s. They enabled breakthroughs in machine translation, speech recognition, handwriting recognition, and many other sequential tasks. Even after Transformers emerged as the dominant architecture for NLP, LSTMs remain important: they use less memory than Transformers (\(O(n)\) vs \(O(n^2)\)), process sequences naturally online (unlike Transformers which typically process entire sequences), and for certain tasks with very long sequences or online processing requirements, still offer advantages. Understanding LSTMs deeply means understanding both a historically important architecture and ongoing principles about managing information flow in recurrent computations.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical formulation of LSTMs reveals how multiple components work together to create controllable memory dynamics. At each time step \(t\), an LSTM maintains two state vectors: the hidden state \(\mathbf{h}_t\) (like vanilla RNNs) and the cell state \(\mathbf{c}_t\) (the LSTM‚Äôs innovation). Given input \(\mathbf{x}_t\) and previous states \(\mathbf{h}_{t-1}\) and \(\mathbf{c}_{t-1}\), the LSTM computes new states through a carefully orchestrated sequence of operations.&lt;/p&gt;

&lt;p&gt;First, we concatenate the previous hidden state and current input into a single vector: \([\mathbf{h}_{t-1}; \mathbf{x}_t]\). This concatenation appears in all gate computations, meaning each gate considers both what‚Äôs happening now (\(\mathbf{x}_t\)) and what the network was previously thinking about (\(\mathbf{h}_{t-1}\)). This design allows gates to make contextual decisions‚Äîwhether to forget might depend on both the current input and previous context.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;forget gate&lt;/strong&gt; determines what information to discard from the cell state:&lt;/p&gt;

\[\mathbf{f}_t = \sigma(\mathbf{W}_f \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t] + \mathbf{b}_f)\]

&lt;p&gt;The sigmoid activation ensures \(\mathbf{f}_t \in (0,1)\), which we can interpret as ‚Äúproportion to keep.‚Äù When \(f_t^{(i)} \approx 1\), we keep nearly all of cell state dimension \(i\). When \(f_t^{(i)} \approx 0\), we forget nearly everything. The network learns through backpropagation when forgetting helps‚Äîfor example, when starting a new sentence, we might forget subject-verb agreement information from the previous sentence.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;input gate&lt;/strong&gt; controls what new information to add to the cell state. It consists of two parts: a gate determining how much to add, and a candidate cell state determining what to add:&lt;/p&gt;

\[\mathbf{i}_t = \sigma(\mathbf{W}_i \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t] + \mathbf{b}_i)\]

\[\tilde{\mathbf{c}}_t = \tanh(\mathbf{W}_C \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t] + \mathbf{b}_C)\]

&lt;p&gt;The candidate \(\tilde{\mathbf{c}}_t\) uses tanh to create values in \([-1, 1]\), representing potential updates to the cell state. The input gate \(\mathbf{i}_t\) then moderates how much of this candidate to actually use. This two-component design provides flexibility: the candidate can propose updates based on the input, while the gate decides whether now is the right time to update memory.&lt;/p&gt;

&lt;p&gt;The cell state update combines forgetting old information and adding new information:&lt;/p&gt;

\[\mathbf{c}_t = \mathbf{f}_t \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \tilde{\mathbf{c}}_t\]

&lt;p&gt;This equation is the heart of the LSTM. The Hadamard (element-wise) product \(\mathbf{f}_t \odot \mathbf{c}_{t-1}\) selectively retains information from the previous cell state. The second term \(\mathbf{i}_t \odot \tilde{\mathbf{c}}_t\) adds selectively chosen new information. Notice this is a weighted sum with minimal nonlinearity‚Äîjust the element-wise multiplications by the gates. Crucially, there‚Äôs no matrix multiplication by recurrent weights here, no tanh squashing the entire state. This is why gradients can flow through the cell state more easily than through vanilla RNN hidden states.&lt;/p&gt;

&lt;p&gt;The gradient flow analysis makes this explicit. When backpropagating through the cell state update:&lt;/p&gt;

\[\frac{\partial \mathbf{c}_t}{\partial \mathbf{c}_{t-1}} = \mathbf{f}_t\]

&lt;p&gt;The gradient is simply the forget gate values! If the forget gate is consistently near 1 (which the network can learn to do when long-term memory is needed), gradients flow backward through time nearly unchanged. This is a dramatic improvement over vanilla RNNs where:&lt;/p&gt;

\[\frac{\partial \mathbf{h}_t}{\partial \mathbf{h}_{t-1}} = \text{diag}(\tanh&apos;(\mathbf{z}_t)) \mathbf{W}_{hh}\]

&lt;p&gt;involves both the weight matrix and activation derivatives, typically causing exponential decay.&lt;/p&gt;

&lt;p&gt;The &lt;strong&gt;output gate&lt;/strong&gt; determines what information from the cell state to expose to the rest of the network:&lt;/p&gt;

\[\mathbf{o}_t = \sigma(\mathbf{W}_o \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t] + \mathbf{b}_o)\]

\[\mathbf{h}_t = \mathbf{o}_t \odot \tanh(\mathbf{c}_t)\]

&lt;p&gt;We apply tanh to the cell state (squashing it to \([-1,1]\)) before the output gate modulates it. Why tanh here? The cell state can grow unbounded through repeated additions, so tanh normalizes it before exposure. The output gate then decides what to show‚Äîperhaps the network has information in the cell state that‚Äôs useful for future computation but not relevant to the current output.&lt;/p&gt;

&lt;p&gt;Counting parameters reveals the cost of LSTM‚Äôs sophistication. With input dimension \(d_x\), hidden dimension \(d_h\), an LSTM has:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Forget gate: \((d_h + d_x) \times d_h + d_h\) parameters (matrix + bias)&lt;/li&gt;
  &lt;li&gt;Input gate: \((d_h + d_x) \times d_h + d_h\) parameters&lt;/li&gt;
  &lt;li&gt;Candidate: \((d_h + d_x) \times d_h + d_h\) parameters&lt;/li&gt;
  &lt;li&gt;Output gate: \((d_h + d_x) \times d_h + d_h\) parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Total: \(4[(d_h + d_x) \times d_h + d_h]\) parameters, about 4√ó more than vanilla RNN. This is the price of controllable memory‚Äîmore parameters to learn, more computation per time step, but dramatically better ability to learn long-range dependencies.&lt;/p&gt;

&lt;p&gt;The Gated Recurrent Unit (GRU), introduced by Cho et al. in 2014, simplifies LSTMs while retaining most benefits. GRUs merge the cell and hidden states, use only two gates instead of three, and have about 25% fewer parameters. The GRU equations:&lt;/p&gt;

&lt;p&gt;\(\mathbf{r}_t = \sigma(\mathbf{W}_r \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t])\) (reset gate: how much past to use)&lt;/p&gt;

&lt;p&gt;\(\mathbf{z}_t = \sigma(\mathbf{W}_z \cdot [\mathbf{h}_{t-1}; \mathbf{x}_t])\) (update gate: how much past to keep)&lt;/p&gt;

&lt;p&gt;\(\tilde{\mathbf{h}}_t = \tanh(\mathbf{W} \cdot [\mathbf{r}_t \odot \mathbf{h}_{t-1}; \mathbf{x}_t])\) (candidate hidden state)&lt;/p&gt;

&lt;p&gt;\(\mathbf{h}_t = (1 - \mathbf{z}_t) \odot \mathbf{h}_{t-1} + \mathbf{z}_t \odot \tilde{\mathbf{h}}_t\) (interpolate between old and new)&lt;/p&gt;

&lt;p&gt;The update gate \(\mathbf{z}_t\) acts like a combined forget-and-input gate, deciding how much to interpolate between the previous state and the candidate. When \(z_t^{(i)} \approx 0\), dimension \(i\) keeps its old value (like forget gate ‚âà 1, input gate ‚âà 0 in LSTM). When \(z_t^{(i)} \approx 1\), it uses the new candidate (like forget gate ‚âà 0, input gate ‚âà 1). This coupling reduces parameters while maintaining the ability to control information flow.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build genuine intuition for how LSTMs manage long-range dependencies, let‚Äôs trace through a concrete linguistic example: processing the sentence ‚ÄúThe cat, which we found in the garden, was hungry‚Äù to predict whether the verb should be singular or plural (‚Äúwas‚Äù vs ‚Äúwere‚Äù).&lt;/p&gt;

&lt;p&gt;This example is challenging for vanilla RNNs because the subject ‚Äúcat‚Äù (singular) appears early, followed by a relative clause ‚Äúwhich we found in the garden‚Äù that could mislead the model with the plural ‚Äúwe,‚Äù and only then comes the verb that must agree with ‚Äúcat.‚Äù A vanilla RNN must maintain the ‚Äúcat is singular‚Äù information through processing six intervening words, during which the hidden state undergoes six transformations that might corrupt or erase this information.&lt;/p&gt;

&lt;p&gt;Let‚Äôs trace what an LSTM might learn to do. When processing ‚Äúcat,‚Äù the input gate allows important information (this is the subject, it‚Äôs singular) to enter the cell state. The cell state now contains something like ‚Äúsubject = cat, number = singular.‚Äù As we process the relative clause, the forget gate learns to keep this subject information (\(f_t \approx 1\) for dimensions encoding subject number) while the input gate allows information about ‚Äúwe found in the garden‚Äù to enter other dimensions of the cell state. Crucially, the subject information persists nearly unchanged through these steps because the forget gate protects it.&lt;/p&gt;

&lt;p&gt;When we finally reach the position where we must generate the verb, the output gate learns to expose the subject number information from the cell state. The downstream layers can then use this information to choose ‚Äúwas‚Äù over ‚Äúwere.‚Äù The relative clause information might be gated off (\(o_t \approx 0\) for those dimensions) since it‚Äôs not relevant for verb conjugation.&lt;/p&gt;

&lt;p&gt;Let‚Äôs make this concrete with simplified numbers. Suppose our cell state has just two dimensions: subject-number and clause-context. After processing ‚Äúcat‚Äù:&lt;/p&gt;

&lt;p&gt;\(\mathbf{c}_{\text{cat}} = \begin{bmatrix} 0.9 \\ 0.1 \end{bmatrix}\) (strongly singular, little clause context)&lt;/p&gt;

&lt;p&gt;As we process ‚Äúwhich we found‚Äù (plural), the forget gate for subject-number stays high:&lt;/p&gt;

&lt;p&gt;\(\mathbf{f}_{\text{which}} = \begin{bmatrix} 0.95 \\ 0.1 \end{bmatrix}\) (keep subject info, forget old clause info)&lt;/p&gt;

&lt;p&gt;The input gate allows clause information:&lt;/p&gt;

&lt;p&gt;\(\mathbf{i}_{\text{which}} = \begin{bmatrix} 0.05 \\ 0.9 \end{bmatrix}\), \(\tilde{\mathbf{c}}_{\text{which}} = \begin{bmatrix} 0.2 \\ 0.7 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;After update:&lt;/p&gt;

\[\mathbf{c}_{\text{which}} = \begin{bmatrix} 0.95 \\ 0.1 \end{bmatrix} \odot \begin{bmatrix} 0.9 \\ 0.1 \end{bmatrix} + \begin{bmatrix} 0.05 \\ 0.9 \end{bmatrix} \odot \begin{bmatrix} 0.2 \\ 0.7 \end{bmatrix} = \begin{bmatrix} 0.865 \\ 0.64 \end{bmatrix}\]

&lt;p&gt;The subject-number information (0.865) has degraded only slightly (from 0.9), while clause context has updated. This selective preservation is what enables long-range dependencies.&lt;/p&gt;

&lt;p&gt;The three-gate design might seem overengineered, but each gate serves a distinct purpose that becomes clear when considering different linguistic phenomena. The forget gate handles context switches (new sentences, topic changes). The input gate manages relevance filtering (not all information deserves storage). The output gate controls exposure (information might be worth remembering but not worth acting on immediately). This three-way decomposition provides fine-grained control over memory dynamics that proves essential for complex sequential tasks.&lt;/p&gt;

&lt;p&gt;Comparing LSTMs to biological memory systems provides another angle of intuition. Human working memory doesn‚Äôt simply accumulate all experiences‚Äîwe forget what‚Äôs irrelevant (forget gate), selectively encode important new information (input gate), and retrieve different memories in different contexts (output gate). While LSTMs are far simpler than biological memory, they capture this fundamental principle that effective memory requires not just storage but selective reading, writing, and forgetting.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation-1&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;Let‚Äôs build up the LSTM equations systematically, understanding each component‚Äôs role in the larger system. At time step \(t\), we have inputs \(\mathbf{x}_t \in \mathbb{R}^{d_x}\), previous hidden state \(\mathbf{h}_{t-1} \in \mathbb{R}^{d_h}\), and previous cell state \(\mathbf{c}_{t-1} \in \mathbb{R}^{d_h}\). We‚Äôll compute new states \(\mathbf{h}_t\) and \(\mathbf{c}_t\) through the following sequence of operations.&lt;/p&gt;

&lt;p&gt;First, all gates operate on the concatenation \([\mathbf{h}_{t-1}; \mathbf{x}_t] \in \mathbb{R}^{d_h + d_x}\). Let‚Äôs define this explicitly:&lt;/p&gt;

\[\mathbf{z}_t = [\mathbf{h}_{t-1}; \mathbf{x}_t]\]

&lt;p&gt;Now the forget gate computation:&lt;/p&gt;

\[\mathbf{f}_t = \sigma(\mathbf{W}_f \mathbf{z}_t + \mathbf{b}_f)\]

&lt;p&gt;where \(\mathbf{W}_f \in \mathbb{R}^{d_h \times (d_h + d_x)}\) and \(\mathbf{b}_f \in \mathbb{R}^{d_h}\). The sigmoid ensures each component of \(\mathbf{f}_t\) lies in \((0, 1)\). We can think of \(f_t^{(i)}\) as the probability of retaining information in cell state dimension \(i\). In practice, forget gates often learn to stay near 1 for most dimensions most of the time, occasionally dropping to near 0 when the network decides to clear memory for that dimension.&lt;/p&gt;

&lt;p&gt;The input gate and candidate computation happen in parallel:&lt;/p&gt;

\[\mathbf{i}_t = \sigma(\mathbf{W}_i \mathbf{z}_t + \mathbf{b}_i)\]

\[\tilde{\mathbf{c}}_t = \tanh(\mathbf{W}_C \mathbf{z}_t + \mathbf{b}_C)\]

&lt;p&gt;The candidate \(\tilde{\mathbf{c}}_t\) uses tanh, producing values in \((-1, 1)\), representing proposed updates to the cell state. These could be positive (add information) or negative (subtract, though this is less common). The input gate \(\mathbf{i}_t\) moderates how much of the candidate to actually add. When processing important information (like a sentence‚Äôs subject), the input gate opens (\(i_t^{(i)} \approx 1\)) to store it. For filler words or irrelevant information, the gate closes (\(i_t^{(i)} \approx 0\)).&lt;/p&gt;

&lt;p&gt;The cell state update is where information actually flows through time:&lt;/p&gt;

\[\mathbf{c}_t = \mathbf{f}_t \odot \mathbf{c}_{t-1} + \mathbf{i}_t \odot \tilde{\mathbf{c}}_t\]

&lt;p&gt;Let‚Äôs analyze this equation‚Äôs gradient properties carefully. When computing \(\frac{\partial \mathbf{c}_t}{\partial \mathbf{c}_{t-1}}\):&lt;/p&gt;

\[\frac{\partial \mathbf{c}_t}{\partial \mathbf{c}_{t-1}} = \mathbf{f}_t\]

&lt;p&gt;This is elementwise‚Äîthe gradient for dimension \(i\) is simply \(f_t^{(i)}\). If the network keeps \(f_t^{(i)} = 0.99\) consistently across \(T\) time steps, the gradient for that dimension is \((0.99)^T\), which for \(T=100\) is about 0.37‚Äîsubstantial retention compared to vanilla RNN where it might be \(10^{-30}\). And the network can learn to keep \(f_t^{(i)}\) near 1 exactly when long-range memory is needed for dimension \(i\).&lt;/p&gt;

&lt;p&gt;Contrast this with vanilla RNN where:&lt;/p&gt;

\[\frac{\partial \mathbf{h}_t}{\partial \mathbf{h}_{t-1}} = \text{diag}(\tanh&apos;(\mathbf{z}_t)) \mathbf{W}_{hh}\]

&lt;p&gt;The derivative involves both the weight matrix (potentially poorly conditioned with eigenvalues far from 1) and \(\tanh&apos;\) which is typically much less than 1 when activations are saturated. The LSTM‚Äôs direct path through the cell state, controlled by learned gates, provides much more stable gradient flow.&lt;/p&gt;

&lt;p&gt;The output gate and hidden state computation:&lt;/p&gt;

\[\mathbf{o}_t = \sigma(\mathbf{W}_o \mathbf{z}_t + \mathbf{b}_o)\]

\[\mathbf{h}_t = \mathbf{o}_t \odot \tanh(\mathbf{c}_t)\]

&lt;p&gt;We squash the cell state with tanh before exposing it. Why? The cell state can grow unbounded through repeated additions (imagine \(c_t = c_{t-1} + 0.1\) for 1000 steps gives \(c_{1000} = 100\)), so tanh normalizes it to \([-1,1]\) before downstream layers process it. The output gate then selectively exposes parts of this normalized cell state based on what‚Äôs relevant for current processing.&lt;/p&gt;

&lt;p&gt;The complete LSTM involves four sets of weights (\(\mathbf{W}_f, \mathbf{W}_i, \mathbf{W}_C, \mathbf{W}_o\)) each of size \(d_h \times (d_h + d_x)\), plus four bias vectors, totaling \(4[d_h(d_h + d_x) + d_h]\) parameters. The computational cost per time step is \(O(d_h^2 + d_h d_x)\), about 4√ó that of vanilla RNN. This is the tradeoff: more computation and parameters buy better gradient flow and longer-range dependency learning.&lt;/p&gt;

&lt;p&gt;GRUs simplify this by combining forget and input gates into a single update gate \(\mathbf{z}_t\), and using a reset gate \(\mathbf{r}_t\) to control how much previous hidden state influences the candidate:&lt;/p&gt;

\[\mathbf{r}_t = \sigma(\mathbf{W}_r [\mathbf{h}_{t-1}; \mathbf{x}_t])\]

\[\mathbf{z}_t = \sigma(\mathbf{W}_z [\mathbf{h}_{t-1}; \mathbf{x}_t])\]

\[\tilde{\mathbf{h}}_t = \tanh(\mathbf{W} [\mathbf{r}_t \odot \mathbf{h}_{t-1}; \mathbf{x}_t])\]

\[\mathbf{h}_t = (1 - \mathbf{z}_t) \odot \mathbf{h}_{t-1} + \mathbf{z}_t \odot \tilde{\mathbf{h}}_t\]

&lt;p&gt;The update gate \(\mathbf{z}_t\) interpolates between keeping the old hidden state and using the new candidate. When \(z_t^{(i)} = 0\), dimension \(i\) copies the previous value (like LSTM with \(f_t^{(i)} = 1, i_t^{(i)} = 0\)). When \(z_t^{(i)} = 1\), it uses the new candidate (like \(f_t^{(i)} = 0, i_t^{(i)} = 1\)). The coupling of forget and input into a single gate reduces parameters while maintaining control over memory.&lt;/p&gt;

&lt;p&gt;The reset gate \(\mathbf{r}_t\) modulates how much previous hidden state influences the candidate computation. When \(r_t^{(i)} = 0\), the candidate ignores previous state for dimension \(i\), essentially ‚Äúresetting‚Äù that dimension. This allows the network to forget when appropriate while computing new representations from input alone.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement LSTM from scratch to understand every operation, then compare with PyTorch‚Äôs optimized version:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMCell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Single LSTM cell implementing one time step of computation.
    
    This implementation makes every operation explicit. Modern frameworks
    fuse these operations for efficiency, but our goal is understanding,
    not speed. We&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll see exactly how gates modulate information flow.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Initialize LSTM cell with careful weight initialization.
        
        We use Xavier/Glorot initialization scaled for sigmoid and tanh.
        This initialization scheme was specifically designed to maintain
        reasonable activation and gradient scales, preventing both vanishing
        and explosion early in training.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Combined input dimension (hidden + input)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize weights for four gates
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Using Xavier initialization: scale by 1/‚àö(combined_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize biases
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Forget gate bias often initialized to 1 to encourage remembering initially
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is called &quot;forget bias trick&quot; - start by remembering everything
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Start with high forget gate!
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Numerically stable sigmoid&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                       &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                       &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        One LSTM time step.
        
        x_t: current input (input_size, 1)
        h_prev: previous hidden state (hidden_size, 1)
        c_prev: previous cell state (hidden_size, 1)
        
        Returns:
            h_t: new hidden state
            c_t: new cell state
            gates: dictionary of gate values (for analysis/debugging)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Concatenate previous hidden state and current input
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This combined vector influences all gates
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;vstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute all gates
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each gate is a learned sigmoid function of the combined input
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;f_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wf&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Forget gate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;i_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Input gate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;C_tilde&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;WC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Candidate values
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;o_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wo&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bo&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Output gate
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Update cell state: forget old, add new
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is THE key equation of LSTM
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Notice: minimal nonlinearity, mostly linear combination
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;c_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C_tilde&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute new hidden state from cell state
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# tanh squashes unbounded cell state to [-1, 1]
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# output gate modulates what&apos;s exposed
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Return states and gates (gates useful for visualization/debugging)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;forget&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;f_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;o_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
            &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;candidate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;C_tilde&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Full LSTM network for sequence processing.
    
    Wraps LSTMCell to process entire sequences, maintaining states across
    time steps. This is the complete LSTM as used in practice.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cell&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMCell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output projection (maps hidden state to predictions)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Process entire sequence.
        
        inputs: list of input vectors [x_1, ..., x_T]
        return_sequences: if True, return outputs at all time steps
                         if False, return only final output
        
        Returns:
            outputs: predictions at each time step (if return_sequences=True)
                     or just final prediction (if False)
            hidden_states: all hidden states [h_0, ..., h_T]
            cell_states: all cell states [c_0, ..., c_T]
            all_gates: gate values at each time step (for analysis)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Initialize states to zero
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Track evolution through time
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cell_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Process sequence step by step
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# LSTM cell update
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cell_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute output from hidden state
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;y_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cell_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# For sequence classification, use only final output
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cell_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate LSTM learning long-range dependencies
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;LSTM: Learning Long-Range Dependencies&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create task requiring long-term memory
# Remember first number, ignore middle numbers, predict first + last
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_memory_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Task: Given sequence [a, x, x, x, ..., x, b], predict a + b
    
    This requires remembering &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; across seq_length-2 intervening values,
    exactly the kind of long-range dependency vanilla RNNs struggle with.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;targets_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Random first and last numbers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Fill middle with noise
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;first&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;last&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;targets_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_list&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create LSTM and data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_memory_task&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_samples&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Simple training loop (gradient descent on small dataset)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training LSTM on long-range dependency task...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Task: Remember first number across 13 noisy numbers, add to last number&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Process each sequence
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hiddens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cells&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Loss (MSE)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# For demonstration, we&apos;ll skip the backward pass implementation
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# (BPTT for LSTM is complex - modern frameworks handle it)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# In practice, use PyTorch!
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Average Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Note: Full LSTM backpropagation is complex - use PyTorch in practice!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Let&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s see PyTorch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s implementation...&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# PyTorch LSTM implementation
&lt;/span&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    LSTM using PyTorch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s optimized implementation.
    
    PyTorch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s LSTM is highly optimized, using cuDNN kernels on GPU
    for maximum performance. It handles all the gate computations,
    state management, and backpropagation automatically.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LSTMNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# PyTorch LSTM module
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# num_layers &amp;gt; 1 stacks LSTMs (output of one feeds into next)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# dropout between layers helps regularize stacked LSTMs
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                           &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.0&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, seq_len, input_size)
        hidden: optional tuple of (h_0, c_0)
        
        Returns:
            output: (batch, seq_len, output_size) if return_sequences
                    or (batch, output_size) if not
            (h_n, c_n): final hidden and cell states
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# LSTM returns:
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# - lstm_out: hidden states at all time steps
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# - (h_n, c_n): final hidden and cell states for all layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;lstm_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Use final time step for sequence classification
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# or all time steps for sequence-to-sequence
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;final_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Last time step
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;c_n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train on memory task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training PyTorch LSTM on Long-Range Memory Task&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Convert data to tensors
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;prepare_torch_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Convert list of sequences to batched tensors&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Find max length (for padding)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Pad sequences and stack
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Convert sequence to tensor and pad
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;seq_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; 
                                  &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;flatten&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Stack into batched tensor
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (n_samples, seq_len, 1)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (n_samples, 1)
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;prepare_torch_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training data shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (200, 15, 1)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Create model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MSELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;300&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# BPTT through LSTM happens here automatically
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Gradient clipping (good practice for RNNs/LSTMs)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip_grad_norm_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test on new examples
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Testing LSTM Memory Capability&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Create test sequences
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_cases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;8.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;7.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;9.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
        &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;9.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;10.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_sum&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_cases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;unsqueeze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;First: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Last: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  True sum: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true_sum&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Predicted: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Error: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true_sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;LSTM successfully learned to remember first value across many steps!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This demonstrates its advantage over vanilla RNNs for long-range dependencies.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let‚Äôs also visualize gate activations to understand what LSTM learns:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Analyze gate behavior
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Analyzing LSTM Gate Activations&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create a simple manual LSTM to track gates
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_analyze&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create sequence: [5, noise, noise, ..., 3]
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_sequence&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;extend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rand&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;3.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Forward pass tracking all gates
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hiddens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cells&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm_analyze&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_sequence&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                                         &lt;span class=&quot;n&quot;&gt;return_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gate activations through time (showing average across hidden dimensions):&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Time | Forget | Input | Output | Cell State (avg)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;f_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;forget&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;i_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;input&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;o_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;c_avg&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cells&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Cell state magnitude
&lt;/span&gt;    
    &lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &amp;lt;-- Important input&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;all_gates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f_avg&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i_avg&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;o_avg&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  | &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;c_avg&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;marker&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Observations:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Forget gate often stays high (~0.9-1.0) to maintain memory&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Input gate opens for important inputs (first and last values)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Output gate controls what information is exposed&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;- Cell state accumulates information, maintaining magnitude&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now implement GRU for comparison:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GRUCell&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    GRU cell - simpler alternative to LSTM.
    
    GRU merges cell and hidden states, uses only 2 gates (vs LSTM&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s 3),
    resulting in ~25% fewer parameters. Often performs comparably to LSTM
    while being faster to train and easier to tune.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Two gates instead of three
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Reset
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Update
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;scale&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Candidate
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;br&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        GRU has no separate cell state - simpler!
        
        Returns only new hidden state (which serves as both hidden and cell state)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;vstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Reset gate: how much past to use for candidate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;r_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;br&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Update gate: how much to interpolate old vs new
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bz&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Candidate hidden state (uses reset previous state)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;combined_reset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;vstack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;r_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h_tilde&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;combined_reset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Interpolate between old and new
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# When z_t ‚âà 0: keep old (h_t ‚âà h_prev)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# When z_t ‚âà 1: use new (h_t ‚âà h_tilde)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_tilde&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;reset&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;r_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;candidate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_tilde&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gates&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Compare LSTM vs GRU on same task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Comparing LSTM vs GRU&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;LSTM&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;lstm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GRUModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gru&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;GRU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;gru&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:])&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train both
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LSTMModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gru_model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;GRUModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Count parameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lstm_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;gru_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gru_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;LSTM parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_params&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GRU parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gru_params&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GRU has &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gru_params&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lstm_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;% fewer parameters&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Both can learn long-range dependencies effectively.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;GRU: Simpler, faster. LSTM: More flexible, sometimes better on complex tasks.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The relationship between LSTMs and vanilla RNNs exemplifies a recurring pattern in deep learning: identifying failure modes of simple architectures and designing targeted solutions through architectural innovation. Vanilla RNNs fail on long sequences due to vanishing gradients during backpropagation through time. LSTMs solve this by creating a separate information pathway (the cell state) with additive rather than multiplicative updates, and by using gates to control information flow. This isn‚Äôt just fixing a bug‚Äîit‚Äôs a fundamental architectural change motivated by understanding the mathematics of gradient flow.&lt;/p&gt;

&lt;p&gt;The evolution from LSTM to GRU illustrates another important principle: simpler can be better when it preserves the essential mechanism. GRUs achieve similar performance to LSTMs for many tasks while having 25% fewer parameters and simpler dynamics (no separate cell state). The GRU‚Äôs design philosophy is minimalism‚Äîuse the fewest mechanisms necessary to achieve the desired behavior. The update gate combines LSTM‚Äôs forget and input gates, reducing parameters while maintaining the crucial ability to control memory. The reset gate replaces the output gate‚Äôs functionality in a different way. For practitioners, this often means starting with GRU (simpler, faster) and only switching to LSTM if the task demonstrably benefits from its additional capacity.&lt;/p&gt;

&lt;p&gt;The connection to gating mechanisms in neural architectures more broadly reveals a powerful pattern. Gates‚Äîsigmoid-activated layers that output values in (0,1) used to modulate other values‚Äîappear throughout deep learning. Highway networks use gates to control skip connections. Attention mechanisms use gates (the attention weights) to select information. Neural Turing Machines use gates to control memory read/write. The pattern is consistent: when we need learnable control over information flow, we use gates. Understanding why this works‚Äîsmooth differentiability, interpretability as probabilities, effectiveness at learning conditional behavior‚Äîhelps appreciate this architectural motif.&lt;/p&gt;

&lt;p&gt;LSTMs and attention mechanisms have an interesting relationship. Both address long-range dependencies, but differently. LSTMs compress all past information into a fixed-size state, updated through gates. Attention allows direct access to all past states, selecting relevant ones through attention weights. This makes attention more powerful (no lossy compression) but more expensive (\(O(n^2)\) instead of \(O(n)\)). The Transformer‚Äôs success suggested that for many NLP tasks with sufficient compute, attention‚Äôs direct access outweighs LSTM‚Äôs efficiency. Yet for tasks with very long sequences or real-time constraints, LSTMs remain relevant.&lt;/p&gt;

&lt;p&gt;The concept of explicit memory management in LSTMs connects to computer science more broadly‚Äîthe idea of caching important information, evicting stale data, and controlling access. Database systems, operating system memory management, and CPU caches all face similar challenges of deciding what to remember and what to forget with limited capacity. LSTMs learn analogous policies from data rather than having them hand-coded. This connection helps frame what LSTMs are doing: they‚Äôre learned, differentiable memory management systems.&lt;/p&gt;

&lt;p&gt;Finally, understanding LSTMs‚Äô success and limitations informs architecture design more generally. LSTMs succeeded because they addressed a specific, well-understood problem (vanishing gradients) with a targeted solution (gated cell state). Their limitations (sequential processing, fixed-size state bottleneck) motivated further innovations (attention, Transformers). This progression from simple RNNs to complex LSTMs to attention-based Transformers shows how the field advances: identify limitations through analysis, design architectures addressing those limitations, discover new limitations, repeat. Each architecture teaches us something about the inductive biases and mechanisms needed for different types of sequential reasoning.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.bioinf.jku.at/publications/older/2604.pdf&quot;&gt;‚ÄúLong Short-Term Memory‚Äù (1997)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Sepp Hochreiter, J√ºrgen Schmidhuber&lt;br /&gt;
This foundational paper introduced the LSTM architecture and rigorously analyzed why vanilla RNNs fail to learn long-range dependencies. Hochreiter and Schmidhuber showed mathematically that during backpropagation through time, gradients either vanish or explode exponentially unless the network is carefully constructed to avoid this. They proposed the LSTM with its constant error carousel (the cell state) as a solution, proving that LSTMs can in principle learn arbitrary long-range dependencies. The paper is remarkably prescient, addressing issues like memory capacity and proposing solutions that became standard (like forget gates, added in later work). While LSTMs took years to gain widespread adoption (partly due to limited computational resources and datasets at the time), this paper established the theoretical foundation and demonstrated LSTM‚Äôs advantages on carefully constructed tasks requiring long-term memory. It‚Äôs one of the most cited papers in all of deep learning and arguably enabled much of the progress in sequence modeling over the next two decades.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://doi.org/10.1162/089976600300015015&quot;&gt;‚ÄúLearning to Forget: Continual Prediction with LSTM‚Äù (2000)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Felix A. Gers, J√ºrgen Schmidhuber, Fred Cummins&lt;br /&gt;
The original LSTM architecture lacked a mechanism to reset the cell state‚Äîit could only add information, not remove it. This led to saturation problems on long sequences where the cell state would fill up with outdated information. This paper introduced the forget gate, allowing the network to selectively clear parts of its memory when they‚Äôre no longer needed. This seemingly simple addition‚Äîone more gate that modulates the cell state update‚Äîmade LSTMs dramatically more practical for real-world tasks. The paper demonstrated improved performance on continual learning tasks where the network must process multiple sequences and reset context between them. The forget gate has become a standard part of all LSTM implementations, and the paper illustrates how architectural details that seem minor can have major practical impacts. It also demonstrates the value of ongoing refinement‚Äîthe best architectures often emerge through iterative improvements addressing practical issues discovered during application.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1406.1078&quot;&gt;‚ÄúLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio&lt;br /&gt;
This paper introduced the Gated Recurrent Unit (GRU) as a simpler alternative to LSTM while also proposing the encoder-decoder architecture for neural machine translation. The GRU‚Äôs design was motivated by LSTM‚Äôs complexity‚Äîcould we achieve similar performance with fewer parameters and simpler dynamics? The paper showed that GRU‚Äôs two gates (reset and update) could control information flow nearly as effectively as LSTM‚Äôs three gates, while being easier to implement and faster to train. The empirical results on machine translation demonstrated that architectural simplification doesn‚Äôt necessarily hurt performance when the essential mechanisms (gating for controlling memory) are preserved. This paper influenced architecture design philosophy: favor simpler designs when they maintain the key properties, as simplicity aids debugging, tuning, and understanding. The encoder-decoder framework introduced here became standard for sequence-to-sequence tasks, whether using RNNs, LSTMs, GRUs, or eventually Transformers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.3555&quot;&gt;‚ÄúEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, Yoshua Bengio&lt;br /&gt;
This paper provided the first comprehensive empirical comparison of LSTM and GRU across multiple sequence modeling tasks including music modeling, speech recognition, and language modeling. The careful experimental methodology‚Äîcontrolling for hyperparameters, architecture depth, and training procedures‚Äîallowed fair comparison focusing on the architectural differences. The findings were nuanced: neither architecture consistently dominated across all tasks, but GRU often matched LSTM performance while training faster due to fewer parameters. The paper established that architecture choice should depend on specific task characteristics and constraints (dataset size, sequence length, computational budget) rather than being a universal recommendation. It also demonstrated how to properly evaluate architectural innovations‚Äînot just showing one good result but systematic comparison across diverse tasks with statistical rigor. This methodology has become standard in deep learning research.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.02078&quot;&gt;‚ÄúVisualizing and Understanding Recurrent Networks‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Andrej Karpathy, Justin Johnson, Li Fei-Fei&lt;br /&gt;
This paper investigated what LSTMs learn by analyzing their internal representations on character-level language modeling. By examining activations of individual hidden units and gates, Karpathy demonstrated that LSTMs spontaneously develop interpretable internal structure. Some cells track quote characters (activating inside quotes, deactivating outside), others track indentation levels in code, others detect line endings or comment blocks. The forget gates learn to reset at sentence boundaries. This emergent structure wasn‚Äôt explicitly programmed but arose from the training objective of predicting the next character. The paper‚Äôs methodology‚Äîsystematic analysis of individual units, gate activations, and error patterns‚Äîestablished approaches for interpretability analysis that have since been applied to all types of neural networks. It showed that LSTMs don‚Äôt just achieve good performance through opaque computation but develop meaningful internal representations that we can understand and validate. This interpretability makes LSTMs valuable not just for their performance but for providing insight into what patterns the model has discovered in data.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most common mistake when implementing LSTMs is initializing the forget gate bias to zero, like other biases. This causes the forget gate to start around 0.5 (from sigmoid of 0), meaning the network initially forgets half its cell state at each step. For most tasks, this aggressive forgetting early in training prevents the network from discovering that long-range dependencies matter. The solution is the ‚Äúforget bias trick‚Äù: initialize \(\mathbf{b}_f = \mathbf{1}\) (a vector of ones). This makes the initial forget gate \(\sigma(0 + 1) \approx 0.73\), biasing toward retention. As training progresses, if forgetting is beneficial, the network can learn to reduce forget gate values. This simple initialization trick can mean the difference between an LSTM that trains successfully and one that never learns long-range dependencies.&lt;/p&gt;

&lt;p&gt;Exploding gradients, while less problematic in LSTMs than vanilla RNNs due to the cell state dynamics, can still occur. The issue now typically comes from the gates themselves. If forget gate saturates at 1 and input gate allows large candidate values, the cell state can grow unboundedly: \(c_t = 1 \cdot c_{t-1} + 1 \cdot \tilde{c}_t\) repeated many times gives exponential growth. This manifests as parameters becoming NaN during training or loss exploding. The standard solution remains gradient clipping, but LSTM-specific solutions include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Constraining candidate values through tanh (which LSTM already does)&lt;/li&gt;
  &lt;li&gt;Using layer normalization to keep cell states in reasonable ranges&lt;/li&gt;
  &lt;li&gt;Careful weight initialization to prevent gate saturation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A subtle issue is the coupling between forget and input gates. In principle, these gates can learn conflicting behaviors‚Äîforget old information (\(f_t \approx 0\)) while not adding new (\(i_t \approx 0\)), causing the cell state to vanish. GRU avoids this by coupling them: \(1 - z_t\) keeps old, \(z_t\) adds new, guaranteeing at least one is substantial. Some LSTM variants also couple gates, though the standard LSTM allows them to be independent. In practice, proper initialization and sufficient training data usually allow LSTMs to learn sensible gate coordination, but when debugging LSTM training failures, checking for pathological gate behaviors (all gates near 0 or 1) can reveal issues.&lt;/p&gt;

&lt;p&gt;The choice between LSTM and GRU has generated much discussion but few universal conclusions. As a practical heuristic: start with GRU because it‚Äôs simpler and faster. If performance plateaus and you have abundant data, try LSTM to see if its additional capacity helps. For very long sequences or complex temporal patterns, LSTM‚Äôs separate cell state often provides advantages. For tasks with limited data or where training time is constrained, GRU‚Äôs efficiency often makes it preferable. Always validate on your specific problem rather than assuming one architecture is universally better.&lt;/p&gt;

&lt;p&gt;When stacking multiple LSTM layers, a common question is whether to apply dropout between layers. The answer: yes, but carefully. Apply dropout to the outputs (hidden states) passed between layers, not to the cell states or the recurrent connections within a layer. Typical dropout rates for LSTMs are lower than for feedforward networks‚Äî0.2 to 0.3 rather than 0.5‚Äîbecause LSTMs are already quite regularized through their gating mechanisms. Too much dropout can prevent LSTMs from learning the long-range dependencies they‚Äôre designed for, as the random dropping disrupts information flow through time.&lt;/p&gt;

&lt;p&gt;Bidirectional LSTMs process sequences in both forward and backward directions, combining information from both at each time step: \(\mathbf{h}_t = [\overrightarrow{\mathbf{h}}_t; \overleftarrow{\mathbf{h}}_t]\). This doubles parameters and computation but provides richer representations when future context is available. However, bidirectional LSTMs can‚Äôt be used for real-time sequential prediction (where we must predict before seeing the complete sequence) or for autoregressive generation. They‚Äôre powerful for tasks like machine translation (where we have the complete source sentence) or speech recognition (where we can process the complete audio before transcribing), but inappropriate for online prediction or generation tasks.&lt;/p&gt;

&lt;p&gt;A powerful technique for analysis and debugging is visualizing gate activations over time. Plot \(f_t\), \(i_t\), \(o_t\) for each dimension as the network processes a sequence. Patterns reveal what the network has learned: forget gates dropping at sentence boundaries, input gates opening for content words and closing for function words, output gates exposing information when decisions are needed. This visualization not only helps debug training issues but provides insight into what linguistic or sequential structure the network has discovered, making LSTMs more interpretable than many other deep learning architectures.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Long Short-Term Memory networks solved the vanishing gradient problem that limited vanilla RNNs by introducing a cell state with gated connections that allow information to flow through time with minimal degradation. The architecture uses three gates‚Äîforget, input, and output‚Äîeach implemented as sigmoid layers, to control what information is retained, added, or exposed at each time step. This gating mechanism enables learning dependencies spanning hundreds of time steps, making LSTMs successful for machine translation, speech recognition, and many other sequential tasks that require long-term memory. The cell state provides an additive update path where gradients can flow more easily than through the multiplicative, nonlinear updates of vanilla RNN hidden states. Gated Recurrent Units simplify LSTMs by using two gates instead of three and merging cell and hidden states, often achieving comparable performance with fewer parameters. The choice between LSTM and GRU depends on task complexity, data availability, and computational constraints, with GRU often being a good starting point due to its simplicity. Understanding LSTMs deeply means appreciating not just the equations but why each component exists‚Äîhow gates enable learnable memory management, why the cell state uses additive updates, how these design choices enable gradient flow‚Äîand recognizing LSTMs as a solution to the specific challenge of learning long-range dependencies in sequential data through gradient-based optimization.&lt;/p&gt;

&lt;p&gt;The LSTM‚Äôs success demonstrates that careful architectural design informed by understanding of gradient dynamics can overcome fundamental limitations, a lesson that has influenced neural architecture design far beyond recurrent networks.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>06 LSTM and GRU - Advanced Recurrent Architectures</title>
   <link href="http://localhost:4000/contents/en/chapter06/06_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter06/06_00_Introduction</id>
   <content type="html">&lt;p&gt;Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU) networks solve the vanishing gradient problem of vanilla RNNs by using gating mechanisms to control information flow. These architectures enable learning long-range dependencies in sequential data and are fundamental to modern NLP and sequence modeling.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>05-01 Recurrent Neural Networks - Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_01_RNN_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter05/05_01_RNN_Fundamentals</id>
   <content type="html">&lt;h1 id=&quot;recurrent-neural-networks-processing-sequential-data&quot;&gt;Recurrent Neural Networks: Processing Sequential Data&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/Recurrent_neural_network_unfold.svg/800px-Recurrent_neural_network_unfold.svg.png&quot; alt=&quot;RNN Architecture&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c RNN v√† qu√° tr√¨nh unfolding theo th·ªùi gian. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Recurrent Neural Networks represent a fundamentally different approach to neural computation than the feedforward networks we‚Äôve studied so far. While feedforward networks process each input independently, treating a batch of images or feature vectors as unrelated samples, RNNs are designed specifically for sequential data where the order of elements carries meaning and where context from previous elements should influence how we interpret current ones. This seemingly simple idea‚Äîadding memory to neural networks‚Äîopens up entire domains that feedforward networks cannot adequately address: natural language, where word order determines meaning; speech, where phonemes unfold over time; financial time series, where past trends inform future predictions; and video, where frames form coherent narratives.&lt;/p&gt;

&lt;p&gt;The core insight of RNNs is to maintain a hidden state that serves as the network‚Äôs memory. At each time step, the network receives a new input and the previous hidden state, processes both through the same set of weights, and produces a new hidden state and output. This recurrence‚Äîusing the same parameters at every time step while the hidden state evolves‚Äîcreates a network that can theoretically process sequences of any length while learning temporal patterns through the shared parameters. The elegance lies in parameter sharing across time: just as convolutional networks share weights spatially to detect features regardless of position, RNNs share weights temporally to recognize patterns regardless of when they occur in a sequence.&lt;/p&gt;

&lt;p&gt;Understanding why RNNs emerged requires appreciating the fundamental challenge of sequential data: variable length. A sentence might have five words or fifty. An audio clip might last three seconds or three minutes. How do we build neural networks that handle this variability? The naive approach‚Äîhaving separate parameters for each time step‚Äîfails immediately because it doesn‚Äôt generalize to sequences longer than those seen during training and requires enormous numbers of parameters. The elegant solution RNNs provide is to use the same transformation at each step, with the hidden state carrying forward information from all previous steps. This creates an architecture that‚Äôs both parameter-efficient and theoretically capable of modeling arbitrarily long sequences.&lt;/p&gt;

&lt;p&gt;However, RNNs are not without profound limitations. The sequential nature that gives them modeling power also makes them computationally slow‚Äîwe cannot process time step \(t\) until we‚Äôve processed step \(t-1\), preventing the parallelization that GPUs excel at. The need to propagate gradients backward through many time steps leads to vanishing or exploding gradients, making it difficult to learn long-range dependencies. And the fixed-size hidden state creates an information bottleneck‚Äîall information from the past must be compressed into this state, which becomes increasingly difficult as sequences grow longer. These limitations motivated the development of LSTM and GRU architectures, and ultimately, the attention mechanisms and Transformers that now dominate sequence modeling.&lt;/p&gt;

&lt;p&gt;Yet RNNs remain important to study, not just for historical reasons but because they embody fundamental principles about sequence processing. They introduce the concept of memory in neural networks. They demonstrate both the power and limitations of sequential processing. They reveal challenges in gradient propagation that inform our understanding of training deep networks more broadly. And in certain applications‚Äîparticularly where sequences are naturally processed online or where computational efficiency on CPUs matters more than GPU throughput‚ÄîRNNs and their sophisticated variants still have advantages over Transformers.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;The mathematical formulation of RNNs reveals both their elegance and their challenges. At each time step \(t\), an RNN maintains a hidden state \(\mathbf{h}_t\) that summarizes all information from the sequence up to that point. Given a new input \(\mathbf{x}_t\), the RNN updates its state according to:&lt;/p&gt;

\[\mathbf{h}_t = f(\mathbf{W}_{hh}\mathbf{h}_{t-1} + \mathbf{W}_{xh}\mathbf{x}_t + \mathbf{b}_h)\]

&lt;p&gt;where \(f\) is a nonlinear activation function (typically \(\tanh\) for vanilla RNNs), \(\mathbf{W}_{hh}\) governs how the previous state influences the current state (the recurrent connection), and \(\mathbf{W}_{xh}\) governs how the current input contributes. The bias \(\mathbf{b}_h\) provides a baseline activation level.&lt;/p&gt;

&lt;p&gt;This formulation deserves careful scrutiny because it encodes several crucial design decisions. First, the same weight matrices \(\mathbf{W}_{hh}\) and \(\mathbf{W}_{xh}\) are used at every time step. This parameter sharing across time is what enables RNNs to generalize to sequences of different lengths and to learn temporal patterns independent of their absolute position in the sequence. Just as convolutional filters detect edges anywhere in an image through spatial parameter sharing, recurrent weights detect temporal patterns anywhere in a sequence through temporal parameter sharing.&lt;/p&gt;

&lt;p&gt;Second, the hidden state \(\mathbf{h}_t\) plays a dual role. It serves as both the network‚Äôs memory (encoding information from all previous inputs) and as input to the next time step. This creates a feedback loop: the current state depends on the previous state, which depends on the state before that, creating a chain of dependencies that theoretically extends back to the beginning of the sequence. Mathematically, we can unroll this recursion:&lt;/p&gt;

\[\mathbf{h}_t = f(\mathbf{W}_{hh}f(\mathbf{W}_{hh}\mathbf{h}_{t-2} + \mathbf{W}_{xh}\mathbf{x}_{t-1} + \mathbf{b}_h) + \mathbf{W}_{xh}\mathbf{x}_t + \mathbf{b}_h)\]

&lt;p&gt;This shows how \(\mathbf{h}_t\) depends on inputs \(\mathbf{x}_t\) and \(\mathbf{x}_{t-1}\), and continuing the expansion, on all previous inputs back to \(\mathbf{x}_1\). The nested composition of functions is what gives RNNs their power to model complex temporal dependencies, but also what makes them challenging to train‚Äîgradients must backpropagate through this entire composition.&lt;/p&gt;

&lt;p&gt;The output at each time step is computed from the hidden state:&lt;/p&gt;

\[\mathbf{y}_t = g(\mathbf{W}_{hy}\mathbf{h}_t + \mathbf{b}_y)\]

&lt;p&gt;where \(g\) is an activation function chosen based on the task (softmax for classification, linear for regression, sigmoid for multi-label, etc.). Importantly, \(\mathbf{W}_{hy}\) is also shared across time steps. This means we‚Äôre using the same ‚Äúdecoder‚Äù to interpret the hidden state at every time step, forcing the hidden state to use a consistent representation scheme throughout the sequence.&lt;/p&gt;

&lt;p&gt;The dimensions of these matrices matter for understanding computational and representational tradeoffs. If the input dimension is \(d_x\), hidden dimension is \(d_h\), and output dimension is \(d_y\), then:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{W}_{xh} \in \mathbb{R}^{d_h \times d_x}\): Projects input to hidden dimension&lt;/li&gt;
  &lt;li&gt;\(\mathbf{W}_{hh} \in \mathbb{R}^{d_h \times d_h}\): Recurrent connections (most important!)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{W}_{hy} \in \mathbb{R}^{d_y \times d_h}\): Projects hidden to output&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The recurrent weight matrix \(\mathbf{W}_{hh}\) is particularly important because it determines how information persists over time. If \(\mathbf{W}_{hh}\) is nearly zero, the hidden state quickly forgets previous inputs. If it‚Äôs close to identity, the hidden state changes slowly. Its eigenvalues directly control gradient flow during backpropagation through time, as we‚Äôll see.&lt;/p&gt;

&lt;p&gt;Different tasks require different architectural patterns. For sequence classification (sentiment analysis, video classification), we typically process the entire sequence and use only the final hidden state: \(\mathbf{y} = g(\mathbf{W}_{hy}\mathbf{h}_T + \mathbf{b}_y)\). The final state \(\mathbf{h}_T\) must summarize the entire sequence. For sequence labeling (part-of-speech tagging, named entity recognition), we produce outputs at every time step: \(\mathbf{y}_t = g(\mathbf{W}_{hy}\mathbf{h}_t + \mathbf{b}_y)\) for all \(t\). For sequence-to-sequence tasks (machine translation), the encoder RNN processes the input sequence into a final hidden state, which initializes a decoder RNN that generates the output sequence.&lt;/p&gt;

&lt;p&gt;Training RNNs requires Backpropagation Through Time (BPTT), which is simply backpropagation applied to the unrolled computational graph of the RNN. The loss over a sequence is typically the sum of losses at each time step:&lt;/p&gt;

\[\mathcal{L} = \sum_{t=1}^{T} \mathcal{L}_t(\mathbf{y}_t, \hat{\mathbf{y}}_t)\]

&lt;p&gt;To compute gradients of this loss with respect to \(\mathbf{W}_{hh}\), we must account for the fact that \(\mathbf{W}_{hh}\) affects the hidden state at every time step. The gradient is:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}_{hh}} = \sum_{t=1}^{T} \frac{\partial \mathcal{L}_t}{\partial \mathbf{W}_{hh}}\]

&lt;p&gt;Each term \(\frac{\partial \mathcal{L}_t}{\partial \mathbf{W}_{hh}}\) requires backpropagating through all time steps from 1 to \(t\) via the chain rule, because \(\mathbf{W}_{hh}\) influences \(\mathbf{h}_1\), which influences \(\mathbf{h}_2\), and so on up to \(\mathbf{h}_t\). This creates a computational graph that grows with sequence length, leading to both memory challenges (must store all hidden states) and the notorious vanishing/exploding gradient problem.&lt;/p&gt;

&lt;p&gt;The gradient flow analysis reveals the core challenge. The gradient of \(\mathbf{h}_t\) with respect to \(\mathbf{h}_k\) (for \(k &amp;lt; t\)) involves a product of Jacobian matrices:&lt;/p&gt;

\[\frac{\partial \mathbf{h}_t}{\partial \mathbf{h}_k} = \prod_{i=k+1}^{t} \frac{\partial \mathbf{h}_i}{\partial \mathbf{h}_{i-1}}\]

&lt;p&gt;Each Jacobian \(\frac{\partial \mathbf{h}_i}{\partial \mathbf{h}_{i-1}} = \text{diag}(f&apos;(\mathbf{z}_i)) \mathbf{W}_{hh}\) is the product of the activation derivative (which for \(\tanh\) is bounded by 1) and the recurrent weight matrix. If the largest singular value of \(\mathbf{W}_{hh}\) is less than 1, these products shrink exponentially with the number of time steps, causing vanishing gradients. If it‚Äôs greater than 1, they explode exponentially. This is not a minor technical issue but a fundamental challenge in training RNNs to capture long-range dependencies.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To build genuine intuition for how RNNs process sequences, let‚Äôs trace through a concrete example of processing the sentence ‚ÄúThe cat sat on the mat‚Äù for sentiment analysis. We‚Äôll use a simple RNN with 3-dimensional hidden state (unrealistically small for clarity) to predict positive or negative sentiment.&lt;/p&gt;

&lt;p&gt;Initially, before seeing any words, we set \(\mathbf{h}_0 = \mathbf{0}\), representing no information. The first word ‚ÄúThe‚Äù arrives. Suppose after embedding it becomes \(\mathbf{x}_1 = [0.2, -0.1, 0.5]\). With initialized weights (let‚Äôs use small random values):&lt;/p&gt;

\[\mathbf{W}_{hh} = \begin{bmatrix} 0.5 &amp;amp; 0.1 &amp;amp; -0.2 \\ -0.1 &amp;amp; 0.6 &amp;amp; 0.3 \\ 0.2 &amp;amp; -0.3 &amp;amp; 0.4 \end{bmatrix}, \quad \mathbf{W}_{xh} = \begin{bmatrix} 0.3 &amp;amp; 0.2 &amp;amp; -0.1 \\ 0.1 &amp;amp; -0.2 &amp;amp; 0.4 \\ -0.2 &amp;amp; 0.3 &amp;amp; 0.1 \end{bmatrix}\]

&lt;p&gt;The hidden state update computes:&lt;/p&gt;

\[\mathbf{z}_1 = \mathbf{W}_{hh}\mathbf{h}_0 + \mathbf{W}_{xh}\mathbf{x}_1 + \mathbf{b}_h = \mathbf{0} + \mathbf{W}_{xh}\mathbf{x}_1 + \mathbf{b}_h\]

&lt;p&gt;Since \(\mathbf{h}_0 = \mathbf{0}\), the first hidden state depends only on the first input:&lt;/p&gt;

\[\mathbf{h}_1 = \tanh(\mathbf{z}_1) = \tanh\begin{pmatrix}\begin{bmatrix} 0.3 &amp;amp; 0.2 &amp;amp; -0.1 \\ 0.1 &amp;amp; -0.2 &amp;amp; 0.4 \\ -0.2 &amp;amp; 0.3 &amp;amp; 0.1 \end{bmatrix} \begin{bmatrix} 0.2 \\ -0.1 \\ 0.5 \end{bmatrix} + \mathbf{b}_h\end{pmatrix}\]

&lt;p&gt;Let‚Äôs say this gives \(\mathbf{h}_1 = [0.1, 0.05, -0.15]\) (after \(\tanh\)). This vector now encodes ‚Äúhaving seen ‚ÄòThe‚Äô‚Äú‚Äînot very informative, but it‚Äôs a start. Now ‚Äúcat‚Äù arrives as \(\mathbf{x}_2 = [0.8, 0.3, -0.2]\). The state update now has TWO contributions:&lt;/p&gt;

\[\mathbf{z}_2 = \mathbf{W}_{hh}\mathbf{h}_1 + \mathbf{W}_{xh}\mathbf{x}_2 + \mathbf{b}_h\]

&lt;p&gt;The first term \(\mathbf{W}_{hh}\mathbf{h}_1\) carries forward information from ‚ÄúThe‚Äù, while \(\mathbf{W}_{xh}\mathbf{x}_2\) processes ‚Äúcat‚Äù. The \(\tanh\) nonlinearity combines these:&lt;/p&gt;

\[\mathbf{h}_2 = \tanh(\mathbf{z}_2)\]

&lt;p&gt;This new state encodes ‚Äúhaving seen ‚ÄòThe cat‚Äô‚Äú‚Äîit‚Äôs been influenced by both words, with the contribution of ‚ÄúThe‚Äù mediated through \(\mathbf{h}_1\) and the recurrent weights \(\mathbf{W}_{hh}\).&lt;/p&gt;

&lt;p&gt;As we continue through ‚Äúsat‚Äù, ‚Äúon‚Äù, ‚Äúthe‚Äù, ‚Äúmat‚Äù, each hidden state incorporates more context. By the time we reach the end, \(\mathbf{h}_6\) theoretically encodes the entire sentence‚Äôs meaning. We then use this to predict sentiment:&lt;/p&gt;

\[\text{sentiment} = \text{sigmoid}(\mathbf{W}_{hy}\mathbf{h}_6 + \mathbf{b}_y)\]

&lt;p&gt;The key insight is that information from ‚ÄúThe‚Äù at the beginning must flow through \(\mathbf{h}_1 \to \mathbf{h}_2 \to \cdots \to \mathbf{h}_6\) to influence the final prediction. Each transition involves multiplication by \(\mathbf{W}_{hh}\) and passing through \(\tanh\). If \(\mathbf{W}_{hh}\) consistently suppresses signals (eigenvalues &amp;lt; 1), information decays exponentially‚Äîthis is vanishing gradients. If it amplifies signals (eigenvalues &amp;gt; 1), information explodes‚Äîexploding gradients. Maintaining stable information flow over many steps is the central challenge of vanilla RNNs.&lt;/p&gt;

&lt;p&gt;Consider what happens during backpropagation. When we compute \(\frac{\partial \mathcal{L}}{\partial \mathbf{W}_{hh}}\), we must account for \(\mathbf{W}_{hh}\) appearing at every time step. The gradient involves products like:&lt;/p&gt;

\[\frac{\partial \mathbf{h}_6}{\partial \mathbf{h}_1} = \frac{\partial \mathbf{h}_6}{\partial \mathbf{h}_5} \frac{\partial \mathbf{h}_5}{\partial \mathbf{h}_4} \cdots \frac{\partial \mathbf{h}_2}{\partial \mathbf{h}_1}\]

&lt;p&gt;Each Jacobian \(\frac{\partial \mathbf{h}_{t+1}}{\partial \mathbf{h}_t} = \text{diag}(\tanh&apos;(\mathbf{z}_{t+1})) \mathbf{W}_{hh}\) involves the recurrent weight matrix and the activation derivative.&lt;/p&gt;

&lt;p&gt;For \(\tanh\), the derivative is bounded by 1 and typically much smaller (approaching 0 for saturated activations). This means each Jacobian typically has norm less than \(\|\mathbf{W}_{hh}\|\), and their product shrinks exponentially unless \(\|\mathbf{W}_{hh}\|\) is precisely calibrated. In practice, this delicate balancing rarely works for vanilla RNNs, limiting their ability to learn dependencies spanning more than about 10-20 time steps.&lt;/p&gt;

&lt;p&gt;The mathematics of different RNN architectures reveals different design philosophies. A many-to-one architecture (sequence ‚Üí single output) computes \(\mathbf{h}_t\) for all \(t\) but only uses \(\mathbf{h}_T\) for the final prediction, appropriate for classification tasks. A many-to-many architecture with the same length (sequence ‚Üí sequence of same length) computes outputs \(\mathbf{y}_t = g(\mathbf{W}_{hy}\mathbf{h}_t + \mathbf{b}_y)\) at every time step, useful for tasks like video frame labeling where we want to classify each frame. A many-to-many architecture with different lengths (sequence-to-sequence) requires an encoder-decoder design: the encoder RNN processes the input into a final hidden state \(\mathbf{h}_T^{enc}\), which initializes the decoder RNN: \(\mathbf{h}_0^{dec} = \mathbf{h}_T^{enc}\). The decoder then autoregressively generates output, with each output feeding into the next time step‚Äôs input until a special end-of-sequence token is generated.&lt;/p&gt;

&lt;p&gt;The computational complexity of RNNs is linear in sequence length: \(O(T \cdot d_h^2)\) where \(T\) is sequence length and \(d_h\) is hidden dimension (dominated by the \(\mathbf{W}_{hh}\mathbf{h}_{t-1}\) multiplication at each step). This seems efficient, but the sequential dependency means we cannot parallelize across time steps. Processing a sequence of length 100 requires 100 sequential matrix multiplications, even with a powerful GPU. Transformers, by contrast, have higher complexity \(O(T^2 d)\) but can process all positions in parallel, making them much faster in practice on modern hardware when \(T\) is not extremely large.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement RNNs from first principles to understand every detail, then show modern PyTorch implementations:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VanillaRNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Vanilla RNN implementation from scratch using NumPy.
    
    This implementation prioritizes clarity over efficiency. We&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll see exactly
    how hidden states evolve over time, how gradients flow backward, and where
    the vanishing gradient problem comes from. Understanding this manual
    implementation is crucial for debugging RNN training issues and for
    appreciating what modern frameworks do automatically.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Initialize RNN with careful weight initialization.
        
        For RNNs, initialization is even more critical than for feedforward networks.
        The recurrent weights Whh determine eigenvalues of the hidden state dynamics.
        If eigenvalues are too large (&amp;gt; 1), hidden states explode. Too small (&amp;lt; 1),
        they vanish. We initialize to small random values hoping to land in a
        stable regime, though this often fails for vanilla RNNs.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Input to hidden weights: map input space to hidden space
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Scale by 1/‚àöhidden_size to maintain variance
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Hidden to hidden weights: THE critical matrix for temporal dynamics
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Some initialize to identity + noise for better gradient flow initially
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Whh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Hidden to output weights
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Biases
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Forward pass through entire sequence.
        
        inputs: list of input vectors [x_1, x_2, ..., x_T], each x_t is (input_size, 1)
        h_prev: initial hidden state (hidden_size, 1)
        
        Returns:
            outputs: list of output vectors [y_1, y_2, ..., y_T]
            hidden_states: list of hidden states [h_0, h_1, ..., h_T]
            
        We must store ALL hidden states because backpropagation through time
        needs them. This creates a memory cost linear in sequence length,
        which becomes prohibitive for very long sequences.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Process sequence one step at a time
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This sequential loop is unavoidable in RNNs - we can&apos;t parallelize
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# across time because h_t depends on h_{t-1}
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Hidden state update: combine previous state and current input
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# The tanh bounds activations to [-1, 1], preventing explosion
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# (though it causes saturation and vanishing gradients)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Whh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_t&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute output from hidden state
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# For sequence classification, we&apos;d use only the final output
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# For sequence labeling, we use all outputs
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Backpropagation Through Time (BPTT).
        
        This is where RNNs get challenging. We must backpropagate gradients
        not just through layers (as in feedforward networks) but also backward
        through time. The gradient of the loss with respect to Whh involves
        contributions from all time steps, creating the long product of Jacobians
        that leads to vanishing/exploding gradients.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize gradient accumulators
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# These will accumulate gradients from all time steps
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wxh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Whh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros_like&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Gradient flowing back through time
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Initially zero, will accumulate as we backprop through time
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dh_next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backpropagate through time (from T down to 1)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is the &quot;backward&quot; in backpropagation through time
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Output error at this time step
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# For MSE loss: dy = y_pred - y_true
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Gradient of output layer parameters
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Backprop into hidden state
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# Two sources of gradient: from output at this time step (dy)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# and from future time steps (dh_next)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dh_next&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Backprop through tanh nonlinearity
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# tanh&apos;(z) = 1 - tanh^2(z) = 1 - h^2
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# This derivative approaches 0 when |h| approaches 1 (saturation)
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# causing vanishing gradients
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dh&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Gradients of hidden layer parameters
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Pass gradient to previous time step
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# This is where the product of Jacobians occurs
&lt;/span&gt;            &lt;span class=&quot;c1&quot;&gt;# dh_next will be used at time step t-1
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dh_next&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Whh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dz&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Clip gradients to prevent explosion
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# This is a hack, but necessary for vanilla RNNs
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# We&apos;re treating the symptom (large gradients) not the cause
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# (fundamental instability of recurrent dynamics)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Standard gradient descent update&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Wxh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWxh&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Whh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhh&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Why&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dWhy&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bh&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dbh&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;by&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dby&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate on simple sequence prediction task
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Vanilla RNN: Predicting Next Number in Sequence&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Task: Given [1, 2, 3], predict [2, 3, 4]
# This tests if RNN can learn simple sequential pattern
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_sequence_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Generate training data: sequences of increasing numbers
    Input: [start, start+1, start+2, ...]
    Target: [start+1, start+2, start+3, ...]
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sequences_in&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sequences_target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randint&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sequences_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;sequences_target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences_target&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create RNN
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;VanillaRNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate data
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_sequence_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_sequences&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training RNN to predict next number...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute loss (MSE)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tgt&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_states&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Update
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_inputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;40&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Average Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test on new sequence
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Testing on new sequence: [10, 11, 12, 13, 14, 15, 16, 17]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;11&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;12&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;13&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;17&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;h_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;h_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_input&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  After seeing &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, predict next: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; (true: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Note: Vanilla RNN struggles with this simple task due to vanishing gradients!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This motivates LSTM/GRU architectures we&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll cover in the next chapter.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let‚Äôs see a modern PyTorch implementation that handles these details automatically:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RNNSequenceModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Modern RNN using PyTorch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s built-in RNN layer.
    
    PyTorch handles the recurrent computation efficiently, unrolling the loop
    in optimized C++ code and managing gradients automatically. This is much
    faster than our NumPy implementation and handles batching elegantly.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;RNNSequenceModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# PyTorch&apos;s RNN module handles the recurrent computation
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# num_layers &amp;gt; 1 creates stacked RNNs (output of one feeds into next)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# batch_first=True means input shape is (batch, seq_len, input_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                         &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nonlinearity&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer to map hidden state to predictions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, seq_len, input_size)
        hidden: optional initial hidden state (num_layers, batch, hidden_size)
        
        Returns:
            output: (batch, seq_len, output_size)
            hidden: final hidden state
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# If no initial hidden state provided, RNN initializes to zeros
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;cuda&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# RNN returns:
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# - rnn_out: hidden states at all time steps (batch, seq_len, hidden_size)
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# - hidden: final hidden state (num_layers, batch, hidden_size)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;rnn_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;rnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Apply output layer to each time step
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Reshape to (batch * seq_len, hidden_size) for efficient computation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;rnn_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;rnn_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rnn_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Character-level language model example
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Character-Level Language Model with PyTorch RNN&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Create simple text dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;hello world, deep learning is amazing! transformers are powerful.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;char_to_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;idx_to_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Vocabulary: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;chars&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Vocabulary size: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Prepare sequences: given &quot;hell&quot; predict &quot;ello&quot;
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Create training sequences from text&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Convert to indices
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;seq_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;15&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Convert to tensors and create one-hot encodings
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_onehot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Convert index sequences to one-hot encoded tensors&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;seq_onehot&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;seq_onehot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_onehot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;stack&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;one_hot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;to_onehot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;targets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Dataset: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequences&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; sequences of length &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (num_sequences, seq_length, vocab_size)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Target shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (num_sequences, seq_length)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Create model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;RNNSequenceModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                         &lt;span class=&quot;n&quot;&gt;output_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Loss and optimizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training character-level language model...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, seq_len, vocab_size)
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Reshape for cross-entropy: (batch * seq_len, vocab_size)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;outputs_flat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;outputs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;targets_flat&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Compute loss
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;outputs_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;targets_flat&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward pass and optimize
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# BPTT happens here automatically!
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Gradient clipping (essential for RNNs!)
&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Without this, gradients can explode and training diverges
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;utils&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip_grad_norm_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate text by sampling from learned distribution
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generating text from learned RNN&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Generate text autoregressively using trained RNN.
    
    We start with a seed text, predict the next character&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s probability
    distribution, sample from it, append to sequence, and repeat.
    This is autoregressive generation‚Äîeach prediction conditions on
    all previous predictions.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Convert start text to indices
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;current_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;start_text&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Hidden state carries information through generation
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Prepare input: last seq_length characters (or pad if shorter)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;current_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;current_seq&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Pad if needed
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;char_to_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Convert to one-hot
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Predict next character
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Get probabilities for next character (last time step)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Sample from distribution (more interesting than argmax)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;next_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;multinomial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;probs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx_to_char&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_char&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;current_seq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;generated&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Generate
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;deep &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;generated_text&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;generate_text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Seed: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Generated: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;generated_text&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;The model learned character-level patterns!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;With more data and training, RNNs can generate coherent text.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let‚Äôs also demonstrate the vanishing gradient problem empirically:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Demonstrating Vanishing Gradients in RNNs&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;analyze_gradient_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sequence_lengths&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Show how gradients diminish with sequence length.
    
    We&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ll create sequences of different lengths, compute gradients, and
    measure their magnitude. This empirically demonstrates why vanilla RNNs
    struggle with long-range dependencies.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;sequence_lengths&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Create simple RNN
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;rnn_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;RNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Random input sequence
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;requires_grad&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;rnn_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute loss from FIRST time step output only
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Gradient must backprop through seq_len-1 steps to reach h_1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Measure gradient magnitude at input
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grad_magnitude&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad_magnitude&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sequence length &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;seq_len&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Gradient magnitude = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad_magnitude&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Typically see exponential decay in gradient magnitude
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Observation: Gradients decay exponentially with sequence length!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This is the vanishing gradient problem that limits vanilla RNNs.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;results&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;gradient_analysis&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;analyze_gradient_flow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;The relationship between RNNs and feedforward networks illuminates fundamental principles about network architecture design. Feedforward networks assume inputs are independent, identically distributed samples‚Äîthe order we present images during training doesn‚Äôt matter because each image is processed in isolation. RNNs, by contrast, explicitly model dependencies between sequential inputs through the hidden state. This difference isn‚Äôt just about architecture; it reflects different assumptions about data structure. When we choose an RNN over a feedforward network, we‚Äôre encoding the inductive bias that temporal or sequential order carries information relevant to the task.&lt;/p&gt;

&lt;p&gt;The connection to finite state machines and dynamical systems provides deeper theoretical insight. An RNN with discrete hidden states and hard-threshold activations is essentially a finite state machine, transitioning between states based on inputs. With continuous hidden states and smooth activations, RNNs become continuous dynamical systems described by the difference equation \(\mathbf{h}_{t+1} = f(\mathbf{W}_{hh}\mathbf{h}_t + \mathbf{W}_{xh}\mathbf{x}_t)\). The stability and expressiveness of this dynamical system depend on the spectrum of \(\mathbf{W}_{hh}\)‚Äîits eigenvalues determine whether the system is stable, chaotic, or marginally stable. This connection to dynamical systems theory helps explain phenomena like vanishing/exploding gradients and motivates architectures like LSTMs that explicitly manage information flow through gating mechanisms.&lt;/p&gt;

&lt;p&gt;The evolution from RNNs to LSTMs to Transformers tells a story about solving fundamental limitations. Vanilla RNNs struggle with long-range dependencies due to vanishing gradients. LSTMs introduce gating mechanisms that create skip connections through time, allowing gradients to flow more easily and information to persist longer. But LSTMs still process sequences sequentially, limiting parallelization. Transformers abandon recurrence entirely, using attention to create direct connections between all time steps, enabling full parallelization at the cost of quadratic complexity in sequence length. Each architecture makes different tradeoffs between expressiveness, trainability, and computational efficiency.&lt;/p&gt;

&lt;p&gt;The relationship between RNNs and convolutional networks is subtler but illuminating. Temporal convolution‚Äîapplying 1D convolution over sequences‚Äîcan capture some sequential patterns and is fully parallelizable. However, its receptive field grows only linearly with depth (a network with \(L\) layers of kernel size \(k\) has receptive field \(1 + L(k-1)\)), whereas RNNs theoretically have infinite receptive field (the hidden state can remember information from arbitrarily far in the past). This tradeoff between parallelizability (favoring convolution) and theoretically unlimited memory (favoring RNNs) has led to hybrid architectures combining both, like WaveNet for audio generation.&lt;/p&gt;

&lt;p&gt;Bidirectional RNNs extend the basic architecture by processing sequences in both forward and backward directions, maintaining two hidden states \(\overrightarrow{\mathbf{h}}_t\) and \(\overleftarrow{\mathbf{h}}_t\). The output at each time step combines information from both: \(\mathbf{y}_t = g(\mathbf{W}_{hy}[\overrightarrow{\mathbf{h}}_t; \overleftarrow{\mathbf{h}}_t] + \mathbf{b}_y)\). This is powerful for tasks where future context is available (like translating a complete sentence) but impossible for real-time prediction where we must make decisions before seeing the complete sequence. The bidirectional design exemplifies how architecture should match task requirements‚Äîusing future context when available, processing causally when necessary.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://doi.org/10.1207/s15516709cog1402_1&quot;&gt;‚ÄúFinding Structure in Time‚Äù (1990)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Jeffrey L. Elman&lt;br /&gt;
This seminal paper introduced the Simple Recurrent Network (SRN), now called Elman network, and demonstrated that recurrent connections enable learning temporal patterns. Elman showed that RNNs could learn to predict the next word in simple sentences, discovering grammatical structure without explicit rules. The key insight was that the hidden state develops internal representations of grammatical categories (noun, verb) and sequential dependencies without being told to do so‚Äîpurely from the prediction task. The paper established RNNs as viable for sequence modeling and influenced subsequent development of more sophisticated recurrent architectures. Elman‚Äôs analysis of hidden state dynamics‚Äîshowing how the state space organizes itself to reflect linguistic structure‚Äîdemonstrated that neural networks could discover interpretable representations, a theme that continues in modern deep learning research.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://doi.org/10.1162/089976600300015015&quot;&gt;‚ÄúLearning to Forget: Continual Prediction with LSTM‚Äù (2000)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Felix A. Gers, J√ºrgen Schmidhuber, Fred Cummins&lt;br /&gt;
While LSTMs were introduced in 1997, this paper made a crucial modification that made them practical: the forget gate. The original LSTM could accumulate information in the cell state but had no mechanism to selectively forget irrelevant information, leading to saturation over long sequences. The forget gate, controlled by \(\mathbf{f}_t = \sigma(\mathbf{W}_f[\mathbf{h}_{t-1}; \mathbf{x}_t] + \mathbf{b}_f)\), allows the network to clear its memory when old information becomes irrelevant. This seemingly simple addition‚Äîletting the network learn when to forget‚Äîdramatically improved LSTM performance on long sequences and became standard in all subsequent LSTM implementations. The paper demonstrates how architectural details that seem minor can have profound practical impacts.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1211.5063&quot;&gt;‚ÄúOn the difficulty of training Recurrent Neural Networks‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Razvan Pascanu, Tomas Mikolov, Yoshua Bengio&lt;br /&gt;
This paper provided the definitive analysis of vanishing and exploding gradients in RNNs, moving beyond empirical observations to rigorous mathematical treatment. The authors showed that when backpropagating through \(t\) time steps, gradients involve products of \(t\) Jacobian matrices, and if the largest eigenvalue of these matrices is less than 1, gradients vanish exponentially; if greater than 1, they explode exponentially. Importantly, they showed this isn‚Äôt just a training trick issue but a fundamental property of recurrent dynamics. The paper proposed gradient clipping to handle explosions (clip gradient norm to maximum threshold, now standard practice) and analyzed how LSTM‚Äôs gating mechanisms create effective paths for gradient flow. This work deepened understanding of why vanilla RNNs fail on long sequences and why architectural innovations like LSTMs are necessary, not optional.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1412.3555&quot;&gt;‚ÄúEmpirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling‚Äù (2014)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Junyoung Chung, Caglar Gulcehre, KyungHyun Cho, Yoshua Bengio&lt;br /&gt;
This paper systematically compared LSTM and GRU (Gated Recurrent Unit) architectures on multiple sequence modeling tasks, providing empirical evidence about when each architecture excels. GRUs, introduced by Cho et al. in 2014, simplify LSTMs by using only two gates instead of three and no separate cell state, reducing parameters by about 25%. The paper showed that GRUs often match LSTM performance while training faster due to fewer parameters. Importantly, it demonstrated that architectural details matter‚Äîcarefully engineered recurrent mechanisms consistently outperformed vanilla RNNs on long sequences. The paper‚Äôs experimental methodology‚Äîcontrolled comparisons on multiple datasets with careful hyperparameter tuning‚Äîset a standard for how to evaluate architectural innovations in deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1506.02078&quot;&gt;‚ÄúVisualizing and Understanding Recurrent Networks‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Andrej Karpathy, Justin Johnson, Li Fei-Fei&lt;br /&gt;
This paper investigated what RNNs learn by analyzing their hidden state dynamics on character-level language modeling. By examining which hidden units activate for which input patterns, the authors discovered that RNNs spontaneously develop interpretable internal representations: certain neurons activate for quotes, others for parentheses balancing, others for code indentation. This demonstrated that RNNs don‚Äôt just memorize but learn meaningful structure. The paper also introduced techniques for visualizing attention-like patterns in RNNs before explicit attention mechanisms were common. Perhaps most influentially, it made accessible the kind of interpretability analysis that helps us understand what neural networks learn, a methodology that has become standard for analyzing all types of models, not just RNNs.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;The most common failure mode when training RNNs is gradient explosion, and recognizing its symptoms is crucial for debugging. Training loss suddenly becomes NaN, parameters become infinite, or loss oscillates wildly rather than decreasing smoothly. This happens when the product of gradients through time steps grows exponentially. The standard solution‚Äîgradient clipping‚Äîis conceptually simple but must be implemented correctly. We compute the global gradient norm across all parameters \(\|\nabla_\theta \mathcal{L}\|_2 = \sqrt{\sum_\theta (\frac{\partial \mathcal{L}}{\partial \theta})^2}\) and if it exceeds a threshold (typically 5-10), we scale all gradients by \(\frac{\text{threshold}}{\|\nabla_\theta \mathcal{L}\|_2}\). This preserves gradient direction while preventing explosive updates. It‚Äôs crucial to clip the global norm, not individual gradient values, because we want to preserve the relative magnitudes of gradients for different parameters.&lt;/p&gt;

&lt;p&gt;Vanishing gradients are more insidious because they don‚Äôt cause obvious training failures‚Äîthe network trains but simply fails to learn long-range dependencies. Symptoms include the model only using recent context (in language modeling, only considering the last few words) or being unable to learn tasks requiring information from the beginning of long sequences. Detection requires careful analysis: plot gradient magnitudes as a function of backpropagation steps or test specifically on tasks requiring long-range memory. Solutions include switching to LSTM/GRU (which mitigate though don‚Äôt eliminate vanishing gradients), using smaller sequence lengths during training (truncated BPTT), or adding auxiliary losses at intermediate time steps to provide more direct gradient paths.&lt;/p&gt;

&lt;p&gt;Initialization of recurrent weights deserves special attention because it directly affects gradient flow stability. The standard small random initialization \(\mathbf{W}_{hh} \sim \mathcal{N}(0, 0.01^2)\) often leads to vanishing gradients. A better approach is orthogonal initialization: initialize \(\mathbf{W}_{hh}\) to a random orthogonal matrix (often generated via QR decomposition of a random matrix). Orthogonal matrices preserve vector norms during multiplication, helping gradients neither vanish nor explode, at least initially. This gives training a better starting point, though as weights update, they drift from orthogonality. Another approach is identity initialization plus small random noise: \(\mathbf{W}_{hh} = I + \mathcal{N}(0, 0.001^2)\), encouraging the hidden state to change slowly, which can help with gradient flow.&lt;/p&gt;

&lt;p&gt;A subtle but important issue is variable-length sequences in batched training. When training on multiple sequences of different lengths simultaneously, we must handle the fact that some sequences end before others. The solution is padding and masking: pad shorter sequences to match the longest sequence in the batch with a special padding token, then mask the loss so padded positions don‚Äôt contribute to gradients. Without masking, the RNN receives meaningless gradient signals from padding, degrading performance. PyTorch‚Äôs PackedSequence functionality handles this elegantly, avoiding computation on padded positions entirely.&lt;/p&gt;

&lt;p&gt;The choice of hidden state dimension involves important tradeoffs. Larger hidden dimensions provide more capacity to remember complex patterns and longer contexts. However, they increase parameters quadratically (\(\mathbf{W}_{hh}\) has \(d_h^2\) elements), slow computation (each time step requires \(O(d_h^2)\) operations), and can lead to overfitting on small datasets. A common starting point is matching hidden dimension to input dimension or using 128-512 depending on task complexity. For character-level modeling, 128-256 often suffices. For word-level language modeling on large vocabularies, 512-1024 is typical. Always validate on a held-out set and watch for train-test gaps indicating overfitting.&lt;/p&gt;

&lt;p&gt;Using teacher forcing during training but autoregressive generation during inference creates train-test mismatch in sequence-to-sequence models. During training with teacher forcing, the decoder receives the true previous token as input, ensuring it sees good inputs even when its predictions are poor. During inference, it must use its own predictions, which may be wrong, leading to compounding errors. This mismatch means the model never learns to recover from its own mistakes during training. Solutions include scheduled sampling (randomly using predicted tokens instead of true tokens during training with increasing probability), or using auxiliary losses that encourage robustness to input perturbations.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Recurrent Neural Networks introduced the fundamental idea of memory in neural networks through hidden states that persist across time steps, enabling modeling of sequential data where order and context matter. The mathematical elegance of parameter sharing across time‚Äîusing the same weights at every step‚Äîallows RNNs to generalize across sequence lengths while learning temporal patterns. However, this same recurrence creates challenges: sequential processing prevents parallelization, making RNNs slow to train on GPUs; the product of Jacobians through time leads to vanishing or exploding gradients, limiting their ability to learn long-range dependencies; and the fixed-size hidden state creates an information bottleneck for long sequences. Despite these limitations, RNNs established principles‚Äîthat networks can maintain state, that temporal structure should be explicitly modeled, that we can learn to predict future from past‚Äîthat influence all subsequent sequence modeling architectures. Understanding RNNs deeply means understanding not just how they work but why they‚Äôre designed this way, where they fail, and how later innovations like LSTMs and Transformers address their limitations while building on their insights.&lt;/p&gt;

&lt;p&gt;The journey from feedforward networks to RNNs represents a crucial conceptual leap in deep learning: from processing static inputs independently to modeling dynamic processes with memory and temporal structure. This leap opens up vast new applications but introduces new challenges that have driven decades of research and continue to inspire innovation in sequence modeling architectures today.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>05 Introduction to Recurrent Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter05/05_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter05/05_00_Introduction</id>
   <content type="html">&lt;p&gt;Recurrent Neural Networks (RNNs) are designed for sequential data where order matters - text, speech, time series, video. Unlike feedforward networks, RNNs have loops that allow information to persist, creating an internal memory. This chapter covers vanilla RNNs, their training challenges, and applications.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>04-02 Pooling Layers and CNN Architectures</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_02_Pooling_and_Architectures/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter04/04_02_Pooling_and_Architectures</id>
   <content type="html">&lt;h2 id=&quot;pooling-layers&quot;&gt;Pooling Layers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Pooling&lt;/strong&gt; (or subsampling) reduces spatial dimensions while retaining important features.&lt;/p&gt;

&lt;h3 id=&quot;max-pooling&quot;&gt;Max Pooling&lt;/h3&gt;

&lt;p&gt;Takes the &lt;strong&gt;maximum&lt;/strong&gt; value in each region:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (4√ó4):          Max Pool 2√ó2, stride=2:
1  3  2  4            3  4
2  1  5  6      ‚Üí     
3  2  1  3            3  6
1  0  3  6
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Output&lt;/strong&gt;: \(\left\lfloor \frac{n + 2p - k}{s} \right\rfloor + 1\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Translation invariance&lt;/strong&gt;: Small shifts don‚Äôt change output&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No learnable parameters&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preserves dominant features&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;average-pooling&quot;&gt;Average Pooling&lt;/h3&gt;

&lt;p&gt;Takes the &lt;strong&gt;average&lt;/strong&gt; value:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;avg_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Average pooling&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                             &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;global-average-pooling-gap&quot;&gt;Global Average Pooling (GAP)&lt;/h3&gt;

&lt;p&gt;Averages each feature map to a single value:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (7√ó7√ó512) ‚Üí GAP ‚Üí Output (512)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Use&lt;/strong&gt;: Replace fully connected layers, reduce overfitting.&lt;/p&gt;

&lt;h2 id=&quot;classic-cnn-architectures&quot;&gt;Classic CNN Architectures&lt;/h2&gt;

&lt;h3 id=&quot;lenet-5-1998&quot;&gt;LeNet-5 (1998)&lt;/h3&gt;

&lt;p&gt;First successful CNN for digit recognition:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (32√ó32) ‚Üí Conv(6, 5√ó5) ‚Üí AvgPool ‚Üí Conv(16, 5√ó5) ‚Üí AvgPool ‚Üí FC(120) ‚Üí FC(84) ‚Üí FC(10)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;alexnet-2012&quot;&gt;AlexNet (2012)&lt;/h3&gt;

&lt;p&gt;Won ImageNet 2012, started deep learning revolution:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (227√ó227√ó3) ‚Üí Conv(96, 11√ó11, s=4) ‚Üí MaxPool ‚Üí Conv(256, 5√ó5) ‚Üí MaxPool 
‚Üí Conv(384, 3√ó3) ‚Üí Conv(384, 3√ó3) ‚Üí Conv(256, 3√ó3) ‚Üí MaxPool ‚Üí FC(4096) ‚Üí FC(4096) ‚Üí FC(1000)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Key innovations&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ReLU activation&lt;/li&gt;
  &lt;li&gt;Dropout&lt;/li&gt;
  &lt;li&gt;Data augmentation&lt;/li&gt;
  &lt;li&gt;GPU training&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vggnet-2014&quot;&gt;VGGNet (2014)&lt;/h3&gt;

&lt;p&gt;Simple but deep architecture:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;VGG-16: 13 conv layers (all 3√ó3) + 3 FC layers
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Pattern&lt;/strong&gt;: Conv-Conv-Pool repeated, doubling filters each stage (64‚Üí128‚Üí256‚Üí512‚Üí512)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Philosophy&lt;/strong&gt;: Deeper is better, small filters are better&lt;/p&gt;

&lt;h3 id=&quot;resnet-2015&quot;&gt;ResNet (2015)&lt;/h3&gt;

&lt;p&gt;Introduced &lt;strong&gt;residual connections&lt;/strong&gt; (skip connections):&lt;/p&gt;

\[\mathbf{y} = F(\mathbf{x}) + \mathbf{x}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Residual block
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;residual_block&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;identity&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Main path
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;batch_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Skip connection
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;identity&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Enables&lt;/strong&gt;: Training very deep networks (50, 101, 152 layers)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why it works&lt;/strong&gt;: Easier to learn residual \(F(\mathbf{x})\) than full mapping&lt;/p&gt;

&lt;h2 id=&quot;complete-cnn-example&quot;&gt;Complete CNN Example&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleCNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Conv layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 32√ó32√ó3 ‚Üí 32√ó32√ó32
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 16√ó16√ó32 ‚Üí 16√ó16√ó64
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 8√ó8√ó64 ‚Üí 8√ó8√ó128
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# FC layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# After 3 pooling layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Block 1
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 32√ó32√ó32 ‚Üí 16√ó16√ó32
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Block 2
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 16√ó16√ó64 ‚Üí 8√ó8√ó64
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Block 3
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;max_pool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 8√ó8√ó128 ‚Üí 4√ó4√ó128
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Flatten
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;reshape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (batch, 4*4*128)
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# FC layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Pooling&lt;/strong&gt; reduces spatial dimensions, adds translation invariance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Max pooling&lt;/strong&gt; is most common&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Classic architectures&lt;/strong&gt;: LeNet ‚Üí AlexNet ‚Üí VGG ‚Üí ResNet&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key innovations&lt;/strong&gt;: Deeper networks, skip connections, batch normalization&lt;/li&gt;
  &lt;li&gt;Modern CNNs: ResNet, EfficientNet, Vision Transformers&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Next chapter: Recurrent Neural Networks for sequential data!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>04-01 Convolutional Layers</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_01_Convolutional_Layers/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter04/04_01_Convolutional_Layers</id>
   <content type="html">&lt;h1 id=&quot;convolutional-layers-building-blocks-of-computer-vision&quot;&gt;Convolutional Layers: Building Blocks of Computer Vision&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Typical_cnn.png/800px-Typical_cnn.png&quot; alt=&quot;CNN Architecture Overview&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c t·ªïng quan c·ªßa Convolutional Neural Network (CNN). Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Convolutional layers&lt;/strong&gt; are specialized neural network layers designed for processing grid-like data, especially images. Instead of connecting every input to every neuron (fully connected), convolutional layers use small, learnable filters that slide across the input to detect local patterns.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Why CNNs matter&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Parameter efficiency&lt;/strong&gt;: Millions fewer parameters than fully connected&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Translation invariance&lt;/strong&gt;: Detects features regardless of position&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hierarchical learning&lt;/strong&gt;: Low-level ‚Üí mid-level ‚Üí high-level features&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;State-of-the-art&lt;/strong&gt;: Best performance on vision tasks&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Key insight&lt;/strong&gt;: Images have spatial structure - nearby pixels are related. Convolutional layers exploit this structure through &lt;strong&gt;local connectivity&lt;/strong&gt; and &lt;strong&gt;parameter sharing&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Analogy&lt;/strong&gt;: Think of convolution as sliding a magnifying glass (filter) across an image to find specific patterns (edges, textures, shapes). Each filter specializes in detecting one type of pattern.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;2d-convolution-operation&quot;&gt;2D Convolution Operation&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://miro.medium.com/v2/resize:fit:1400/1*Zx-ZMLKab7VOCQTxdZ1OAw.gif&quot; alt=&quot;Convolution Operation&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça ph√©p to√°n Convolution 2D tr√™n ·∫£nh. Ngu·ªìn: Medium&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;For image \(I\) (height \(H\), width \(W\)) and kernel \(K\) (size \(k \times k\)):&lt;/p&gt;

\[(I * K)[i,j] = \sum_{m=0}^{k-1}\sum_{n=0}^{k-1} I[i+m, j+n] \cdot K[m,n]\]

&lt;p&gt;&lt;strong&gt;In deep learning&lt;/strong&gt;, we use cross-correlation (same but without kernel flipping):&lt;/p&gt;

\[S[i,j] = \sum_{m=0}^{k-1}\sum_{n=0}^{k-1} I[i+m, j+n] \cdot K[m,n]\]

&lt;h3 id=&quot;multi-channel-convolution&quot;&gt;Multi-Channel Convolution&lt;/h3&gt;

&lt;p&gt;For RGB image (\(H \times W \times 3\)) and filter (\(k \times k \times 3\)):&lt;/p&gt;

\[S[i,j] = \sum_{c=0}^{C_{in}-1} \sum_{m=0}^{k-1}\sum_{n=0}^{k-1} I[i+m, j+n, c] \cdot K[m,n,c] + b\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(C_{in}\): number of input channels (3 for RGB)&lt;/li&gt;
  &lt;li&gt;\(b\): bias term&lt;/li&gt;
  &lt;li&gt;Each filter produces one output channel&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;output-dimensions&quot;&gt;Output Dimensions&lt;/h3&gt;

&lt;p&gt;With:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input size: \(n \times n\)&lt;/li&gt;
  &lt;li&gt;Kernel size: \(k \times k\)&lt;/li&gt;
  &lt;li&gt;Stride: \(s\)&lt;/li&gt;
  &lt;li&gt;Padding: \(p\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Output size&lt;/strong&gt;:&lt;/p&gt;

\[n_{out} = \left\lfloor \frac{n + 2p - k}{s} \right\rfloor + 1\]

&lt;h3 id=&quot;parameter-count&quot;&gt;Parameter Count&lt;/h3&gt;

&lt;p&gt;For a convolutional layer:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt; = \((k \times k \times C_{in}) \times C_{out} + C_{out}\)&lt;/p&gt;

&lt;p&gt;where \(C_{out}\) is number of output channels (filters).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Input: \(32 \times 32 \times 3\) (RGB image)&lt;/li&gt;
  &lt;li&gt;Filter: \(3 \times 3\), 64 filters&lt;/li&gt;
  &lt;li&gt;Parameters: \((3 \times 3 \times 3) \times 64 + 64 = 1,792\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Compare to fully connected&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\((32 \times 32 \times 3) \times 64 = 196,608\) parameters!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;110√ó reduction&lt;/strong&gt; with convolution!&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;h3 id=&quot;example-1-edge-detection&quot;&gt;Example 1: Edge Detection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Vertical edge detector&lt;/strong&gt; (3√ó3):&lt;/p&gt;

\[K = \begin{bmatrix} 1 &amp;amp; 0 &amp;amp; -1 \\ 1 &amp;amp; 0 &amp;amp; -1 \\ 1 &amp;amp; 0 &amp;amp; -1 \end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Input image&lt;/strong&gt;:
\(I = \begin{bmatrix} 
10 &amp;amp; 10 &amp;amp; 10 &amp;amp; 0 &amp;amp; 0 \\
10 &amp;amp; 10 &amp;amp; 10 &amp;amp; 0 &amp;amp; 0 \\
10 &amp;amp; 10 &amp;amp; 10 &amp;amp; 0 &amp;amp; 0 \\
10 &amp;amp; 10 &amp;amp; 10 &amp;amp; 0 &amp;amp; 0 \\
10 &amp;amp; 10 &amp;amp; 10 &amp;amp; 0 &amp;amp; 0
\end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Convolution at position (1,1)&lt;/strong&gt;:&lt;/p&gt;

\[\begin{align}
S[1,1] &amp;amp;= (10√ó1 + 10√ó0 + 10√ó(-1)) \\
&amp;amp;+ (10√ó1 + 10√ó0 + 10√ó(-1)) \\
&amp;amp;+ (10√ó1 + 10√ó0 + 10√ó(-1)) \\
&amp;amp;= 0
\end{align}\]

&lt;p&gt;&lt;strong&gt;At position (1,2)&lt;/strong&gt; (on the edge):&lt;/p&gt;

\[S[1,2] = (10√ó1 + 0√ó0 + 0√ó(-1)) + \ldots = 30\]

&lt;p&gt;Result: &lt;strong&gt;High activation at vertical edges!&lt;/strong&gt;&lt;/p&gt;

&lt;h3 id=&quot;example-2-how-cnns-see&quot;&gt;Example 2: How CNNs See&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Layer 1 (low-level)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Horizontal edges: \(\begin{bmatrix} 1 &amp;amp; 1 &amp;amp; 1 \\ 0 &amp;amp; 0 &amp;amp; 0 \\ -1 &amp;amp; -1 &amp;amp; -1 \end{bmatrix}\)&lt;/li&gt;
  &lt;li&gt;Vertical edges: \(\begin{bmatrix} 1 &amp;amp; 0 &amp;amp; -1 \\ 1 &amp;amp; 0 &amp;amp; -1 \\ 1 &amp;amp; 0 &amp;amp; -1 \end{bmatrix}\)&lt;/li&gt;
  &lt;li&gt;Diagonal edges, color blobs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Layer 2-3 (mid-level)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Corners (combination of edges)&lt;/li&gt;
  &lt;li&gt;Simple shapes (circles, rectangles)&lt;/li&gt;
  &lt;li&gt;Textures (patterns of edges)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Layer 4-5 (high-level)&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Object parts (eyes, wheels, ears)&lt;/li&gt;
  &lt;li&gt;Complex patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Final layers&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Complete objects (faces, cars, animals)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;h3 id=&quot;numpy-implementation&quot;&gt;NumPy Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv2d_simple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Simple 2D convolution (single channel)
    
    image: (H, W)
    kernel: (k, k)
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Add padding
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;constant&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;H&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Output dimensions
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Convolution
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;H_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Extract region and apply filter
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;region&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;j&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;region&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example: Edge detection
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;vertical_edge_kernel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv2d_simple&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vertical_edge_kernel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Edge detection result:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;pytorch-implementation&quot;&gt;PyTorch Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn.functional&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                 &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                             &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: (batch, in_channels, height, width)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example: RGB to 64 feature maps
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_layer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConvLayer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                       &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Input: batch of 8 RGB images, 32x32
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;conv_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# (8, 3, 32, 32)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (8, 64, 32, 32)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Check parameters
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;conv_layer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Number of parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_params&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 3*3*3*64 + 64 = 1,792
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;complete-cnn-block&quot;&gt;Complete CNN Block&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CNNBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CNNBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;in_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                             &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BatchNorm2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out_channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pool&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MaxPool2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;conv&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;bn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;pool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example: Standard CNN
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleCNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SimpleCNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CNNBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;      &lt;span class=&quot;c1&quot;&gt;# 32x32x3 ‚Üí 16x16x64
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CNNBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# 16x16x64 ‚Üí 8x8x128
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;block3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;CNNBlock&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;   &lt;span class=&quot;c1&quot;&gt;# 8x8x128 ‚Üí 4x4x256
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dropout&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;512&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;block1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;block2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;block3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Flatten
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dropout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleCNN&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_classes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Batch of 4 images
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (4, 10)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;h3 id=&quot;fully-connected-layers&quot;&gt;Fully Connected Layers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Connect every input to every output&lt;/li&gt;
  &lt;li&gt;No spatial structure assumption&lt;/li&gt;
  &lt;li&gt;Many more parameters&lt;/li&gt;
  &lt;li&gt;Used after conv layers for classification&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;pooling-layers&quot;&gt;Pooling Layers&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Downsample feature maps&lt;/li&gt;
  &lt;li&gt;Add translation invariance&lt;/li&gt;
  &lt;li&gt;Reduce computation&lt;/li&gt;
  &lt;li&gt;No learnable parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;batch-normalization&quot;&gt;Batch Normalization&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Normalize activations&lt;/li&gt;
  &lt;li&gt;Stabilize training&lt;/li&gt;
  &lt;li&gt;Often used after convolution&lt;/li&gt;
  &lt;li&gt;Enables higher learning rates&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;residual-connections-resnet&quot;&gt;Residual Connections (ResNet)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Skip connections bypass layers&lt;/li&gt;
  &lt;li&gt;Help gradients flow&lt;/li&gt;
  &lt;li&gt;Enable very deep networks&lt;/li&gt;
  &lt;li&gt;
\[\mathbf{y} = F(\mathbf{x}) + \mathbf{x}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;depthwise-separable-convolutions&quot;&gt;Depthwise Separable Convolutions&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Factorize standard convolution&lt;/li&gt;
  &lt;li&gt;Fewer parameters and computations&lt;/li&gt;
  &lt;li&gt;Used in MobileNet, EfficientNet&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf&quot;&gt;‚ÄúGradient-Based Learning Applied to Document Recognition‚Äù (1998)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Yann LeCun, L√©on Bottou, Yoshua Bengio, Patrick Haffner&lt;br /&gt;
Introduced LeNet-5, the first successful CNN for digit recognition. Demonstrated that convolutional layers with shared weights can learn hierarchical features, establishing CNNs as the architecture of choice for computer vision.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;‚ÄúImageNet Classification with Deep Convolutional Neural Networks‚Äù (2012)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alex Krizhevsky, Ilya Sutskever, Geoffrey E. Hinton&lt;br /&gt;
AlexNet won ImageNet 2012 by a huge margin using deep CNNs with ReLU, dropout, and GPU training. This victory sparked the deep learning revolution and proved CNNs could scale to real-world vision tasks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1409.1556&quot;&gt;‚ÄúVery Deep Convolutional Networks for Large-Scale Image Recognition‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Karen Simonyan, Andrew Zisserman&lt;br /&gt;
VGGNet showed that network depth is crucial - using small 3√ó3 filters consistently through 16-19 layers achieved excellent results. Demonstrated that simple, deep architectures with repeated patterns can be very effective.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;‚ÄúDeep Residual Learning for Image Recognition‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun&lt;br /&gt;
ResNet introduced skip connections enabling training of 152+ layer networks. Solved degradation problem in very deep networks. Winner of ImageNet 2015, fundamentally changed how we build deep CNNs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1704.04861&quot;&gt;‚ÄúMobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Andrew G. Howard et al.&lt;br /&gt;
Introduced depthwise separable convolutions for efficient CNNs on mobile devices. Showed how to maintain accuracy while dramatically reducing computation and parameters, enabling deployment on edge devices.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-1-not-using-padding&quot;&gt;‚ö†Ô∏è Pitfall 1: Not Using Padding&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Output shrinks with each layer, losing boundary information&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: Use ‚Äúsame‚Äù padding to maintain spatial dimensions&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Without padding: 32√ó32 ‚Üí 30√ó30 ‚Üí 28√ó28 (shrinks!)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# With padding: 32√ó32 ‚Üí 32√ó32 ‚Üí 32√ó32 (maintains size)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-2-too-large-kernel-size&quot;&gt;‚ö†Ô∏è Pitfall 2: Too Large Kernel Size&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Fewer parameters but worse performance&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: Stack multiple 3√ó3 instead of one large kernel&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Less effective
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 7√ó7 = 49 params per channel
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Better (VGG approach)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;conv2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Two 3√ó3 = 18 params, same receptive field as 5√ó5
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;Ô∏è-pitfall-3-forgetting-channel-dimension&quot;&gt;‚ö†Ô∏è Pitfall 3: Forgetting Channel Dimension&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Issue&lt;/strong&gt;: Confusing (H, W, C) vs (C, H, W) formats&lt;br /&gt;
&lt;strong&gt;Solution&lt;/strong&gt;: PyTorch uses (N, C, H, W), TensorFlow uses (N, H, W, C)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# PyTorch format
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# TensorFlow format
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;tf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;normal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;channels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-1-11-convolutions&quot;&gt;‚úÖ Trick 1: 1√ó1 Convolutions&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Reduce channels (dimensionality reduction)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_1x1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;256&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Input: 32√ó32√ó256 ‚Üí Output: 32√ó32√ó64
# Adds nonlinearity without changing spatial dims
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-2-strided-convolution-for-downsampling&quot;&gt;‚úÖ Trick 2: Strided Convolution for Downsampling&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Instead of pooling, use stride &amp;gt; 1
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conv_downsample&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Conv2d&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kernel_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stride&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;padding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 32√ó32√ó64 ‚Üí 16√ó16√ó128 (learnable downsampling!)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;-trick-3-receptive-field-calculation&quot;&gt;‚úÖ Trick 3: Receptive Field Calculation&lt;/h3&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Receptive field after n layers of 3√ó3 convs
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;receptive_field&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# 3 layers: 1 + 2*3 = 7√ó7 receptive field
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Convolution&lt;/strong&gt; = local connectivity + parameter sharing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Filters&lt;/strong&gt; detect local patterns (edges, textures, shapes)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameter efficiency&lt;/strong&gt;: Millions fewer parameters than FC&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Translation invariance&lt;/strong&gt;: Same filter applied everywhere&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hierarchical features&lt;/strong&gt;: Low ‚Üí mid ‚Üí high level&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Modern practice&lt;/strong&gt;: Small 3√ó3 filters, deep networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output size&lt;/strong&gt;: Depends on kernel size, stride, padding&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Convolutional layers are the foundation of computer vision in deep learning. Mastering them is essential for any vision application!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;: Pooling layers and complete CNN architectures (AlexNet, VGG, ResNet)!&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>04 Introduction to Convolutional Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter04/04_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter04/04_00_Introduction</id>
   <content type="html">&lt;p&gt;Convolutional Neural Networks (CNNs) are specialized neural networks designed for processing grid-like data, especially images. This chapter introduces the fundamental concepts of CNNs including convolutional layers, pooling layers, and common CNN architectures that have revolutionized computer vision.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03-04 Practical Training Techniques</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_04_Training_Techniques/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter03/03_04_Training_Techniques</id>
   <content type="html">&lt;p&gt;This lesson covers practical techniques and best practices for training neural networks effectively.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;weight-initialization&quot;&gt;Weight Initialization&lt;/h2&gt;

&lt;p&gt;Proper initialization is crucial for successful training. Poor initialization can lead to vanishing/exploding gradients or slow convergence.&lt;/p&gt;

&lt;h3 id=&quot;bad-initialization-methods&quot;&gt;Bad Initialization Methods&lt;/h3&gt;

&lt;h4 id=&quot;1-all-zeros&quot;&gt;1. All Zeros&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: All neurons compute the same output and receive the same gradient ‚Üí No learning!&lt;/p&gt;

&lt;h4 id=&quot;2-all-same-values&quot;&gt;2. All Same Values&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Same as zeros - breaks symmetry.&lt;/p&gt;

&lt;h3 id=&quot;good-initialization-methods&quot;&gt;Good Initialization Methods&lt;/h3&gt;

&lt;h4 id=&quot;1-random-small-values&quot;&gt;1. Random Small Values&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Pros&lt;/strong&gt;: Breaks symmetry
&lt;strong&gt;Cons&lt;/strong&gt;: May be too small for deep networks&lt;/p&gt;

&lt;h4 id=&quot;2-xavierglorot-initialization&quot;&gt;2. Xavier/Glorot Initialization&lt;/h4&gt;

&lt;p&gt;For &lt;strong&gt;sigmoid&lt;/strong&gt; or &lt;strong&gt;tanh&lt;/strong&gt; activations:&lt;/p&gt;

\[\mathbf{W}^{[l]} \sim \mathcal{N}\left(0, \frac{1}{n^{[l-1]}}\right)\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;or&lt;/p&gt;

\[\mathbf{W}^{[l]} \sim \mathcal{N}\left(0, \frac{2}{n^{[l-1]} + n^{[l]}}\right)\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: Maintains variance of activations across layers.&lt;/p&gt;

&lt;h4 id=&quot;3-he-initialization&quot;&gt;3. He Initialization&lt;/h4&gt;

&lt;p&gt;For &lt;strong&gt;ReLU&lt;/strong&gt; activations (most common):&lt;/p&gt;

\[\mathbf{W}^{[l]} \sim \mathcal{N}\left(0, \frac{2}{n^{[l-1]}}\right)\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_l_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Why factor of 2?&lt;/strong&gt; ReLU zeros out half the neurons on average.&lt;/p&gt;

&lt;h3 id=&quot;bias-initialization&quot;&gt;Bias Initialization&lt;/h3&gt;

&lt;p&gt;Biases can typically be initialized to zero:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;complete-initialization-function&quot;&gt;Complete Initialization Function&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization_method&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;he&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Initialize network parameters
    
    layer_dims: list of layer sizes [n_x, n_h1, ..., n_y]
    initialization_method: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;xavier&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;he&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;xavier&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization_method&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;he&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;data-preprocessing&quot;&gt;Data Preprocessing&lt;/h2&gt;

&lt;h3 id=&quot;1-feature-scaling&quot;&gt;1. Feature Scaling&lt;/h3&gt;

&lt;p&gt;Normalize input features to similar ranges.&lt;/p&gt;

&lt;h4 id=&quot;standardization-z-score-normalization&quot;&gt;Standardization (Z-score Normalization)&lt;/h4&gt;

\[x_{\text{norm}} = \frac{x - \mu}{\sigma}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;standardize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Standardize features to mean=0, std=1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;std&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;std&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Add epsilon to avoid division by zero
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;std&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;min-max-normalization&quot;&gt;Min-Max Normalization&lt;/h4&gt;

\[x_{\text{norm}} = \frac{x - x_{\min}}{x_{\max} - x_{\min}}\]

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;min_max_normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Scale features to [0, 1]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_min&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_max&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;When to use what:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Standardization&lt;/strong&gt;: When features are normally distributed or have outliers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Min-Max&lt;/strong&gt;: When you need features in a specific range (e.g., [0, 1])&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-data-shuffling&quot;&gt;2. Data Shuffling&lt;/h3&gt;

&lt;p&gt;Shuffle training data before each epoch to prevent learning order-dependent patterns.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shuffle_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Shuffle training data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;batch-processing&quot;&gt;Batch Processing&lt;/h2&gt;

&lt;h3 id=&quot;creating-mini-batches&quot;&gt;Creating Mini-Batches&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Create list of mini-batches
    
    X: (n_x, m)
    Y: (n_y, m)
    batch_size: size of each mini-batch
    
    Returns: list of (X_batch, Y_batch) tuples
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Shuffle data
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shuffle_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Partition
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;num_complete_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_complete_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Handle remaining examples (if m is not divisible by batch_size)
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_complete_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_complete_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;trainvalidationtest-split&quot;&gt;Train/Validation/Test Split&lt;/h2&gt;

&lt;h3 id=&quot;why-three-sets&quot;&gt;Why Three Sets?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Training set&lt;/strong&gt;: Learn parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Validation set&lt;/strong&gt;: Tune hyperparameters, monitor overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Test set&lt;/strong&gt;: Final evaluation (use only once!)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;typical-splits&quot;&gt;Typical Splits&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Small dataset (&amp;lt; 10,000 examples):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train: 60%, Val: 20%, Test: 20%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Medium dataset (10,000 - 1,000,000):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train: 80%, Val: 10%, Test: 10%&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Large dataset (&amp;gt; 1,000,000):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Train: 98%, Val: 1%, Test: 1%&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;implementation&quot;&gt;Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_val_test_split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_ratio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_ratio&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Split data into train, validation, and test sets
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Shuffle first
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;shuffle_data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Calculate split indices
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_ratio&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Split
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]&lt;/span&gt;
    
    &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;monitoring-training&quot;&gt;Monitoring Training&lt;/h2&gt;

&lt;h3 id=&quot;metrics-to-track&quot;&gt;Metrics to Track&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Training Loss&lt;/strong&gt;: Should decrease steadily&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Validation Loss&lt;/strong&gt;: Should decrease; if it increases, overfitting!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Training Accuracy&lt;/strong&gt;: Should increase&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Validation Accuracy&lt;/strong&gt;: Should increase; gap with training accuracy indicates overfitting&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;visualization&quot;&gt;Visualization&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;matplotlib.pyplot&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;plot_training_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Plot training history&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;fig&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;subplots&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;figsize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;14&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Loss plot
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Validation Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training and Validation Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Accuracy plot
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;plot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Validation Accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_xlabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_ylabel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;set_title&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training and Validation Accuracy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;legend&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;ax2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;grid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tight_layout&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;plt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;show&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;early-stopping&quot;&gt;Early Stopping&lt;/h2&gt;

&lt;p&gt;Stop training when validation loss stops improving.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_delta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        patience: number of epochs to wait before stopping
        min_delta: minimum change to qualify as improvement
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min_delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;min_delta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__call__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_loss&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;is&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;min_delta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;EarlyStopping counter: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stop&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;copy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stop&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Usage in training loop
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Training...
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_one_epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;validate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(...)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Early stopping triggered!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;gradient-clipping&quot;&gt;Gradient Clipping&lt;/h2&gt;

&lt;p&gt;Prevent exploding gradients by clipping gradient magnitudes.&lt;/p&gt;

&lt;h3 id=&quot;clip-by-value&quot;&gt;Clip by Value&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;clip_gradients_by_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_value&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Clip gradients to [-max_value, max_value]&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_value&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;clip-by-norm&quot;&gt;Clip by Norm&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;clip_gradients_by_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Clip gradients by global norm&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Compute global norm
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;total_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;values&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;total_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Clip if necessary
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;clip_coef&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;total_norm&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clip_coef&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;key&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grad&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clip_coef&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;clipped_gradients&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;complete-training-loop&quot;&gt;Complete Training Loop&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;he&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping_patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Complete training function with all best practices
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Initialize
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initialization&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;EarlyStopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;early_stopping_patience&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# History
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Create mini-batches
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;create_mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Process each mini-batch
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Forward propagation
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute cost
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;batch_cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_cost&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Backward propagation
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Gradient clipping (optional)
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;clip_gradients_by_norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_norm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;5.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameters
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradients&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Average loss over all batches
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mini_batches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute training accuracy
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;train_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Validation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;val_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;val_pred_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_pred_labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Print progress
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;or&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
                  &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Train Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Train Acc: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;
                  &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Val Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Val Acc: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Early stopping
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Early stopping at epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;early_stopping&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_parameters&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Plot history
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;plot_training_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_accs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;hyperparameter-tuning&quot;&gt;Hyperparameter Tuning&lt;/h2&gt;

&lt;h3 id=&quot;key-hyperparameters&quot;&gt;Key Hyperparameters&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Learning rate&lt;/strong&gt; (most important)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Batch size&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number of layers&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Number of neurons per layer&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Activation functions&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Initialization method&lt;/strong&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;tuning-strategies&quot;&gt;Tuning Strategies&lt;/h3&gt;

&lt;h4 id=&quot;1-manual-search&quot;&gt;1. Manual Search&lt;/h4&gt;

&lt;p&gt;Try different values based on intuition and experience.&lt;/p&gt;

&lt;h4 id=&quot;2-grid-search&quot;&gt;2. Grid Search&lt;/h4&gt;

&lt;p&gt;Try all combinations of a predefined set of values.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;learning_rates&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;batch_sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;best_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rates&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                                     &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Last validation accuracy
&lt;/span&gt;        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;best_params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Best: LR=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, BS=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Val Acc=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;3-random-search&quot;&gt;3. Random Search&lt;/h4&gt;

&lt;p&gt;Often more efficient than grid search.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;num_trials&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;20&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trial&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_trials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;uniform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Log-uniform between 0.0001 and 0.1
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;choice&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_val&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                                 &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;best_val_acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;New best: LR=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, BS=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Val Acc=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;val_acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Proper initialization&lt;/strong&gt; (He for ReLU) prevents training issues&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data preprocessing&lt;/strong&gt; (standardization/normalization) improves convergence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mini-batch processing&lt;/strong&gt; balances speed and stability&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Train/Val/Test split&lt;/strong&gt; enables proper evaluation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monitoring&lt;/strong&gt; training/validation metrics detects overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Early stopping&lt;/strong&gt; prevents overfitting and saves time&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gradient clipping&lt;/strong&gt; prevents exploding gradients&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hyperparameter tuning&lt;/strong&gt; is essential for optimal performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;With these techniques, you‚Äôre equipped to train neural networks effectively. The next chapter covers Convolutional Neural Networks for computer vision tasks!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03-03 Backpropagation Algorithm</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_03_Backpropagation/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter03/03_03_Backpropagation</id>
   <content type="html">&lt;h1 id=&quot;backpropagation-the-engine-of-deep-learning&quot;&gt;Backpropagation: The Engine of Deep Learning&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/e/e4/Backpropagation_example.svg/600px-Backpropagation_example.svg.png&quot; alt=&quot;Backpropagation Visualization&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça qu√° tr√¨nh Backpropagation trong m·∫°ng neural. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Backpropagation is the algorithmic heart of deep learning, the mechanism that makes training neural networks practical. Without it, deep learning as we know it would not exist. The algorithm solves a deceptively simple problem: given a neural network with potentially millions of parameters and a measure of how wrong its predictions are, how should we adjust each parameter to improve performance? The naive approach‚Äîcomputing the gradient of each parameter independently through finite differences‚Äîwould require millions of forward passes per training example, making training prohibitively expensive. Backpropagation computes all these gradients simultaneously in roughly the same time as a single forward pass, a computational efficiency gain of millions.&lt;/p&gt;

&lt;p&gt;The fundamental insight of backpropagation is that gradients can be computed efficiently by reusing calculations. When we compute how the loss changes with respect to a parameter deep in the network, we‚Äôre applying the chain rule from calculus, but we‚Äôre doing so cleverly. Rather than recomputing the entire chain for each parameter, we compute intermediate derivatives once and reuse them. This dynamic programming approach transforms an exponential-time problem into a linear-time one, making training practical.&lt;/p&gt;

&lt;p&gt;What makes backpropagation particularly elegant is its local nature. Each layer needs only to know how to compute its own local gradients‚Äîhow its outputs change with respect to its inputs and parameters. It receives gradients from the layer above and passes gradients to the layer below. This modularity means we can mix different layer types (convolutional, recurrent, attention, etc.) in the same network, and as long as each can compute its local gradients, backpropagation works seamlessly. This is why modern deep learning frameworks can support such diverse architectures‚Äîthe backpropagation algorithm naturally handles any differentiable computational graph.&lt;/p&gt;

&lt;p&gt;Understanding backpropagation deeply means understanding not just the mechanics of computing gradients but why the algorithm is structured the way it is, what assumptions it makes, and where it can fail. The algorithm assumes our network consists of differentiable operations‚Äîthis is why activation functions must be smooth. It assumes we can store intermediate computations from the forward pass‚Äîthis is why memory limits constrain the batch sizes we can use. It propagates errors backward proportional to the weights‚Äîthis is why extremely large or small weights cause gradient explosions or vanishing. These aren‚Äôt just implementation details; they‚Äôre fundamental properties that shape how we design and train networks.&lt;/p&gt;

&lt;p&gt;The historical importance of backpropagation cannot be overstated. While gradient descent had been known since the 19th century and the chain rule is elementary calculus, recognizing how to apply these efficiently to multi-layer networks was the breakthrough that revived neural network research in the 1980s after the first AI winter. The algorithm was actually discovered multiple times independently by different researchers (Werbos in 1974, Rumelhart/Hinton/Williams in 1986, and others), but it was the 1986 Nature paper that brought it to widespread attention and demonstrated its power on problems like speech recognition and image classification. This marks one of those rare moments in science where a computational technique‚Äînot new data or more powerful hardware‚Äîfundamentally expanded what was possible.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;To truly understand backpropagation, we must first be precise about what we‚Äôre computing and why. Our goal is to minimize a loss function \(\mathcal{L}(\mathbf{y}, \hat{\mathbf{y}})\) that measures the discrepancy between our network‚Äôs predictions \(\hat{\mathbf{y}}\) and the true labels \(\mathbf{y}\). The network is a composition of functions, one per layer, and each layer has parameters (weights and biases) that we can adjust. Gradient descent tells us that to minimize the loss, we should adjust each parameter \(\theta\) in the direction opposite to the gradient:&lt;/p&gt;

\[\theta \leftarrow \theta - \eta \frac{\partial \mathcal{L}}{\partial \theta}\]

&lt;p&gt;The challenge is computing \(\frac{\partial \mathcal{L}}{\partial \theta}\) efficiently for every parameter in the network. Let‚Äôs build up the mathematics carefully, starting with a simple two-layer network and then generalizing.&lt;/p&gt;

&lt;p&gt;Consider a network with input \(\mathbf{x}\), one hidden layer with activation \(\mathbf{h}\), and output \(\hat{\mathbf{y}}\). The forward pass computes:&lt;/p&gt;

&lt;p&gt;\(\mathbf{z}^{[1]} = \mathbf{W}^{[1]} \mathbf{x} + \mathbf{b}^{[1]}\)
\(\mathbf{h} = \mathbf{a}^{[1]} = g^{[1]}(\mathbf{z}^{[1]})\)
\(\mathbf{z}^{[2]} = \mathbf{W}^{[2]} \mathbf{h} + \mathbf{b}^{[2]}\)
\(\hat{\mathbf{y}} = \mathbf{a}^{[2]} = g^{[2]}(\mathbf{z}^{[2]})\)
\(\mathcal{L} = \mathcal{L}(\mathbf{y}, \hat{\mathbf{y}})\)&lt;/p&gt;

&lt;p&gt;where \(g^{[l]}\) denotes the activation function for layer \(l\). To find \(\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[1]}}\), we apply the chain rule:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[1]}} = \frac{\partial \mathcal{L}}{\partial \hat{\mathbf{y}}} \frac{\partial \hat{\mathbf{y}}}{\partial \mathbf{z}^{[2]}} \frac{\partial \mathbf{z}^{[2]}}{\partial \mathbf{h}} \frac{\partial \mathbf{h}}{\partial \mathbf{z}^{[1]}} \frac{\partial \mathbf{z}^{[1]}}{\partial \mathbf{W}^{[1]}}\]

&lt;p&gt;Computing this directly involves multiplying many Jacobian matrices, which seems expensive. The key insight of backpropagation is to compute these products right-to-left, reusing intermediate results.&lt;/p&gt;

&lt;p&gt;Define the error term for each layer as:&lt;/p&gt;

\[\boldsymbol{\delta}^{[l]} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}^{[l]}}\]

&lt;p&gt;This quantity represents the sensitivity of the loss to changes in the pre-activation of layer \(l\). For the output layer with binary cross-entropy loss and sigmoid activation, something remarkable happens:&lt;/p&gt;

\[\boldsymbol{\delta}^{[L]} = \frac{\partial \mathcal{L}}{\partial \mathbf{z}^{[L]}} = \frac{\partial \mathcal{L}}{\partial \mathbf{a}^{[L]}} \frac{\partial \mathbf{a}^{[L]}}{\partial \mathbf{z}^{[L]}}\]

&lt;p&gt;The loss derivative is \(\frac{\partial \mathcal{L}}{\partial \mathbf{a}^{[L]}} = -\frac{\mathbf{y}}{\mathbf{a}^{[L]}} + \frac{1-\mathbf{y}}{1-\mathbf{a}^{[L]}}\), and the sigmoid derivative is \(\frac{\partial \mathbf{a}^{[L]}}{\partial \mathbf{z}^{[L]}} = \mathbf{a}^{[L]}(1-\mathbf{a}^{[L]})\). When you multiply these together and simplify, almost all terms cancel, leaving simply:&lt;/p&gt;

\[\boldsymbol{\delta}^{[L]} = \mathbf{a}^{[L]} - \mathbf{y}\]

&lt;p&gt;This beautiful simplification‚Äîthat the output error is just the difference between prediction and truth‚Äîoccurs for several common loss/activation combinations (MSE with linear, cross-entropy with sigmoid, cross-entropy with softmax). It‚Äôs not a coincidence but a deliberate design: these combinations were chosen precisely because they yield simple gradients.&lt;/p&gt;

&lt;p&gt;For hidden layers, we propagate the error backward:&lt;/p&gt;

\[\boldsymbol{\delta}^{[l]} = (\mathbf{W}^{[l+1]})^T \boldsymbol{\delta}^{[l+1]} \odot g&apos;^{[l]}(\mathbf{z}^{[l]})\]

&lt;p&gt;Let‚Äôs parse this equation carefully because it encodes the core of backpropagation. The term \((\mathbf{W}^{[l+1]})^T \boldsymbol{\delta}^{[l+1]}\) propagates the error from layer \(l+1\) back to layer \(l\), weighted by the connection strengths (the transpose of the weight matrix). If a particular hidden neuron has strong connections to neurons with large errors in the next layer, it receives a large error signal. The Hadamard product \(\odot g&apos;^{[l]}(\mathbf{z}^{[l]})\) then scales this by the local gradient of the activation function. This scaling is crucial: if the activation function is saturated (gradient near zero), the error signal is suppressed, which is exactly what causes the vanishing gradient problem in deep networks with sigmoid/tanh activations.&lt;/p&gt;

&lt;p&gt;Once we have the error terms \(\boldsymbol{\delta}^{[l]}\), computing parameter gradients becomes straightforward:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[l]}} = \boldsymbol{\delta}^{[l]} (\mathbf{a}^{[l-1]})^T\]

\[\frac{\partial \mathcal{L}}{\partial \mathbf{b}^{[l]}} = \boldsymbol{\delta}^{[l]}\]

&lt;p&gt;The weight gradient is an outer product of the error signal with the layer‚Äôs input, which has an elegant interpretation: we adjust connection strength proportionally to both the error at the output and the activation at the input. Strong input with large error means this connection should change substantially. The bias gradient is simply the error signal itself, since the bias always has an ‚Äúinput‚Äù of 1.&lt;/p&gt;

&lt;p&gt;The computational complexity analysis reveals backpropagation‚Äôs efficiency. A forward pass through a network with \(L\) layers, \(n\) neurons per layer, and batch size \(m\) requires \(O(L \cdot n^2 \cdot m)\) operations (dominated by matrix multiplications). Amazingly, backpropagation requires exactly the same complexity‚Äîwe compute all gradients for all parameters in the same time as one forward pass. Compare this to naive gradient computation via finite differences, which would require \(O(P)\) forward passes where \(P\) is the number of parameters, potentially millions. This efficiency difference‚Äîlinear versus quadratic in the number of parameters‚Äîis what makes deep learning tractable.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;Let‚Äôs work through a complete example with actual numbers to demystify backpropagation. Consider the simplest interesting case: a two-layer network for binary classification. We have two inputs, two hidden neurons with ReLU activation, and one output with sigmoid activation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Network architecture&lt;/strong&gt;:
\(\mathbf{x} \in \mathbb{R}^2 \xrightarrow{\mathbf{W}^{[1]}, \mathbf{b}^{[1]}} \mathbf{z}^{[1]} \in \mathbb{R}^2 \xrightarrow{\text{ReLU}} \mathbf{a}^{[1]} \in \mathbb{R}^2 \xrightarrow{\mathbf{W}^{[2]}, \mathbf{b}^{[2]}} z^{[2]} \in \mathbb{R} \xrightarrow{\text{Sigmoid}} \hat{y} \in (0,1)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt; (initialized):
\(\mathbf{W}^{[1]} = \begin{bmatrix} 0.5 &amp;amp; -0.3 \\ 0.2 &amp;amp; 0.8 \end{bmatrix}, \quad \mathbf{b}^{[1]} = \begin{bmatrix} 0.1 \\ -0.2 \end{bmatrix}\)&lt;/p&gt;

\[\mathbf{W}^{[2]} = \begin{bmatrix} 1.0 &amp;amp; -0.5 \end{bmatrix}, \quad b^{[2]} = 0.5\]

&lt;p&gt;&lt;strong&gt;Input and label&lt;/strong&gt;: \(\mathbf{x} = \begin{bmatrix} 1.0 \\ 2.0 \end{bmatrix}\), \(y = 1\) (true class is positive)&lt;/p&gt;

&lt;p&gt;Now let‚Äôs trace through forward and backward passes step by step, understanding what each computation means.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Forward Pass&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{z}^{[1]} = \begin{bmatrix} 0.5 &amp;amp; -0.3 \\ 0.2 &amp;amp; 0.8 \end{bmatrix} \begin{bmatrix} 1.0 \\ 2.0 \end{bmatrix} + \begin{bmatrix} 0.1 \\ -0.2 \end{bmatrix} = \begin{bmatrix} 0.5 - 0.6 + 0.1 \\ 0.2 + 1.6 - 0.2 \end{bmatrix} = \begin{bmatrix} 0.0 \\ 1.6 \end{bmatrix}\]

&lt;p&gt;The first hidden neuron receives \(z^{[1]}_1 = 0\), exactly at the ReLU threshold. The second receives \(z^{[1]}_2 = 1.6\), a strong positive signal. Applying ReLU:&lt;/p&gt;

\[\mathbf{a}^{[1]} = \max(0, \mathbf{z}^{[1]}) = \begin{bmatrix} 0.0 \\ 1.6 \end{bmatrix}\]

&lt;p&gt;The first neuron outputs zero (it‚Äôs on the boundary), while the second is active. This creates a sparse representation‚Äîonly one of two neurons is contributing. Now these activations feed into the output layer:&lt;/p&gt;

\[z^{[2]} = \begin{bmatrix} 1.0 &amp;amp; -0.5 \end{bmatrix} \begin{bmatrix} 0.0 \\ 1.6 \end{bmatrix} + 0.5 = 0 - 0.8 + 0.5 = -0.3\]

&lt;p&gt;The output layer receives a slightly negative input, suggesting the network currently leans toward predicting class 0. Applying sigmoid:&lt;/p&gt;

\[\hat{y} = \sigma(-0.3) = \frac{1}{1 + e^{0.3}} \approx 0.426\]

&lt;p&gt;Our network predicts 42.6% probability of class 1, but the true label is 1 (100% probability). The loss, using binary cross-entropy, is:&lt;/p&gt;

\[\mathcal{L} = -[1 \cdot \log(0.426) + 0 \cdot \log(1-0.426)] = -\log(0.426) \approx 0.853\]

&lt;p&gt;This loss quantifies our mistake. Now backpropagation will tell us how to adjust each weight to reduce this loss.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Backward Pass&lt;/strong&gt;:&lt;/p&gt;

&lt;p&gt;Starting from the output, the error is:&lt;/p&gt;

\[\delta^{[2]} = \hat{y} - y = 0.426 - 1 = -0.574\]

&lt;p&gt;This negative error means our output is too low‚Äîwe need to increase it. The gradient with respect to the output layer weights is:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[2]}} = \delta^{[2]} (\mathbf{a}^{[1]})^T = -0.574 \times \begin{bmatrix} 0.0 &amp;amp; 1.6 \end{bmatrix} = \begin{bmatrix} 0 &amp;amp; -0.918 \end{bmatrix}\]

&lt;p&gt;The gradient is zero for the connection from the first hidden neuron (which was inactive) and -0.918 for the second. This tells us to increase \(W^{[2]}_2\) (currently -0.5) to make the output larger. This makes perfect sense: the second hidden neuron was active and could have contributed more to the output, so we strengthen that connection.&lt;/p&gt;

&lt;p&gt;Now we propagate error to the hidden layer:&lt;/p&gt;

\[\boldsymbol{\delta}^{[1]} = (\mathbf{W}^{[2]})^T \delta^{[2]} \odot \text{ReLU}&apos;(\mathbf{z}^{[1]})\]

&lt;p&gt;Let‚Äôs compute each part. The weights-transposed-times-error gives:&lt;/p&gt;

\[(\mathbf{W}^{[2]})^T \delta^{[2]} = \begin{bmatrix} 1.0 \\ -0.5 \end{bmatrix} \times (-0.574) = \begin{bmatrix} -0.574 \\ 0.287 \end{bmatrix}\]

&lt;p&gt;The ReLU derivative is 1 where the input was positive, 0 where it was negative:&lt;/p&gt;

\[\text{ReLU}&apos;(\mathbf{z}^{[1]}) = \text{ReLU}&apos;\begin{pmatrix} \begin{bmatrix} 0.0 \\ 1.6 \end{bmatrix} \end{pmatrix} = \begin{bmatrix} 0 \\ 1 \end{bmatrix}\]

&lt;p&gt;Note that the first hidden neuron, which was exactly at the threshold (\(z=0\)), has zero gradient. This is the dying ReLU problem in action‚Äîneurons at or below zero don‚Äôt propagate gradients. The element-wise product gives:&lt;/p&gt;

\[\boldsymbol{\delta}^{[1]} = \begin{bmatrix} -0.574 \\ 0.287 \end{bmatrix} \odot \begin{bmatrix} 0 \\ 1 \end{bmatrix} = \begin{bmatrix} 0 \\ 0.287 \end{bmatrix}\]

&lt;p&gt;Finally, the input layer weight gradients:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[1]}} = \boldsymbol{\delta}^{[1]} \mathbf{x}^T = \begin{bmatrix} 0 \\ 0.287 \end{bmatrix} \begin{bmatrix} 1.0 &amp;amp; 2.0 \end{bmatrix} = \begin{bmatrix} 0 &amp;amp; 0 \\ 0.287 &amp;amp; 0.574 \end{bmatrix}\]

&lt;p&gt;Only the second hidden neuron‚Äôs weights receive gradients. The gradient suggests increasing both weights to make this neuron activate more strongly for similar inputs, which would ultimately increase the network‚Äôs output toward the target of 1.&lt;/p&gt;

&lt;p&gt;This step-by-step walkthrough reveals the logic of backpropagation. Errors flow backward through the network, attenuated by the local derivatives. Active neurons with strong connections to high-error outputs receive large gradients and update substantially. Inactive neurons or those with weak connections receive small gradients and update little or not at all. This automatic assignment of credit and blame is what enables networks to learn complex functions‚Äîeach parameter adjusts proportionally to its contribution to the error.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement backpropagation from scratch to understand every detail, then show how PyTorch automates this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Sigmoid activation: maps real numbers to (0, 1)
    
    Why sigmoid? It&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s smooth (differentiable everywhere), bounded (outputs
    don&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t explode), and has probabilistic interpretation. The derivative
    has a beautiful form: œÉ&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;(z) = œÉ(z)(1 - œÉ(z)), which we can compute
    from the activation itself without storing z.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Clip for numerical stability
&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Derivative in terms of activation (not z!)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    ReLU: max(0, z) - outputs input if positive, zero otherwise
    
    Why ReLU? It&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s computationally trivial (just thresholding), doesn&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t
    saturate for positive inputs (gradient is 1, not approaching 0),
    and induces sparse representations. These properties make it vastly
    superior for deep networks compared to sigmoid/tanh.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Derivative is 1 where z &amp;gt; 0, zero elsewhere
    
    Note: at z=0, derivative is undefined. In practice, we define it as 0
    or sometimes 0.5, but this rarely matters since exact equality is rare.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetworkBackprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Implementing backpropagation manually to understand every step.
    
    This implementation prioritizes clarity over efficiency. Each operation
    is explicit, gradients are computed manually, and we store everything
    needed for understanding. A production implementation would vectorize
    more aggressively and use automatic differentiation.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        layer_sizes: list like [2, 4, 3, 1] for 2 inputs, hidden layers of 4 and 3, 1 output
        
        We initialize weights using He initialization for hidden layers (assuming ReLU)
        and small random values for output layer. This initialization scheme ensures
        activations maintain reasonable scale through forward pass and gradients
        maintain reasonable scale through backward pass.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Number of weight layers
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# He initialization for ReLU layers: variance = 2/n_in
&lt;/span&gt;                &lt;span class=&quot;c1&quot;&gt;# Why? ReLU zeros half the neurons, so we need ‚àö2 instead of ‚àö1
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Output layer: smaller weights for numerical stability
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_in&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Initialized network with architecture: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Total parameters: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;count_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;count_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Count total trainable parameters&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;size&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Forward propagation with detailed caching for backward pass.
        
        We must store Z (pre-activations) and A (activations) for each layer
        because backpropagation needs them. This is a memory vs computation tradeoff:
        we could recompute forward pass during backward pass, but storing is faster.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;A0&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Hidden layers with ReLU
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer with sigmoid
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Binary cross-entropy loss with numerical stability tricks.
        
        The loss -[y log(≈∑) + (1-y) log(1-≈∑)] has a problem: if ≈∑ is exactly
        0 or 1, we compute log(0) = -‚àû. We clip predictions to [Œµ, 1-Œµ] to prevent this.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;AL_clipped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL_clipped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL_clipped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Backpropagation: compute all parameter gradients efficiently.
        
        The algorithm processes layers in reverse order, maintaining error terms
        and using cached forward pass values. Each layer&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s gradient depends on
        gradients from layers above it, creating the backward flow of information
        that gives the algorithm its name.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer error (for BCE + sigmoid this is remarkably simple!)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Derivative of loss
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dZL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dAL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# But actually, dZL = AL - Y works directly
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Simplification for BCE + Sigmoid (should use this in practice)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dZL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize dA for propagation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZL&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Hidden layers (backward through layers L-1 down to 1)
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;reversed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Current layer&apos;s error
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Gradients for this layer
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Propagate error to previous layer (if not input layer)
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;dA&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dZ&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Gradient descent update: Œ∏ ‚Üê Œ∏ - Œ∑ ‚àáŒ∏ L
        
        We move parameters in the direction that decreases loss. The learning
        rate Œ∑ controls step size‚Äîtoo large causes overshooting and instability,
        too small causes slow convergence.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;dW&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;params&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;db&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Complete training loop: forward ‚Üí loss ‚Üí backward ‚Üí update
        
        This is the standard training loop for neural networks. Each iteration
        processes the entire dataset (batch gradient descent). In practice, we&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;d
        use mini-batches for efficiency.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Forward propagation
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute loss
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;compute_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Backward propagation
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameters
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;update_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;grads&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Print progress
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_every&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Accuracy = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate on XOR problem
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Neural Network on XOR using Manual Backpropagation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# XOR dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                  &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Shape: (2, 4)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Shape: (1, 4)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Create and train network
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;42&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# For reproducibility
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetworkBackprop&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 2‚Üí4‚Üí4‚Üí1 architecture
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;losses&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;print_every&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test final performance
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final Results&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;AL_final&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL_final&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, True: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predicted: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Probability: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;AL_final&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Success! Backpropagation enabled the network to learn XOR.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let‚Äôs see how PyTorch automates all of this:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleNetPyTorch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Same network using PyTorch&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s automatic differentiation.
    
    Notice how we don&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t implement backward() - PyTorch computes all gradients
    automatically by building a computational graph during forward pass and
    applying backpropagation when we call loss.backward().
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SimpleNetPyTorch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training with PyTorch
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleNetPyTorch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;SGD&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Convert to PyTorch tensors
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_torch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (4, 2)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_torch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Y_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;float32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (4, 1)
&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training with PyTorch Automatic Differentiation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward pass - PyTorch does backpropagation automatically!
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Clear old gradients
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Compute gradients via automatic differentiation
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;       &lt;span class=&quot;c1&quot;&gt;# Update weights
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;500&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Y_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Loss = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Accuracy = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;acc&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Final test
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;final_preds&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;PyTorch Final Results&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;70&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Input: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Predicted: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_preds&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The comparison reveals the power of modern frameworks. Our manual implementation took ~100 lines to implement backpropagation for a simple network. PyTorch handles arbitrary architectures automatically. However, understanding the manual implementation is invaluable. When debugging why a network isn‚Äôt training, when implementing custom layers, or when reading research papers that discuss gradient flow, the deep understanding from manual implementation is essential.&lt;/p&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Backpropagation doesn‚Äôt exist in isolation‚Äîit‚Äôs intimately connected to numerous other concepts in deep learning and machine learning more broadly. Understanding these connections transforms backpropagation from a mere algorithm into a window into the fundamental principles of learning systems.&lt;/p&gt;

&lt;p&gt;The most direct connection is to gradient descent and its variants. Backpropagation solves the problem of computing gradients, but it‚Äôs gradient descent that uses these gradients to update parameters. The choice of optimization algorithm‚Äîvanilla gradient descent, SGD with momentum, Adam, etc.‚Äîdetermines how we use backpropagation‚Äôs gradients. Understanding this separation helps clarify responsibilities: backpropagation tells us which direction decreases loss, while the optimizer decides how far to move in that direction and potentially accumulates information across iterations.&lt;/p&gt;

&lt;p&gt;Automatic differentiation, the technology underlying PyTorch and TensorFlow, is backpropagation‚Äôs computational cousin. While backpropagation is typically described as an algorithm for neural networks, automatic differentiation is a more general technique for computing derivatives of arbitrary programs. Modern frameworks build a computational graph during the forward pass, where nodes represent operations (matrix multiply, add, ReLU, etc.) and edges represent data flow. Backpropagation is then simply reverse-mode automatic differentiation on this graph. Understanding this connection explains why frameworks can handle arbitrary architectures‚Äîas long as each operation is differentiable, backpropagation works automatically.&lt;/p&gt;

&lt;p&gt;The vanishing and exploding gradient problems are direct consequences of how backpropagation propagates errors through layers. Each layer‚Äôs error is the previous layer‚Äôs error multiplied by weights and activation derivatives. If these multipliers are consistently less than 1 (as with saturated sigmoid/tanh activations), errors shrink exponentially with depth‚Äîthis is vanishing gradients. If multipliers are greater than 1, errors explode. This understanding motivated numerous innovations: ReLU activations keep gradients at 1 for positive inputs, batch normalization keeps activations in reasonable ranges, residual connections provide gradient highways bypassing many layers, and careful initialization ensures neither vanishing nor explosion at the start of training.&lt;/p&gt;

&lt;p&gt;Computational graphs and backpropagation connect to a beautiful area of computer science: automatic differentiation and the calculus of variations. Every differentiable program can be seen as defining a function from inputs to outputs, and automatic differentiation provides the gradient of this function. This generality means backpropagation isn‚Äôt limited to feedforward networks‚Äîit works for recurrent networks (backpropagation through time), for networks with complex control flow, even for networks where the architecture itself depends on the data (dynamic networks). The principle is always the same: build the computational graph, compute forward pass, compute backward pass using the chain rule.&lt;/p&gt;

&lt;p&gt;Finally, backpropagation connects to the broader question of credit assignment in learning systems. When a network makes a mistake, which parameters were responsible? Backpropagation provides one answer: assign credit proportional to gradients. But this isn‚Äôt the only possible answer. Reinforcement learning uses different credit assignment mechanisms for sequential decision problems. Attention mechanisms provide another form of credit assignment for sequence-to-sequence tasks. Understanding backpropagation as one solution to credit assignment helps us appreciate both its power and its limitations, and motivates alternative approaches when backpropagation‚Äôs assumptions don‚Äôt hold.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.nature.com/articles/323533a0&quot;&gt;‚ÄúLearning representations by back-propagating errors‚Äù (1986)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams&lt;br /&gt;
This seminal Nature paper made backpropagation widely known and demonstrated its power on practical problems including speech recognition and image classification. The paper elegantly presented the algorithm, proved its correctness via the chain rule, and showed that multi-layer networks trained with backpropagation could solve problems impossible for single-layer perceptrons. The authors demonstrated learning internal representations‚Äîhidden layers discovering useful features automatically‚Äîwhich was revelatory at the time. This paper effectively launched the connectionist revolution and remains one of the most cited papers in all of machine learning. Reading it today, one is struck by how clearly the authors understood both the algorithm‚Äôs power and its challenges, including what we now call vanishing gradients.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf&quot;&gt;‚ÄúEfficient BackProp‚Äù (1998)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Yann LeCun, L√©on Bottou, Genevieve B. Orr, Klaus-Robert M√ºller&lt;br /&gt;
This technical report, though less famous than the original backpropagation paper, is arguably more important for practitioners. LeCun and colleagues systematically analyzed what makes backpropagation work well in practice, covering initialization (why random weights should have carefully chosen variance), normalization (why standardizing inputs helps), learning rate selection, and activation function choices. The paper provides the practical wisdom accumulated from years of making backpropagation work on real problems. Many ‚Äútricks‚Äù taught in modern deep learning courses‚Äîlike He initialization and input normalization‚Äîhave their roots in insights from this paper. It‚Äôs essential reading for anyone who wants to train networks effectively rather than just mechanically applying backpropagation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1211.5063&quot;&gt;‚ÄúOn the difficulty of training Recurrent Neural Networks‚Äù (2013)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Razvan Pascanu, Tomas Mikolov, Yoshua Bengio&lt;br /&gt;
This paper rigorously analyzed why backpropagation fails in recurrent neural networks‚Äîspecifically, why gradients vanish or explode when propagating back through time. The authors showed that when unrolling an RNN through many time steps, gradients must pass through repeated matrix multiplications, and if the largest eigenvalue of the recurrent weight matrix is less than 1, gradients vanish exponentially; if greater than 1, they explode. The paper proposed gradient clipping to handle explosions (still standard practice today) and analyzed how LSTM‚Äôs gating mechanisms mitigate vanishing gradients. This work deepened our understanding of backpropagation‚Äôs limitations and motivated architectural innovations like LSTMs and GRUs that make recurrent backpropagation more stable.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://openreview.net/forum?id=BJJsrmfCZ&quot;&gt;‚ÄúAutomatic differentiation in PyTorch‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Adam Paszke, Sam Gross, Soumith Chintala, et al.&lt;br /&gt;
This paper described PyTorch‚Äôs autograd system, which automates backpropagation using dynamic computational graphs. Unlike earlier frameworks that required defining the network structure statically, PyTorch builds the graph during forward execution, allowing for dynamic architectures (where the computation depends on the data). The paper explained how PyTorch computes gradients using reverse-mode automatic differentiation‚Äîwhich is backpropagation generalized to arbitrary code, not just neural networks. This flexibility made PyTorch popular in research where experimenting with novel architectures is common. Understanding how frameworks automate backpropagation helps users debug gradient issues and implement custom operations correctly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://www.deeplearningbook.org/contents/mlp.html&quot;&gt;‚ÄúDeep Learning‚Äù - Chapter 6 (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ian Goodfellow, Yoshua Bengio, Aaron Courville&lt;br /&gt;
While not a research paper, this textbook chapter provides the most comprehensive and rigorous treatment of backpropagation available. It covers the algorithm from first principles, discusses computational graphs in detail, analyzes complexity, and addresses practical considerations like numerical stability and memory management. The chapter bridges theory and practice, explaining not just what backpropagation computes but why it computes it that way, how to implement it efficiently, and when it might fail. For anyone seeking a complete mathematical understanding of backpropagation, this chapter is the definitive resource. It‚Äôs also freely available online, making it accessible to all learners.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;Perhaps the most insidious pitfall in backpropagation is failing to cache forward pass values. During the forward pass, we must store both pre-activations \(\mathbf{z}^{[l]}\) and activations \(\mathbf{a}^{[l]}\) for every layer because the backward pass needs them. Forgetting to cache these values or overwriting them before the backward pass completes means you‚Äôll have to recompute the forward pass, doubling computation time, or worse, using incorrect values and getting wrong gradients. This is why modern frameworks automatically handle caching‚Äîthe computational graph remembers all intermediate values. When implementing backpropagation manually, explicitly maintain a cache dictionary is good practice.&lt;/p&gt;

&lt;p&gt;Dimension mismatches between gradients and parameters are another common error that can be subtle to debug. The gradient \(\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[l]}}\) must have exactly the same shape as \(\mathbf{W}^{[l]}\)‚Äîif \(\mathbf{W}^{[l]}\) is \(n_{out} \times n_{in}\), so must be its gradient. When computing \(\boldsymbol{\delta}^{[l]} (\mathbf{a}^{[l-1]})^T\), getting the order of multiplication wrong or forgetting the transpose can produce a matrix of the wrong shape that Python might broadcast incorrectly, leading to subtle bugs. Always assert that gradient shapes match parameter shapes after computing them.&lt;/p&gt;

&lt;p&gt;Numerical instability in gradient computation can cause training to fail in ways that aren‚Äôt immediately obvious. When computing sigmoid derivatives \(\sigma&apos;(z) = \sigma(z)(1-\sigma(z))\), if \(z\) is very large, \(\sigma(z) \approx 1\) and the derivative becomes \(1 \times (1-1) = 0\) numerically, even though mathematically it should be a small positive number. This causes gradients to vanish not due to network depth but due to floating-point precision. Clipping intermediate values to reasonable ranges and using numerically stable implementations (like log-sum-exp trick for softmax) prevents these issues.&lt;/p&gt;

&lt;p&gt;A powerful debugging technique is gradient checking through numerical approximation. For any parameter \(\theta\), we can approximate its gradient using finite differences:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \theta} \approx \frac{\mathcal{L}(\theta + \epsilon) - \mathcal{L}(\theta - \epsilon)}{2\epsilon}\]

&lt;p&gt;with \(\epsilon \approx 10^{-7}\). Comparing this numerical gradient to the backpropagation gradient reveals implementation errors. The relative difference should be less than \(10^{-7}\) for correct implementations. However, gradient checking is slow (requires multiple forward passes) so use it only for debugging, never during actual training.&lt;/p&gt;

&lt;p&gt;Gradient clipping deserves special mention as an essential trick when training recurrent networks or any deep architecture prone to gradient explosion. We monitor the global gradient norm \(\|\nabla_\theta \mathcal{L}\|_2 = \sqrt{\sum_{\theta} (\frac{\partial \mathcal{L}}{\partial \theta})^2}\) and if it exceeds a threshold (typically 5 or 10), we scale all gradients by \(\frac{\text{threshold}}{\|\nabla_\theta \mathcal{L}\|_2}\). This preserves gradient directions while preventing the explosive updates that would destabilize training. It‚Äôs a simple trick that makes training many architectures possible.&lt;/p&gt;

&lt;p&gt;Finally, understanding that backpropagation is just an efficient implementation of the chain rule means you can derive gradients for custom layers yourself. When implementing a novel operation, derive its local gradient (how outputs change with respect to inputs), and backpropagation automatically incorporates it into the full network gradient. This understanding is empowering‚Äîyou‚Äôre not limited to predefined layers but can create whatever computations your problem requires, as long as you can differentiate them.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;Backpropagation is fundamentally an efficient application of the calculus chain rule to compute gradients in neural networks. Its efficiency‚Äîcomputing all gradients in time proportional to one forward pass‚Äîmakes training deep networks tractable. The algorithm processes layers in reverse order, propagating errors backward and using cached forward pass values to compute parameter gradients. The beautiful simplicity of \(\boldsymbol{\delta}^{[L]} = \mathbf{a}^{[L]} - \mathbf{y}\) for output layers with appropriate loss/activation pairs is not coincidence but careful design. Modern frameworks automate backpropagation through automatic differentiation, building computational graphs and applying reverse-mode differentiation. Understanding backpropagation deeply means understanding not just the mechanics but the why‚Äîwhy we cache values, why gradients vanish or explode, why certain design choices simplify gradients‚Äîand this understanding is essential for debugging training failures, designing novel architectures, and truly mastering deep learning rather than merely applying it.&lt;/p&gt;

&lt;p&gt;The journey from manually implementing backpropagation to using it seamlessly through PyTorch mirrors the journey from understanding to application, and both are necessary for expertise.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>03-02 Gradient Descent</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_02_Gradient_Descent/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter03/03_02_Gradient_Descent</id>
   <content type="html">&lt;p&gt;This lesson introduces gradient descent, the fundamental deep-learning algorithm used to train neural networks.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;the-deep-learning-problem&quot;&gt;The Deep Learning Problem&lt;/h2&gt;

&lt;p&gt;Training a neural network is an &lt;strong&gt;deep-learning problem&lt;/strong&gt;: Find parameters \(\theta = \{\mathbf{W}^{[1]}, \mathbf{b}^{[1]}, \ldots, \mathbf{W}^{[L]}, \mathbf{b}^{[L]}\}\) that minimize the cost function:&lt;/p&gt;

\[\theta^* = \arg\min_{\theta} J(\theta)\]

&lt;p&gt;where \(J(\theta)\) is the average loss over all training examples.&lt;/p&gt;

&lt;h2 id=&quot;gradient-descent-the-core-idea&quot;&gt;Gradient Descent: The Core Idea&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/f/ff/Gradient_descent.svg/600px-Gradient_descent.svg.png&quot; alt=&quot;Gradient Descent Visualization&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Minh h·ªça Gradient Descent tr√™n h√†m m·∫•t m√°t. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; is an iterative deep-learning algorithm that moves parameters in the direction that decreases the cost function most rapidly.&lt;/p&gt;

&lt;h3 id=&quot;the-gradient&quot;&gt;The Gradient&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;gradient&lt;/strong&gt; \(\nabla_{\theta} J(\theta)\) is a vector of partial derivatives:&lt;/p&gt;

\[\nabla_{\theta} J = \begin{bmatrix} \frac{\partial J}{\partial \theta_1} \\ \frac{\partial J}{\partial \theta_2} \\ \vdots \\ \frac{\partial J}{\partial \theta_n} \end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Key property&lt;/strong&gt;: The gradient points in the direction of &lt;strong&gt;steepest ascent&lt;/strong&gt;. Therefore, the negative gradient points in the direction of &lt;strong&gt;steepest descent&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;update-rule&quot;&gt;Update Rule&lt;/h3&gt;

&lt;p&gt;The gradient descent update rule is:&lt;/p&gt;

\[\theta := \theta - \eta \nabla_{\theta} J(\theta)\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\eta\) is the &lt;strong&gt;learning rate&lt;/strong&gt; (a positive scalar hyperparameter)&lt;/li&gt;
  &lt;li&gt;\(:=\) denotes assignment/update&lt;/li&gt;
  &lt;li&gt;\(\nabla_{\theta} J(\theta)\) is the gradient of the cost function&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;For each parameter in a neural network:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{W}^{[l]} := \mathbf{W}^{[l]} - \eta \frac{\partial J}{\partial \mathbf{W}^{[l]}}\]

\[\mathbf{b}^{[l]} := \mathbf{b}^{[l]} - \eta \frac{\partial J}{\partial \mathbf{b}^{[l]}}\]

&lt;h3 id=&quot;geometric-intuition&quot;&gt;Geometric Intuition&lt;/h3&gt;

&lt;p&gt;Imagine you‚Äôre on a mountainside and want to reach the valley (minimum):&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Check the slope around you (compute gradient)&lt;/li&gt;
  &lt;li&gt;Take a step downhill (in the direction of negative gradient)&lt;/li&gt;
  &lt;li&gt;Repeat until you reach the bottom (convergence)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The learning rate \(\eta\) determines the &lt;strong&gt;step size&lt;/strong&gt;.&lt;/p&gt;

&lt;h2 id=&quot;variants-of-gradient-descent&quot;&gt;Variants of Gradient Descent&lt;/h2&gt;

&lt;h3 id=&quot;1-batch-gradient-descent-vanilla-gd&quot;&gt;1. Batch Gradient Descent (Vanilla GD)&lt;/h3&gt;

&lt;p&gt;Uses &lt;strong&gt;all training examples&lt;/strong&gt; to compute the gradient at each step.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Repeat until convergence:
    1. Compute gradient using all m examples:
       ‚àáJ(Œ∏) = (1/m) Œ£·µ¢‚Çå‚ÇÅ·µê ‚àáL(≈∑‚ÅΩ‚Å±‚Åæ, y‚ÅΩ‚Å±‚Åæ)
    
    2. Update parameters:
       Œ∏ := Œ∏ - Œ∑ ‚àáJ(Œ∏)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Guaranteed to converge to global minimum (for convex functions)&lt;/li&gt;
  &lt;li&gt;Stable convergence&lt;/li&gt;
  &lt;li&gt;Can use theoretical convergence guarantees&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Very slow&lt;/strong&gt; for large datasets (must process all data before one update)&lt;/li&gt;
  &lt;li&gt;Requires entire dataset in memory&lt;/li&gt;
  &lt;li&gt;Can get stuck in local minima (for non-convex functions)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-stochastic-gradient-descent-sgd&quot;&gt;2. Stochastic Gradient Descent (SGD)&lt;/h3&gt;

&lt;p&gt;Uses &lt;strong&gt;one random training example&lt;/strong&gt; at a time to compute the gradient.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Repeat until convergence:
    1. Randomly shuffle training data
    
    2. For each example i:
        a. Compute gradient using only example i:
           ‚àáL(≈∑‚ÅΩ‚Å±‚Åæ, y‚ÅΩ‚Å±‚Åæ)
        
        b. Update parameters:
           Œ∏ := Œ∏ - Œ∑ ‚àáL(≈∑‚ÅΩ‚Å±‚Åæ, y‚ÅΩ‚Å±‚Åæ)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Much faster&lt;/strong&gt; updates (can start learning immediately)&lt;/li&gt;
  &lt;li&gt;Can escape local minima due to noisy updates&lt;/li&gt;
  &lt;li&gt;Online learning possible (process data streams)&lt;/li&gt;
  &lt;li&gt;Memory efficient&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Noisy gradient estimates&lt;/strong&gt; ‚Üí erratic convergence path&lt;/li&gt;
  &lt;li&gt;Never truly ‚Äúconverges‚Äù (oscillates around minimum)&lt;/li&gt;
  &lt;li&gt;Harder to parallelize&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-mini-batch-gradient-descent-most-common&quot;&gt;3. Mini-Batch Gradient Descent (Most Common)&lt;/h3&gt;

&lt;p&gt;Uses a &lt;strong&gt;small batch of examples&lt;/strong&gt; (typically 32, 64, 128, or 256) to compute the gradient.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Algorithm:&lt;/strong&gt;&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Repeat until convergence:
    1. Randomly shuffle training data
    
    2. Divide data into mini-batches of size B
    
    3. For each mini-batch:
        a. Compute gradient using the batch:
           ‚àáJ_batch(Œ∏) = (1/B) Œ£·µ¢‚ààbatch ‚àáL(≈∑‚ÅΩ‚Å±‚Åæ, y‚ÅΩ‚Å±‚Åæ)
        
        b. Update parameters:
           Œ∏ := Œ∏ - Œ∑ ‚àáJ_batch(Œ∏)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Best of both worlds&lt;/strong&gt;: Fast updates + stable convergence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Highly parallelizable&lt;/strong&gt;: Can utilize GPU/TPU efficiently&lt;/li&gt;
  &lt;li&gt;Reduced variance in gradient estimates&lt;/li&gt;
  &lt;li&gt;Memory efficient (process batches, not entire dataset)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Introduces batch size as a hyperparameter&lt;/li&gt;
  &lt;li&gt;Still has some noise (less than SGD)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;comparison-table&quot;&gt;Comparison Table&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Variant&lt;/th&gt;
      &lt;th&gt;Examples per Update&lt;/th&gt;
      &lt;th&gt;Speed&lt;/th&gt;
      &lt;th&gt;Stability&lt;/th&gt;
      &lt;th&gt;Memory&lt;/th&gt;
      &lt;th&gt;Parallelization&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Batch GD&lt;/td&gt;
      &lt;td&gt;All (m)&lt;/td&gt;
      &lt;td&gt;Slow&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;Difficult&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SGD&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;Fast&lt;/td&gt;
      &lt;td&gt;Low&lt;/td&gt;
      &lt;td&gt;Low&lt;/td&gt;
      &lt;td&gt;Difficult&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Mini-batch GD&lt;/td&gt;
      &lt;td&gt;Batch size (B)&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Fast&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Medium&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Low&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Easy&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Recommendation&lt;/strong&gt;: Use &lt;strong&gt;mini-batch gradient descent&lt;/strong&gt; with batch size 32-256.&lt;/p&gt;

&lt;h2 id=&quot;the-learning-rate&quot;&gt;The Learning Rate&lt;/h2&gt;

&lt;p&gt;The learning rate \(\eta\) is one of the most important hyperparameters.&lt;/p&gt;

&lt;h3 id=&quot;effect-of-learning-rate&quot;&gt;Effect of Learning Rate&lt;/h3&gt;

&lt;h4 id=&quot;too-small-eta-too-low&quot;&gt;Too Small (\(\eta\) too low)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Very slow convergence&lt;/li&gt;
  &lt;li&gt;May take too long to train&lt;/li&gt;
  &lt;li&gt;Can get stuck in plateaus&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;too-large-eta-too-high&quot;&gt;Too Large (\(\eta\) too high)&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Unstable training&lt;/li&gt;
  &lt;li&gt;May overshoot minimum&lt;/li&gt;
  &lt;li&gt;Loss may diverge (increase)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;just-right&quot;&gt;Just Right&lt;/h4&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth, steady decrease in loss&lt;/li&gt;
  &lt;li&gt;Reasonable training time&lt;/li&gt;
  &lt;li&gt;Converges to good solution&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;typical-values&quot;&gt;Typical Values&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Good starting points&lt;/strong&gt;: 0.001, 0.01, 0.1&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deep networks&lt;/strong&gt;: Often 0.001 - 0.01&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Shallow networks&lt;/strong&gt;: Can use higher rates (0.01 - 0.1)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;learning-rate-schedules&quot;&gt;Learning Rate Schedules&lt;/h3&gt;

&lt;p&gt;Instead of a fixed learning rate, use a &lt;strong&gt;schedule&lt;/strong&gt; that changes \(\eta\) during training:&lt;/p&gt;

&lt;h4 id=&quot;1-step-decay&quot;&gt;1. Step Decay&lt;/h4&gt;

\[\eta_t = \eta_0 \cdot \gamma^{\lfloor t / k \rfloor}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\eta_0\) is initial learning rate&lt;/li&gt;
  &lt;li&gt;\(\gamma \in (0, 1)\) is decay factor (e.g., 0.5)&lt;/li&gt;
  &lt;li&gt;\(k\) is step interval (e.g., every 10 epochs)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;: Start at 0.1, multiply by 0.5 every 10 epochs&lt;/p&gt;

&lt;h4 id=&quot;2-exponential-decay&quot;&gt;2. Exponential Decay&lt;/h4&gt;

\[\eta_t = \eta_0 \cdot e^{-\lambda t}\]

&lt;p&gt;where \(\lambda\) is decay constant.&lt;/p&gt;

&lt;h4 id=&quot;3-1t-decay&quot;&gt;3. 1/t Decay&lt;/h4&gt;

\[\eta_t = \frac{\eta_0}{1 + \lambda t}\]

&lt;h4 id=&quot;4-cosine-annealing&quot;&gt;4. Cosine Annealing&lt;/h4&gt;

\[\eta_t = \eta_{\min} + \frac{1}{2}(\eta_{\max} - \eta_{\min})\left(1 + \cos\left(\frac{t}{T}\pi\right)\right)\]

&lt;p&gt;where \(T\) is the total number of iterations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Warm restarts&lt;/strong&gt;: Periodically reset learning rate to initial value.&lt;/p&gt;

&lt;h4 id=&quot;5-learning-rate-warm-up&quot;&gt;5. Learning Rate Warm-up&lt;/h4&gt;

&lt;p&gt;Start with very small learning rate and gradually increase to target value:&lt;/p&gt;

\[\eta_t = \eta_0 \cdot \min\left(1, \frac{t}{T_{\text{warmup}}}\right)\]

&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: Large batch training, transformers&lt;/p&gt;

&lt;h2 id=&quot;implementation&quot;&gt;Implementation&lt;/h2&gt;

&lt;h3 id=&quot;basic-gradient-descent&quot;&gt;Basic Gradient Descent&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Basic gradient descent for linear regression
    
    X: (m, n) input matrix
    y: (m, 1) target vector
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Initialize parameters
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward pass: predictions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute cost
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute gradient
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Update parameters
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Print progress
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Cost = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 100 examples, 3 features
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 100 targets
&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;theta_optimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;mini-batch-gradient-descent&quot;&gt;Mini-Batch Gradient Descent&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mini_batch_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Mini-batch gradient descent
    
    X: (m, n) input matrix
    y: (m, 1) target vector
    batch_size: size of each mini-batch
    num_epochs: number of complete passes through the dataset
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Shuffle data
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;permutation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_shuffled&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;indices&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Process mini-batches
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Get batch
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_shuffled&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Compute gradient on batch
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size_actual&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_batch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Update parameters
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Compute cost on full dataset (for monitoring)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_pred_full&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred_full&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: Cost = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost_history&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta_optimal&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;costs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mini_batch_gradient_descent&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;32&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
    &lt;span class=&quot;n&quot;&gt;num_epochs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;50&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;with-learning-rate-schedule&quot;&gt;With Learning Rate Schedule&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LearningRateSchedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;decay_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decay_steps&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;decay_steps&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_steps&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;exponential&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;decay_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.95&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;inverse&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;kwargs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;decay_rate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent_with_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Gradient descent with learning rate schedule&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LearningRateSchedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;schedule_type&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decay_steps&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;200&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Get current learning rate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;get_lr&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward and gradient computation
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;T&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Update with current learning rate
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;: LR = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Cost = &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;theta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gradient_descent_with_schedule&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;initial_lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;num_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;convergence-criteria&quot;&gt;Convergence Criteria&lt;/h2&gt;

&lt;p&gt;How do we know when to stop training?&lt;/p&gt;

&lt;h3 id=&quot;1-maximum-iterations&quot;&gt;1. Maximum Iterations&lt;/h3&gt;

&lt;p&gt;Stop after a fixed number of iterations/epochs.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-cost-threshold&quot;&gt;2. Cost Threshold&lt;/h3&gt;

&lt;p&gt;Stop when cost drops below a threshold.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;threshold&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-gradient-magnitude&quot;&gt;3. Gradient Magnitude&lt;/h3&gt;

&lt;p&gt;Stop when gradient is very small (near stationary point).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linalg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;norm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;gradient&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;4-cost-change&quot;&gt;4. Cost Change&lt;/h3&gt;

&lt;p&gt;Stop when cost stops decreasing significantly.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cost&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;previous_cost&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;5-validation-loss-most-common-in-deep-learning&quot;&gt;5. Validation Loss (Most Common in Deep Learning)&lt;/h3&gt;

&lt;p&gt;Stop when validation loss stops improving (early stopping).&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;best_validation_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;patience_counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patience_counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;patience&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;best_validation_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;validation_loss&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;patience_counter&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;challenges-with-gradient-descent&quot;&gt;Challenges with Gradient Descent&lt;/h2&gt;

&lt;h3 id=&quot;1-local-minima&quot;&gt;1. Local Minima&lt;/h3&gt;

&lt;p&gt;Non-convex functions (like neural networks) have multiple local minima.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Random initialization (try different starting points)&lt;/li&gt;
  &lt;li&gt;Momentum (covered in advanced optimizers)&lt;/li&gt;
  &lt;li&gt;Simulated annealing&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-saddle-points&quot;&gt;2. Saddle Points&lt;/h3&gt;

&lt;p&gt;Points where gradient is zero but not a minimum.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Momentum and adaptive learning rates help escape&lt;/li&gt;
  &lt;li&gt;Second-order methods (Newton‚Äôs method)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-plateaus&quot;&gt;3. Plateaus&lt;/h3&gt;

&lt;p&gt;Flat regions where gradient is very small.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Patience (wait longer)&lt;/li&gt;
  &lt;li&gt;Learning rate schedules&lt;/li&gt;
  &lt;li&gt;Adaptive optimizers (Adam, RMSprop)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-vanishingexploding-gradients&quot;&gt;4. Vanishing/Exploding Gradients&lt;/h3&gt;

&lt;p&gt;Gradients become too small or too large in deep networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Proper initialization (Xavier, He)&lt;/li&gt;
  &lt;li&gt;Batch normalization&lt;/li&gt;
  &lt;li&gt;Residual connections&lt;/li&gt;
  &lt;li&gt;Gradient clipping (for exploding gradients)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Gradient descent&lt;/strong&gt; is the fundamental deep-learning algorithm for neural networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Update rule&lt;/strong&gt;: \(\theta := \theta - \eta \nabla_{\theta} J(\theta)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mini-batch gradient descent&lt;/strong&gt; is the most commonly used variant&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Learning rate&lt;/strong&gt; \(\eta\) is crucial: too small ‚Üí slow, too large ‚Üí unstable&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Learning rate schedules&lt;/strong&gt; can improve convergence&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convergence criteria&lt;/strong&gt; help determine when to stop training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Challenges&lt;/strong&gt; include local minima, saddle points, and gradient issues&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next lesson, we‚Äôll explore &lt;strong&gt;backpropagation&lt;/strong&gt;, the algorithm that efficiently computes gradients in neural networks.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03-01 Loss Functions</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_01_Loss_Functions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter03/03_01_Loss_Functions</id>
   <content type="html">&lt;p&gt;This lesson covers loss functions (also called cost functions or objective functions), which quantify how well a neural network is performing.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;what-is-a-loss-function&quot;&gt;What is a Loss Function?&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;loss function&lt;/strong&gt; \(\mathcal{L}\) measures the discrepancy between the predicted output \(\hat{y}\) and the true output \(y\). The goal of training is to find parameters \(\theta\) (weights and biases) that minimize this loss.&lt;/p&gt;

&lt;h3 id=&quot;single-example-loss&quot;&gt;Single Example Loss&lt;/h3&gt;

&lt;p&gt;For a single training example:&lt;/p&gt;

\[\mathcal{L}(\hat{y}, y)\]

&lt;h3 id=&quot;cost-function-total-loss&quot;&gt;Cost Function (Total Loss)&lt;/h3&gt;

&lt;p&gt;For a dataset with \(m\) examples, the &lt;strong&gt;cost function&lt;/strong&gt; \(J\) is typically the average loss:&lt;/p&gt;

\[J(\theta) = \frac{1}{m} \sum_{i=1}^{m} \mathcal{L}(\hat{y}^{(i)}, y^{(i)})\]

&lt;p&gt;Some formulations also include regularization terms (covered later).&lt;/p&gt;

&lt;h2 id=&quot;loss-functions-for-regression&quot;&gt;Loss Functions for Regression&lt;/h2&gt;

&lt;h3 id=&quot;1-mean-squared-error-mse&quot;&gt;1. Mean Squared Error (MSE)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{MSE}}(\hat{y}, y) = \frac{1}{2}(y - \hat{y})^2\]

&lt;p&gt;&lt;strong&gt;Cost function:&lt;/strong&gt;&lt;/p&gt;

\[J_{\text{MSE}} = \frac{1}{m} \sum_{i=1}^{m} \frac{1}{2}(y^{(i)} - \hat{y}^{(i)})^2 = \frac{1}{2m} \sum_{i=1}^{m} (y^{(i)} - \hat{y}^{(i)})^2\]

&lt;p&gt;&lt;strong&gt;Note&lt;/strong&gt;: The factor \(\frac{1}{2}\) is included for mathematical convenience (simplifies derivatives).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Always non-negative&lt;/li&gt;
  &lt;li&gt;Heavily penalizes large errors (quadratic penalty)&lt;/li&gt;
  &lt;li&gt;Sensitive to outliers&lt;/li&gt;
  &lt;li&gt;Smooth and differentiable everywhere&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\frac{\partial \mathcal{L}_{\text{MSE}}}{\partial \hat{y}} = \hat{y} - y\]

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Regression tasks&lt;/strong&gt;: Predicting continuous values&lt;/li&gt;
  &lt;li&gt;When errors are normally distributed&lt;/li&gt;
  &lt;li&gt;When all errors should be weighted equally&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Simple and intuitive&lt;/li&gt;
  &lt;li&gt;Smooth gradients&lt;/li&gt;
  &lt;li&gt;Well-understood theoretically&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Very sensitive to outliers (large errors are heavily penalized)&lt;/li&gt;
  &lt;li&gt;Assumes errors are normally distributed&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-mean-absolute-error-mae&quot;&gt;2. Mean Absolute Error (MAE)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{MAE}}(\hat{y}, y) = |y - \hat{y}|\]

&lt;p&gt;&lt;strong&gt;Cost function:&lt;/strong&gt;&lt;/p&gt;

\[J_{\text{MAE}} = \frac{1}{m} \sum_{i=1}^{m} |y^{(i)} - \hat{y}^{(i)}|\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Linear penalty for errors&lt;/li&gt;
  &lt;li&gt;More robust to outliers than MSE&lt;/li&gt;
  &lt;li&gt;Not differentiable at \(\hat{y} = y\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\frac{\partial \mathcal{L}_{\text{MAE}}}{\partial \hat{y}} = \begin{cases} 1 &amp;amp; \text{if } \hat{y} &amp;gt; y \\ -1 &amp;amp; \text{if } \hat{y} &amp;lt; y \\ \text{undefined} &amp;amp; \text{if } \hat{y} = y \end{cases}\]

&lt;p&gt;(In practice, we use subgradients or smooth approximations)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Regression with outliers&lt;/li&gt;
  &lt;li&gt;When you want equal penalty for all error magnitudes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Robust to outliers&lt;/li&gt;
  &lt;li&gt;Intuitive interpretation (average absolute error)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Non-differentiable at zero&lt;/li&gt;
  &lt;li&gt;Can be slower to converge&lt;/li&gt;
  &lt;li&gt;Constant gradient may cause issues near minimum&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-huber-loss&quot;&gt;3. Huber Loss&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{Huber}}(\hat{y}, y) = \begin{cases} \frac{1}{2}(y - \hat{y})^2 &amp;amp; \text{if } |y - \hat{y}| \leq \delta \\ \delta |y - \hat{y}| - \frac{1}{2}\delta^2 &amp;amp; \text{otherwise} \end{cases}\]

&lt;p&gt;where \(\delta\) is a threshold parameter.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Combines advantages of MSE and MAE&lt;/li&gt;
  &lt;li&gt;Quadratic for small errors, linear for large errors&lt;/li&gt;
  &lt;li&gt;Smooth and differentiable everywhere&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Regression with potential outliers&lt;/li&gt;
  &lt;li&gt;When you want smooth gradients but outlier robustness&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Less sensitive to outliers than MSE&lt;/li&gt;
  &lt;li&gt;Smooth gradients (unlike MAE)&lt;/li&gt;
  &lt;li&gt;Configurable via \(\delta\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Requires tuning \(\delta\) hyperparameter&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-for-binary-classification&quot;&gt;Loss Functions for Binary Classification&lt;/h2&gt;

&lt;h3 id=&quot;1-binary-cross-entropy-log-loss&quot;&gt;1. Binary Cross-Entropy (Log Loss)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{BCE}}(\hat{y}, y) = -[y \log(\hat{y}) + (1-y) \log(1-\hat{y})]\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(y \in \{0, 1\}\) is the true label&lt;/li&gt;
  &lt;li&gt;\(\hat{y} \in (0, 1)\) is the predicted probability&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cost function:&lt;/strong&gt;&lt;/p&gt;

\[J_{\text{BCE}} = -\frac{1}{m} \sum_{i=1}^{m} [y^{(i)} \log(\hat{y}^{(i)}) + (1-y^{(i)}) \log(1-\hat{y}^{(i)})]\]

&lt;p&gt;&lt;strong&gt;Intuition:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(y = 1\): Loss is \(-\log(\hat{y})\), minimized when \(\hat{y} \to 1\)&lt;/li&gt;
  &lt;li&gt;If \(y = 0\): Loss is \(-\log(1-\hat{y})\), minimized when \(\hat{y} \to 0\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Based on maximum likelihood estimation&lt;/li&gt;
  &lt;li&gt;Smooth and differentiable&lt;/li&gt;
  &lt;li&gt;Well-suited for gradient-based optimization&lt;/li&gt;
  &lt;li&gt;Heavily penalizes confident wrong predictions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Derivative (with sigmoid output):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For output layer with sigmoid: \(\hat{y} = \sigma(z)\)&lt;/p&gt;

\[\frac{\partial \mathcal{L}_{\text{BCE}}}{\partial z} = \hat{y} - y\]

&lt;p&gt;This remarkably simple derivative makes training efficient!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Binary classification&lt;/strong&gt;: Is this image a cat or dog?&lt;/li&gt;
  &lt;li&gt;Output layer with sigmoid activation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Proper probabilistic interpretation&lt;/li&gt;
  &lt;li&gt;Strong gradients for wrong predictions&lt;/li&gt;
  &lt;li&gt;Well-suited for sigmoid outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Can produce very large losses for confident wrong predictions&lt;/li&gt;
  &lt;li&gt;Requires predicted probabilities (not logits directly)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-hinge-loss-svm-loss&quot;&gt;2. Hinge Loss (SVM Loss)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{Hinge}}(\hat{y}, y) = \max(0, 1 - y \cdot \hat{y})\]

&lt;p&gt;where \(y \in \{-1, +1\}\) and \(\hat{y}\) is the raw score (not probability).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Used in Support Vector Machines&lt;/li&gt;
  &lt;li&gt;Encourages margin maximization&lt;/li&gt;
  &lt;li&gt;Not differentiable at \(y \cdot \hat{y} = 1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Binary classification with SVM-like objectives&lt;/li&gt;
  &lt;li&gt;When you want maximum margin classifiers&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;loss-functions-for-multi-class-classification&quot;&gt;Loss Functions for Multi-Class Classification&lt;/h2&gt;

&lt;h3 id=&quot;1-categorical-cross-entropy&quot;&gt;1. Categorical Cross-Entropy&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{CCE}}(\hat{\mathbf{y}}, \mathbf{y}) = -\sum_{c=1}^{C} y_c \log(\hat{y}_c)\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{y}\) is the true label in &lt;strong&gt;one-hot encoding&lt;/strong&gt;: \(y_c \in \{0, 1\}\), \(\sum_c y_c = 1\)&lt;/li&gt;
  &lt;li&gt;\(\hat{\mathbf{y}}\) is the predicted probability distribution: \(\hat{y}_c \in (0, 1)\), \(\sum_c \hat{y}_c = 1\)&lt;/li&gt;
  &lt;li&gt;\(C\) is the number of classes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Cost function:&lt;/strong&gt;&lt;/p&gt;

\[J_{\text{CCE}} = -\frac{1}{m} \sum_{i=1}^{m} \sum_{c=1}^{C} y_c^{(i)} \log(\hat{y}_c^{(i)})\]

&lt;p&gt;&lt;strong&gt;Simplified form&lt;/strong&gt; (since only one \(y_c = 1\)):&lt;/p&gt;

\[\mathcal{L}_{\text{CCE}} = -\log(\hat{y}_{c^*})\]

&lt;p&gt;where \(c^*\) is the true class.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Derivative (with softmax output):&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;For softmax output: \(\hat{\mathbf{y}} = \text{softmax}(\mathbf{z})\)&lt;/p&gt;

\[\frac{\partial \mathcal{L}_{\text{CCE}}}{\partial z_j} = \hat{y}_j - y_j\]

&lt;p&gt;Again, remarkably simple!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Multi-class classification&lt;/strong&gt;: Digit recognition (MNIST), image classification (ImageNet)&lt;/li&gt;
  &lt;li&gt;Output layer with softmax activation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Proper probabilistic framework&lt;/li&gt;
  &lt;li&gt;Standard for multi-class problems&lt;/li&gt;
  &lt;li&gt;Simple gradients with softmax&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Requires one-hot encoded labels&lt;/li&gt;
  &lt;li&gt;Can be numerically unstable (use log-softmax trick)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-sparse-categorical-cross-entropy&quot;&gt;2. Sparse Categorical Cross-Entropy&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Same as categorical cross-entropy, but accepts integer labels instead of one-hot encoding.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Input format:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(y \in \{0, 1, \ldots, C-1\}\) (integer class index)&lt;/li&gt;
  &lt;li&gt;\(\hat{\mathbf{y}} \in \mathbb{R}^C\) (probability distribution)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{SCCE}}(\hat{\mathbf{y}}, y) = -\log(\hat{y}_y)\]

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Multi-class classification with integer labels&lt;/li&gt;
  &lt;li&gt;Memory-efficient (no need to create one-hot vectors)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-kullback-leibler-kl-divergence&quot;&gt;3. Kullback-Leibler (KL) Divergence&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Formula:&lt;/strong&gt;&lt;/p&gt;

\[\mathcal{L}_{\text{KL}}(\mathbf{p}, \mathbf{q}) = \sum_{c=1}^{C} p_c \log\left(\frac{p_c}{q_c}\right) = \sum_{c=1}^{C} [p_c \log(p_c) - p_c \log(q_c)]\]

&lt;p&gt;where \(\mathbf{p}\) is the true distribution and \(\mathbf{q}\) is the predicted distribution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Measures ‚Äúdistance‚Äù between two probability distributions&lt;/li&gt;
  &lt;li&gt;Always non-negative&lt;/li&gt;
  &lt;li&gt;Not symmetric: \(\text{KL}(p \| q) \neq \text{KL}(q \| p)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Relation to Cross-Entropy:&lt;/strong&gt;&lt;/p&gt;

\[\text{KL}(p \| q) = H(p, q) - H(p)\]

&lt;p&gt;where \(H(p, q)\) is cross-entropy and \(H(p)\) is entropy of \(p\).&lt;/p&gt;

&lt;p&gt;Since \(H(p)\) is constant (true distribution doesn‚Äôt change), minimizing KL divergence is equivalent to minimizing cross-entropy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Variational autoencoders (VAE)&lt;/li&gt;
  &lt;li&gt;Distribution matching&lt;/li&gt;
  &lt;li&gt;Knowledge distillation&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h2&gt;

&lt;h3 id=&quot;numerical-stability&quot;&gt;Numerical Stability&lt;/h3&gt;

&lt;h4 id=&quot;problem-log-of-small-numbers&quot;&gt;Problem: Log of Small Numbers&lt;/h4&gt;

&lt;p&gt;Computing \(\log(\hat{y})\) when \(\hat{y}\) is very close to 0 can cause numerical issues.&lt;/p&gt;

&lt;h4 id=&quot;solution-clip-values&quot;&gt;Solution: Clip Values&lt;/h4&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_pred_clipped&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred_clipped&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;better-solution-logsumexp-trick&quot;&gt;Better Solution: LogSumExp Trick&lt;/h4&gt;

&lt;p&gt;For cross-entropy with softmax, compute loss directly from logits:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;softmax_cross_entropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Numerically stable softmax + cross-entropy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Log-sum-exp trick
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;logits_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log_sum_exp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits_max&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits_max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;logits&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_sum_exp&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Cross-entropy
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;log_softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;implementation-examples&quot;&gt;Implementation Examples&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;LossFunctions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mse&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Mean Squared Error&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;mae&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Mean Absolute Error&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;binary_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Binary Cross-Entropy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Categorical Cross-Entropy&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sparse_categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1e-7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sparse Categorical Cross-Entropy
        
        y_true: integer labels (m,)
        y_pred: probabilities (m, C)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;m&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;clip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epsilon&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;log_likelihood&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;log&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;m&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;log_likelihood&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;huber&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Huber Loss&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;is_small_error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;squared_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;linear_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;delta&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;**&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;mean&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;is_small_error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;squared_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;linear_loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.9&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Binary Cross-Entropy:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LossFunctions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;binary_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Multi-class example
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true_categorical&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_pred_categorical&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Categorical Cross-Entropy:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;LossFunctions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;categorical_crossentropy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_true_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred_categorical&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;choosing-the-right-loss-function&quot;&gt;Choosing the Right Loss Function&lt;/h2&gt;

&lt;h3 id=&quot;decision-tree&quot;&gt;Decision Tree&lt;/h3&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Task Type?
‚îú‚îÄ Regression
‚îÇ  ‚îú‚îÄ With outliers? ‚Üí MAE or Huber Loss
‚îÇ  ‚îî‚îÄ Without outliers? ‚Üí MSE
‚îÇ
‚îú‚îÄ Binary Classification
‚îÇ  ‚îú‚îÄ Probabilistic output? ‚Üí Binary Cross-Entropy
‚îÇ  ‚îî‚îÄ Margin-based? ‚Üí Hinge Loss
‚îÇ
‚îî‚îÄ Multi-class Classification
   ‚îú‚îÄ One-hot labels? ‚Üí Categorical Cross-Entropy
   ‚îî‚îÄ Integer labels? ‚Üí Sparse Categorical Cross-Entropy
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;quick-reference&quot;&gt;Quick Reference&lt;/h3&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Task&lt;/th&gt;
      &lt;th&gt;Loss Function&lt;/th&gt;
      &lt;th&gt;Output Activation&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Regression&lt;/td&gt;
      &lt;td&gt;MSE, MAE, Huber&lt;/td&gt;
      &lt;td&gt;Linear&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Binary Classification&lt;/td&gt;
      &lt;td&gt;Binary Cross-Entropy&lt;/td&gt;
      &lt;td&gt;Sigmoid&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multi-class Classification&lt;/td&gt;
      &lt;td&gt;Categorical Cross-Entropy&lt;/td&gt;
      &lt;td&gt;Softmax&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Multi-label Classification&lt;/td&gt;
      &lt;td&gt;Binary Cross-Entropy (per label)&lt;/td&gt;
      &lt;td&gt;Sigmoid (per label)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Loss functions&lt;/strong&gt; quantify the difference between predictions and true values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regression losses&lt;/strong&gt;: MSE (sensitive to outliers), MAE (robust), Huber (balanced)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Classification losses&lt;/strong&gt;: Cross-entropy (probabilistic, standard choice)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Binary classification&lt;/strong&gt;: Binary cross-entropy with sigmoid&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multi-class classification&lt;/strong&gt;: Categorical cross-entropy with softmax&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Numerical stability&lt;/strong&gt; is crucial when implementing loss functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Choice of loss&lt;/strong&gt; should match the task and data characteristics&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next lesson, we‚Äôll learn about gradient descent, the algorithm that uses these loss functions to update network parameters.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>03 Introduction to Training Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter03/03_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter03/03_00_Introduction</id>
   <content type="html">&lt;p&gt;Training neural networks is the process of finding the optimal weights and biases that minimize the difference between predictions and actual outputs. This chapter covers the fundamental algorithms and techniques used to train deep neural networks, including backpropagation, gradient descent, loss functions, and practical training strategies.&lt;/p&gt;

&lt;p&gt;Understanding how neural networks learn from data is crucial for building effective deep learning systems.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>02-04 Forward Propagation</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_04_Forward_Propagation/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter02/02_04_Forward_Propagation</id>
   <content type="html">&lt;p&gt;This lesson provides a comprehensive understanding of forward propagation, the process by which neural networks make predictions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;what-is-forward-propagation&quot;&gt;What is Forward Propagation?&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Forward propagation&lt;/strong&gt; is the process of computing the output of a neural network given an input. Data ‚Äúflows forward‚Äù through the network from the input layer to the output layer, passing through all hidden layers in sequence.&lt;/p&gt;

&lt;p&gt;This is the &lt;strong&gt;inference&lt;/strong&gt; or &lt;strong&gt;prediction&lt;/strong&gt; phase of a neural network.&lt;/p&gt;

&lt;h2 id=&quot;the-forward-pass-step-by-step&quot;&gt;The Forward Pass: Step by Step&lt;/h2&gt;

&lt;p&gt;Consider a simple 3-layer network:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Input layer&lt;/strong&gt;: \(n^{[0]} = 3\) features&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hidden layer 1&lt;/strong&gt;: \(n^{[1]} = 4\) neurons with ReLU&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hidden layer 2&lt;/strong&gt;: \(n^{[2]} = 4\) neurons with ReLU&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output layer&lt;/strong&gt;: \(n^{[3]} = 1\) neuron with sigmoid (binary classification)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;layer-0-input&quot;&gt;Layer 0: Input&lt;/h3&gt;

\[\mathbf{a}^{[0]} = \mathbf{x} = \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix}\]

&lt;h3 id=&quot;layer-1-first-hidden-layer&quot;&gt;Layer 1: First Hidden Layer&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Linear transformation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{z}^{[1]} = \mathbf{W}^{[1]} \mathbf{a}^{[0]} + \mathbf{b}^{[1]}\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{W}^{[1]} \in \mathbb{R}^{4 \times 3}\) (4 neurons, 3 inputs each)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{b}^{[1]} \in \mathbb{R}^{4}\) (4 biases)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{z}^{[1]} \in \mathbb{R}^{4}\) (pre-activation values)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Activation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{a}^{[1]} = \text{ReLU}(\mathbf{z}^{[1]}) = \max(0, \mathbf{z}^{[1]})\]

&lt;p&gt;\(\mathbf{a}^{[1]} \in \mathbb{R}^{4}\) (activations/outputs of layer 1)&lt;/p&gt;

&lt;h3 id=&quot;layer-2-second-hidden-layer&quot;&gt;Layer 2: Second Hidden Layer&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Linear transformation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{z}^{[2]} = \mathbf{W}^{[2]} \mathbf{a}^{[1]} + \mathbf{b}^{[2]}\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\mathbf{W}^{[2]} \in \mathbb{R}^{4 \times 4}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\mathbf{b}^{[2]} \in \mathbb{R}^{4}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Activation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{a}^{[2]} = \text{ReLU}(\mathbf{z}^{[2]})\]

&lt;h3 id=&quot;layer-3-output-layer&quot;&gt;Layer 3: Output Layer&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Linear transformation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{z}^{[3]} = \mathbf{W}^{[3]} \mathbf{a}^{[2]} + \mathbf{b}^{[3]}\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\mathbf{W}^{[3]} \in \mathbb{R}^{1 \times 4}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\mathbf{b}^{[3]} \in \mathbb{R}^{1}\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Activation (output):&lt;/strong&gt;&lt;/p&gt;

\[\hat{y} = \mathbf{a}^{[3]} = \sigma(\mathbf{z}^{[3]}) = \frac{1}{1 + e^{-\mathbf{z}^{[3]}}}\]

&lt;p&gt;This gives us the predicted probability of the positive class.&lt;/p&gt;

&lt;h2 id=&quot;vectorized-forward-propagation&quot;&gt;Vectorized Forward Propagation&lt;/h2&gt;

&lt;p&gt;For computational efficiency, we process &lt;strong&gt;multiple examples simultaneously&lt;/strong&gt; using &lt;strong&gt;vectorization&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;batch-processing&quot;&gt;Batch Processing&lt;/h3&gt;

&lt;p&gt;Instead of processing one example at a time, we organize \(m\) examples into a matrix:&lt;/p&gt;

\[\mathbf{X} = \begin{bmatrix} | &amp;amp; | &amp;amp; &amp;amp; | \\ \mathbf{x}^{(1)} &amp;amp; \mathbf{x}^{(2)} &amp;amp; \cdots &amp;amp; \mathbf{x}^{(m)} \\ | &amp;amp; | &amp;amp; &amp;amp; | \end{bmatrix} \in \mathbb{R}^{n^{[0]} \times m}\]

&lt;p&gt;Each column is one training example.&lt;/p&gt;

&lt;h3 id=&quot;vectorized-computation&quot;&gt;Vectorized Computation&lt;/h3&gt;

&lt;p&gt;For layer \(l\):&lt;/p&gt;

\[\mathbf{Z}^{[l]} = \mathbf{W}^{[l]} \mathbf{A}^{[l-1]} + \mathbf{b}^{[l]}\]

\[\mathbf{A}^{[l]} = g^{[l]}(\mathbf{Z}^{[l]})\]

&lt;p&gt;Where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}^{[l]} \in \mathbb{R}^{n^{[l]} \times m}\) (each column is activations for one example)&lt;/li&gt;
  &lt;li&gt;
\[\mathbf{Z}^{[l]} \in \mathbb{R}^{n^{[l]} \times m}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\mathbf{W}^{[l]} \in \mathbb{R}^{n^{[l]} \times n^{[l-1]}}\]
  &lt;/li&gt;
  &lt;li&gt;\(\mathbf{b}^{[l]} \in \mathbb{R}^{n^{[l]} \times 1}\) (broadcasted across all \(m\) examples)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;broadcasting&quot;&gt;Broadcasting&lt;/h3&gt;

&lt;p&gt;Python/NumPy automatically broadcasts \(\mathbf{b}^{[l]}\) across all examples:&lt;/p&gt;

\[\mathbf{b}^{[l]} \in \mathbb{R}^{n^{[l]} \times 1} \rightarrow \mathbb{R}^{n^{[l]} \times m}\]

&lt;p&gt;Each column of the result gets the same bias vector added.&lt;/p&gt;

&lt;h2 id=&quot;concrete-example-with-numbers&quot;&gt;Concrete Example with Numbers&lt;/h2&gt;

&lt;p&gt;Let‚Äôs work through a small example with actual numbers.&lt;/p&gt;

&lt;h3 id=&quot;network-setup&quot;&gt;Network Setup&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Input: 2 features (\(n^{[0]} = 2\))&lt;/li&gt;
  &lt;li&gt;Hidden layer: 3 neurons with ReLU (\(n^{[1]} = 3\))&lt;/li&gt;
  &lt;li&gt;Output: 1 neuron with sigmoid (\(n^{[2]} = 1\))&lt;/li&gt;
  &lt;li&gt;Batch size: 2 examples (\(m = 2\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;parameters&quot;&gt;Parameters&lt;/h3&gt;

\[\mathbf{W}^{[1]} = \begin{bmatrix} 0.5 &amp;amp; -0.3 \\ 0.2 &amp;amp; 0.8 \\ -0.4 &amp;amp; 0.6 \end{bmatrix}, \quad \mathbf{b}^{[1]} = \begin{bmatrix} 0.1 \\ -0.2 \\ 0.3 \end{bmatrix}\]

\[\mathbf{W}^{[2]} = \begin{bmatrix} 1.0 &amp;amp; -0.5 &amp;amp; 0.7 \end{bmatrix}, \quad \mathbf{b}^{[2]} = \begin{bmatrix} 0.5 \end{bmatrix}\]

&lt;h3 id=&quot;input-data&quot;&gt;Input Data&lt;/h3&gt;

\[\mathbf{X} = \mathbf{A}^{[0]} = \begin{bmatrix} 1.0 &amp;amp; 0.5 \\ 2.0 &amp;amp; 1.5 \end{bmatrix}\]

&lt;p&gt;Example 1: \(\mathbf{x}^{(1)} = \begin{bmatrix} 1.0 \\ 2.0 \end{bmatrix}\), Example 2: \(\mathbf{x}^{(2)} = \begin{bmatrix} 0.5 \\ 1.5 \end{bmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;forward-pass-layer-1&quot;&gt;Forward Pass: Layer 1&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compute \(\mathbf{Z}^{[1]}\):&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{Z}^{[1]} = \mathbf{W}^{[1]} \mathbf{A}^{[0]} + \mathbf{b}^{[1]}\]

\[= \begin{bmatrix} 0.5 &amp;amp; -0.3 \\ 0.2 &amp;amp; 0.8 \\ -0.4 &amp;amp; 0.6 \end{bmatrix} \begin{bmatrix} 1.0 &amp;amp; 0.5 \\ 2.0 &amp;amp; 1.5 \end{bmatrix} + \begin{bmatrix} 0.1 \\ -0.2 \\ 0.3 \end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Matrix multiplication:&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;First column: \(\begin{bmatrix} 0.5(1.0) + (-0.3)(2.0) \\ 0.2(1.0) + 0.8(2.0) \\ -0.4(1.0) + 0.6(2.0) \end{bmatrix} = \begin{bmatrix} -0.1 \\ 1.8 \\ 0.8 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;Second column: \(\begin{bmatrix} 0.5(0.5) + (-0.3)(1.5) \\ 0.2(0.5) + 0.8(1.5) \\ -0.4(0.5) + 0.6(1.5) \end{bmatrix} = \begin{bmatrix} -0.2 \\ 1.3 \\ 0.7 \end{bmatrix}\)&lt;/p&gt;

&lt;p&gt;After adding bias:&lt;/p&gt;

\[\mathbf{Z}^{[1]} = \begin{bmatrix} -0.1+0.1 &amp;amp; -0.2+0.1 \\ 1.8-0.2 &amp;amp; 1.3-0.2 \\ 0.8+0.3 &amp;amp; 0.7+0.3 \end{bmatrix} = \begin{bmatrix} 0.0 &amp;amp; -0.1 \\ 1.6 &amp;amp; 1.1 \\ 1.1 &amp;amp; 1.0 \end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Apply ReLU activation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{A}^{[1]} = \text{ReLU}(\mathbf{Z}^{[1]}) = \begin{bmatrix} 0.0 &amp;amp; 0.0 \\ 1.6 &amp;amp; 1.1 \\ 1.1 &amp;amp; 1.0 \end{bmatrix}\]

&lt;h3 id=&quot;forward-pass-layer-2-output&quot;&gt;Forward Pass: Layer 2 (Output)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compute \(\mathbf{Z}^{[2]}\):&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{Z}^{[2]} = \mathbf{W}^{[2]} \mathbf{A}^{[1]} + \mathbf{b}^{[2]}\]

\[= \begin{bmatrix} 1.0 &amp;amp; -0.5 &amp;amp; 0.7 \end{bmatrix} \begin{bmatrix} 0.0 &amp;amp; 0.0 \\ 1.6 &amp;amp; 1.1 \\ 1.1 &amp;amp; 1.0 \end{bmatrix} + \begin{bmatrix} 0.5 \end{bmatrix}\]

\[= \begin{bmatrix} 1.0(0.0) + (-0.5)(1.6) + 0.7(1.1) + 0.5 &amp;amp; 1.0(0.0) + (-0.5)(1.1) + 0.7(1.0) + 0.5 \end{bmatrix}\]

\[= \begin{bmatrix} 0.47 &amp;amp; 0.65 \end{bmatrix}\]

&lt;p&gt;&lt;strong&gt;Apply sigmoid activation:&lt;/strong&gt;&lt;/p&gt;

\[\mathbf{A}^{[2]} = \sigma(\mathbf{Z}^{[2]}) = \begin{bmatrix} \frac{1}{1+e^{-0.47}} &amp;amp; \frac{1}{1+e^{-0.65}} \end{bmatrix} \approx \begin{bmatrix} 0.615 &amp;amp; 0.657 \end{bmatrix}\]

&lt;h3 id=&quot;final-predictions&quot;&gt;Final Predictions&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Example 1: \(\hat{y}^{(1)} = 0.615\) (61.5% probability of positive class)&lt;/li&gt;
  &lt;li&gt;Example 2: \(\hat{y}^{(2)} = 0.657\) (65.7% probability of positive class)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;implementation-in-python&quot;&gt;Implementation in Python&lt;/h2&gt;

&lt;h3 id=&quot;basic-implementation&quot;&gt;Basic Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Arguments:
    X -- input data of shape (n_x, m)
    parameters -- python dictionary containing W1, b1, W2, b2, W3, b3, ...
    
    Returns:
    AL -- last post-activation value (predictions)
    caches -- list of caches containing (A_prev, W, b, Z) for each layer
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;//&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# number of layers
&lt;/span&gt;    
    &lt;span class=&quot;c1&quot;&gt;# Forward through hidden layers (ReLU activation)
&lt;/span&gt;    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Output layer (sigmoid activation)
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cache&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;AL&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
              &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
                    &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b1&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W2&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]),&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b2&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward_propagation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Output: Predictions: [[0.615 0.657]]
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;object-oriented-implementation&quot;&gt;Object-Oriented Implementation&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Arguments:
        layer_dims -- list containing dimensions of each layer
                     Example: [2, 3, 1] means 2 inputs, 3 hidden, 1 output
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;initialize_parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_dims&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Forward propagation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Hidden layers with ReLU
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;l&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# ReLU
&lt;/span&gt;            
            &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer with sigmoid
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;L&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        
        &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Sigmoid
&lt;/span&gt;        
        &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Make predictions (0 or 1)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;A&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;caches&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;common-issues-and-debugging&quot;&gt;Common Issues and Debugging&lt;/h2&gt;

&lt;h3 id=&quot;1-dimension-mismatch&quot;&gt;1. Dimension Mismatch&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Matrix multiplication fails due to incompatible dimensions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Check that \(\mathbf{W}^{[l]}\) has shape \((n^{[l]}, n^{[l-1]})\)&lt;/li&gt;
  &lt;li&gt;Check that \(\mathbf{A}^{[l-1]}\) has shape \((n^{[l-1]}, m)\)&lt;/li&gt;
  &lt;li&gt;Use print statements or debugger to verify shapes&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Layer &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;l&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  W shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;W&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  A_prev shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;A_prev&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  b shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Z shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-numerical-instability&quot;&gt;2. Numerical Instability&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Overflow or underflow in exponentials (especially sigmoid/softmax).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Use numerical stability tricks:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Unstable
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_unstable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Stable version
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_stable&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; 
                    &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)),&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-incorrect-broadcasting&quot;&gt;3. Incorrect Broadcasting&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Problem&lt;/strong&gt;: Bias not broadcast correctly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: Ensure bias has shape \((n^{[l]}, 1)\) not \((n^{[l]},)\)&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Correct
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Shape (n_l, 1)
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Incorrect (may cause issues)
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_l&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Shape (n_l,)
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;forward-propagation-complexity&quot;&gt;Forward Propagation Complexity&lt;/h2&gt;

&lt;h3 id=&quot;time-complexity&quot;&gt;Time Complexity&lt;/h3&gt;

&lt;p&gt;For a network with \(L\) layers and \(n\) neurons per layer:&lt;/p&gt;

\[O(L \cdot n^2 \cdot m)\]

&lt;p&gt;where \(m\) is the batch size.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Breakdown:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Each layer: \(O(n^2 \cdot m)\) for matrix multiplication \(\mathbf{W}^{[l]} \mathbf{A}^{[l-1]}\)&lt;/li&gt;
  &lt;li&gt;\(L\) layers total&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;space-complexity&quot;&gt;Space Complexity&lt;/h3&gt;

\[O(L \cdot n \cdot m)\]

&lt;p&gt;Need to store activations for each layer (needed for backpropagation).&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Forward propagation&lt;/strong&gt; computes predictions by passing inputs through the network&lt;/li&gt;
  &lt;li&gt;Each layer performs: &lt;strong&gt;linear transformation&lt;/strong&gt; ‚Üí &lt;strong&gt;activation function&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vectorization&lt;/strong&gt; allows efficient batch processing of multiple examples&lt;/li&gt;
  &lt;li&gt;The process is: \(\mathbf{Z}^{[l]} = \mathbf{W}^{[l]} \mathbf{A}^{[l-1]} + \mathbf{b}^{[l]}, \quad \mathbf{A}^{[l]} = g^{[l]}(\mathbf{Z}^{[l]})\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Caching&lt;/strong&gt; intermediate values is essential for efficient backpropagation&lt;/li&gt;
  &lt;li&gt;Proper handling of &lt;strong&gt;dimensions&lt;/strong&gt; and &lt;strong&gt;numerical stability&lt;/strong&gt; is crucial&lt;/li&gt;
  &lt;li&gt;Forward propagation is &lt;strong&gt;computationally efficient&lt;/strong&gt; (\(O(L \cdot n^2 \cdot m)\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now that we understand how networks make predictions, we need to learn how to train them. In the next chapter, we‚Äôll cover &lt;strong&gt;backpropagation&lt;/strong&gt; and &lt;strong&gt;gradient descent&lt;/strong&gt;, the algorithms that enable neural networks to learn from data.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>02-03 Activation Functions in Detail</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_03_Activation_Functions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter02/02_03_Activation_Functions</id>
   <content type="html">&lt;p&gt;This lesson provides an in-depth exploration of activation functions, their properties, and how to choose the right one for your neural network.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;why-activation-functions-matter&quot;&gt;Why Activation Functions Matter&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Without activation functions&lt;/strong&gt;, neural networks would be limited to learning only linear transformations. No matter how many layers you stack, a composition of linear functions is still linear:&lt;/p&gt;

\[f(g(h(\mathbf{x}))) = \mathbf{A}_1(\mathbf{A}_2(\mathbf{A}_3 \mathbf{x})) = (\mathbf{A}_1 \mathbf{A}_2 \mathbf{A}_3)\mathbf{x} = \mathbf{A}\mathbf{x}\]

&lt;p&gt;&lt;strong&gt;Activation functions introduce nonlinearity&lt;/strong&gt;, enabling networks to learn complex patterns and approximate arbitrary functions.&lt;/p&gt;

&lt;h2 id=&quot;desirable-properties-of-activation-functions&quot;&gt;Desirable Properties of Activation Functions&lt;/h2&gt;

&lt;p&gt;An ideal activation function should have:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinearity&lt;/strong&gt;: Enable learning of complex patterns&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Differentiability&lt;/strong&gt;: Enable gradient-based deep-learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monotonicity&lt;/strong&gt;: Preserve ordering (helpful for deep-learning)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational efficiency&lt;/strong&gt;: Fast to compute forward and backward&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounded or unbounded appropriately&lt;/strong&gt;: Depending on the task&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero-centered&lt;/strong&gt;: Help with gradient flow (for hidden layers)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Avoid saturation&lt;/strong&gt;: Prevent vanishing gradients&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;No single activation function satisfies all properties perfectly, so the choice depends on the specific use case.&lt;/p&gt;

&lt;h2 id=&quot;common-activation-functions&quot;&gt;Common Activation Functions&lt;/h2&gt;

&lt;h3 id=&quot;1-sigmoid-logistic-function&quot;&gt;1. Sigmoid (Logistic Function)&lt;/h3&gt;

\[\sigma(z) = \frac{1}{1 + e^{-z}}\]

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\sigma&apos;(z) = \sigma(z)(1 - \sigma(z))\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Range: \((0, 1)\)&lt;/li&gt;
  &lt;li&gt;Smooth, differentiable everywhere&lt;/li&gt;
  &lt;li&gt;Monotonically increasing&lt;/li&gt;
  &lt;li&gt;Saturates at both ends&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Clear probabilistic interpretation&lt;/li&gt;
  &lt;li&gt;Smooth gradient&lt;/li&gt;
  &lt;li&gt;Historically popular&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Vanishing gradient problem&lt;/strong&gt;: Gradients near 0 for $$&lt;/td&gt;
          &lt;td&gt;z&lt;/td&gt;
          &lt;td&gt;&amp;gt; 4$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Not zero-centered&lt;/strong&gt;: Outputs always positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computationally expensive&lt;/strong&gt;: Requires exponential calculation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Output layer for binary classification&lt;/li&gt;
  &lt;li&gt;Gate activations in LSTMs&lt;/li&gt;
  &lt;li&gt;Generally avoided in hidden layers of deep networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-hyperbolic-tangent-tanh&quot;&gt;2. Hyperbolic Tangent (tanh)&lt;/h3&gt;

\[\tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}} = \frac{e^{2z} - 1}{e^{2z} + 1} = 2\sigma(2z) - 1\]

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\tanh&apos;(z) = 1 - \tanh^2(z)\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Range: \((-1, 1)\)&lt;/li&gt;
  &lt;li&gt;Zero-centered (improvement over sigmoid)&lt;/li&gt;
  &lt;li&gt;Saturates at both ends&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Zero-centered (better gradient flow)&lt;/li&gt;
  &lt;li&gt;Stronger gradients than sigmoid (derivative range: \((0, 1]\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Still suffers from vanishing gradients&lt;/li&gt;
  &lt;li&gt;Computationally expensive&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hidden layers (better than sigmoid but worse than ReLU)&lt;/li&gt;
  &lt;li&gt;RNN/LSTM cells&lt;/li&gt;
  &lt;li&gt;When zero-centered outputs are beneficial&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-rectified-linear-unit-relu&quot;&gt;3. Rectified Linear Unit (ReLU)&lt;/h3&gt;

\[\text{ReLU}(z) = \max(0, z) = \begin{cases} z &amp;amp; \text{if } z &amp;gt; 0 \\ 0 &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\text{ReLU}&apos;(z) = \begin{cases} 1 &amp;amp; \text{if } z &amp;gt; 0 \\ 0 &amp;amp; \text{if } z \leq 0 \\ \text{undefined} &amp;amp; \text{if } z = 0 \end{cases}\]

&lt;p&gt;(In practice, we define \(\text{ReLU}&apos;(0) = 0\) or \(0.5\))&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Range: \([0, \infty)\)&lt;/li&gt;
  &lt;li&gt;Not saturating for positive values&lt;/li&gt;
  &lt;li&gt;Sparse activation (many neurons output 0)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Computational efficiency&lt;/strong&gt;: Just thresholding at zero&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Alleviates vanishing gradient&lt;/strong&gt;: Gradient is 1 for positive inputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sparse representations&lt;/strong&gt;: Natural sparsity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Empirically successful&lt;/strong&gt;: Works very well in practice&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Not zero-centered&lt;/strong&gt;: All outputs are non-negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Dying ReLU problem&lt;/strong&gt;: Neurons can become inactive forever
    &lt;ul&gt;
      &lt;li&gt;If \(z &amp;lt; 0\) always, gradient is always 0, no learning occurs&lt;/li&gt;
      &lt;li&gt;Can happen with high learning rates or poor initialization&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Default choice&lt;/strong&gt; for hidden layers in deep networks&lt;/li&gt;
  &lt;li&gt;CNNs, ResNets, most modern architectures&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-leaky-relu&quot;&gt;4. Leaky ReLU&lt;/h3&gt;

\[\text{LeakyReLU}(z) = \begin{cases} z &amp;amp; \text{if } z &amp;gt; 0 \\ \alpha z &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;where \(\alpha\) is a small constant (typically 0.01)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\text{LeakyReLU}&apos;(z) = \begin{cases} 1 &amp;amp; \text{if } z &amp;gt; 0 \\ \alpha &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Prevents dying ReLU&lt;/strong&gt;: Small gradient even for negative inputs&lt;/li&gt;
  &lt;li&gt;Computationally efficient&lt;/li&gt;
  &lt;li&gt;All benefits of ReLU&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Introduces hyperparameter \(\alpha\)&lt;/li&gt;
  &lt;li&gt;Not always better than ReLU in practice&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Variants:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Parametric ReLU (PReLU)&lt;/strong&gt;: \(\alpha\) is learned during training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Randomized Leaky ReLU (RReLU)&lt;/strong&gt;: \(\alpha\) is randomly sampled during training&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-exponential-linear-unit-elu&quot;&gt;5. Exponential Linear Unit (ELU)&lt;/h3&gt;

\[\text{ELU}(z) = \begin{cases} z &amp;amp; \text{if } z &amp;gt; 0 \\ \alpha(e^z - 1) &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;where \(\alpha &amp;gt; 0\) (typically \(\alpha = 1\))&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\text{ELU}&apos;(z) = \begin{cases} 1 &amp;amp; \text{if } z &amp;gt; 0 \\ \alpha e^z = \text{ELU}(z) + \alpha &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth everywhere&lt;/li&gt;
  &lt;li&gt;Negative values push mean activation closer to zero&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closer to zero-centered&lt;/strong&gt;: Negative outputs possible&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No dying ReLU problem&lt;/strong&gt;: Gradients exist for all inputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Smooth&lt;/strong&gt;: Better deep-learning landscape&lt;/li&gt;
  &lt;li&gt;Often leads to faster learning and better performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Computationally more expensive (exponential)&lt;/li&gt;
  &lt;li&gt;Introduces hyperparameter \(\alpha\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Alternative to ReLU when extra computation is acceptable&lt;/li&gt;
  &lt;li&gt;Tasks where zero-centered activations help&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;6-scaled-exponential-linear-unit-selu&quot;&gt;6. Scaled Exponential Linear Unit (SELU)&lt;/h3&gt;

\[\text{SELU}(z) = \lambda \begin{cases} z &amp;amp; \text{if } z &amp;gt; 0 \\ \alpha(e^z - 1) &amp;amp; \text{if } z \leq 0 \end{cases}\]

&lt;p&gt;where \(\lambda \approx 1.0507\) and \(\alpha \approx 1.6733\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Self-normalizing&lt;/strong&gt;: Under certain conditions, activations automatically converge to zero mean and unit variance&lt;/li&gt;
  &lt;li&gt;Requires specific initialization (LeCun normal)&lt;/li&gt;
  &lt;li&gt;Requires specific architecture (fully connected layers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Can enable very deep networks without batch normalization&lt;/li&gt;
  &lt;li&gt;Theoretical guarantees about convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Strict requirements on network architecture&lt;/li&gt;
  &lt;li&gt;Not widely adopted&lt;/li&gt;
  &lt;li&gt;Doesn‚Äôt work well with dropout or convolutional layers&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-swish-silu---sigmoid-linear-unit&quot;&gt;7. Swish (SiLU - Sigmoid Linear Unit)&lt;/h3&gt;

\[\text{Swish}(z) = z \cdot \sigma(z) = \frac{z}{1 + e^{-z}}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth, non-monotonic&lt;/li&gt;
  &lt;li&gt;Unbounded above, bounded below&lt;/li&gt;
  &lt;li&gt;Self-gated (input modulated by sigmoid of itself)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Better performance&lt;/strong&gt;: Empirically shown to outperform ReLU in some tasks&lt;/li&gt;
  &lt;li&gt;Smooth gradients&lt;/li&gt;
  &lt;li&gt;Non-monotonicity can be beneficial&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Computationally more expensive than ReLU&lt;/li&gt;
  &lt;li&gt;Requires careful tuning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Modern architectures (EfficientNet uses Swish)&lt;/li&gt;
  &lt;li&gt;When computational cost is not critical&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;8-gelu-gaussian-error-linear-unit&quot;&gt;8. GELU (Gaussian Error Linear Unit)&lt;/h3&gt;

\[\text{GELU}(z) = z \cdot \Phi(z)\]

&lt;p&gt;where \(\Phi(z)\) is the cumulative distribution function of the standard normal distribution.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Approximation:&lt;/strong&gt;&lt;/p&gt;

\[\text{GELU}(z) \approx 0.5z\left(1 + \tanh\left(\sqrt{\frac{2}{\pi}}(z + 0.044715z^3)\right)\right)\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth, non-monotonic&lt;/li&gt;
  &lt;li&gt;Stochastic regularizer interpretation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;State-of-the-art performance&lt;/strong&gt;: Used in BERT, GPT models&lt;/li&gt;
  &lt;li&gt;Smooth everywhere&lt;/li&gt;
  &lt;li&gt;Captures aspects of dropout and zoneout&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Computationally expensive&lt;/li&gt;
  &lt;li&gt;Harder to interpret&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Transformer models&lt;/strong&gt;: BERT, GPT-2, GPT-3&lt;/li&gt;
  &lt;li&gt;NLP tasks&lt;/li&gt;
  &lt;li&gt;Modern large-scale models&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;9-softmax-output-layer&quot;&gt;9. Softmax (Output Layer)&lt;/h3&gt;

\[\text{softmax}(\mathbf{z})_i = \frac{e^{z_i}}{\sum_{j=1}^K e^{z_j}}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Converts logits to probability distribution&lt;/li&gt;
  &lt;li&gt;Output range: \((0, 1)\) with \(\sum_i p_i = 1\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Derivative (for class \(i\) with respect to \(z_j\)):&lt;/strong&gt;&lt;/p&gt;

\[\frac{\partial \text{softmax}(\mathbf{z})_i}{\partial z_j} = \begin{cases} \text{softmax}(\mathbf{z})_i(1 - \text{softmax}(\mathbf{z})_i) &amp;amp; \text{if } i = j \\ -\text{softmax}(\mathbf{z})_i \cdot \text{softmax}(\mathbf{z})_j &amp;amp; \text{if } i \neq j \end{cases}\]

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Multi-class classification&lt;/strong&gt; output layer&lt;/li&gt;
  &lt;li&gt;Attention mechanisms&lt;/li&gt;
  &lt;li&gt;Any scenario requiring probability distribution over classes&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;10-softplus&quot;&gt;10. Softplus&lt;/h3&gt;

\[\text{softplus}(z) = \ln(1 + e^z)\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Smooth approximation of ReLU&lt;/li&gt;
  &lt;li&gt;Always positive&lt;/li&gt;
  &lt;li&gt;Asymptotically approaches ReLU for large \(z\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Derivative:&lt;/strong&gt;&lt;/p&gt;

\[\text{softplus}&apos;(z) = \frac{e^z}{1 + e^z} = \sigma(z)\]

&lt;p&gt;&lt;strong&gt;Use cases:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Occasionally used in hidden layers&lt;/li&gt;
  &lt;li&gt;Generative models (ensuring positive outputs)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;comparison-summary&quot;&gt;Comparison Summary&lt;/h2&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Activation&lt;/th&gt;
      &lt;th&gt;Range&lt;/th&gt;
      &lt;th&gt;Zero-Centered&lt;/th&gt;
      &lt;th&gt;Vanishing Gradient&lt;/th&gt;
      &lt;th&gt;Dying Units&lt;/th&gt;
      &lt;th&gt;Computational Cost&lt;/th&gt;
      &lt;th&gt;Common Use&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Sigmoid&lt;/td&gt;
      &lt;td&gt;(0,1)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;Output (binary)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;tanh&lt;/td&gt;
      &lt;td&gt;(-1,1)&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;Hidden (old), RNN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ReLU&lt;/td&gt;
      &lt;td&gt;[0,‚àû)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No (for z&amp;gt;0)&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Low&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Hidden (default)&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Leaky ReLU&lt;/td&gt;
      &lt;td&gt;(-‚àû,‚àû)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Low&lt;/strong&gt;&lt;/td&gt;
      &lt;td&gt;Hidden&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;ELU&lt;/td&gt;
      &lt;td&gt;(-Œ±,‚àû)&lt;/td&gt;
      &lt;td&gt;~Yes&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Medium&lt;/td&gt;
      &lt;td&gt;Hidden&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;SELU&lt;/td&gt;
      &lt;td&gt;(-ŒªŒ±,‚àû)&lt;/td&gt;
      &lt;td&gt;Yes (self-norm)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Medium&lt;/td&gt;
      &lt;td&gt;Hidden (specific)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Swish&lt;/td&gt;
      &lt;td&gt;(-‚àû,‚àû)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;Medium&lt;/td&gt;
      &lt;td&gt;Hidden (modern)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;GELU&lt;/td&gt;
      &lt;td&gt;(-‚àû,‚àû)&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Transformers&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Softmax&lt;/td&gt;
      &lt;td&gt;(0,1)&lt;/td&gt;
      &lt;td&gt;N/A&lt;/td&gt;
      &lt;td&gt;Yes&lt;/td&gt;
      &lt;td&gt;No&lt;/td&gt;
      &lt;td&gt;High&lt;/td&gt;
      &lt;td&gt;&lt;strong&gt;Output (multi-class)&lt;/strong&gt;&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&quot;choosing-the-right-activation-function&quot;&gt;Choosing the Right Activation Function&lt;/h2&gt;

&lt;h3 id=&quot;for-hidden-layers&quot;&gt;For Hidden Layers&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Default recommendation: ReLU&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Start with ReLU for most applications&lt;/li&gt;
  &lt;li&gt;Computationally efficient&lt;/li&gt;
  &lt;li&gt;Works well in practice&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;If dying ReLU is a problem:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Try Leaky ReLU or ELU&lt;/li&gt;
  &lt;li&gt;Check learning rate and initialization&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;For modern/large-scale models:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;GELU for transformers and NLP&lt;/li&gt;
  &lt;li&gt;Swish for image models when performance is critical&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;For very deep networks:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Consider ELU or SELU&lt;/li&gt;
  &lt;li&gt;May need normalization techniques (covered later)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;for-output-layers&quot;&gt;For Output Layers&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Binary classification:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;: Outputs probability for positive class&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Multi-class classification:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;: Outputs probability distribution over classes&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Regression:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear (identity)&lt;/strong&gt;: For unbounded outputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt;: For non-negative outputs (e.g., prices, counts)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sigmoid/tanh&lt;/strong&gt;: For bounded outputs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Multi-label classification:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt;: Independent probability for each label&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-implementation&quot;&gt;Practical Implementation&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;sigmoid_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;s&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;tanh_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;return &lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;astype&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;leaky_relu_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;elu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;elu_derivative&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;elu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;alpha&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Numerical stability: subtract max
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;swish&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;nd&quot;&gt;@staticmethod&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;gelu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Approximation
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.044715&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;**&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;ReLU:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Leaky ReLU:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;leaky_relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Sigmoid:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Tanh:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;the-vanishing-gradient-problem&quot;&gt;The Vanishing Gradient Problem&lt;/h2&gt;

&lt;h3 id=&quot;why-it-matters&quot;&gt;Why It Matters&lt;/h3&gt;

&lt;p&gt;During backpropagation, gradients are multiplied through layers:&lt;/p&gt;

\[\frac{\partial \mathcal{L}}{\partial \mathbf{W}^{[1]}} = \frac{\partial \mathcal{L}}{\partial \mathbf{a}^{[L]}} \cdot \frac{\partial \mathbf{a}^{[L]}}{\partial \mathbf{z}^{[L]}} \cdot \ldots \cdot \frac{\partial \mathbf{z}^{[2]}}{\partial \mathbf{a}^{[1]}} \cdot \frac{\partial \mathbf{a}^{[1]}}{\partial \mathbf{z}^{[1]}} \cdot \frac{\partial \mathbf{z}^{[1]}}{\partial \mathbf{W}^{[1]}}\]

&lt;h3 id=&quot;problem-with-sigmoidtanh&quot;&gt;Problem with Sigmoid/Tanh&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Maximum derivative: \(\sigma&apos;(z) = 0.25\) (sigmoid), \(\tanh&apos;(z) = 1\) (tanh at \(z=0\))&lt;/li&gt;
  &lt;li&gt;Typical derivative: Much smaller (\(&amp;lt; 0.25\) for sigmoid)&lt;/li&gt;
  &lt;li&gt;After many layers: \(0.25^{10} \approx 9.5 \times 10^{-7}\) (extremely small!)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Result&lt;/strong&gt;: Gradients vanish, early layers learn very slowly or not at all.&lt;/p&gt;

&lt;h3 id=&quot;relu-to-the-rescue&quot;&gt;ReLU to the Rescue&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Derivative is 1 for positive inputs (no vanishing)&lt;/li&gt;
  &lt;li&gt;Gradient flows unchanged through active ReLU units&lt;/li&gt;
  &lt;li&gt;Enables training of much deeper networks&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-dying-relu-problem&quot;&gt;The Dying ReLU Problem&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;If \(z &amp;lt; 0\) always, gradient is 0, no learning&lt;/li&gt;
  &lt;li&gt;Can happen with:
    &lt;ul&gt;
      &lt;li&gt;Poor initialization&lt;/li&gt;
      &lt;li&gt;High learning rates&lt;/li&gt;
      &lt;li&gt;Unlucky updates&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Solutions:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Use Leaky ReLU, ELU, or other variants&lt;/li&gt;
  &lt;li&gt;Proper initialization (He initialization for ReLU)&lt;/li&gt;
  &lt;li&gt;Reasonable learning rates&lt;/li&gt;
  &lt;li&gt;Batch normalization (covered later)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Activation functions&lt;/strong&gt; introduce nonlinearity, enabling networks to learn complex patterns&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt; is the default choice for hidden layers in modern deep learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sigmoid&lt;/strong&gt; is used for binary classification outputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt; is used for multi-class classification outputs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Advanced activations&lt;/strong&gt; (ELU, Swish, GELU) can provide performance improvements&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Vanishing gradients&lt;/strong&gt; are a major issue with sigmoid/tanh in deep networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;ReLU&lt;/strong&gt; alleviates vanishing gradients but introduces the dying ReLU problem&lt;/li&gt;
  &lt;li&gt;Choice of activation function significantly impacts training and performance&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next lesson, we‚Äôll explore forward propagation in detail with concrete examples.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>02-02 Neural Network Architecture</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_02_Neural_Network_Architecture/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter02/02_02_Neural_Network_Architecture</id>
   <content type="html">&lt;h1 id=&quot;neural-network-architecture-from-neurons-to-deep-systems&quot;&gt;Neural Network Architecture: From Neurons to Deep Systems&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/4/46/Colored_neural_network.svg/500px-Colored_neural_network.svg.png&quot; alt=&quot;Neural Network Layers&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Ki·∫øn tr√∫c neural network v·ªõi input, hidden v√† output layers. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;Neural network architecture is the blueprint that defines how individual neurons are organized, connected, and structured to solve complex problems. While a single neuron can only learn linear decision boundaries (as we saw with the perceptron), the true power of deep learning emerges when we compose many neurons into layers and stack these layers into deep architectures. This compositional structure is not merely a engineering convenience‚Äîit reflects a profound insight about how complex intelligence can emerge from simple computational units working in concert.&lt;/p&gt;

&lt;p&gt;Understanding architecture is crucial because the way we organize neurons fundamentally determines what a network can learn and how efficiently it learns. A poorly designed architecture might fail to learn even simple patterns, while a well-designed one can discover intricate relationships in data with remarkable efficiency. The architecture embodies our inductive biases‚Äîour assumptions about the problem structure‚Äîallowing the network to learn more effectively than treating all problems as completely general function approximation tasks.&lt;/p&gt;

&lt;h3 id=&quot;the-layered-paradigm&quot;&gt;The Layered Paradigm&lt;/h3&gt;

&lt;p&gt;The fundamental organizing principle of neural networks is &lt;strong&gt;layers&lt;/strong&gt;‚Äîgroups of neurons that perform transformations at the same stage of computation. This layered structure naturally implements compositional computation: each layer transforms its input into a new representation, and subsequent layers build on these representations to create increasingly abstract features. When recognizing a face, early layers might detect edges, middle layers combine edges into facial features (eyes, nose, mouth), and deep layers recognize complete identities.&lt;/p&gt;

&lt;p&gt;This hierarchical processing mirrors both biological neural systems and the compositional nature of many real-world concepts. A ‚Äúcar‚Äù is composed of wheels, windows, and doors; these components are composed of shapes and textures; these are composed of edges and colors. Neural network layers naturally capture this hierarchy through learned transformations, with each layer learning the appropriate level of abstraction for its position in the processing pipeline.&lt;/p&gt;

&lt;h3 id=&quot;why-architecture-matters-the-depth-vs-width-tradeoff&quot;&gt;Why Architecture Matters: The Depth vs Width Tradeoff&lt;/h3&gt;

&lt;p&gt;A critical insight from both theory and practice is that &lt;strong&gt;depth&lt;/strong&gt; (number of layers) and &lt;strong&gt;width&lt;/strong&gt; (neurons per layer) have fundamentally different effects on network capacity and learning. The Universal Approximation Theorem tells us that a single hidden layer with sufficiently many neurons can approximate any continuous function. Yet in practice, deep networks with relatively few neurons per layer dramatically outperform shallow wide networks on complex tasks.&lt;/p&gt;

&lt;p&gt;This isn‚Äôt just about parameter efficiency, though deep networks often achieve the same representational power with exponentially fewer parameters than shallow ones. Deep networks learn hierarchical features naturally‚Äîyou don‚Äôt need to tell them to detect edges first, then shapes, then objects; this emerges automatically from the training process. They also exhibit better generalization: the intermediate representations learned by deep networks transfer across tasks, enabling powerful techniques like transfer learning and pre-training that shallow networks don‚Äôt support nearly as well.&lt;/p&gt;

&lt;p&gt;Understanding the tradeoff between depth and width, and how architecture choices affect training dynamics, generalization, and computational efficiency, is essential for designing effective neural networks. This lesson provides the foundational understanding of how networks are structured, why these structures work, and how to make informed architectural decisions for your own applications.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;h3 id=&quot;feedforward-neural-networks-formal-definition&quot;&gt;Feedforward Neural Networks: Formal Definition&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;feedforward neural network&lt;/strong&gt; (also called &lt;strong&gt;Multilayer Perceptron&lt;/strong&gt; or &lt;strong&gt;MLP&lt;/strong&gt;) is a function \(f: \mathbb{R}^{n_0} \to \mathbb{R}^{n_L}\) defined by composition of layer transformations. For a network with \(L\) layers, the function is:&lt;/p&gt;

\[f(\mathbf{x}) = f^{[L]} \circ f^{[L-1]} \circ \cdots \circ f^{[1]}(\mathbf{x})\]

&lt;p&gt;where each layer function \(f^{[l]}\) is an affine transformation followed by an element-wise nonlinearity:&lt;/p&gt;

\[f^{[l]}(\mathbf{a}^{[l-1]}) = \sigma^{[l]}(\mathbf{W}^{[l]} \mathbf{a}^{[l-1]} + \mathbf{b}^{[l]})\]

&lt;p&gt;Let‚Äôs carefully unpack each component and understand why this seemingly simple formulation is so powerful.&lt;/p&gt;

&lt;h3 id=&quot;layer-by-layer-computation&quot;&gt;Layer-by-Layer Computation&lt;/h3&gt;

&lt;p&gt;For a network with \(L\) layers (not counting the input), layer \(l \in \{1, 2, \ldots, L\}\) computes:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-activation (linear transformation)&lt;/strong&gt;:
\(\mathbf{z}^{[l]} = \mathbf{W}^{[l]} \mathbf{a}^{[l-1]} + \mathbf{b}^{[l]}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Activation (nonlinear transformation)&lt;/strong&gt;:
\(\mathbf{a}^{[l]} = \sigma^{[l]}(\mathbf{z}^{[l]})\)&lt;/p&gt;

&lt;p&gt;The dimensions are:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{a}^{[l-1]} \in \mathbb{R}^{n_{l-1}}\): input to layer \(l\) (output from previous layer)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{W}^{[l]} \in \mathbb{R}^{n_l \times n_{l-1}}\): weight matrix&lt;/li&gt;
  &lt;li&gt;\(\mathbf{b}^{[l]} \in \mathbb{R}^{n_l}\): bias vector&lt;/li&gt;
  &lt;li&gt;\(\mathbf{z}^{[l]} \in \mathbb{R}^{n_l}\): pre-activation values&lt;/li&gt;
  &lt;li&gt;\(\mathbf{a}^{[l]} \in \mathbb{R}^{n_l}\): post-activation values (layer output)&lt;/li&gt;
  &lt;li&gt;\(n_l\): number of neurons in layer \(l\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-role-of-each-component&quot;&gt;The Role of Each Component&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Weight Matrix \(\mathbf{W}^{[l]}\)&lt;/strong&gt;: Each row \(\mathbf{w}_i^{[l]}\) defines one neuron‚Äôs linear combination of inputs. The matrix multiplication \(\mathbf{W}^{[l]} \mathbf{a}^{[l-1]}\) computes all neurons‚Äô pre-activations in parallel. The weights are the learnable parameters that adapt during training to capture patterns in data.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bias Vector \(\mathbf{b}^{[l]}\)&lt;/strong&gt;: Shifts the activation function left or right, allowing neurons to activate even when inputs are near zero. Without bias, a ReLU neuron with all-zero inputs would always output zero, limiting expressiveness. Bias is crucial for learning appropriate thresholds.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Activation Function \(\sigma^{[l]}\)&lt;/strong&gt;: Introduces nonlinearity, enabling the network to learn non-linear decision boundaries. Without activation functions, stacking layers would be pointless‚Äîmultiple linear transformations compose into a single linear transformation. Common choices include:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;ReLU: \(\sigma(z) = \max(0, z)\)&lt;/li&gt;
  &lt;li&gt;Sigmoid: \(\sigma(z) = \frac{1}{1+e^{-z}}\)&lt;/li&gt;
  &lt;li&gt;Tanh: \(\sigma(z) = \tanh(z)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;output-layer-design&quot;&gt;Output Layer Design&lt;/h3&gt;

&lt;p&gt;The output layer‚Äôs structure depends fundamentally on the task, as it must produce outputs in the appropriate format for the loss function.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Binary Classification&lt;/strong&gt; (\(y \in \{0, 1\}\)):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Single output neuron with sigmoid activation&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Interpretation: $$\hat{y} = P(y=1&lt;/td&gt;
          &lt;td&gt;\mathbf{x})$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Output: \(\hat{y} = \sigma(z) = \frac{1}{1 + e^{-z}} \in (0,1)\)&lt;/li&gt;
  &lt;li&gt;Loss: Binary cross-entropy \(\mathcal{L} = -[y \log \hat{y} + (1-y) \log(1-\hat{y})]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Multi-class Classification&lt;/strong&gt; (\(y \in \{1,2,\ldots,K\}\)):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(K\) output neurons with softmax activation&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;Interpretation: $$\hat{y}_k = P(y=k&lt;/td&gt;
          &lt;td&gt;\mathbf{x})$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;Output: \(\hat{y}_k = \frac{e^{z_k}}{\sum_{j=1}^K e^{z_j}}\) where \(\sum_{k=1}^K \hat{y}_k = 1\)&lt;/li&gt;
  &lt;li&gt;Loss: Categorical cross-entropy \(\mathcal{L} = -\sum_{k=1}^K y_k \log \hat{y}_k\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The softmax function has elegant properties: it‚Äôs differentiable, outputs form a probability distribution, and it ‚Äúsoftens‚Äù the argmax operation (hence the name), allowing gradient-based learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Regression&lt;/strong&gt; (\(y \in \mathbb{R}\)):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;One or more output neurons with linear (identity) activation&lt;/li&gt;
  &lt;li&gt;Output: \(\hat{y} = z\) (no activation function)&lt;/li&gt;
  &lt;li&gt;Loss: Mean Squared Error \(\mathcal{L} = \frac{1}{2}(y - \hat{y})^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;forward-propagation-the-complete-picture&quot;&gt;Forward Propagation: The Complete Picture&lt;/h3&gt;

&lt;p&gt;Given input \(\mathbf{x} \in \mathbb{R}^{n_0}\), forward propagation computes:&lt;/p&gt;

\[\begin{align}
\mathbf{a}^{[0]} &amp;amp;= \mathbf{x} \quad \text{(initialize with input)} \\
\\
\text{For } l &amp;amp;= 1 \text{ to } L: \\
\mathbf{z}^{[l]} &amp;amp;= \mathbf{W}^{[l]} \mathbf{a}^{[l-1]} + \mathbf{b}^{[l]} \quad \text{(affine transformation)} \\
\mathbf{a}^{[l]} &amp;amp;= \sigma^{[l]}(\mathbf{z}^{[l]}) \quad \text{(nonlinear activation)} \\
\\
\hat{\mathbf{y}} &amp;amp;= \mathbf{a}^{[L]} \quad \text{(final output)}
\end{align}\]

&lt;p&gt;This sequential computation builds increasingly complex representations. Each layer learns features at a different level of abstraction, with the composition of layers enabling the network to represent highly complex functions.&lt;/p&gt;

&lt;h3 id=&quot;parameter-count-and-complexity&quot;&gt;Parameter Count and Complexity&lt;/h3&gt;

&lt;p&gt;The total number of learnable parameters is:&lt;/p&gt;

\[\text{Parameters} = \sum_{l=1}^{L} (n_l \times n_{l-1} + n_l) = \sum_{l=1}^{L} n_l(n_{l-1} + 1)\]

&lt;p&gt;For a concrete example with architecture [784, 128, 64, 10]:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Layer 1: \(128 \times 784 + 128 = 100,480\) parameters&lt;/li&gt;
  &lt;li&gt;Layer 2: \(64 \times 128 + 64 = 8,256\) parameters&lt;/li&gt;
  &lt;li&gt;Layer 3: \(10 \times 64 + 10 = 650\) parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Total&lt;/strong&gt;: \(109,386\) parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This parameter count grows quadratically with layer width but only linearly with depth, explaining why deep narrow networks are often more parameter-efficient than shallow wide ones for similar representational capacity.&lt;/p&gt;

&lt;h3 id=&quot;the-universal-approximation-theorem&quot;&gt;The Universal Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt; (Cybenko 1989, Hornik et al. 1989): Let \(\sigma\) be a non-constant, bounded, monotonically-increasing continuous function (e.g., sigmoid). Then for any continuous function \(g\) on a compact subset \(K \subset \mathbb{R}^n\), any \(\epsilon &amp;gt; 0\), and any probability measure \(\mu\) on \(K\), there exists a one-hidden-layer neural network \(f\) such that:&lt;/p&gt;

\[\int_K |f(\mathbf{x}) - g(\mathbf{x})| d\mu(\mathbf{x}) &amp;lt; \epsilon\]

&lt;p&gt;&lt;strong&gt;What This Means&lt;/strong&gt;: Neural networks can approximate any continuous function arbitrarily well. This is remarkable‚Äîit means neural networks are universal function approximators, capable of representing any relationship we might want to learn.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important Caveats&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Existence ‚â† Learnability&lt;/strong&gt;: The theorem guarantees a solution exists but doesn‚Äôt tell us how to find it via gradient descent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Width Requirements&lt;/strong&gt;: May need exponentially many neurons (in input dimension or precision \(1/\epsilon\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Depth Efficiency&lt;/strong&gt;: Deeper networks can often achieve the same approximation with exponentially fewer parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;No Guidance on Architecture&lt;/strong&gt;: Doesn‚Äôt tell us what activation functions, initializations, or learning rates to use&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The theorem explains &lt;em&gt;why&lt;/em&gt; neural networks work in principle, but practical deep learning success comes from additional insights about depth, architecture, optimization, and regularization that the theorem doesn‚Äôt address.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To solidify understanding of neural network architecture, let‚Äôs trace through a concrete example step by step, watching how information transforms as it flows through layers.&lt;/p&gt;

&lt;h3 id=&quot;example-3-layer-network-for-mnist&quot;&gt;Example: 3-Layer Network for MNIST&lt;/h3&gt;

&lt;p&gt;Consider a network designed to classify handwritten digits (28√ó28 grayscale images into 10 classes):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Architecture&lt;/strong&gt;: [784 ‚Üí 128 ‚Üí 64 ‚Üí 10]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Input&lt;/strong&gt;: 784 pixels (28√ó28 flattened)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hidden Layer 1&lt;/strong&gt;: 128 neurons with ReLU&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Hidden Layer 2&lt;/strong&gt;: 64 neurons with ReLU&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output Layer&lt;/strong&gt;: 10 neurons with softmax&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;information-flow-a-detailed-walkthrough&quot;&gt;Information Flow: A Detailed Walkthrough&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Step 1: Input (Layer 0)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;We receive a 28√ó28 image of the digit ‚Äú3‚Äù. Flattened into a vector:
\(\mathbf{a}^{[0]} = [0.2, 0.1, 0.0, 0.8, 0.9, \ldots] \in \mathbb{R}^{784}\)&lt;/p&gt;

&lt;p&gt;Each value represents a pixel intensity (0=black, 1=white). The network sees this as a point in 784-dimensional space.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 2: First Hidden Layer (Layer 1)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This layer has 128 neurons, each looking for different patterns:&lt;/p&gt;

\[\mathbf{z}^{[1]} = \mathbf{W}^{[1]} \mathbf{a}^{[0]} + \mathbf{b}^{[1]}\]

&lt;p&gt;Where \(\mathbf{W}^{[1]} \in \mathbb{R}^{128 \times 784}\) and \(\mathbf{b}^{[1]} \in \mathbb{R}^{128}\).&lt;/p&gt;

&lt;p&gt;Each of the 128 neurons computes:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Neuron 1 might activate for vertical edges in the top-left&lt;/li&gt;
  &lt;li&gt;Neuron 2 might activate for circular curves&lt;/li&gt;
  &lt;li&gt;Neuron 3 might activate for diagonal strokes&lt;/li&gt;
  &lt;li&gt;‚Ä¶ and so on&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After ReLU activation: \(\mathbf{a}^{[1]} = \max(0, \mathbf{z}^{[1]}) \in \mathbb{R}^{128}\)&lt;/p&gt;

&lt;p&gt;Some neurons fire strongly (values close to their maximum), others don‚Äôt fire at all (zeroed out by ReLU). The network has transformed the raw pixel representation into a feature representation: ‚Äúthis image has strong vertical edges, moderate curves, weak horizontal strokes.‚Äù&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 3: Second Hidden Layer (Layer 2)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This layer combines the low-level features from Layer 1 into higher-level concepts:&lt;/p&gt;

\[\mathbf{z}^{[2]} = \mathbf{W}^{[2]} \mathbf{a}^{[1]} + \mathbf{b}^{[2]}\]

&lt;p&gt;Where \(\mathbf{W}^{[2]} \in \mathbb{R}^{64 \times 128}\).&lt;/p&gt;

&lt;p&gt;These 64 neurons might recognize:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Neuron 1: ‚Äútop loop‚Äù (combining curves and top-positioned edges)&lt;/li&gt;
  &lt;li&gt;Neuron 2: ‚Äúbottom loop‚Äù (different curve combinations)&lt;/li&gt;
  &lt;li&gt;Neuron 3: ‚Äúvertical stroke‚Äù (combining vertical edges)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;After ReLU: \(\mathbf{a}^{[2]} = \max(0, \mathbf{z}^{[2]}) \in \mathbb{R}^{64}\)&lt;/p&gt;

&lt;p&gt;The representation is now even more abstract: ‚Äúthis image has a top loop and a bottom loop, characteristic of digits like 3, 8, or possibly 0.‚Äù&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Step 4: Output Layer (Layer 3)&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;The final layer makes the classification decision:&lt;/p&gt;

\[\mathbf{z}^{[3]} = \mathbf{W}^{[3]} \mathbf{a}^{[2]} + \mathbf{b}^{[3]} \in \mathbb{R}^{10}\]

&lt;p&gt;where \(\mathbf{W}^{[3]} \in \mathbb{R}^{10 \times 64}\).&lt;/p&gt;

&lt;p&gt;This gives raw scores (logits) for each digit. To convert to probabilities:&lt;/p&gt;

\[\hat{\mathbf{y}} = \text{softmax}(\mathbf{z}^{[3]})\]

&lt;p&gt;Resulting in something like:
\(\hat{\mathbf{y}} = [0.01, 0.02, 0.05, 0.82, 0.03, 0.01, 0.02, 0.02, 0.01, 0.01]\)&lt;/p&gt;

&lt;p&gt;The network is 82% confident this is a ‚Äú3‚Äù (index 3), with some probability mass on other digits that share similar features.&lt;/p&gt;

&lt;h3 id=&quot;why-this-layered-structure-works&quot;&gt;Why This Layered Structure Works&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Hierarchical Feature Learning&lt;/strong&gt;: Layer 1 learned edges and curves. Layer 2 combined these into digit parts. Layer 3 combined parts into complete digit predictions. This hierarchy emerges automatically from training‚Äîwe never explicitly told the network to detect edges first!&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Distributed Representation&lt;/strong&gt;: The digit ‚Äú3‚Äù isn‚Äôt represented by a single neuron but by a pattern of activation across all 64 neurons in Layer 2. This makes the representation robust (losing a few neurons doesn‚Äôt destroy the concept) and efficient (the same features help recognize multiple digits).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Dimensionality Reduction&lt;/strong&gt;: We started with 784 dimensions and compressed through 128 ‚Üí 64 ‚Üí 10. Each reduction forced the network to extract increasingly essential information, discarding noise and irrelevant details while preserving discriminative features.&lt;/p&gt;

&lt;h3 id=&quot;intuition-why-depth-beats-width&quot;&gt;Intuition: Why Depth Beats Width&lt;/h3&gt;

&lt;p&gt;Consider two alternative networks for the same task:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Shallow-Wide&lt;/strong&gt;: [784 ‚Üí 4096 ‚Üí 10]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Single massive hidden layer with 4096 neurons&lt;/li&gt;
  &lt;li&gt;Total parameters: ~3.2M&lt;/li&gt;
  &lt;li&gt;Each neuron must learn complete pattern from raw pixels&lt;/li&gt;
  &lt;li&gt;No explicit feature hierarchy&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Deep-Narrow&lt;/strong&gt;: [784 ‚Üí 128 ‚Üí 64 ‚Üí 32 ‚Üí 10]&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Four smaller hidden layers&lt;/li&gt;
  &lt;li&gt;Total parameters: ~110K (29√ó fewer!)&lt;/li&gt;
  &lt;li&gt;Natural feature hierarchy emerges&lt;/li&gt;
  &lt;li&gt;Better generalization, easier to train&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The deep network wins because most real-world patterns are compositional. Faces are composed of eyes, noses, mouths (not random pixel patterns). Sentences are composed of phrases, composed of words, composed of letters. Deep networks naturally capture this compositional structure through their layered architecture.&lt;/p&gt;

&lt;h2 id=&quot;network-depth-and-width&quot;&gt;Network Depth and Width&lt;/h2&gt;

&lt;h3 id=&quot;width&quot;&gt;Width&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;width&lt;/strong&gt; of a layer refers to the number of neurons it contains.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Wider networks&lt;/strong&gt;: More neurons per layer
    &lt;ul&gt;
      &lt;li&gt;Greater capacity to learn complex patterns within a single layer&lt;/li&gt;
      &lt;li&gt;More parameters (can lead to overfitting)&lt;/li&gt;
      &lt;li&gt;More computational cost per layer&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;depth&quot;&gt;Depth&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;depth&lt;/strong&gt; of a network refers to the number of layers.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Deeper networks&lt;/strong&gt;: More layers
    &lt;ul&gt;
      &lt;li&gt;Can learn hierarchical representations&lt;/li&gt;
      &lt;li&gt;More expressive (can represent more complex functions)&lt;/li&gt;
      &lt;li&gt;Can be harder to train (vanishing/exploding gradients)&lt;/li&gt;
      &lt;li&gt;The term ‚Äúdeep learning‚Äù comes from using deep networks&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;the-universal-approximation-theorem-1&quot;&gt;The Universal Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Theorem&lt;/strong&gt;: A feedforward neural network with:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;A single hidden layer&lt;/li&gt;
  &lt;li&gt;Finite number of neurons&lt;/li&gt;
  &lt;li&gt;Appropriate activation function (e.g., sigmoid, ReLU)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;can approximate any continuous function on a compact subset of \(\mathbb{R}^n\) to arbitrary accuracy.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important Notes:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;This is an &lt;strong&gt;existence theorem&lt;/strong&gt;, not a practical guideline&lt;/li&gt;
  &lt;li&gt;It doesn‚Äôt specify how many neurons are needed (could be exponentially many)&lt;/li&gt;
  &lt;li&gt;Deeper networks can often approximate functions with far fewer parameters&lt;/li&gt;
  &lt;li&gt;Deeper networks tend to learn hierarchical features naturally&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;common-design-patterns&quot;&gt;Common Design Patterns&lt;/h2&gt;

&lt;h3 id=&quot;decreasing-width&quot;&gt;Decreasing Width&lt;/h3&gt;

&lt;p&gt;A common pattern is to gradually decrease the layer width:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (784) ‚Üí 512 ‚Üí 256 ‚Üí 128 ‚Üí 64 ‚Üí Output (10)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: Progressively compress information into higher-level abstractions.&lt;/p&gt;

&lt;h3 id=&quot;hourglassbottleneck-architecture&quot;&gt;Hourglass/Bottleneck Architecture&lt;/h3&gt;

&lt;p&gt;Decrease then increase width:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (784) ‚Üí 256 ‚Üí 64 ‚Üí 256 ‚Üí Output (784)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Use case&lt;/strong&gt;: Autoencoders for dimensionality reduction and reconstruction.&lt;/p&gt;

&lt;h3 id=&quot;uniform-width&quot;&gt;Uniform Width&lt;/h3&gt;

&lt;p&gt;Keep all hidden layers the same size:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (784) ‚Üí 256 ‚Üí 256 ‚Üí 256 ‚Üí Output (10)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Rationale&lt;/strong&gt;: Simplicity and easier hyperparameter tuning.&lt;/p&gt;

&lt;h2 id=&quot;activation-functions-per-layer&quot;&gt;Activation Functions Per Layer&lt;/h2&gt;

&lt;p&gt;Different layers can use different activation functions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Typical configuration:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Hidden layers&lt;/strong&gt;: ReLU (or variants like Leaky ReLU, ELU)
    &lt;ul&gt;
      &lt;li&gt;Computational efficiency&lt;/li&gt;
      &lt;li&gt;Mitigates vanishing gradient&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output layer&lt;/strong&gt;: Task-dependent
    &lt;ul&gt;
      &lt;li&gt;Binary classification: Sigmoid&lt;/li&gt;
      &lt;li&gt;Multi-class classification: Softmax&lt;/li&gt;
      &lt;li&gt;Regression: Linear (identity function)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;fully-connected-vs-other-architectures&quot;&gt;Fully Connected vs. Other Architectures&lt;/h2&gt;

&lt;h3 id=&quot;fully-connected-dense-layers&quot;&gt;Fully Connected (Dense) Layers&lt;/h3&gt;

&lt;p&gt;Every neuron in layer \(l\) is connected to every neuron in layer \(l-1\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Advantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Maximum flexibility&lt;/li&gt;
  &lt;li&gt;Can learn any pattern (given enough neurons)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disadvantages:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Many parameters (\(n^{[l]} \times n^{[l-1]}\))&lt;/li&gt;
  &lt;li&gt;No built-in assumption about input structure&lt;/li&gt;
  &lt;li&gt;Not efficient for structured data (images, sequences)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;specialized-architectures&quot;&gt;Specialized Architectures&lt;/h3&gt;

&lt;p&gt;For specific data types, specialized architectures are more efficient:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Convolutional layers&lt;/strong&gt;: For images (spatial structure)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Recurrent layers&lt;/strong&gt;: For sequences (temporal structure)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Attention mechanisms&lt;/strong&gt;: For handling long-range dependencies&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We‚Äôll cover these in later chapters.&lt;/p&gt;

&lt;h2 id=&quot;network-representation&quot;&gt;Network Representation&lt;/h2&gt;

&lt;h3 id=&quot;graphical-representation&quot;&gt;Graphical Representation&lt;/h3&gt;

&lt;p&gt;Networks are often visualized as directed acyclic graphs (DAGs):&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;      Input Layer    Hidden Layer 1   Hidden Layer 2   Output Layer
         (3)             (4)              (4)              (2)
    
    x‚ÇÅ  ‚óã‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè  ≈∑‚ÇÅ
                        ‚ï±‚îÇ‚ï≤              ‚ï±‚îÇ‚ï≤              ‚ï±‚îÇ
    x‚ÇÇ  ‚óã‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚óè‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚óè‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚óè
                        ‚ï≤‚îÇ‚ï±              ‚ï≤‚îÇ‚ï±              ‚ï≤‚îÇ
    x‚ÇÉ  ‚óã‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚óè  ≈∑‚ÇÇ
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;matrix-representation&quot;&gt;Matrix Representation&lt;/h3&gt;

&lt;p&gt;For computational efficiency, we represent operations as matrix multiplications:&lt;/p&gt;

\[\mathbf{Z}^{[l]} = \mathbf{W}^{[l]} \mathbf{A}^{[l-1]} + \mathbf{b}^{[l]}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}^{[l-1]}\): activation matrix (each column is one example)&lt;/li&gt;
  &lt;li&gt;\(\mathbf{W}^{[l]}\): weight matrix&lt;/li&gt;
  &lt;li&gt;\(\mathbf{b}^{[l]}\): bias vector (broadcasted across examples)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;practical-implementation&quot;&gt;Practical Implementation&lt;/h2&gt;

&lt;h3 id=&quot;example-simple-neural-network-in-python&quot;&gt;Example: Simple Neural Network in Python&lt;/h3&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        layer_sizes: list of layer sizes including input and output
        Example: [784, 128, 64, 10] for MNIST
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Initialize weights and biases
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# He initialization for ReLU networks
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;w&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sqrt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;b&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;layer_sizes&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;w&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;maximum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;exp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;exp_z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keepdims&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        x: input of shape (input_size, num_examples)
        Returns: output of shape (output_size, num_examples)
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Forward through hidden layers
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num_layers&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer (softmax)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;@&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;biases&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;softmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;zs&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Returns class predictions&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;axis&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Example usage
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;NeuralNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;random&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;randn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# 5 examples
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Output shape: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shape&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# (10, 5)
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;network&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;design-considerations&quot;&gt;Design Considerations&lt;/h2&gt;

&lt;h3 id=&quot;number-of-layers&quot;&gt;Number of Layers&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;1-2 hidden layers&lt;/strong&gt;: Simple problems, small datasets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;3-5 hidden layers&lt;/strong&gt;: Moderate complexity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;5+ hidden layers&lt;/strong&gt;: Complex problems, large datasets, ‚Äúdeep‚Äù learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;number-of-neurons-per-layer&quot;&gt;Number of Neurons Per Layer&lt;/h3&gt;

&lt;p&gt;Rules of thumb:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Start with layers of size between input and output size&lt;/li&gt;
  &lt;li&gt;Common sizes: 32, 64, 128, 256, 512&lt;/li&gt;
  &lt;li&gt;More neurons = more capacity but more overfitting risk&lt;/li&gt;
  &lt;li&gt;Use validation performance to guide choices&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;architecture-search&quot;&gt;Architecture Search&lt;/h3&gt;

&lt;p&gt;Finding the optimal architecture is often done through:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Manual experimentation&lt;/strong&gt;: Try different configurations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Grid search&lt;/strong&gt;: Systematically try combinations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Random search&lt;/strong&gt;: Often more efficient than grid search&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neural Architecture Search (NAS)&lt;/strong&gt;: Automated methods (advanced topic)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Neural networks&lt;/strong&gt; consist of layers of neurons organized into input, hidden, and output layers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Feedforward networks&lt;/strong&gt; (MLPs) are the simplest architecture where information flows in one direction&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Forward propagation&lt;/strong&gt; computes the output by passing inputs through successive layers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Network depth&lt;/strong&gt; (number of layers) and &lt;strong&gt;width&lt;/strong&gt; (neurons per layer) determine capacity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Universal Approximation Theorem&lt;/strong&gt; shows networks can approximate any function, but doesn‚Äôt guarantee efficiency&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Fully connected layers&lt;/strong&gt; connect every neuron to every neuron in adjacent layers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Proper architecture design&lt;/strong&gt; depends on the problem, data, and computational resources&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In the next lesson, we‚Äôll explore activation functions in more detail and understand their critical role in learning.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>02-01 The Perceptron and Artificial Neurons</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_01_Perceptron_and_Neurons/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter02/02_01_Perceptron_and_Neurons</id>
   <content type="html">&lt;h1 id=&quot;the-perceptron-and-artificial-neurons&quot;&gt;The Perceptron and Artificial Neurons&lt;/h1&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Perceptron_moj.png/400px-Perceptron_moj.png&quot; alt=&quot;Perceptron Diagram&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: S∆° ƒë·ªì c·∫•u tr√∫c c·ªßa m·ªôt Perceptron. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;The journey into deep learning begins with understanding its most fundamental building block: the artificial neuron. While modern deep learning has evolved far beyond the simple perceptron introduced by Frank Rosenblatt in 1958, comprehending this historical starting point is essential for grasping why contemporary neural networks are designed the way they are. The perceptron represents humanity‚Äôs first attempt to create a machine that could learn from examples, mimicking in an extremely simplified way how biological neurons process information.&lt;/p&gt;

&lt;p&gt;The perceptron is, at its core, a binary classifier. It takes multiple numerical inputs, combines them using learned weights, and produces a single binary output indicating which of two classes the input belongs to. What makes this seemingly simple mechanism profound is that it can learn these weights automatically from examples, adjusting them iteratively until it correctly classifies the training data. This learning capability, primitive as it may seem compared to modern standards, was revolutionary in its time and laid the conceptual groundwork for all subsequent developments in neural networks.&lt;/p&gt;

&lt;p&gt;Understanding the perceptron is crucial because it introduces several concepts that persist throughout deep learning. The notion of weighted inputs captures the idea that different features contribute differently to a decision. The bias term allows the decision boundary to shift away from the origin. The learning rule demonstrates how we can adjust parameters based on errors. Perhaps most importantly, the perceptron‚Äôs fundamental limitation‚Äîits inability to solve non-linearly separable problems like XOR‚Äîdirectly motivates the need for multiple layers and the deep architectures that define modern deep learning.&lt;/p&gt;

&lt;p&gt;The transition from the perceptron to modern artificial neurons involves replacing the harsh step function with smooth, differentiable activation functions. This seemingly small change has profound implications. Smooth activation functions enable gradient-based learning through backpropagation, allowing us to train networks with many layers. They introduce the nonlinearity necessary for neural networks to approximate complex functions. The choice of activation function affects everything from training speed to the network‚Äôs ability to represent certain types of patterns, making this one of the most important architectural decisions in deep learning.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Blausen_0657_MultipolarNeuron.png/500px-Blausen_0657_MultipolarNeuron.png&quot; alt=&quot;Biological vs Artificial Neuron&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: Neuron sinh h·ªçc (tr√°i) ƒë√£ truy·ªÅn c·∫£m h·ª©ng cho neuron nh√¢n t·∫°o. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The perceptron performs a remarkably simple computation, yet understanding its mathematical formulation reveals deep insights about linear classifiers and decision boundaries. Given an input vector \(\mathbf{x} = (x_1, x_2, \ldots, x_n)\) where each \(x_i\) represents a feature, and a corresponding weight vector \(\mathbf{w} = (w_1, w_2, \ldots, w_n)\), the perceptron first computes a weighted sum:&lt;/p&gt;

\[z = \sum_{i=1}^{n} w_i x_i + b = \mathbf{w}^T \mathbf{x} + b\]

&lt;p&gt;This quantity \(z\), often called the pre-activation or logit, represents a linear combination of the inputs. Each weight \(w_i\) determines how strongly the corresponding input \(x_i\) influences the final decision. The bias term \(b\) provides a threshold that allows the decision boundary to be positioned optimally in the input space, independent of whether all inputs are zero.&lt;/p&gt;

&lt;p&gt;The perceptron then applies the Heaviside step function to this linear combination to produce a binary output:&lt;/p&gt;

\[y = H(z) = \begin{cases} 
1 &amp;amp; \text{if } z \geq 0 \\
0 &amp;amp; \text{if } z &amp;lt; 0
\end{cases}\]

&lt;p&gt;This step function creates a sharp decision boundary. Everything on one side gets classified as positive (1), everything on the other side as negative (0). The geometric interpretation of this is elegant: the weights define a hyperplane in the input space according to the equation \(\mathbf{w}^T \mathbf{x} + b = 0\). Points are classified based on which side of this hyperplane they fall on.&lt;/p&gt;

&lt;p&gt;The weight vector \(\mathbf{w}\) is perpendicular (orthogonal) to the decision hyperplane. This is a fundamental geometric fact: if two points \(\mathbf{x}_1\) and \(\mathbf{x}_2\) lie on the hyperplane, then \(\mathbf{w}^T(\mathbf{x}_1 - \mathbf{x}_2) = 0\), meaning \(\mathbf{w}\) is orthogonal to any vector in the hyperplane. The magnitude of \(\mathbf{w}\) determines how quickly the activation \(z\) changes as we move perpendicular to the hyperplane, while the bias \(b\) controls the hyperplane‚Äôs distance from the origin along the direction of \(\mathbf{w}\).&lt;/p&gt;

&lt;p&gt;The perceptron learning algorithm provides a simple yet elegant way to find appropriate weights when the data is linearly separable. Starting from initial weights (often zeros or small random values), the algorithm processes each training example \((\mathbf{x}_i, y_i)\). When it makes a correct prediction, it does nothing. When it misclassifies, it adjusts the weights according to:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt; $$\mathbf{w} \leftarrow \mathbf{w} + \eta (y_i - \hat{y}_i) \mathbf{x}_i$$
 $$b \leftarrow b + \eta (y_i - \hat{y}_i)$$
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Here \(\eta\) is the learning rate controlling step size, and \((y_i - \hat{y}_i)\) is the error. If the true label is 1 but we predicted 0, the error is +1, and we move the weights in the direction of \(\mathbf{x}_i\), making this input more likely to be classified as 1 in the future. If we predicted 1 but the truth is 0, we move away from \(\mathbf{x}_i\). This geometric intuition‚Äîmoving the decision boundary toward correctly classified points and away from incorrectly classified ones‚Äîunderlies much of machine learning.&lt;/p&gt;

&lt;p&gt;The Perceptron Convergence Theorem guarantees that if the training data is linearly separable, this algorithm will find a separating hyperplane in a finite number of steps. However, this theorem also reveals the perceptron‚Äôs fundamental limitation: it cannot solve problems where the classes are not linearly separable. The classic example is the XOR problem, where the positive and negative classes are interleaved in such a way that no single straight line (or hyperplane in higher dimensions) can separate them. This limitation sparked the first ‚ÄúAI winter‚Äù in the 1970s when it became clear that single-layer perceptrons could not solve many practical problems.&lt;/p&gt;

&lt;p&gt;Modern artificial neurons address these limitations while preserving the core insight of weighted summation. Instead of the step function, we apply a smooth activation function \(\sigma\):&lt;/p&gt;

\[a = \sigma\left(\sum_{i=1}^{n} w_i x_i + b\right) = \sigma(\mathbf{w}^T \mathbf{x} + b)\]

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Gjl-t%28x%29.svg/500px-Gjl-t%28x%29.svg.png&quot; alt=&quot;Activation Functions&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: C√°c h√†m k√≠ch ho·∫°t ph·ªï bi·∫øn (Sigmoid, Tanh, ReLU). Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The choice of \(\sigma\) dramatically affects the neuron‚Äôs behavior. The sigmoid function \(\sigma(z) = \frac{1}{1+e^{-z}}\) smoothly transitions between 0 and 1, providing a probabilistic interpretation and crucially, being differentiable everywhere. The hyperbolic tangent \(\tanh(z)\) ranges from -1 to 1 and is zero-centered, which often improves gradient flow. The Rectified Linear Unit (ReLU), defined as \(\max(0, z)\), has become dominant in modern deep learning because it‚Äôs computationally efficient, doesn‚Äôt saturate for positive inputs (avoiding vanishing gradients), and introduces useful sparsity where negative-activated neurons output exactly zero.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To truly understand how a perceptron works, let‚Äôs walk through a concrete example that reveals both its power and limitations. Consider the simple logical AND function, which outputs 1 only when both inputs are 1. While this seems trivial, it was groundbreaking that a machine could learn this relationship from examples alone.&lt;/p&gt;

&lt;p&gt;Suppose we want a perceptron to learn AND using these examples: (0,0)‚Üí0, (0,1)‚Üí0, (1,0)‚Üí0, (1,1)‚Üí1. Let‚Äôs initialize with \(w_1 = 0, w_2 = 0, b = 0\) and use learning rate \(\eta = 1\). For the first example (0,0) with label 0, our prediction is \(H(0 \cdot 0 + 0 \cdot 0 + 0) = H(0) = 1\), which is wrong! The error is \(0 - 1 = -1\), so we update: \(w_1 \leftarrow 0 + 1 \cdot (-1) \cdot 0 = 0\), \(w_2 \leftarrow 0\), \(b \leftarrow 0 + 1 \cdot (-1) = -1\). Now we have a bias of -1, which provides a threshold.&lt;/p&gt;

&lt;p&gt;Continuing this process through the training examples, the perceptron eventually converges to weights like \(w_1 = 1, w_2 = 1, b = -1.5\). Let‚Äôs verify this works: For input (1,1), we get \(z = 1 \cdot 1 + 1 \cdot 1 - 1.5 = 0.5\), so \(H(0.5) = 1\) ‚úì. For (1,0), we get \(z = 1 \cdot 1 + 1 \cdot 0 - 1.5 = -0.5\), so \(H(-0.5) = 0\) ‚úì. The perceptron has learned to require both inputs to exceed the threshold of 1.5 combined.&lt;/p&gt;

&lt;p&gt;Now consider why the XOR problem is impossible for a single perceptron. XOR outputs 1 when inputs differ: (0,0)‚Üí0, (0,1)‚Üí1, (1,0)‚Üí1, (1,1)‚Üí0. If you plot these points in 2D space, you‚Äôll see that the positive examples (0,1) and (1,0) are diagonally opposite, with negative examples (0,0) and (1,1) at the other diagonal. No single straight line can separate these classes‚Äîyou would need a nonlinear boundary, like a curve or multiple line segments. This geometric impossibility reveals a fundamental computational limitation: single-layer linear models cannot capture certain logical relationships.&lt;/p&gt;

&lt;p&gt;This limitation drove the development of multi-layer networks. If we stack two perceptrons feeding into a third, we can solve XOR. The first layer can learn to detect \(x_1\) OR \(x_2\), and \(x_1\) AND \(x_2\), and the second layer can learn ‚ÄúOR but not AND,‚Äù which is exactly XOR. This demonstrates a crucial principle: depth (multiple layers) enables learning increasingly complex decision boundaries. Each additional layer can combine features from previous layers in new ways, exponentially expanding the space of representable functions.&lt;/p&gt;

&lt;p&gt;The biological inspiration, while imperfect, provides useful intuition. Real neurons in the brain receive signals through dendrites, integrate these signals in the cell body (soma), and fire an action potential down the axon if the integrated signal exceeds a threshold. The synapse strengths correspond to our weights‚Äîstronger synapses contribute more to whether the neuron fires. However, we must be careful not to take this analogy too far. Biological neurons are vastly more complex than artificial ones, with intricate biochemistry, complex dendritic computations, and temporal dynamics that our simple weighted-sum model doesn‚Äôt capture. Artificial neurons are engineering tools inspired by biology, not accurate models of brain function.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement both a classical perceptron and a modern neuron to understand their similarities and differences. We‚Äôll start with a clean NumPy implementation that makes the learning process transparent:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;numpy&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Classical Perceptron with step function activation&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Initialize perceptron with random small weights.
        
        Why small random weights? We need to break symmetry - if all weights
        start equal, all neurons learn the same features. Small values ensure
        we start in a region where gradients (for smooth activations) are meaningful.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Start with zeros for classical perceptron (simple and works for linearly separable data)
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zeros&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Track errors per epoch for diagnostics
&lt;/span&gt;    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Heaviside step function: outputs 1 if z &amp;gt;= 0, else 0
        
        This creates a sharp decision boundary. Everything above the threshold
        gets classified as 1, everything below as 0. This all-or-nothing nature
        is both the perceptron&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s strength (clear decisions) and weakness 
        (not differentiable, can&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;t use gradient descent).
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;where&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Make predictions for input X.
        
        The computation X @ weights is a batch matrix-vector product.
        For each example (row of X), we compute the dot product with weights,
        add bias, and apply activation. This vectorized approach is orders of
        magnitude faster than looping through examples.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Train perceptron using the perceptron learning rule.
        
        Why does this work? The perceptron learning rule has a beautiful
        geometric interpretation: when we misclassify a point, we adjust
        the decision boundary to move toward that point (if it should be
        positive) or away from it (if it should be negative). For linearly
        separable data, this process is guaranteed to converge.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
                &lt;span class=&quot;c1&quot;&gt;# Compute prediction
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;dot&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x_i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;
                &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                
                &lt;span class=&quot;c1&quot;&gt;# Update only if prediction is wrong
&lt;/span&gt;                &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_pred&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                    &lt;span class=&quot;c1&quot;&gt;# The update rule: w ‚Üê w + Œ∑(y - ≈∑)x
&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# When y=1, ≈∑=0: error=+1, move toward x (increase dot product)
&lt;/span&gt;                    &lt;span class=&quot;c1&quot;&gt;# When y=0, ≈∑=1: error=-1, move away from x (decrease dot product)
&lt;/span&gt;                    &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x_i&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;
                    &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;abs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;error&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            
            &lt;span class=&quot;c1&quot;&gt;# Early stopping if converged
&lt;/span&gt;            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;errors&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Converged at iteration &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;iteration&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate learning the AND function
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training Perceptron on AND gate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_and&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_and&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_and&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_and&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Learned weights: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Learned bias: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_and&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True labels:  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_and&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Decision boundary equation: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*x1 + &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;*x2 + &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bias&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; = 0&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Demonstrate XOR impossibility
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Attempting to learn XOR (will fail!)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;array&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;perceptron_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Perceptron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;n_features&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;learning_rate&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;n_iterations&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;perceptron_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fit&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;predictions_xor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;perceptron_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;predict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Predictions: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions_xor&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;True labels:  &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;y_xor&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Errors remaining: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;perceptron_xor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;errors_&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Note: Perceptron cannot solve XOR because it&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s not linearly separable!&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Now let‚Äôs implement a modern neuron with smooth activation functions that enable gradient-based learning:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ModernNeuron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Modern artificial neuron with smooth activation function.
    
    The key difference from the perceptron is the activation function.
    Instead of a step function that&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;s either 0 or 1, we use smooth functions
    that can output any value in a range and, crucially, are differentiable.
    This differentiability is what enables backpropagation and gradient descent.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ModernNeuron&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Linear layer: y = Wx + b
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# PyTorch initializes weights using Kaiming uniform by default,
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# which is designed for ReLU activations
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;linear&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Choose activation function
&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Each has different properties and use cases
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# ReLU: max(0, z) - most common, prevents vanishing gradients
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Sigmoid: 1/(1+e^(-z)) - outputs [0,1], good for probabilities
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;elif&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Tanh: (e^z - e^(-z))/(e^z + e^(-z)) - outputs [-1,1], zero-centered
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;c1&quot;&gt;# Linear: f(z) = z - for regression
&lt;/span&gt;            &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;activation&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Identity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
        Forward pass through the neuron.
        
        The computation is the same as perceptron (weighted sum + bias)
        but we apply a smooth activation function. This smoothness is critical:
        it means small changes in weights cause small changes in output,
        enabling gradient descent to work effectively.
        &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Linear combination: z = w^T x + b
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;activation&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Apply nonlinear activation
&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;# Demonstrate that modern neurons can learn XOR with multiple layers
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TwoLayerNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    Two-layer network that CAN solve XOR.
    
    This demonstrates why depth matters: the first layer creates a new
    representation space where XOR becomes linearly separable, and the
    second layer can then separate it with a linear boundary.
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TwoLayerNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# First layer creates nonlinear features
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;h&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;hidden&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Second layer combines these features
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;h&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train on XOR
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training 2-Layer Network on XOR&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;X_xor_torch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;y_xor_torch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;1.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;TwoLayerNetwork&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;input_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hidden_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;BCELoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Binary Cross-Entropy
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.01&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c1&quot;&gt;# Forward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_xor_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;c1&quot;&gt;# Backward pass
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;d&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Test the learned model
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;final_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;binary_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;final_predictions&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;float&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final Predictions (probabilities):&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zip&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;X_xor_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;final_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y_xor_torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)):&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Input &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;inp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;numpy&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; ‚Üí Pred: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, True: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;true&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;
          &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Classified as: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;binary_predictions&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Success! The network learned XOR, something a single perceptron cannot do.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;This demonstrates why depth (multiple layers) is fundamental to neural networks.&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Let‚Äôs also understand how different activation functions shape neuron behavior by examining their effects on the same input:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Compare activation functions
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;linspace&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;relu_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sigmoid_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;tanh_out&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;z&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Activation Function Characteristics&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;60&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;For z = -2.0:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  ReLU:    &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (zero for negative)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Sigmoid: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (near 0, but not exactly)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Tanh:    &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (negative output)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;For z = 2.0:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  ReLU:    &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (linear for positive)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Sigmoid: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sigmoid&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (approaching 1)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  Tanh:    &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tanh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;tensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;2.0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  (approaching 1)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Key observations:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - ReLU: Outputs exactly zero for negative inputs, creates sparsity&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Sigmoid: Always positive, good for probabilities but can saturate&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;  - Tanh: Zero-centered (outputs can be negative), better gradient flow than sigmoid&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The reason ReLU has become dominant deserves deeper explanation. When using sigmoid or tanh, the gradient becomes very small when the input is large in magnitude (positive or negative). This ‚Äúsaturation‚Äù means that during backpropagation, gradients diminish as they propagate backward through layers, making it difficult to train deep networks. ReLU doesn‚Äôt saturate for positive inputs‚Äîits gradient is exactly 1‚Äîallowing gradients to flow unchanged through many layers. This property enabled the training of much deeper networks and was crucial to the deep learning revolution of the 2010s.&lt;/p&gt;

&lt;p&gt;However, ReLU introduces its own challenge: the ‚Äúdying ReLU‚Äù problem. If a neuron‚Äôs input is always negative during training, its output is always zero, and its gradient is also always zero, meaning it never updates and effectively dies. This can happen with poor initialization or excessively high learning rates. Variants like Leaky ReLU (\(\max(\alpha z, z)\) with \(\alpha \approx 0.01\)) address this by allowing small negative values, ensuring gradients never completely vanish.&lt;/p&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Understanding the perceptron and artificial neurons properly requires seeing how they connect to the broader landscape of machine learning and deep learning. The perceptron is essentially a simplified form of logistic regression when we replace the step function with a sigmoid activation. In logistic regression, we model the probability of class membership as $$P(y=1&lt;/td&gt;
      &lt;td&gt;\mathbf{x}) = \sigma(\mathbf{w}^T \mathbf{x} + b)$$, which is exactly a perceptron with sigmoid activation. The connection runs deeper: logistic regression is typically trained using maximum likelihood estimation, which, for the binary case, leads to minimizing binary cross-entropy loss. This same loss function is used to train the output layer of neural networks for binary classification.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;The relationship to Support Vector Machines (SVMs) is also illuminating. Like the perceptron, SVMs find a separating hyperplane for linearly separable data. However, SVMs optimize for the maximum margin hyperplane‚Äîthe one that‚Äôs as far as possible from the nearest data points of both classes. This margin maximization provides better generalization guarantees. The perceptron, in contrast, is satisfied with any separating hyperplane and doesn‚Äôt optimize for margin. Despite this theoretical advantage of SVMs, deep neural networks built from perceptron-like units have proven more practical for complex, high-dimensional problems because they can learn nonlinear features through multiple layers.&lt;/p&gt;

&lt;p&gt;The evolution from perceptron to Multi-Layer Perceptron (MLP) represents one of the most important developments in machine learning. An MLP is simply multiple layers of neurons, where each layer‚Äôs outputs become the next layer‚Äôs inputs. This stacking enables the network to learn hierarchical representations. The first layer might learn to detect simple patterns (edges in images, or common word combinations in text). The second layer combines these simple patterns into mid-level features (shapes formed by edges, or phrase meanings). Deeper layers build even higher-level concepts. This hierarchical learning is arguably the most powerful aspect of deep neural networks and is only possible because we moved beyond single-layer perceptrons.&lt;/p&gt;

&lt;p&gt;The connection to biological neural networks, while limited, provides useful intuition about why distributed representations work. In the brain, memories and concepts aren‚Äôt stored in single neurons but in patterns of activity across many neurons. Similarly, in artificial neural networks, representations are distributed across multiple neurons. This distribution provides robustness‚Äîif a few neurons fail or are dropped (as in dropout), the network can still function. It also enables the network to represent exponentially many concepts with linearly many neurons, a property called representational efficiency that partially explains deep learning‚Äôs success.&lt;/p&gt;

&lt;p&gt;Finally, understanding why we need smooth activation functions connects to the broader topic of optimization. Gradient descent, the primary algorithm for training neural networks, requires gradients. The step function‚Äôs gradient is zero almost everywhere (and undefined at the threshold), making gradient-based optimization impossible. Smooth activation functions like sigmoid, tanh, and especially ReLU provide meaningful gradients that guide the learning process. The choice of activation function affects not just whether we can compute gradients but also their magnitudes, which determines how quickly different layers learn‚Äîa consideration that becomes critical in deep networks where gradients must propagate through many layers.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://psycnet.apa.org/record/1959-09865-001&quot;&gt;‚ÄúThe Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain‚Äù (1958)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Author&lt;/em&gt;: Frank Rosenblatt&lt;br /&gt;
This foundational paper introduced the perceptron and demonstrated that a simple artificial neuron could learn from examples. Rosenblatt showed both the theoretical convergence properties and practical implementations, building physical machines that could perform pattern recognition. The perceptron‚Äôs success sparked immense optimism about artificial intelligence, though this was later tempered by the discovery of its limitations. The paper is historically significant not just for the algorithm but for establishing the paradigm of learning from data that underlies all of modern machine learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://mitpress.mit.edu/books/perceptrons&quot;&gt;‚ÄúPerceptrons: An Introduction to Computational Geometry‚Äù (1969)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Marvin Minsky and Seymour Papert&lt;br /&gt;
While not available on arXiv, this influential book rigorously analyzed the perceptron‚Äôs limitations, proving that single-layer perceptrons cannot solve problems like XOR. The analysis was so thorough and the conclusions so discouraging that it contributed to the first AI winter, with research funding for neural networks drying up for over a decade. Ironically, Minsky and Papert noted that multi-layer networks could overcome these limitations, but the lack of a training algorithm (backpropagation hadn‚Äôt been rediscovered) meant this observation didn‚Äôt prevent the field‚Äôs decline. The book remains important for understanding both the mathematical foundations of linear classifiers and the historical development of neural networks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.nature.com/articles/323533a0&quot;&gt;‚ÄúLearning representations by back-propagating errors‚Äù (1986)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: David E. Rumelhart, Geoffrey E. Hinton, Ronald J. Williams&lt;br /&gt;
This paper revitalized neural network research by showing how to train multi-layer networks of perceptron-like units using backpropagation. The key insight was that by computing gradients layer by layer using the chain rule, we could assign credit (or blame) for errors to all weights in the network, not just the output layer. This enabled training networks deep enough to solve XOR and many other problems that single perceptrons couldn‚Äôt handle. The paper marked the beginning of connectionism‚Äôs resurgence and laid the groundwork for modern deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://proceedings.mlr.press/v15/glorot11a.html&quot;&gt;‚ÄúDeep Sparse Rectifier Neural Networks‚Äù (2011)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Xavier Glorot, Antoine Bordes, Yoshua Bengio&lt;br /&gt;
This paper introduced the Rectified Linear Unit (ReLU) as a superior activation function for deep networks and empirically demonstrated its advantages over sigmoid and tanh. The authors showed that ReLU enables training deeper networks by avoiding the vanishing gradient problem that plagued earlier activation functions. ReLU neurons are also computationally efficient (just a max operation) and induce sparse representations (many neurons output exactly zero), which can be both computationally beneficial and interpretable. The adoption of ReLU was a critical factor in the deep learning revolution, enabling the training of networks with dozens or even hundreds of layers.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1502.01852&quot;&gt;‚ÄúDelving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification‚Äù (2015)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun&lt;br /&gt;
This paper introduced both PReLU (Parametric ReLU, where the slope for negative inputs is learned) and He initialization, a weight initialization scheme specifically designed for ReLU networks. The paper demonstrated that with proper initialization, extremely deep networks (22 layers at the time, which seemed very deep) could not only train successfully but surpass human performance on ImageNet classification. The He initialization scheme, which uses variance \(\sqrt{2/n_{in}}\) instead of \(\sqrt{1/n_{in}}\) (Xavier), accounts for the fact that ReLU zeros out half the neurons on average, maintaining appropriate activation and gradient magnitudes through deep networks.&lt;/p&gt;

&lt;h2 id=&quot;common-pitfalls-and-tricks&quot;&gt;Common Pitfalls and Tricks&lt;/h2&gt;

&lt;p&gt;One of the most common mistakes when implementing neurons is initializing all weights to the same value, particularly zero. This might seem sensible‚Äîstart from a ‚Äúneutral‚Äù position and let the data guide learning‚Äîbut it has a devastating consequence called the symmetry problem. If all neurons in a layer start with identical weights, they receive identical gradients during backpropagation and thus make identical updates. They remain identical throughout training, learning exactly the same features. A layer of 100 neurons with identical weights is no more powerful than a single neuron. Random initialization breaks this symmetry, ensuring each neuron follows a different learning trajectory and learns to detect different patterns.&lt;/p&gt;

&lt;p&gt;The scale of initialization also matters profoundly, though the reasons are subtle. If weights are too large, activations can saturate (for sigmoid/tanh) or explode (growing exponentially through layers), while gradients can also explode, causing training instability. If weights are too small, activations shrink toward zero through layers, and gradients vanish, making learning impossibly slow, especially in deep networks. The solution is to scale initial weights based on layer dimensions. Xavier initialization (\(\mathcal{N}(0, 1/n_{in})\)) works well for sigmoid and tanh, maintaining variance of activations across layers. He initialization (\(\mathcal{N}(0, 2/n_{in})\)) is specifically designed for ReLU, accounting for its property of zeroing negative inputs.&lt;/p&gt;

&lt;p&gt;The dying ReLU problem deserves special attention because it‚Äôs a common failure mode in practice. When a ReLU neuron‚Äôs input becomes negative during training and remains negative, the neuron outputs zero and has zero gradient, so it never updates. This can happen due to unlucky initialization, too-high learning rates causing large weight updates that push neurons into the negative region, or systematic biases in the data. Once a neuron dies, it‚Äôs permanently dead for that training run. To diagnose this, monitor what fraction of neurons are always outputting zero. If more than 20-30% are dead, you likely have a problem. Solutions include using Leaky ReLU (which has small gradient even for negative inputs), reducing learning rate, improving initialization, or using batch normalization (which we‚Äôll cover later) to keep activations in reasonable ranges.&lt;/p&gt;

&lt;p&gt;A powerful technique that‚Äôs often overlooked is using small positive biases for ReLU neurons. While weights should be random, initializing biases to small positive values like 0.01 ensures that most neurons are initially active (outputting positive values) rather than starting in the zero region. This gives them a chance to learn before potentially dying. This is a simple trick that can noticeably improve training in very deep networks.&lt;/p&gt;

&lt;p&gt;Understanding the geometric interpretation of weights helps debug and interpret models. The weight vector defines a direction in input space that the neuron is ‚Äúlooking‚Äù along. Its magnitude determines sensitivity‚Äîlarger weights mean the neuron responds more strongly to changes in that direction. In image processing, you can literally visualize what a neuron has learned by finding the input pattern that maximally activates it, often revealing that low-level neurons learn to detect oriented edges, while deeper neurons learn to detect increasingly complex patterns like textures, object parts, or eventually complete objects.&lt;/p&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;The perceptron, despite its simplicity, introduces fundamental concepts that persist throughout deep learning: the idea that we can learn from examples by adjusting weights based on errors, that weighted combinations of inputs can perform computation, and that linear models have inherent limitations necessitating nonlinearity and depth. Modern neurons extend the perceptron by using smooth, differentiable activation functions, enabling gradient-based learning through arbitrarily deep networks. The choice of activation function profoundly affects training dynamics, with ReLU emerging as the dominant choice for hidden layers due to its computational efficiency and resistance to vanishing gradients. Proper initialization breaks symmetry while maintaining appropriate activation and gradient scales, with He initialization being standard for ReLU networks. Understanding these foundational concepts deeply‚Äînot just what the formulas are but why they work and when they fail‚Äîis essential for anyone seeking to master deep learning rather than merely apply it superficially.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>02 Introduction to Neural Networks</title>
   <link href="http://localhost:4000/contents/en/chapter02/02_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter02/02_00_Introduction</id>
   <content type="html">&lt;p&gt;Neural Networks are the foundation of modern deep learning. This chapter introduces the basic building blocks of neural networks, including neurons, layers, activation functions, and forward propagation. We‚Äôll explore how these simple units combine to create powerful learning systems capable of solving complex problems.&lt;/p&gt;

&lt;p&gt;Understanding neural networks is essential for anyone working in deep learning, as they form the basis for more advanced architectures and techniques covered in later chapters.&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>01-01 Why Deep Learning?</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_01_Why_Deep_Learning/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter01/01_01_Why_Deep_Learning</id>
   <content type="html">&lt;h2 id=&quot;the-power-of-deep-learning&quot;&gt;The Power of Deep Learning&lt;/h2&gt;

&lt;p&gt;Deep learning has become the dominant approach in artificial intelligence because it solves fundamental limitations of traditional machine learning.&lt;/p&gt;

&lt;h2 id=&quot;limitations-of-traditional-machine-learning&quot;&gt;Limitations of Traditional Machine Learning&lt;/h2&gt;

&lt;h3 id=&quot;1-manual-feature-engineering&quot;&gt;1. Manual Feature Engineering&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Traditional Approach&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# Manual feature extraction for image classification
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;calculate_histogram&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;detect_edges&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;extract_textures&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;compute_color_moments&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Then train a classifier on these features
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train_svm&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;features&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Problems&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Requires domain expertise&lt;/li&gt;
  &lt;li&gt;Time-consuming&lt;/li&gt;
  &lt;li&gt;May miss important patterns&lt;/li&gt;
  &lt;li&gt;Not scalable across domains&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Deep Learning Solution&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;# End-to-end learning
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;build_cnn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;labels&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Learns features automatically!
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;2-fixed-representations&quot;&gt;2. Fixed Representations&lt;/h3&gt;

&lt;p&gt;Traditional ML uses handcrafted features that:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Don‚Äôt adapt to data&lt;/li&gt;
  &lt;li&gt;May not be optimal for the task&lt;/li&gt;
  &lt;li&gt;Require redesign for new problems&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep learning &lt;strong&gt;learns optimal representations&lt;/strong&gt; for each specific task.&lt;/p&gt;

&lt;h3 id=&quot;3-scalability-limitations&quot;&gt;3. Scalability Limitations&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Traditional ML&lt;/strong&gt;: Often plateaus with more data&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Learning&lt;/strong&gt;: Performance improves with scale&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Traditional ML:  _______________  (plateaus)
                     /
Deep Learning:     /  (keeps improving)
                  /
                 |
              Performance
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;what-makes-deep-learning-different&quot;&gt;What Makes Deep Learning Different?&lt;/h2&gt;

&lt;h3 id=&quot;1-hierarchical-feature-learning&quot;&gt;1. Hierarchical Feature Learning&lt;/h3&gt;

&lt;p&gt;Deep networks learn features at multiple levels:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example: Face Recognition&lt;/strong&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Layer 1 (Low-level):    Edges, colors, simple patterns
         ‚Üì
Layer 2 (Mid-level):    Eyes, nose, mouth parts
         ‚Üì
Layer 3 (High-level):   Complete faces, expressions
         ‚Üì
Output:                  Person identity
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;This mirrors how humans perceive - from simple to complex concepts.&lt;/p&gt;

&lt;h3 id=&quot;2-end-to-end-learning&quot;&gt;2. End-to-End Learning&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Traditional Pipeline&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Raw Data ‚Üí Preprocessing ‚Üí Feature Extraction ‚Üí Feature Selection ‚Üí Model ‚Üí Output
         (Manual)        (Manual)            (Manual)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;strong&gt;Deep Learning&lt;/strong&gt;:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Raw Data ‚Üí Neural Network ‚Üí Output
         (All learned automatically)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;3-universal-function-approximators&quot;&gt;3. Universal Function Approximators&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Universal Approximation Theorem&lt;/strong&gt;: A neural network with even a single hidden layer can approximate any continuous function (given enough neurons).&lt;/p&gt;

&lt;p&gt;Deep networks can learn to approximate:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Image transformations&lt;/li&gt;
  &lt;li&gt;Language patterns&lt;/li&gt;
  &lt;li&gt;Game strategies&lt;/li&gt;
  &lt;li&gt;Physical simulations&lt;/li&gt;
  &lt;li&gt;Complex decision boundaries&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;when-to-use-deep-learning&quot;&gt;When to Use Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;deep-learning-excels-when&quot;&gt;Deep Learning Excels When:&lt;/h3&gt;

&lt;p&gt;‚úÖ &lt;strong&gt;Large amounts of data&lt;/strong&gt; available&lt;br /&gt;
‚úÖ &lt;strong&gt;Complex patterns&lt;/strong&gt; to learn&lt;br /&gt;
‚úÖ &lt;strong&gt;High-dimensional inputs&lt;/strong&gt; (images, text, audio)&lt;br /&gt;
‚úÖ &lt;strong&gt;End-to-end learning&lt;/strong&gt; desired&lt;br /&gt;
‚úÖ &lt;strong&gt;Sufficient computational resources&lt;/strong&gt;&lt;br /&gt;
‚úÖ &lt;strong&gt;Non-linear relationships&lt;/strong&gt; in data&lt;/p&gt;

&lt;h3 id=&quot;traditional-ml-may-be-better-when&quot;&gt;Traditional ML May Be Better When:&lt;/h3&gt;

&lt;p&gt;‚ö†Ô∏è Small datasets (&amp;lt; 1000 samples)&lt;br /&gt;
‚ö†Ô∏è Need interpretability (medical diagnosis decisions)&lt;br /&gt;
‚ö†Ô∏è Limited computational resources&lt;br /&gt;
‚ö†Ô∏è Simple, well-understood problems&lt;br /&gt;
‚ö†Ô∏è Fast training required&lt;br /&gt;
‚ö†Ô∏è Linear relationships suffice&lt;/p&gt;

&lt;h2 id=&quot;success-stories&quot;&gt;Success Stories&lt;/h2&gt;

&lt;h3 id=&quot;computer-vision-imagenet-2012&quot;&gt;Computer Vision: ImageNet (2012)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;AlexNet&lt;/strong&gt; achieved 15.3% error rate (vs 26% for traditional methods)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;First deep learning victory in computer vision&lt;/li&gt;
  &lt;li&gt;Sparked the deep learning revolution&lt;/li&gt;
  &lt;li&gt;8-layer CNN with 60M parameters&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;natural-language-machine-translation&quot;&gt;Natural Language: Machine Translation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Google Neural Machine Translation (2016)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Reduced translation errors by 60%&lt;/li&gt;
  &lt;li&gt;Learned to translate better than phrase-based systems&lt;/li&gt;
  &lt;li&gt;Enabled near-human quality translation&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;games-alphago-2016&quot;&gt;Games: AlphaGo (2016)&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Defeated world champion Lee Sedol 4-1&lt;/li&gt;
  &lt;li&gt;Combined deep learning with Monte Carlo tree search&lt;/li&gt;
  &lt;li&gt;Mastered Go, considered much harder than chess&lt;/li&gt;
  &lt;li&gt;Demonstrated creative, intuitive play&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;healthcare-medical-imaging&quot;&gt;Healthcare: Medical Imaging&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Skin Cancer Detection (2017)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Deep learning matched dermatologist performance&lt;/li&gt;
  &lt;li&gt;Analyzed dermoscopic images&lt;/li&gt;
  &lt;li&gt;Potential to democratize expert-level diagnosis&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;speech-voice-assistants&quot;&gt;Speech: Voice Assistants&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Near-human accuracy in speech recognition&lt;/li&gt;
  &lt;li&gt;Enables Siri, Alexa, Google Assistant&lt;/li&gt;
  &lt;li&gt;Works across accents and languages&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-data-advantage&quot;&gt;The Data Advantage&lt;/h2&gt;

&lt;h3 id=&quot;why-more-data-helps&quot;&gt;Why More Data Helps&lt;/h3&gt;

&lt;p&gt;Traditional ML:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Performance
    |     _______________
    |    /
    |   /
    |  /
    |_/________________
         Amount of Data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Deep Learning:&lt;/p&gt;
&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Performance
    |              /
    |            /
    |          /
    |        /
    |      /
    |    /
    |__/________________
         Amount of Data
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;the-scaling-law&quot;&gt;The Scaling Law&lt;/h3&gt;

&lt;p&gt;Empirical observation: Deep learning performance often follows:&lt;/p&gt;

\[\text{Error} \propto \frac{1}{(\text{Data size})^\alpha}\]

&lt;p&gt;where \(\alpha \approx 0.5\) for many tasks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Implication&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;4√ó more data ‚Üí 2√ó error reduction&lt;/li&gt;
  &lt;li&gt;100√ó more data ‚Üí 10√ó error reduction&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;computational-requirements&quot;&gt;Computational Requirements&lt;/h2&gt;

&lt;h3 id=&quot;gpu-revolution&quot;&gt;GPU Revolution&lt;/h3&gt;

&lt;p&gt;Deep learning became practical due to GPUs:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Operation&lt;/th&gt;
      &lt;th&gt;CPU Time&lt;/th&gt;
      &lt;th&gt;GPU Time&lt;/th&gt;
      &lt;th&gt;Speedup&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Matrix Multiply (1000√ó1000)&lt;/td&gt;
      &lt;td&gt;100ms&lt;/td&gt;
      &lt;td&gt;5ms&lt;/td&gt;
      &lt;td&gt;20√ó&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Conv2D Layer&lt;/td&gt;
      &lt;td&gt;1000ms&lt;/td&gt;
      &lt;td&gt;10ms&lt;/td&gt;
      &lt;td&gt;100√ó&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;Full Model Training&lt;/td&gt;
      &lt;td&gt;Days/Weeks&lt;/td&gt;
      &lt;td&gt;Hours/Days&lt;/td&gt;
      &lt;td&gt;10-100√ó&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;modern-infrastructure&quot;&gt;Modern Infrastructure&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Cloud Computing&lt;/strong&gt;: AWS, Google Cloud, Azure&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Specialized Hardware&lt;/strong&gt;: TPUs, Neural Processing Units&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Distributed Training&lt;/strong&gt;: Multi-GPU, multi-machine&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mixed Precision&lt;/strong&gt;: FP16 training for speed&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-deep-learning-workflow&quot;&gt;The Deep Learning Workflow&lt;/h2&gt;

&lt;h3 id=&quot;typical-process&quot;&gt;Typical Process&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Data Collection&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Gather large dataset&lt;/li&gt;
      &lt;li&gt;Ensure quality and diversity&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Data Preparation&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Clean and preprocess&lt;/li&gt;
      &lt;li&gt;Split into train/val/test&lt;/li&gt;
      &lt;li&gt;Augment if needed&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Model Design&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Choose architecture&lt;/li&gt;
      &lt;li&gt;Define layers and connections&lt;/li&gt;
      &lt;li&gt;Set hyperparameters&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Training&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Initialize parameters&lt;/li&gt;
      &lt;li&gt;Forward pass ‚Üí loss ‚Üí backward pass&lt;/li&gt;
      &lt;li&gt;Update weights&lt;/li&gt;
      &lt;li&gt;Monitor metrics&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Evaluation&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Test on held-out data&lt;/li&gt;
      &lt;li&gt;Analyze errors&lt;/li&gt;
      &lt;li&gt;Visualize predictions&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Iteration&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Improve data&lt;/li&gt;
      &lt;li&gt;Tune architecture&lt;/li&gt;
      &lt;li&gt;Adjust hyperparameters&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deployment&lt;/strong&gt;
    &lt;ul&gt;
      &lt;li&gt;Optimize for inference&lt;/li&gt;
      &lt;li&gt;Deploy to production&lt;/li&gt;
      &lt;li&gt;Monitor performance&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;tools-and-frameworks&quot;&gt;Tools and Frameworks&lt;/h2&gt;

&lt;h3 id=&quot;deep-learning-frameworks&quot;&gt;Deep Learning Frameworks&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;PyTorch&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Dynamic computation graphs&lt;/li&gt;
  &lt;li&gt;Pythonic interface&lt;/li&gt;
  &lt;li&gt;Popular in research&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;TensorFlow/Keras&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Production-ready&lt;/li&gt;
  &lt;li&gt;Extensive ecosystem&lt;/li&gt;
  &lt;li&gt;Easy deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;JAX&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Functional approach&lt;/li&gt;
  &lt;li&gt;Fast and flexible&lt;/li&gt;
  &lt;li&gt;Growing adoption&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;supporting-libraries&quot;&gt;Supporting Libraries&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;NumPy&lt;/strong&gt;: Numerical computing&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Pandas&lt;/strong&gt;: Data manipulation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Matplotlib/Seaborn&lt;/strong&gt;: Visualization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Scikit-learn&lt;/strong&gt;: Preprocessing, metrics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;recommended-books-for-this-course&quot;&gt;Recommended Books for This Course&lt;/h2&gt;

&lt;p&gt;To deepen your understanding, we recommend these essential deep learning books:&lt;/p&gt;

&lt;h3 id=&quot;1-deep-learning-by-ian-goodfellow-yoshua-bengio-and-aaron-courville&quot;&gt;1. &lt;strong&gt;Deep Learning&lt;/strong&gt; by Ian Goodfellow, Yoshua Bengio, and Aaron Courville&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;The definitive deep learning textbook&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Comprehensive coverage of theory and mathematics&lt;/li&gt;
  &lt;li&gt;Written by pioneers in the field&lt;/li&gt;
  &lt;li&gt;Free online: &lt;a href=&quot;http://www.deeplearningbook.org/&quot;&gt;deeplearningbook.org&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use for&lt;/strong&gt;: Mathematical foundations, theoretical depth&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-hands-on-machine-learning-with-scikit-learn-keras-and-tensorflow-by-aur√©lien-g√©ron&quot;&gt;2. &lt;strong&gt;Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow&lt;/strong&gt; by Aur√©lien G√©ron&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Best practical implementation guide&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Step-by-step code examples&lt;/li&gt;
  &lt;li&gt;End-to-end ML projects&lt;/li&gt;
  &lt;li&gt;Covers Scikit-Learn, TensorFlow, and Keras&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use for&lt;/strong&gt;: Implementation, practical projects&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-understanding-deep-learning-by-simon-jd-prince&quot;&gt;3. &lt;strong&gt;Understanding Deep Learning&lt;/strong&gt; by Simon J.D. Prince&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Modern, accessible introduction&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Clear explanations with excellent visualizations&lt;/li&gt;
  &lt;li&gt;Covers recent architectures (Transformers, etc.)&lt;/li&gt;
  &lt;li&gt;Intuitive approach to complex concepts&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use for&lt;/strong&gt;: Building intuition, visual understanding&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-mit-deep-learning-book&quot;&gt;4. &lt;strong&gt;MIT Deep Learning Book&lt;/strong&gt;&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Rigorous academic treatment&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;Strong theoretical foundations&lt;/li&gt;
  &lt;li&gt;Research-oriented perspective&lt;/li&gt;
  &lt;li&gt;Mathematical proofs and derivations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use for&lt;/strong&gt;: Academic depth, research preparation&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-to-use-these-books&quot;&gt;How to Use These Books&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Beginner Path&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Start with ‚ÄúUnderstanding Deep Learning‚Äù for intuition&lt;/li&gt;
  &lt;li&gt;Follow this course for structured learning&lt;/li&gt;
  &lt;li&gt;Reference ‚ÄúHands-On ML‚Äù for implementation&lt;/li&gt;
  &lt;li&gt;Dive into ‚ÄúDeep Learning‚Äù for theory&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Intermediate Path&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Use this course as primary guide&lt;/li&gt;
  &lt;li&gt;Reference ‚ÄúHands-On ML‚Äù for practical tips&lt;/li&gt;
  &lt;li&gt;Read ‚ÄúDeep Learning‚Äù chapters for depth&lt;/li&gt;
  &lt;li&gt;Consult ‚ÄúUnderstanding DL‚Äù for clarifications&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Advanced Path&lt;/strong&gt;:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Use this course for comprehensive coverage&lt;/li&gt;
  &lt;li&gt;Study ‚ÄúDeep Learning‚Äù for rigorous theory&lt;/li&gt;
  &lt;li&gt;Implement with ‚ÄúHands-On ML‚Äù techniques&lt;/li&gt;
  &lt;li&gt;Reference MIT book for research details&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;current-trends-2024-2025&quot;&gt;Current Trends (2024-2025)&lt;/h2&gt;

&lt;h3 id=&quot;large-language-models-llms&quot;&gt;Large Language Models (LLMs)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;GPT-4, Claude, Gemini&lt;/li&gt;
  &lt;li&gt;Billions to trillions of parameters&lt;/li&gt;
  &lt;li&gt;Emergent capabilities at scale&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;multimodal-models&quot;&gt;Multimodal Models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;CLIP: Vision + Language&lt;/li&gt;
  &lt;li&gt;GPT-4V: Text + Images&lt;/li&gt;
  &lt;li&gt;Unified understanding across modalities&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;efficient-ai&quot;&gt;Efficient AI&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Model compression&lt;/li&gt;
  &lt;li&gt;Quantization&lt;/li&gt;
  &lt;li&gt;Neural architecture search&lt;/li&gt;
  &lt;li&gt;Edge deployment&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;foundation-models&quot;&gt;Foundation Models&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Pre-train on massive data&lt;/li&gt;
  &lt;li&gt;Fine-tune for specific tasks&lt;/li&gt;
  &lt;li&gt;Transfer learning at scale&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;challenges-ahead&quot;&gt;Challenges Ahead&lt;/h2&gt;

&lt;h3 id=&quot;technical-challenges&quot;&gt;Technical Challenges&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Sample efficiency (learning from less data)&lt;/li&gt;
  &lt;li&gt;Robustness (handling distribution shift)&lt;/li&gt;
  &lt;li&gt;Interpretability (understanding decisions)&lt;/li&gt;
  &lt;li&gt;Computational cost (training and inference)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;societal-challenges&quot;&gt;Societal Challenges&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Bias and fairness&lt;/li&gt;
  &lt;li&gt;Privacy concerns&lt;/li&gt;
  &lt;li&gt;Environmental impact&lt;/li&gt;
  &lt;li&gt;Job displacement&lt;/li&gt;
  &lt;li&gt;Misinformation (deepfakes)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;p&gt;Deep learning succeeds because it:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;‚úÖ Learns features automatically&lt;/li&gt;
  &lt;li&gt;‚úÖ Scales with data and compute&lt;/li&gt;
  &lt;li&gt;‚úÖ Handles high-dimensional inputs&lt;/li&gt;
  &lt;li&gt;‚úÖ Achieves state-of-the-art results&lt;/li&gt;
  &lt;li&gt;‚úÖ Enables end-to-end learning&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Best used when:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Large datasets available&lt;/li&gt;
  &lt;li&gt;Complex patterns exist&lt;/li&gt;
  &lt;li&gt;Computational resources sufficient&lt;/li&gt;
  &lt;li&gt;High performance required&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The field continues to evolve rapidly with new architectures, techniques, and applications emerging constantly.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Next&lt;/strong&gt;: We‚Äôll dive into the fundamentals of neural networks and understand how they actually work!&lt;/p&gt;

</content>
 </entry>
 
 <entry>
   <title>01 Introduction to Deep Learning</title>
   <link href="http://localhost:4000/contents/en/chapter01/01_00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter01/01_00_Introduction</id>
   <content type="html">&lt;h1 id=&quot;introduction-to-deep-learning&quot;&gt;Introduction to Deep Learning&lt;/h1&gt;

&lt;h2 id=&quot;1-concept-overview&quot;&gt;1. Concept Overview&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/3/32/AI-ML-DL.svg/800px-AI-ML-DL.svg.png&quot; alt=&quot;Deep Learning Hierarchy&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: M·ªëi quan h·ªá gi·ªØa AI, Machine Learning v√† Deep Learning. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Deep Learning represents one of the most transformative technological advances of the 21st century. At its core, &lt;strong&gt;deep learning&lt;/strong&gt; is a subset of machine learning that uses artificial neural networks with multiple layers‚Äîhence ‚Äúdeep‚Äù‚Äîto automatically learn hierarchical representations of data. What makes deep learning revolutionary is not just that it works, but how fundamentally it changes our approach to building intelligent systems.&lt;/p&gt;

&lt;p&gt;To truly understand deep learning‚Äôs significance, we must appreciate what preceded it. Traditional machine learning required human experts to manually engineer features‚Äîthe relevant patterns or characteristics that algorithms would use to make decisions. For image recognition, this meant designing edge detectors, texture analyzers, and shape descriptors by hand. For speech recognition, it meant crafting phoneme representations and acoustic models based on linguistic theory. This feature engineering was both an art and a science, requiring deep domain expertise and often years of iterative refinement.&lt;/p&gt;

&lt;p&gt;Deep learning eliminates this bottleneck through &lt;strong&gt;representation learning&lt;/strong&gt;‚Äîthe ability to automatically discover the representations needed for detection or classification directly from raw data. A deep neural network learns features at multiple levels of abstraction: in computer vision, the first layer might learn to detect edges, the second layer combines edges into simple shapes, the third layer assembles shapes into object parts, and deeper layers recognize complete objects. Critically, the network discovers these hierarchical features on its own, without human guidance beyond providing the training data and the learning objective.&lt;/p&gt;

&lt;p&gt;This automatic feature learning has profound implications. It means deep learning can tackle problems where we don‚Äôt know how to manually engineer good features. It means the same basic architecture‚Äîwith appropriate modifications‚Äîcan excel at diverse tasks: recognizing faces, translating languages, generating images, playing games, or folding proteins. It means that as we collect more data and apply more computation, performance continues to improve, rather than plateauing as it often does with carefully hand-tuned classical systems.&lt;/p&gt;

&lt;h3 id=&quot;key-characteristics-of-deep-learning&quot;&gt;Key Characteristics of Deep Learning&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;1. Hierarchical Feature Learning&lt;/strong&gt;: Deep networks learn features at multiple levels of abstraction. Low-level layers capture simple patterns (edges, colors, basic phonemes), while higher layers combine these into complex concepts (objects, faces, semantic meanings). This hierarchy mirrors how we believe biological vision and cognition work‚Äîbuilding understanding layer by layer from simple to complex.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. End-to-End Learning&lt;/strong&gt;: Rather than building modular pipelines where each component is optimized separately, deep learning enables end-to-end optimization where the entire system learns jointly. For machine translation, instead of separate modules for parsing, alignment, and generation, a single neural network learns to map source language to target language directly, with all components optimized together toward the final translation quality.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Scalability with Data and Computation&lt;/strong&gt;: Traditional machine learning often exhibits diminishing returns‚Äîadding more data beyond a certain point provides little benefit. Deep learning‚Äôs performance continues to improve with more data and more computation, a scaling property that has driven the revolution in large language models and computer vision systems. This scalability is both a strength (enabling superhuman performance on many tasks) and a challenge (requiring massive datasets and computational resources).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Distributed Representations&lt;/strong&gt;: Deep networks learn to represent concepts as patterns of activation across many neurons, rather than having dedicated neurons for each concept. This enables generalization: knowledge about ‚Äúdogs‚Äù can inform understanding of ‚Äúwolves‚Äù because they share many representational features. It also provides robustness: if some neurons fail or are dropped out during training, the distributed representation still functions.&lt;/p&gt;

&lt;h3 id=&quot;why-deep-learning-matters&quot;&gt;Why Deep Learning Matters&lt;/h3&gt;

&lt;p&gt;The impact of deep learning extends far beyond academic curiosity. It has fundamentally changed multiple industries and aspects of daily life:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Computer Vision&lt;/strong&gt;: From barely functional digit recognition in the 1990s to systems that surpass human performance on many visual tasks, recognize thousands of object categories, generate photorealistic images, and enable autonomous vehicles.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Natural Language Processing&lt;/strong&gt;: From rigid rule-based systems to neural language models that can write essays, answer questions, translate between languages with near-human quality, and engage in coherent dialogue.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;: From slow, error-prone manual diagnosis to AI systems that detect diseases from medical images with expert-level accuracy, predict patient outcomes, accelerate drug discovery, and personalize treatment plans.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Scientific Discovery&lt;/strong&gt;: From traditional hypothesis-driven research to AI systems that discover novel materials, predict protein structures (AlphaFold solving a 50-year grand challenge), generate hypotheses from literature, and design experiments.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Perhaps most importantly, deep learning has democratized AI. Open-source frameworks like PyTorch and TensorFlow, pre-trained models available freely, and educational resources have made powerful AI accessible to anyone with a laptop and curiosity. This democratization accelerates innovation as millions of researchers and developers worldwide contribute to advancing the field.&lt;/p&gt;

&lt;h2 id=&quot;2-mathematical-foundation&quot;&gt;2. Mathematical Foundation&lt;/h2&gt;

&lt;p&gt;At its mathematical core, deep learning is about &lt;strong&gt;function approximation&lt;/strong&gt;. Given training data \(\{(\mathbf{x}_1, y_1), (\mathbf{x}_2, y_2), \ldots, (\mathbf{x}_n, y_n)\}\) where \(\mathbf{x}_i\) are inputs (images, text, sensor readings) and \(y_i\) are desired outputs (labels, translations, actions), we want to find a function \(f_\theta\) parameterized by \(\theta\) that accurately maps inputs to outputs.&lt;/p&gt;

&lt;h3 id=&quot;the-universal-approximation-theorem&quot;&gt;The Universal Approximation Theorem&lt;/h3&gt;

&lt;p&gt;A fundamental theoretical result states that a neural network with even a single hidden layer containing sufficiently many neurons can approximate any continuous function to arbitrary accuracy. Mathematically, for any continuous function \(g: \mathbb{R}^n \to \mathbb{R}^m\) and any \(\epsilon &amp;gt; 0\), there exists a neural network \(f_\theta\) such that:&lt;/p&gt;

\[\|f_\theta(\mathbf{x}) - g(\mathbf{x})\| &amp;lt; \epsilon \quad \text{for all } \mathbf{x}\]

&lt;p&gt;This is remarkable: neural networks are &lt;strong&gt;universal function approximators&lt;/strong&gt;. However, this theorem has important caveats. It guarantees existence but not learnability‚Äîfinding the parameters \(\theta\) through gradient descent is not guaranteed. It requires potentially exponentially many neurons in the hidden layer, which is impractical. And it applies to shallow networks, but doesn‚Äôt explain why deep networks work better in practice.&lt;/p&gt;

&lt;h3 id=&quot;why-depth-matters&quot;&gt;Why Depth Matters&lt;/h3&gt;

&lt;p&gt;While shallow networks are theoretically sufficient, &lt;strong&gt;deep networks&lt;/strong&gt; are exponentially more efficient for many real-world functions. Consider representing a function with \(k\) levels of composition: \(f = f_k \circ f_{k-1} \circ \cdots \circ f_1\). A shallow network might need exponentially many neurons to represent this, while a deep network with \(k\) layers can represent it naturally with polynomial complexity.&lt;/p&gt;

&lt;p&gt;The mathematical intuition is that many functions in nature exhibit compositional structure. To recognize a face, we first detect edges, then combine edges into facial features (eyes, nose, mouth), then combine features into a face representation. This hierarchical composition is naturally expressed as successive transformations through layers:&lt;/p&gt;

&lt;p&gt;\(\mathbf{h}^{(1)} = \sigma(\mathbf{W}^{(1)}\mathbf{x} + \mathbf{b}^{(1)})\)
\(\mathbf{h}^{(2)} = \sigma(\mathbf{W}^{(2)}\mathbf{h}^{(1)} + \mathbf{b}^{(2)})\)
\(\vdots\)
\(\mathbf{y} = \mathbf{W}^{(L)}\mathbf{h}^{(L-1)} + \mathbf{b}^{(L)}\)&lt;/p&gt;

&lt;p&gt;where \(\sigma\) is a nonlinear activation function (ReLU, sigmoid, tanh), \(\mathbf{W}^{(l)}\) are weight matrices, and \(\mathbf{b}^{(l)}\) are bias vectors at layer \(l\).&lt;/p&gt;

&lt;h3 id=&quot;the-learning-objective&quot;&gt;The Learning Objective&lt;/h3&gt;

&lt;p&gt;Training a neural network means finding parameters \(\theta = \{\mathbf{W}^{(1)}, \mathbf{b}^{(1)}, \ldots, \mathbf{W}^{(L)}, \mathbf{b}^{(L)}\}\) that minimize a loss function \(\mathcal{L}(\theta)\) measuring prediction error:&lt;/p&gt;

\[\theta^* = \arg\min_\theta \frac{1}{n}\sum_{i=1}^n \mathcal{L}(f_\theta(\mathbf{x}_i), y_i)\]

&lt;p&gt;For classification, we typically use cross-entropy loss:
\(\mathcal{L}(\hat{\mathbf{y}}, \mathbf{y}) = -\sum_j y_j \log \hat{y}_j\)&lt;/p&gt;

&lt;p&gt;For regression, mean squared error:
\(\mathcal{L}(\hat{y}, y) = \frac{1}{2}(y - \hat{y})^2\)&lt;/p&gt;

&lt;p&gt;We optimize this via &lt;strong&gt;gradient descent&lt;/strong&gt;: iteratively updating parameters in the direction that decreases loss:&lt;/p&gt;

\[\theta \leftarrow \theta - \eta \nabla_\theta \mathcal{L}(\theta)\]

&lt;p&gt;where \(\eta\) is the learning rate. Computing gradients efficiently through backpropagation‚Äîapplying the chain rule layer by layer‚Äîis what makes training deep networks practical.&lt;/p&gt;

&lt;h3 id=&quot;why-it-works-the-bias-variance-tradeoff&quot;&gt;Why It Works: The Bias-Variance Tradeoff&lt;/h3&gt;

&lt;p&gt;Deep learning‚Äôs success can be understood through the classical bias-variance tradeoff. High bias (underfitting) means the model can‚Äôt capture the data‚Äôs complexity. High variance (overfitting) means the model fits noise rather than true patterns. Deep networks have enormous capacity (low bias) but are surprisingly resistant to overfitting when properly regularized, achieving low variance despite having millions of parameters‚Äîoften more parameters than training examples!&lt;/p&gt;

&lt;p&gt;This seems to violate classical statistical learning theory, which suggests models should be simpler than the data. Recent theoretical work on ‚Äúdouble descent‚Äù and ‚Äúimplicit regularization‚Äù shows that overparameterized networks trained with gradient descent implicitly prefer simpler functions, providing a form of automatic regularization that classical theory didn‚Äôt account for.&lt;/p&gt;

&lt;h2 id=&quot;3-example--intuition&quot;&gt;3. Example / Intuition&lt;/h2&gt;

&lt;p&gt;To develop intuition for how deep learning works, let‚Äôs walk through a concrete example: teaching a network to recognize handwritten digits.&lt;/p&gt;

&lt;h3 id=&quot;the-problem-mnist-digit-recognition&quot;&gt;The Problem: MNIST Digit Recognition&lt;/h3&gt;

&lt;p&gt;Imagine you have 28√ó28 pixel grayscale images of handwritten digits (0-9), and you want a system that can correctly identify which digit is in each image. Each image is just a 784-dimensional vector (28√ó28 = 784 pixels, each with intensity 0-255).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Traditional Approach&lt;/strong&gt;: You might manually design features:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Count loops (0, 6, 8, 9 have loops; 1, 7 don‚Äôt)&lt;/li&gt;
  &lt;li&gt;Detect vertical/horizontal strokes&lt;/li&gt;
  &lt;li&gt;Measure height-to-width ratios&lt;/li&gt;
  &lt;li&gt;Identify endpoints and intersections&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This requires deep expertise and doesn‚Äôt generalize well (what about cursive? different fonts?).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Deep Learning Approach&lt;/strong&gt;: Feed the 784 pixel values directly into a neural network:&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;Input (784 pixels) ‚Üí Hidden Layer 1 (128 neurons) ‚Üí Hidden Layer 2 (64 neurons) ‚Üí Output (10 classes)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The network automatically learns:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Layer 1&lt;/strong&gt; discovers edge detectors‚Äîneurons that activate for vertical lines, horizontal lines, curves at different positions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Layer 2&lt;/strong&gt; combines edges into stroke patterns‚Äîlong vertical strokes (for 1, 7), circular shapes (for 0, 6, 8, 9), specific curve combinations&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Output layer&lt;/strong&gt; combines these patterns to recognize complete digits&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;how-learning-happens-an-intuitive-example&quot;&gt;How Learning Happens: An Intuitive Example&lt;/h3&gt;

&lt;p&gt;Initially, weights are random. When shown a ‚Äú3‚Äù:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Forward pass&lt;/strong&gt;: Network makes a random prediction, say 70% confident it‚Äôs a ‚Äú7‚Äù&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compute error&lt;/strong&gt;: True label is ‚Äú3‚Äù, prediction was ‚Äú7‚Äù‚Äîbig error!&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Backward pass (backpropagation)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Output layer: ‚ÄúI should have activated neuron 3 more and neuron 7 less‚Äù&lt;/li&gt;
      &lt;li&gt;Hidden layers: ‚ÄúWhich of my activations contributed to the wrong prediction? Adjust weights to fix this‚Äù&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Update weights&lt;/strong&gt;: Slightly modify all weights to reduce this particular error&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Repeat&lt;/strong&gt;: After seeing thousands of ‚Äú3‚Äùs with various handwriting styles, the network learns the essential features of ‚Äú3‚Äù-ness&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The magic is that this simple process‚Äîforward pass, compute error, backpropagate, update‚Äîwhen repeated millions of times, discovers the hierarchical features needed for recognition.&lt;/p&gt;

&lt;h3 id=&quot;why-hierarchical-learning-matters&quot;&gt;Why Hierarchical Learning Matters&lt;/h3&gt;

&lt;p&gt;Consider recognizing a face:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Low-level features&lt;/strong&gt; (Layer 1): Edge detectors at various orientations, color blobs&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mid-level features&lt;/strong&gt; (Layer 2-3): Combine edges into simple shapes‚Äîcurves, corners, textures&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;High-level features&lt;/strong&gt; (Layer 4-5): Combine shapes into facial features‚Äîeyes (pair of dark circles with highlights), nose (triangular region with shadows), mouth (horizontal dark region, possibly with teeth)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complete concept&lt;/strong&gt; (Output): Combine facial features into specific face identities&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Each layer learns increasingly abstract representations, naturally capturing the compositional nature of visual recognition. The network discovers that eyes, noses, and mouths are reusable components that appear in all faces, just as strokes and curves are reusable components in all digits.&lt;/p&gt;

&lt;p&gt;This hierarchical, distributed representation also explains deep learning‚Äôs sample efficiency. Once the network learns ‚Äúedge detector‚Äù and ‚Äúcircle detector‚Äù neurons from seeing digits, these same neurons help recognize letters, faces, and objects‚Äîtransfer learning happens naturally through shared low-level features.&lt;/p&gt;

&lt;h2 id=&quot;4-code-snippet&quot;&gt;4. Code Snippet&lt;/h2&gt;

&lt;p&gt;Let‚Äôs implement a simple deep learning example to make concepts concrete. We‚Äôll build a neural network to classify MNIST digits using PyTorch.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.optim&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torchvision&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Define a simple deep neural network
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDeepNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;
    A 3-layer neural network for MNIST digit classification.
    
    Architecture:
    - Input: 784 dimensions (28x28 flattened image)
    - Hidden Layer 1: 128 neurons with ReLU activation
    - Hidden Layer 2: 64 neurons with ReLU activation  
    - Output Layer: 10 neurons (one per digit class)
    &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&quot;&quot;&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;nf&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SimpleDeepNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# First hidden layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;    &lt;span class=&quot;c1&quot;&gt;# Second hidden layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fc3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Linear&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;     &lt;span class=&quot;c1&quot;&gt;# Output layer
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;relu&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ReLU&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;forward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Flatten the 28x28 images to 784-dimensional vectors
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;view&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;784&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Layer 1: Learn low-level features
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Layer 2: Learn mid-level feature combinations
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;relu&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Output layer: Classify into 10 digit classes
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;fc3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Load MNIST dataset
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Compose&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;ToTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;transforms&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Normalize&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.1307&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,),&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.3081&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,))&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Normalize with MNIST mean/std
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;download&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;datasets&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;MNIST&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;./data&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;transform&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1000&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;False&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Initialize model, loss function, and optimizer
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;SimpleDeepNet&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;CrossEntropyLoss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Combines softmax + negative log likelihood
&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optim&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;Adam&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;parameters&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mf&quot;&gt;0.001&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Training loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Set model to training mode
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c1&quot;&gt;# Forward pass: compute predictions
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Backward pass: compute gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;zero_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Clear previous gradients
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;backward&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;        &lt;span class=&quot;c1&quot;&gt;# Backpropagation
&lt;/span&gt;        
        &lt;span class=&quot;c1&quot;&gt;# Update weights
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;step&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;c1&quot;&gt;# Track accuracy
&lt;/span&gt;        &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
        
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;%&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;100&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Batch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_idx&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, &lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;
                  &lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Loss: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;loss&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;total_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Epoch &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt; Training: Avg Loss=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;avg_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Accuracy=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Evaluation loop
&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eval&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Set model to evaluation mode
&lt;/span&gt;    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
    
    &lt;span class=&quot;k&quot;&gt;with&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;torch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;no_grad&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Disable gradient computation for efficiency
&lt;/span&gt;        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;data&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;output&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;argmax&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dim&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pred&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;eq&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;target&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    
    &lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;100.&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;correct&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Test: Avg Loss=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_loss&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;, Accuracy=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&apos;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;accuracy&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;# Train for multiple epochs
&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Starting training...&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;6&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  &lt;span class=&quot;c1&quot;&gt;# Train for 5 epochs
&lt;/span&gt;    &lt;span class=&quot;nf&quot;&gt;train&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;train_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;optimizer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;epoch&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;test&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;test_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;criterion&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sa&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Final test accuracy: &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;test_accuracy&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;f&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;Training complete! The network learned to recognize digits through:&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;1. Forward propagation (making predictions)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;2. Loss computation (measuring errors)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;3. Backpropagation (computing gradients)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;nf&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;4. Weight updates (learning from mistakes)&lt;/span&gt;&lt;span class=&quot;sh&quot;&gt;&quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;understanding-the-code&quot;&gt;Understanding the Code&lt;/h3&gt;

&lt;p&gt;This simple example demonstrates core deep learning principles:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Architecture Design&lt;/strong&gt;: Three layers transform 784-dimensional input to 10-dimensional output through learned representations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Automatic Feature Learning&lt;/strong&gt;: We never told the network what features to look for‚Äîit discovers useful representations automatically.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. The Training Loop&lt;/strong&gt;: The standard pattern of forward pass ‚Üí compute loss ‚Üí backpropagate ‚Üí update weights that underlies all deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Nonlinearity is Crucial&lt;/strong&gt;: ReLU activation functions between layers enable learning complex, nonlinear functions. Without them, multiple layers would collapse to a single linear transformation.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Scalability&lt;/strong&gt;: This same code structure, with appropriate modifications, works for much larger datasets and more complex tasks‚Äîcomputer vision, natural language processing, etc.&lt;/p&gt;

&lt;p&gt;After just 5 epochs (5 passes through 60,000 training images), this simple network typically achieves ~97% accuracy‚Äîdemonstrating deep learning‚Äôs power to learn from data.&lt;/p&gt;

&lt;h2 id=&quot;5-related-concepts&quot;&gt;5. Related Concepts&lt;/h2&gt;

&lt;p&gt;Understanding deep learning requires seeing how it connects to broader machine learning and AI concepts:&lt;/p&gt;

&lt;h3 id=&quot;supervised-vs-unsupervised-vs-reinforcement-learning&quot;&gt;Supervised vs Unsupervised vs Reinforcement Learning&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Supervised Learning&lt;/strong&gt; (what we‚Äôve primarily discussed) learns from labeled examples: input-output pairs like (image, label) or (sentence, translation). The network learns to map inputs to correct outputs.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Unsupervised Learning&lt;/strong&gt; discovers structure in data without labels. Autoencoders learn compressed representations. Clustering groups similar examples. Generative models learn data distributions to create new samples. These techniques are crucial when labels are expensive or unavailable.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reinforcement Learning&lt;/strong&gt; learns from interaction: an agent takes actions in an environment, receives rewards, and learns policies to maximize cumulative reward. This enables learning behaviors (game playing, robotics) where we can‚Äôt provide explicit correct actions for every situation, only feedback on outcomes.&lt;/p&gt;

&lt;p&gt;Deep learning has transformed all three paradigms, but the principles differ significantly. This course focuses primarily on supervised learning initially, with later chapters covering unsupervised and reinforcement learning.&lt;/p&gt;

&lt;h3 id=&quot;classical-machine-learning-vs-deep-learning&quot;&gt;Classical Machine Learning vs Deep Learning&lt;/h3&gt;

&lt;p&gt;Traditional machine learning (SVMs, decision trees, logistic regression) typically requires:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Hand-engineered features&lt;/li&gt;
  &lt;li&gt;Explicit model assumptions (linearity, independence)&lt;/li&gt;
  &lt;li&gt;Works well with moderate data (hundreds to thousands of examples)&lt;/li&gt;
  &lt;li&gt;More interpretable (feature importance, decision boundaries)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Deep learning:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Learns features automatically end-to-end&lt;/li&gt;
  &lt;li&gt;Fewer assumptions about data structure&lt;/li&gt;
  &lt;li&gt;Requires large datasets (thousands to millions of examples)&lt;/li&gt;
  &lt;li&gt;Less interpretable but more powerful for complex patterns&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Neither approach is universally superior‚Äîclassical ML can be better for small datasets, tabular data, or when interpretability is critical. Deep learning excels with large datasets, high-dimensional inputs (images, text), and complex patterns.&lt;/p&gt;

&lt;h3 id=&quot;transfer-learning-and-pre-training&quot;&gt;Transfer Learning and Pre-training&lt;/h3&gt;

&lt;p&gt;One of deep learning‚Äôs most powerful techniques is &lt;strong&gt;transfer learning&lt;/strong&gt;: training a network on one task (e.g., ImageNet classification) then adapting it to related tasks (medical image analysis, wildlife detection). The network‚Äôs learned representations‚Äîedge detectors, texture patterns, shape recognizers‚Äîtransfer across domains.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Pre-training&lt;/strong&gt; on large general datasets, then &lt;strong&gt;fine-tuning&lt;/strong&gt; on specific tasks, has become standard practice. GPT, BERT, and other large language models are pre-trained on massive text corpora, then specialized for particular applications through fine-tuning with much less task-specific data. This dramatically reduces data requirements for new tasks.&lt;/p&gt;

&lt;h3 id=&quot;the-role-of-architecture-vs-data-vs-compute&quot;&gt;The Role of Architecture vs Data vs Compute&lt;/h3&gt;

&lt;p&gt;Deep learning‚Äôs success derives from three factors working together:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Architecture innovations&lt;/strong&gt; (CNNs, Transformers, ResNets) enable learning certain patterns efficiently. The right architecture provides appropriate inductive biases for the problem structure.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Data scale&lt;/strong&gt; provides the raw material for learning. More diverse, high-quality data enables networks to learn more robust, generalizable representations.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Computational scale&lt;/strong&gt; makes training large networks on large datasets practical. GPUs parallelize the matrix operations neural networks depend on, reducing training time from months to hours.&lt;/p&gt;

&lt;p&gt;Modern deep learning progress comes from advances in all three: better architectures (Transformers), larger datasets (web-scale text and images), and more compute (GPU clusters, TPUs). No single factor alone explains the field‚Äôs success.&lt;/p&gt;

&lt;h2 id=&quot;6-fundamental-papers&quot;&gt;6. Fundamental Papers&lt;/h2&gt;

&lt;p&gt;Understanding deep learning‚Äôs historical development through key papers provides context for current practice and future directions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://link.springer.com/article/10.1007/BF02478259&quot;&gt;‚ÄúA Logical Calculus of Ideas Immanent in Nervous Activity‚Äù (1943)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Warren McCulloch and Walter Pitts&lt;br /&gt;
This foundational paper introduced the mathematical model of artificial neurons, showing that networks of simple threshold units could compute any logical function. While vastly simplified compared to biological neurons, this work established the theoretical basis for neural computation and inspired subsequent research in both neuroscience and artificial intelligence.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://www.nature.com/articles/323533a0&quot;&gt;‚ÄúLearning representations by back-propagating errors‚Äù (1986)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: David Rumelhart, Geoffrey Hinton, Ronald Williams&lt;br /&gt;
Backpropagation wasn‚Äôt invented here (it was discovered independently multiple times), but this paper brought it to widespread attention and demonstrated its power for training multi-layer networks. By showing how to efficiently compute gradients through composition of functions via the chain rule, backpropagation made deep learning practical. This paper ended the first AI winter by proving that neural networks could learn complex functions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;http://yann.lecun.com/exdb/publis/pdf/lecun-01a.pdf&quot;&gt;‚ÄúGradient-Based Learning Applied to Document Recognition‚Äù (1998)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Yann LeCun, L√©on Bottou, Yoshua Bengio, Patrick Haffner&lt;br /&gt;
LeNet-5, introduced in this paper, demonstrated that convolutional neural networks could achieve excellent performance on real-world tasks (check reading, digit recognition). More importantly, it established design principles‚Äîlocal connectivity, weight sharing, pooling‚Äîthat remain central to modern computer vision. This paper showed that deep learning could move from toy problems to practical applications.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks&quot;&gt;‚ÄúImageNet Classification with Deep Convolutional Neural Networks‚Äù (2012)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton&lt;br /&gt;
AlexNet‚Äôs crushing victory in the 2012 ImageNet competition (15.3% error vs 26.2% for second place) sparked the modern deep learning revolution. By combining deeper architectures, ReLU activations, dropout regularization, and GPU training, it demonstrated that neural networks could scale to large, complex datasets. This success convinced the broader computer vision community to adopt deep learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1706.03762&quot;&gt;‚ÄúAttention Is All You Need‚Äù (2017)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Ashish Vaswani et al. (Google)&lt;br /&gt;
The Transformer architecture introduced here has become the foundation of modern NLP and increasingly other domains. By replacing recurrence with attention mechanisms, Transformers enable full parallelization during training and better capture long-range dependencies. This paper‚Äôs influence extends far beyond its original machine translation application‚ÄîBERT, GPT, and most recent large language models build on this architecture.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;&lt;a href=&quot;https://arxiv.org/abs/1512.03385&quot;&gt;‚ÄúDeep Residual Learning for Image Recognition‚Äù (2016)&lt;/a&gt;&lt;/strong&gt;&lt;br /&gt;
&lt;em&gt;Authors&lt;/em&gt;: Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun&lt;br /&gt;
ResNet introduced skip connections that enabled training networks hundreds of layers deep by providing direct gradient pathways. Beyond winning ImageNet 2015, this work fundamentally changed how we think about deep architectures‚Äîdepth is crucial, but networks need architectural innovations (skip connections, careful normalization) to train effectively. ResNet‚Äôs principles appear in most modern deep architectures.&lt;/p&gt;

&lt;h2 id=&quot;applications-of-deep-learning&quot;&gt;Applications of Deep Learning&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://upload.wikimedia.org/wikipedia/commons/thumb/1/19/Deep_Learning_Applications.png/800px-Deep_Learning_Applications.png&quot; alt=&quot;Deep Learning Applications&quot; /&gt;
&lt;em&gt;H√¨nh ·∫£nh: C√°c ·ª©ng d·ª•ng c·ªßa Deep Learning trong nhi·ªÅu lƒ©nh v·ª±c. Ngu·ªìn: Wikimedia Commons&lt;/em&gt;&lt;/p&gt;

&lt;h3 id=&quot;computer-vision&quot;&gt;Computer Vision&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Image classification&lt;/li&gt;
  &lt;li&gt;Object detection&lt;/li&gt;
  &lt;li&gt;Semantic segmentation&lt;/li&gt;
  &lt;li&gt;Face recognition&lt;/li&gt;
  &lt;li&gt;Image generation&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;natural-language-processing&quot;&gt;Natural Language Processing&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Machine translation&lt;/li&gt;
  &lt;li&gt;Sentiment analysis&lt;/li&gt;
  &lt;li&gt;Question answering&lt;/li&gt;
  &lt;li&gt;Text generation (GPT models)&lt;/li&gt;
  &lt;li&gt;Language understanding (BERT)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;speech-and-audio&quot;&gt;Speech and Audio&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Speech recognition&lt;/li&gt;
  &lt;li&gt;Text-to-speech synthesis&lt;/li&gt;
  &lt;li&gt;Music generation&lt;/li&gt;
  &lt;li&gt;Voice cloning&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reinforcement-learning&quot;&gt;Reinforcement Learning&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Game playing (Chess, Go, Atari)&lt;/li&gt;
  &lt;li&gt;Robotics control&lt;/li&gt;
  &lt;li&gt;Autonomous driving&lt;/li&gt;
  &lt;li&gt;Resource optimization&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;healthcare&quot;&gt;Healthcare&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Disease diagnosis from images&lt;/li&gt;
  &lt;li&gt;Drug discovery&lt;/li&gt;
  &lt;li&gt;Protein folding (AlphaFold)&lt;/li&gt;
  &lt;li&gt;Personalized medicine&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;other-domains&quot;&gt;Other Domains&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Financial prediction&lt;/li&gt;
  &lt;li&gt;Recommendation systems&lt;/li&gt;
  &lt;li&gt;Climate modeling&lt;/li&gt;
  &lt;li&gt;Scientific discovery&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;challenges-and-limitations&quot;&gt;Challenges and Limitations&lt;/h2&gt;

&lt;h3 id=&quot;current-challenges&quot;&gt;Current Challenges&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Data Requirements&lt;/strong&gt;: Need large labeled datasets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational Cost&lt;/strong&gt;: Training large models is expensive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpretability&lt;/strong&gt;: ‚ÄúBlack box‚Äù nature&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Generalization&lt;/strong&gt;: Overfitting, domain shift&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Robustness&lt;/strong&gt;: Adversarial examples&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Ethics&lt;/strong&gt;: Bias, fairness, privacy concerns&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;active-research-areas&quot;&gt;Active Research Areas&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Efficient Deep Learning&lt;/strong&gt;: Model compression, quantization&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Few-Shot Learning&lt;/strong&gt;: Learning from limited data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Transfer Learning&lt;/strong&gt;: Leveraging pre-trained models&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Explainable AI&lt;/strong&gt;: Understanding model decisions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Continual Learning&lt;/strong&gt;: Learning without forgetting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Multimodal Learning&lt;/strong&gt;: Combining vision, language, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;what-youll-learn-in-this-course&quot;&gt;What You‚Äôll Learn in This Course&lt;/h2&gt;

&lt;h3 id=&quot;part-i-foundations-chapters-00-03&quot;&gt;Part I: Foundations (Chapters 00-03)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Mathematical prerequisites&lt;/li&gt;
  &lt;li&gt;Neural network basics&lt;/li&gt;
  &lt;li&gt;Training techniques (backpropagation, optimization)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;part-ii-core-architectures-chapters-04-08&quot;&gt;Part II: Core Architectures (Chapters 04-08)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;CNNs for computer vision&lt;/li&gt;
  &lt;li&gt;RNNs for sequences&lt;/li&gt;
  &lt;li&gt;Attention and Transformers&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;part-iii-advanced-topics-chapters-09-16&quot;&gt;Part III: Advanced Topics (Chapters 09-16)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Regularization and optimization&lt;/li&gt;
  &lt;li&gt;Generative models (VAE, GANs)&lt;/li&gt;
  &lt;li&gt;Transfer and self-supervised learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;part-iv-applications-chapters-17-25&quot;&gt;Part IV: Applications (Chapters 17-25)&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Computer vision applications&lt;/li&gt;
  &lt;li&gt;Natural language processing&lt;/li&gt;
  &lt;li&gt;Reinforcement learning&lt;/li&gt;
  &lt;li&gt;Specialized topics (GNNs, efficiency, interpretability)&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;prerequisites-for-this-course&quot;&gt;Prerequisites for This Course&lt;/h2&gt;

&lt;h3 id=&quot;required&quot;&gt;Required&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Programming&lt;/strong&gt;: Python basics&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Mathematics&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Linear algebra (vectors, matrices)&lt;/li&gt;
      &lt;li&gt;Calculus (derivatives, chain rule)&lt;/li&gt;
      &lt;li&gt;Probability (distributions, expectation)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Machine Learning&lt;/strong&gt;: Basic understanding helpful&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;recommended&quot;&gt;Recommended&lt;/h3&gt;
&lt;ul&gt;
  &lt;li&gt;Experience with NumPy, basic ML algorithms&lt;/li&gt;
  &lt;li&gt;Familiarity with Python ML libraries&lt;/li&gt;
  &lt;li&gt;Understanding of optimization concepts&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;how-to-succeed-in-deep-learning&quot;&gt;How to Succeed in Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;practical-tips&quot;&gt;Practical Tips&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Implement from Scratch&lt;/strong&gt;: Understand fundamentals&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Work with Frameworks&lt;/strong&gt;: Master PyTorch or TensorFlow&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Read Papers&lt;/strong&gt;: Stay current with research&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Do Projects&lt;/strong&gt;: Apply knowledge to real problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Join Community&lt;/strong&gt;: Participate in discussions, competitions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Iterate and Experiment&lt;/strong&gt;: Learning by doing&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;resources-beyond-this-course&quot;&gt;Resources Beyond This Course&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Papers&lt;/strong&gt;: ArXiv.org, Papers with Code&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Courses&lt;/strong&gt;: Fast.ai, Stanford CS231n/CS224n&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Books&lt;/strong&gt;: Deep Learning (Goodfellow), Dive into Deep Learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Competitions&lt;/strong&gt;: Kaggle, AIcrowd&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Communities&lt;/strong&gt;: Reddit r/MachineLearning, Discord servers&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-deep-learning-mindset&quot;&gt;The Deep Learning Mindset&lt;/h2&gt;

&lt;h3 id=&quot;key-principles&quot;&gt;Key Principles&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Start Simple&lt;/strong&gt;: Begin with basic models, add complexity&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Visualize&lt;/strong&gt;: Plot loss curves, attention maps, features&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Debug Systematically&lt;/strong&gt;: Check data, architecture, training&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Use Baselines&lt;/strong&gt;: Compare against simple models&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Monitor Metrics&lt;/strong&gt;: Track training and validation performance&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Be Patient&lt;/strong&gt;: Training takes time and iteration&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;common-pitfalls-to-avoid&quot;&gt;Common Pitfalls to Avoid&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;Insufficient data preprocessing&lt;/li&gt;
  &lt;li&gt;Poor initialization&lt;/li&gt;
  &lt;li&gt;Wrong learning rate&lt;/li&gt;
  &lt;li&gt;Ignoring validation set&lt;/li&gt;
  &lt;li&gt;Overfitting to training data&lt;/li&gt;
  &lt;li&gt;Not using proper evaluation metrics&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;the-road-ahead&quot;&gt;The Road Ahead&lt;/h2&gt;

&lt;p&gt;Deep learning is a rapidly evolving field. This course provides:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Solid foundations&lt;/strong&gt; in neural networks&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Practical skills&lt;/strong&gt; for implementing models&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Understanding&lt;/strong&gt; of modern architectures&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Preparation&lt;/strong&gt; for advanced research and applications&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;By the end of this course, you‚Äôll be equipped to:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Build and train neural networks from scratch&lt;/li&gt;
  &lt;li&gt;Apply deep learning to real-world problems&lt;/li&gt;
  &lt;li&gt;Read and implement research papers&lt;/li&gt;
  &lt;li&gt;Contribute to the field‚Äôs advancement&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Let‚Äôs begin this exciting journey into deep learning! üöÄ&lt;/p&gt;

&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Deep Learning&lt;/strong&gt;: Neural networks with multiple layers for hierarchical learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Revolution&lt;/strong&gt;: Transformed AI with breakthrough applications&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Core Idea&lt;/strong&gt;: Automatic feature learning from raw data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Key Architectures&lt;/strong&gt;: MLPs, CNNs, RNNs, Transformers&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Vision, NLP, speech, games, healthcare, and more&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Course Goal&lt;/strong&gt;: Master theory and practice of deep learning&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h2&gt;

&lt;p&gt;This introductory lesson establishes the foundational understanding needed for the deep learning journey ahead:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;1. Core Concept&lt;/strong&gt;: Deep learning uses multi-layer neural networks to automatically learn hierarchical representations from data, eliminating the need for manual feature engineering.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;2. Mathematical Foundation&lt;/strong&gt;: Neural networks are universal function approximators that learn through gradient descent and backpropagation, with depth providing exponential efficiency for compositional functions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;3. Practical Power&lt;/strong&gt;: From MNIST digit recognition achieving 97%+ accuracy in minutes to modern systems surpassing human performance on complex tasks, deep learning has transformed AI from research curiosity to practical tool.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;4. Historical Context&lt;/strong&gt;: The field evolved through AI winters and revivals, with key innovations (backpropagation, CNNs, Transformers) building on each other to create today‚Äôs powerful systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;5. Broader Connections&lt;/strong&gt;: Deep learning connects to classical ML, transfer learning, and the interplay of architecture, data, and compute that drives modern progress.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;6. Foundational Papers&lt;/strong&gt;: Understanding the historical development through seminal papers (McCulloch-Pitts neurons, backpropagation, LeNet, AlexNet, Transformers, ResNet) provides context for current practice.&lt;/p&gt;

&lt;h2 id=&quot;whats-next&quot;&gt;What‚Äôs Next?&lt;/h2&gt;

&lt;p&gt;In the next chapter, we‚Äôll dive into &lt;strong&gt;Neural Networks Fundamentals&lt;/strong&gt; and understand how artificial neurons work together to learn from data. You‚Äôll learn:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The mathematical model of artificial neurons (perceptrons)&lt;/li&gt;
  &lt;li&gt;How neurons combine into networks through layers&lt;/li&gt;
  &lt;li&gt;Activation functions and their role in enabling nonlinear learning&lt;/li&gt;
  &lt;li&gt;Forward propagation: how networks make predictions&lt;/li&gt;
  &lt;li&gt;The architecture choices that define different network types&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Armed with the conceptual understanding from this introduction and the detailed mechanics from the next chapter, you‚Äôll be ready to understand training algorithms, implement your own networks, and appreciate the sophisticated architectures that power modern AI systems.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Remember&lt;/strong&gt;: Deep learning is fundamentally about letting data reveal its own structure rather than imposing our assumptions. This paradigm shift‚Äîfrom hand-crafted features to learned representations‚Äîis what makes deep learning both powerful and philosophically different from traditional approaches. As you progress through this course, you‚Äôll see this principle manifest in countless ways across different domains and architectures.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00 Introduction</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_Introduction/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_Introduction</id>
   <content type="html">&lt;p&gt;Deep Learning is at the heart of data science. Whether you‚Äôre training a neural network, minimizing errors in regression models, or efficiently allocating resources in recommendation systems, you‚Äôre essentially solving problems that involve finding the ‚Äúbest‚Äù solution from a vast set of possibilities. But to do this effectively, you need to speak the language of mathematics. We‚Äôll revisit key ideas from linear algebra, set theory, and calculus, ensuring you‚Äôre equipped to handle gradients, matrices, constraints, and uncertainties that arise in deep-learning tasks.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04 Probability and Statistics</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_Probability_and_Statistics/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_04_Probability_and_Statistics</id>
   <content type="html">&lt;h2 id=&quot;probability-and-statistics-for-deep-learning&quot;&gt;Probability and Statistics for Deep Learning&lt;/h2&gt;

&lt;p&gt;Probability and statistics form a crucial foundation for understanding many deep-learning problems, especially in machine learning and data science. This section introduces the essential probabilistic concepts that frequently appear in convex deep-learning, from maximum likelihood estimation to Bayesian deep-learning.&lt;/p&gt;

&lt;h3 id=&quot;why-probability-matters-in-deep-learning&quot;&gt;Why Probability Matters in Deep Learning&lt;/h3&gt;

&lt;p&gt;Many deep-learning problems arise from statistical modeling:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Maximum Likelihood Estimation (MLE)&lt;/strong&gt;: Finding parameters that maximize the likelihood of observed data&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bayesian Deep Learning&lt;/strong&gt;: Using probabilistic models to guide the search for optimal solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Stochastic Deep Learning&lt;/strong&gt;: Dealing with uncertainty and randomness in objective functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Adding probabilistic priors to prevent overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Risk Minimization&lt;/strong&gt;: Optimizing expected loss over probability distributions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;key-topics-covered&quot;&gt;Key Topics Covered&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Basic Probability Theory&lt;/strong&gt;: Sample spaces, events, and probability axioms&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Common Probability Distributions&lt;/strong&gt;: Normal, exponential, and other distributions crucial for deep-learning&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Expectation and Variance&lt;/strong&gt;: Computing and optimizing expected values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bayes‚Äô Theorem&lt;/strong&gt;: Foundation for Bayesian deep-learning and inference&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Statistical Estimation&lt;/strong&gt;: Connecting probability theory to deep-learning problems&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;connection-to-deep-learning&quot;&gt;Connection to Deep Learning&lt;/h3&gt;

&lt;p&gt;Understanding probability helps you:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Formulate Problems&lt;/strong&gt;: Convert real-world uncertainty into mathematical deep-learning problems&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Choose Objective Functions&lt;/strong&gt;: Select appropriate loss functions based on probabilistic assumptions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interpret Results&lt;/strong&gt;: Understand confidence intervals and statistical significance of solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Handle Noise&lt;/strong&gt;: Deal with measurement errors and stochastic processes&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Design Algorithms&lt;/strong&gt;: Develop robust deep-learning methods that work under uncertainty&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This foundation will be essential as we explore how probabilistic models lead to convex deep-learning problems in machine learning, statistics, and engineering applications.&lt;/p&gt;

&lt;div style=&quot;background: #e8f4fd; padding: 15px; border-left: 4px solid #2196F3; margin: 20px 0;&quot;&gt;
&lt;strong&gt;üí° Learning Path:&lt;/strong&gt; Start with basic probability concepts, then explore how they connect to deep-learning through maximum likelihood estimation and Bayesian methods. Each lesson builds toward understanding how uncertainty and randomness create deep-learning problems.
&lt;/div&gt;
</content>
 </entry>
 
 <entry>
   <title>00-04-02 Common Probability Distributions</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_02_Common_Probability_Distributions/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_04_02_Common_Probability_Distributions</id>
   <content type="html">&lt;h2 id=&quot;common-probability-distributions&quot;&gt;Common Probability Distributions&lt;/h2&gt;

&lt;p&gt;Understanding key probability distributions is essential for deep-learning problems in machine learning and statistics. These distributions frequently appear as assumptions in models, priors in Bayesian methods, and error models in regression.&lt;/p&gt;

&lt;h3 id=&quot;1-discrete-distributions&quot;&gt;1. Discrete Distributions&lt;/h3&gt;

&lt;h4 id=&quot;bernoulli-distribution&quot;&gt;Bernoulli Distribution&lt;/h4&gt;

&lt;p&gt;Models a single trial with two outcomes (success/failure).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(p \in [0,1]\) (probability of success)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = p^k (1-p)^{1-k}\) for \(k \in \{0,1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = p\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = p(1-p)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Binary classification, coin flips, A/B testing&lt;/p&gt;

&lt;h4 id=&quot;binomial-distribution&quot;&gt;Binomial Distribution&lt;/h4&gt;

&lt;p&gt;Models the number of successes in \(n\) independent Bernoulli trials.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(n \in \mathbb{N}\) (trials), \(p \in [0,1]\) (success probability)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\) for \(k = 0,1,\ldots,n\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = np\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = np(1-p)\)&lt;/p&gt;

&lt;h4 id=&quot;poisson-distribution&quot;&gt;Poisson Distribution&lt;/h4&gt;

&lt;p&gt;Models the number of events in a fixed interval when events occur independently at a constant rate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (rate parameter)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PMF&lt;/strong&gt;: \(P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}\) for \(k = 0,1,2,\ldots\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \lambda\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Count data, rare events, queueing theory&lt;/p&gt;

&lt;div id=&quot;discrete-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Discrete Distributions&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;discreteCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Probability mass functions of discrete distributions.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Distribution Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;bernoulli&quot; checked=&quot;&quot; /&gt; Bernoulli
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;binomial&quot; /&gt; Binomial
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;discrete-dist&quot; value=&quot;poisson&quot; /&gt; Poisson
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-params&quot;&gt;
                    &lt;div id=&quot;p-param&quot; style=&quot;margin-bottom: 15px;&quot;&gt;
                        &lt;label for=&quot;p-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;p: &lt;span id=&quot;p-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;p-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;n-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;n-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;n: &lt;span id=&quot;n-value&quot;&gt;10&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;n-slider&quot; min=&quot;5&quot; max=&quot;50&quot; step=&quot;1&quot; value=&quot;10&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;lambda-param&quot; style=&quot;margin-bottom: 15px; display: none;&quot;&gt;
                        &lt;label for=&quot;lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œª: &lt;span id=&quot;lambda-value&quot;&gt;3.0&lt;/span&gt;&lt;/label&gt;
                        &lt;input type=&quot;range&quot; id=&quot;lambda-slider&quot; min=&quot;0.5&quot; max=&quot;10&quot; step=&quot;0.5&quot; value=&quot;3.0&quot; style=&quot;width: 100%;&quot; /&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;discrete-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Mean: &lt;span id=&quot;discrete-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Variance: &lt;span id=&quot;discrete-variance&quot;&gt;0.250&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Mode: &lt;span id=&quot;discrete-mode&quot;&gt;0 or 1&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-continuous-distributions&quot;&gt;2. Continuous Distributions&lt;/h3&gt;

&lt;h4 id=&quot;uniform-distribution&quot;&gt;Uniform Distribution&lt;/h4&gt;

&lt;p&gt;All values in an interval are equally likely.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(a, b \in \mathbb{R}\) with \(a &amp;lt; b\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{b-a}\) for \(x \in [a,b]\), 0 otherwise&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{a+b}{2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{(b-a)^2}{12}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Applications&lt;/strong&gt;: Random sampling, initialization in algorithms&lt;/p&gt;

&lt;h4 id=&quot;normal-gaussian-distribution&quot;&gt;Normal (Gaussian) Distribution&lt;/h4&gt;

&lt;p&gt;The most important distribution in statistics and deep-learning.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\mu \in \mathbb{R}\) (mean), \(\sigma^2 &amp;gt; 0\) (variance)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(x-\mu)^2}{2\sigma^2}\right)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \mu\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \sigma^2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Symmetric around \(\mu\)&lt;/li&gt;
  &lt;li&gt;68-95-99.7 rule&lt;/li&gt;
  &lt;li&gt;Central Limit Theorem&lt;/li&gt;
  &lt;li&gt;Maximum entropy for given mean and variance&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;exponential-distribution&quot;&gt;Exponential Distribution&lt;/h4&gt;

&lt;p&gt;Models waiting times between events in a Poisson process.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\lambda &amp;gt; 0\) (rate parameter)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \lambda e^{-\lambda x}\) for \(x \geq 0\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{1}{\lambda}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{1}{\lambda^2}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;: Memoryless property&lt;/p&gt;

&lt;h4 id=&quot;beta-distribution&quot;&gt;Beta Distribution&lt;/h4&gt;

&lt;p&gt;Flexible distribution on \([0,1]\), often used for modeling probabilities.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\alpha, \beta &amp;gt; 0\) (shape parameters)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;PDF&lt;/strong&gt;: \(f(x) = \frac{\Gamma(\alpha+\beta)}{\Gamma(\alpha)\Gamma(\beta)} x^{\alpha-1}(1-x)^{\beta-1}\) for \(x \in [0,1]\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Mean&lt;/strong&gt;: \(\mathbb{E}[X] = \frac{\alpha}{\alpha+\beta}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Variance&lt;/strong&gt;: \(\text{Var}(X) = \frac{\alpha\beta}{(\alpha+\beta)^2(\alpha+\beta+1)}\)&lt;/p&gt;

&lt;div id=&quot;continuous-distributions-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Continuous Distributions&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;continuousCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Probability density functions of continuous distributions.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Distribution Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;uniform&quot; checked=&quot;&quot; /&gt; Uniform
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;normal&quot; /&gt; Normal
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;exponential&quot; /&gt; Exponential
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;continuous-dist&quot; value=&quot;beta&quot; /&gt; Beta
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-params&quot;&gt;
                    &lt;div id=&quot;uniform-params&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;a: &lt;span id=&quot;a-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;a-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;b: &lt;span id=&quot;b-value&quot;&gt;1&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;b-slider&quot; min=&quot;0.5&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;1&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;normal-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº: &lt;span id=&quot;mu-value&quot;&gt;0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;mu-slider&quot; min=&quot;-3&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;sigma-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ: &lt;span id=&quot;sigma-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;sigma-slider&quot; min=&quot;0.5&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;exponential-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;exp-lambda-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œª: &lt;span id=&quot;exp-lambda-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;exp-lambda-slider&quot; min=&quot;0.2&quot; max=&quot;3&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                    
                    &lt;div id=&quot;beta-params&quot; style=&quot;display: none;&quot;&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;alpha-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œ±: &lt;span id=&quot;alpha-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;alpha-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                        &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                            &lt;label for=&quot;beta-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œ≤: &lt;span id=&quot;beta-value&quot;&gt;2&lt;/span&gt;&lt;/label&gt;
                            &lt;input type=&quot;range&quot; id=&quot;beta-slider&quot; min=&quot;0.5&quot; max=&quot;5&quot; step=&quot;0.1&quot; value=&quot;2&quot; style=&quot;width: 100%;&quot; /&gt;
                        &lt;/div&gt;
                    &lt;/div&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;continuous-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Mean: &lt;span id=&quot;continuous-mean&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Variance: &lt;span id=&quot;continuous-variance&quot;&gt;0.083&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Support: &lt;span id=&quot;continuous-support&quot;&gt;[0, 1]&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;3-multivariate-distributions&quot;&gt;3. Multivariate Distributions&lt;/h3&gt;

&lt;h4 id=&quot;multivariate-normal-distribution&quot;&gt;Multivariate Normal Distribution&lt;/h4&gt;

&lt;p&gt;Extension of the normal distribution to multiple dimensions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Parameters&lt;/strong&gt;: \(\boldsymbol{\mu} \in \mathbb{R}^d\) (mean vector), \(\boldsymbol{\Sigma} \in \mathbb{R}^{d \times d}\) (covariance matrix, positive definite)&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;&lt;strong&gt;PDF&lt;/strong&gt;: $$f(\mathbf{x}) = \frac{1}{(2\pi)^{d/2}&lt;/td&gt;
      &lt;td&gt;\boldsymbol{\Sigma}&lt;/td&gt;
      &lt;td&gt;^{1/2}} \exp\left(-\frac{1}{2}(\mathbf{x}-\boldsymbol{\mu})^T\boldsymbol{\Sigma}^{-1}(\mathbf{x}-\boldsymbol{\mu})\right)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;strong&gt;Properties&lt;/strong&gt;:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Marginal distributions are normal&lt;/li&gt;
  &lt;li&gt;Linear combinations are normal&lt;/li&gt;
  &lt;li&gt;Conditional distributions are normal&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;multivariate-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Multivariate Normal Distribution&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;multivariateCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;2D Visualization:&lt;/strong&gt; Contour plot of bivariate normal distribution. Samples shown as dots.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Parameters&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº‚ÇÅ: &lt;span id=&quot;mu1-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu1-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;mu2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Œº‚ÇÇ: &lt;span id=&quot;mu2-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;mu2-slider&quot; min=&quot;-2&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma1-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ‚ÇÅ: &lt;span id=&quot;sigma1-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma1-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sigma2-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÉ‚ÇÇ: &lt;span id=&quot;sigma2-value&quot;&gt;1.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sigma2-slider&quot; min=&quot;0.5&quot; max=&quot;2&quot; step=&quot;0.1&quot; value=&quot;1.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;rho-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;œÅ (correlation): &lt;span id=&quot;rho-value&quot;&gt;0.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;rho-slider&quot; min=&quot;-0.9&quot; max=&quot;0.9&quot; step=&quot;0.1&quot; value=&quot;0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-samples&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Generate Samples&lt;/button&gt;
                
                &lt;div id=&quot;multivariate-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Covariance Matrix:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÅ‚ÇÅ: &lt;span id=&quot;cov11&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÅ‚ÇÇ: &lt;span id=&quot;cov12&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Œ£‚ÇÇ‚ÇÇ: &lt;span id=&quot;cov22&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Det(Œ£): &lt;span id=&quot;det-cov&quot;&gt;1.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;4-applications-in-deep-learning&quot;&gt;4. Applications in Deep Learning&lt;/h3&gt;

&lt;h4 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum Likelihood Estimation&lt;/h4&gt;
&lt;p&gt;Many deep-learning problems involve finding parameters that maximize the likelihood of observed data under a specific distribution:&lt;/p&gt;

\[\hat{\theta} = \arg\max_\theta \prod_{i=1}^n f(x_i; \theta)\]

&lt;h4 id=&quot;bayesian-deep-learning&quot;&gt;Bayesian Deep Learning&lt;/h4&gt;
&lt;p&gt;Prior distributions encode beliefs about parameters before seeing data:&lt;/p&gt;

\[p(\theta|data) \propto p(data|\theta) \cdot p(\theta)\]

&lt;h4 id=&quot;regularization&quot;&gt;Regularization&lt;/h4&gt;
&lt;p&gt;Distributions can be used as priors to regularize deep-learning problems:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;L2 regularization ‚Üî Gaussian prior&lt;/li&gt;
  &lt;li&gt;L1 regularization ‚Üî Laplace prior&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&quot;stochastic-deep-learning&quot;&gt;Stochastic Deep Learning&lt;/h4&gt;
&lt;p&gt;Distributions model noise and uncertainty in objective functions and constraints.&lt;/p&gt;

&lt;h3 id=&quot;key-insights-for-deep-learning&quot;&gt;Key Insights for Deep Learning&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Model Selection&lt;/strong&gt;: Choose distributions that match your data‚Äôs characteristics&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parameter Estimation&lt;/strong&gt;: Use MLE or Bayesian methods to estimate distribution parameters&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Uncertainty Quantification&lt;/strong&gt;: Distributions provide natural ways to quantify uncertainty&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Regularization&lt;/strong&gt;: Prior distributions can prevent overfitting&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational Efficiency&lt;/strong&gt;: Some distributions have closed-form solutions for common operations&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding these distributions and their properties is crucial for formulating and solving deep-learning problems in machine learning, statistics, and engineering applications.&lt;/p&gt;

&lt;script&gt;
// Discrete Distributions Demo
class DiscreteDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;discreteCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;bernoulli&apos;;
        this.params = { p: 0.5, n: 10, lambda: 3.0 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;discrete-dist&quot;]&apos;);
        const pSlider = document.getElementById(&apos;p-slider&apos;);
        const nSlider = document.getElementById(&apos;n-slider&apos;);
        const lambdaSlider = document.getElementById(&apos;lambda-slider&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        pSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.p = parseFloat(e.target.value);
            document.getElementById(&apos;p-value&apos;).textContent = this.params.p.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        nSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.n = parseInt(e.target.value);
            document.getElementById(&apos;n-value&apos;).textContent = this.params.n;
            this.updateStats();
            this.draw();
        });
        
        lambdaSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.params.lambda = parseFloat(e.target.value);
            document.getElementById(&apos;lambda-value&apos;).textContent = this.params.lambda.toFixed(1);
            this.updateStats();
            this.draw();
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;p-param&apos;).style.display = 
            (this.distType === &apos;bernoulli&apos; || this.distType === &apos;binomial&apos;) ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;n-param&apos;).style.display = 
            this.distType === &apos;binomial&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;lambda-param&apos;).style.display = 
            this.distType === &apos;poisson&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, mode;
        
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                mean = this.params.p;
                variance = this.params.p * (1 - this.params.p);
                mode = this.params.p &gt; 0.5 ? &apos;1&apos; : (this.params.p &lt; 0.5 ? &apos;0&apos; : &apos;0 or 1&apos;);
                break;
            case &apos;binomial&apos;:
                mean = this.params.n * this.params.p;
                variance = this.params.n * this.params.p * (1 - this.params.p);
                mode = Math.floor((this.params.n + 1) * this.params.p).toString();
                break;
            case &apos;poisson&apos;:
                mean = this.params.lambda;
                variance = this.params.lambda;
                mode = Math.floor(this.params.lambda).toString();
                break;
        }
        
        document.getElementById(&apos;discrete-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;discrete-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;discrete-mode&apos;).textContent = mode;
    }
    
    factorial(n) {
        if (n &lt;= 1) return 1;
        return n * this.factorial(n - 1);
    }
    
    binomialCoeff(n, k) {
        if (k &gt; n) return 0;
        return this.factorial(n) / (this.factorial(k) * this.factorial(n - k));
    }
    
    getProbability(k) {
        switch(this.distType) {
            case &apos;bernoulli&apos;:
                return k === 0 ? (1 - this.params.p) : (k === 1 ? this.params.p : 0);
            case &apos;binomial&apos;:
                if (k &lt; 0 || k &gt; this.params.n) return 0;
                return this.binomialCoeff(this.params.n, k) * 
                       Math.pow(this.params.p, k) * 
                       Math.pow(1 - this.params.p, this.params.n - k);
            case &apos;poisson&apos;:
                if (k &lt; 0) return 0;
                return Math.pow(this.params.lambda, k) * Math.exp(-this.params.lambda) / this.factorial(k);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Determine range
        let maxK;
        switch(this.distType) {
            case &apos;bernoulli&apos;: maxK = 1; break;
            case &apos;binomial&apos;: maxK = this.params.n; break;
            case &apos;poisson&apos;: maxK = Math.min(20, this.params.lambda + 3 * Math.sqrt(this.params.lambda)); break;
        }
        
        // Find max probability for scaling
        let maxProb = 0;
        for (let k = 0; k &lt;= maxK; k++) {
            maxProb = Math.max(maxProb, this.getProbability(k));
        }
        
        // Draw bars
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        const barWidth = plotWidth / (maxK + 2);
        
        for (let k = 0; k &lt;= maxK; k++) {
            const prob = this.getProbability(k);
            const x = marginX + (k + 0.5) * barWidth;
            const height = (prob / maxProb) * plotHeight * 0.8;
            const y = this.height - marginY - height;
            
            this.ctx.fillRect(x - barWidth * 0.3, y, barWidth * 0.6, height);
            
            // Label
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(k.toString(), x, this.height - marginY + 15);
            this.ctx.fillText(prob.toFixed(3), x, y - 5);
            this.ctx.fillStyle = &apos;#2196f3&apos;;
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;k&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;P(X = k)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Continuous Distributions Demo
class ContinuousDistributionsDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;continuousCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.distType = &apos;uniform&apos;;
        this.params = { a: 0, b: 1, mu: 0, sigma: 1, lambda: 1, alpha: 2, beta: 2 };
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;continuous-dist&quot;]&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.distType = e.target.value;
                this.updateParameterVisibility();
                this.updateStats();
                this.draw();
            });
        });
        
        // Setup all sliders
        const sliders = [&apos;a&apos;, &apos;b&apos;, &apos;mu&apos;, &apos;sigma&apos;, &apos;exp-lambda&apos;, &apos;alpha&apos;, &apos;beta&apos;];
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            if (element) {
                element.addEventListener(&apos;input&apos;, (e) =&gt; {
                    const value = parseFloat(e.target.value);
                    const param = slider === &apos;exp-lambda&apos; ? &apos;lambda&apos; : slider;
                    this.params[param] = value;
                    
                    const valueSpan = document.getElementById(slider + &apos;-value&apos;);
                    if (valueSpan) {
                        valueSpan.textContent = value.toFixed(1);
                    }
                    
                    this.updateStats();
                    this.draw();
                });
            }
        });
        
        this.updateParameterVisibility();
        this.updateStats();
    }
    
    updateParameterVisibility() {
        document.getElementById(&apos;uniform-params&apos;).style.display = 
            this.distType === &apos;uniform&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;normal-params&apos;).style.display = 
            this.distType === &apos;normal&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;exponential-params&apos;).style.display = 
            this.distType === &apos;exponential&apos; ? &apos;block&apos; : &apos;none&apos;;
        document.getElementById(&apos;beta-params&apos;).style.display = 
            this.distType === &apos;beta&apos; ? &apos;block&apos; : &apos;none&apos;;
    }
    
    updateStats() {
        let mean, variance, support;
        
        switch(this.distType) {
            case &apos;uniform&apos;:
                mean = (this.params.a + this.params.b) / 2;
                variance = Math.pow(this.params.b - this.params.a, 2) / 12;
                support = `[${this.params.a}, ${this.params.b}]`;
                break;
            case &apos;normal&apos;:
                mean = this.params.mu;
                variance = this.params.sigma * this.params.sigma;
                support = &apos;(-‚àû, ‚àû)&apos;;
                break;
            case &apos;exponential&apos;:
                mean = 1 / this.params.lambda;
                variance = 1 / (this.params.lambda * this.params.lambda);
                support = &apos;[0, ‚àû)&apos;;
                break;
            case &apos;beta&apos;:
                mean = this.params.alpha / (this.params.alpha + this.params.beta);
                variance = (this.params.alpha * this.params.beta) / 
                          (Math.pow(this.params.alpha + this.params.beta, 2) * 
                           (this.params.alpha + this.params.beta + 1));
                support = &apos;[0, 1]&apos;;
                break;
        }
        
        document.getElementById(&apos;continuous-mean&apos;).textContent = mean.toFixed(3);
        document.getElementById(&apos;continuous-variance&apos;).textContent = variance.toFixed(3);
        document.getElementById(&apos;continuous-support&apos;).textContent = support;
    }
    
    gamma(z) {
        // Stirling&apos;s approximation for gamma function
        if (z &lt; 0.5) return Math.PI / (Math.sin(Math.PI * z) * this.gamma(1 - z));
        z -= 1;
        let x = 0.99999999999980993;
        const p = [676.5203681218851, -1259.1392167224028, 771.32342877765313,
                  -176.61502916214059, 12.507343278686905, -0.13857109526572012,
                  9.9843695780195716e-6, 1.5056327351493116e-7];
        for (let i = 0; i &lt; p.length; i++) {
            x += p[i] / (z + i + 1);
        }
        const t = z + p.length - 0.5;
        return Math.sqrt(2 * Math.PI) * Math.pow(t, z + 0.5) * Math.exp(-t) * x;
    }
    
    getPDF(x) {
        switch(this.distType) {
            case &apos;uniform&apos;:
                return (x &gt;= this.params.a &amp;&amp; x &lt;= this.params.b) ? 
                       1 / (this.params.b - this.params.a) : 0;
            case &apos;normal&apos;:
                return Math.exp(-0.5 * Math.pow((x - this.params.mu) / this.params.sigma, 2)) / 
                       (this.params.sigma * Math.sqrt(2 * Math.PI));
            case &apos;exponential&apos;:
                return x &gt;= 0 ? this.params.lambda * Math.exp(-this.params.lambda * x) : 0;
            case &apos;beta&apos;:
                if (x &lt; 0 || x &gt; 1) return 0;
                const B = this.gamma(this.params.alpha) * this.gamma(this.params.beta) / 
                         this.gamma(this.params.alpha + this.params.beta);
                return Math.pow(x, this.params.alpha - 1) * Math.pow(1 - x, this.params.beta - 1) / B;
        }
    }
    
    getRange() {
        switch(this.distType) {
            case &apos;uniform&apos;: return [this.params.a - 0.5, this.params.b + 0.5];
            case &apos;normal&apos;: return [this.params.mu - 4 * this.params.sigma, this.params.mu + 4 * this.params.sigma];
            case &apos;exponential&apos;: return [0, 5 / this.params.lambda];
            case &apos;beta&apos;: return [0, 1];
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        const [minX, maxX] = this.getRange();
        
        // Find max PDF for scaling
        let maxPDF = 0;
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            maxPDF = Math.max(maxPDF, this.getPDF(x));
        }
        
        // Draw PDF curve
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 200; i++) {
            const x = minX + (maxX - minX) * i / 200;
            const pdf = this.getPDF(x);
            const plotX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            const plotY = this.height - marginY - (pdf / maxPDF) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(plotX, plotY);
            } else {
                this.ctx.lineTo(plotX, plotY);
            }
        }
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;x&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;f(x)&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Multivariate Normal Demo
class MultivariateDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;multivariateCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.params = { mu1: 0, mu2: 0, sigma1: 1, sigma2: 1, rho: 0 };
        this.samples = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const sliders = [&apos;mu1&apos;, &apos;mu2&apos;, &apos;sigma1&apos;, &apos;sigma2&apos;, &apos;rho&apos;];
        
        sliders.forEach(slider =&gt; {
            const element = document.getElementById(slider + &apos;-slider&apos;);
            element.addEventListener(&apos;input&apos;, (e) =&gt; {
                this.params[slider] = parseFloat(e.target.value);
                document.getElementById(slider + &apos;-value&apos;).textContent = this.params[slider].toFixed(1);
                this.updateStats();
                this.draw();
            });
        });
        
        document.getElementById(&apos;generate-samples&apos;).addEventListener(&apos;click&apos;, () =&gt; {
            this.generateSamples();
            this.draw();
        });
        
        this.updateStats();
    }
    
    updateStats() {
        const cov11 = this.params.sigma1 * this.params.sigma1;
        const cov12 = this.params.rho * this.params.sigma1 * this.params.sigma2;
        const cov22 = this.params.sigma2 * this.params.sigma2;
        const det = cov11 * cov22 - cov12 * cov12;
        
        document.getElementById(&apos;cov11&apos;).textContent = cov11.toFixed(3);
        document.getElementById(&apos;cov12&apos;).textContent = cov12.toFixed(3);
        document.getElementById(&apos;cov22&apos;).textContent = cov22.toFixed(3);
        document.getElementById(&apos;det-cov&apos;).textContent = det.toFixed(3);
    }
    
    generateSamples() {
        this.samples = [];
        const n = 100;
        
        for (let i = 0; i &lt; n; i++) {
            // Box-Muller transform
            const u1 = Math.random();
            const u2 = Math.random();
            const z1 = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            const z2 = Math.sqrt(-2 * Math.log(u1)) * Math.sin(2 * Math.PI * u2);
            
            // Transform to correlated normal
            const x1 = this.params.mu1 + this.params.sigma1 * z1;
            const x2 = this.params.mu2 + this.params.sigma2 * (this.params.rho * z1 + Math.sqrt(1 - this.params.rho * this.params.rho) * z2);
            
            this.samples.push([x1, x2]);
        }
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Draw contour ellipses
        const levels = [0.5, 1, 1.5, 2];
        const colors = [&apos;#ff9999&apos;, &apos;#ff6666&apos;, &apos;#ff3333&apos;, &apos;#ff0000&apos;];
        
        levels.forEach((level, idx) =&gt; {
            this.ctx.strokeStyle = colors[idx];
            this.ctx.lineWidth = 1;
            this.ctx.beginPath();
            
            const a = level * this.params.sigma1;
            const b = level * this.params.sigma2;
            const angle = 0.5 * Math.atan2(2 * this.params.rho * this.params.sigma1 * this.params.sigma2,
                                          this.params.sigma1 * this.params.sigma1 - this.params.sigma2 * this.params.sigma2);
            
            for (let i = 0; i &lt;= 100; i++) {
                const t = 2 * Math.PI * i / 100;
                const x = a * Math.cos(t) * Math.cos(angle) - b * Math.sin(t) * Math.sin(angle) + this.params.mu1;
                const y = a * Math.cos(t) * Math.sin(angle) + b * Math.sin(t) * Math.cos(angle) + this.params.mu2;
                
                const plotX = marginX + (x + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (y + 4) / 8 * plotHeight;
                
                if (i === 0) {
                    this.ctx.moveTo(plotX, plotY);
                } else {
                    this.ctx.lineTo(plotX, plotY);
                }
            }
            this.ctx.stroke();
        });
        
        // Draw samples
        if (this.samples.length &gt; 0) {
            this.ctx.fillStyle = &apos;#2196f3&apos;;
            this.samples.forEach(([x1, x2]) =&gt; {
                const plotX = marginX + (x1 + 4) / 8 * plotWidth;
                const plotY = this.height - marginY - (x2 + 4) / 8 * plotHeight;
                
                if (plotX &gt;= marginX &amp;&amp; plotX &lt;= this.width - marginX &amp;&amp;
                    plotY &gt;= marginY &amp;&amp; plotY &lt;= this.height - marginY) {
                    this.ctx.beginPath();
                    this.ctx.arc(plotX, plotY, 2, 0, 2 * Math.PI);
                    this.ctx.fill();
                }
            });
        }
        
        // Draw mean point
        const meanX = marginX + (this.params.mu1 + 4) / 8 * plotWidth;
        const meanY = this.height - marginY - (this.params.mu2 + 4) / 8 * plotHeight;
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.beginPath();
        this.ctx.arc(meanX, meanY, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;X‚ÇÅ&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;X‚ÇÇ&apos;, 0, 0);
        this.ctx.restore();
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new DiscreteDistributionsDemo();
    new ContinuousDistributionsDemo();
    new MultivariateDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-04-01 Basic Probability Theory</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_04_01_Basic_Probability_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_04_01_Basic_Probability_Theory</id>
   <content type="html">&lt;h2 id=&quot;basic-probability-theory&quot;&gt;Basic Probability Theory&lt;/h2&gt;

&lt;p&gt;Probability theory provides the mathematical framework for reasoning about uncertainty, which is fundamental to many deep-learning problems in machine learning and data science.&lt;/p&gt;

&lt;h3 id=&quot;1-sample-space-and-events&quot;&gt;1. Sample Space and Events&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Sample Space (Œ©)&lt;/strong&gt;: The set of all possible outcomes of an experiment.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Event (A)&lt;/strong&gt;: A subset of the sample space representing a collection of outcomes.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Coin flip: Œ© = {H, T}&lt;/li&gt;
  &lt;li&gt;Die roll: Œ© = {1, 2, 3, 4, 5, 6}&lt;/li&gt;
  &lt;li&gt;Continuous: Œ© = [0, 1] for uniform random variable&lt;/li&gt;
&lt;/ul&gt;

&lt;div id=&quot;sample-space-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Interactive Sample Space Visualization&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;sampleSpaceCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Visualization:&lt;/strong&gt; Click to generate random samples. Different colors represent different events.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Experiment Type&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;coin&quot; checked=&quot;&quot; /&gt; Coin Flip
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;dice&quot; /&gt; Dice Roll
                    &lt;/label&gt;
                    &lt;label style=&quot;display: block; margin-bottom: 10px;&quot;&gt;
                        &lt;input type=&quot;radio&quot; name=&quot;experiment&quot; value=&quot;uniform&quot; /&gt; Uniform [0,1]
                    &lt;/label&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-sample&quot; style=&quot;width: 100%; padding: 10px; background: #007bff; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 10px;&quot;&gt;Generate Sample&lt;/button&gt;
                &lt;button id=&quot;clear-samples&quot; style=&quot;width: 100%; padding: 8px; background: #6c757d; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Clear&lt;/button&gt;
                
                &lt;div id=&quot;sample-stats&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Statistics:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;Total samples: &lt;span id=&quot;total-samples&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Event A: &lt;span id=&quot;event-a-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Event B: &lt;span id=&quot;event-b-count&quot;&gt;0&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) ‚âà &lt;span id=&quot;prob-a&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) ‚âà &lt;span id=&quot;prob-b&quot;&gt;0.000&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;2-probability-axioms-kolmogorov-axioms&quot;&gt;2. Probability Axioms (Kolmogorov Axioms)&lt;/h3&gt;

&lt;p&gt;For any probability measure P, the following axioms must hold:&lt;/p&gt;

&lt;h4 id=&quot;axiom-1-non-negativity&quot;&gt;Axiom 1: Non-negativity&lt;/h4&gt;
&lt;p&gt;\(P(A) \geq 0 \text{ for all events } A\)&lt;/p&gt;

&lt;h4 id=&quot;axiom-2-normalization&quot;&gt;Axiom 2: Normalization&lt;/h4&gt;
&lt;p&gt;\(P(\Omega) = 1\)&lt;/p&gt;

&lt;h4 id=&quot;axiom-3-countable-additivity&quot;&gt;Axiom 3: Countable Additivity&lt;/h4&gt;
&lt;p&gt;For mutually exclusive events \(A_1, A_2, \ldots\):
\(P\left(\bigcup_{i=1}^{\infty} A_i\right) = \sum_{i=1}^{\infty} P(A_i)\)&lt;/p&gt;

&lt;h3 id=&quot;3-basic-properties-and-rules&quot;&gt;3. Basic Properties and Rules&lt;/h3&gt;

&lt;h4 id=&quot;complement-rule&quot;&gt;Complement Rule&lt;/h4&gt;
&lt;p&gt;\(P(A^c) = 1 - P(A)\)&lt;/p&gt;

&lt;h4 id=&quot;addition-rule&quot;&gt;Addition Rule&lt;/h4&gt;
&lt;p&gt;For any two events A and B:
\(P(A \cup B) = P(A) + P(B) - P(A \cap B)\)&lt;/p&gt;

&lt;h4 id=&quot;multiplication-rule&quot;&gt;Multiplication Rule&lt;/h4&gt;
&lt;p&gt;\(P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)\)&lt;/p&gt;

&lt;h3 id=&quot;4-conditional-probability&quot;&gt;4. Conditional Probability&lt;/h3&gt;

&lt;p&gt;The probability of event A given that event B has occurred:&lt;/p&gt;

\[P(A|B) = \frac{P(A \cap B)}{P(B)}, \quad P(B) &amp;gt; 0\]

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Conditional probability updates our belief about A when we have information about B.&lt;/p&gt;

&lt;div id=&quot;conditional-prob-demo&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f9f9f9;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Conditional Probability Visualization&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;conditionalCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;Venn Diagram:&lt;/strong&gt; Blue circle is event A, red circle is event B. Purple intersection shows A ‚à© B.
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;Adjust Probabilities&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-a-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(A): &lt;span id=&quot;prob-a-value&quot;&gt;0.4&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-a-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.4&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;prob-b-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;P(B): &lt;span id=&quot;prob-b-value&quot;&gt;0.5&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;prob-b-slider&quot; min=&quot;0.1&quot; max=&quot;0.9&quot; step=&quot;0.05&quot; value=&quot;0.5&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;overlap-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Overlap: &lt;span id=&quot;overlap-value&quot;&gt;0.2&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;overlap-slider&quot; min=&quot;0&quot; max=&quot;0.4&quot; step=&quot;0.05&quot; value=&quot;0.2&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div id=&quot;conditional-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Probabilities:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A) = &lt;span id=&quot;display-prob-a&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B) = &lt;span id=&quot;display-prob-b&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ‚à© B) = &lt;span id=&quot;display-prob-ab&quot;&gt;0.200&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(A ‚à™ B) = &lt;span id=&quot;display-prob-union&quot;&gt;0.700&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;&lt;strong&gt;Conditional:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;P(A|B) = &lt;span id=&quot;display-prob-a-given-b&quot;&gt;0.400&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;P(B|A) = &lt;span id=&quot;display-prob-b-given-a&quot;&gt;0.500&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;5-independence&quot;&gt;5. Independence&lt;/h3&gt;

&lt;p&gt;Two events A and B are &lt;strong&gt;independent&lt;/strong&gt; if:
\(P(A \cap B) = P(A) \cdot P(B)\)&lt;/p&gt;

&lt;p&gt;Equivalently:
\(P(A|B) = P(A) \quad \text{and} \quad P(B|A) = P(B)\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Interpretation&lt;/strong&gt;: Knowledge about one event doesn‚Äôt change the probability of the other.&lt;/p&gt;

&lt;h3 id=&quot;6-random-variables&quot;&gt;6. Random Variables&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;random variable&lt;/strong&gt; X is a function that assigns a real number to each outcome in the sample space:
\(X: \Omega \rightarrow \mathbb{R}\)&lt;/p&gt;

&lt;h4 id=&quot;types-of-random-variables&quot;&gt;Types of Random Variables:&lt;/h4&gt;

&lt;p&gt;&lt;strong&gt;Discrete&lt;/strong&gt;: Takes countable values (e.g., number of heads in coin flips)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Probability Mass Function (PMF): \(P(X = x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Continuous&lt;/strong&gt;: Takes uncountable values (e.g., height, weight)&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Probability Density Function (PDF): \(f_X(x)\)&lt;/li&gt;
  &lt;li&gt;
\[P(a \leq X \leq b) = \int_a^b f_X(x) dx\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;7-connection-to-deep-learning&quot;&gt;7. Connection to Deep Learning&lt;/h3&gt;

&lt;p&gt;Probability theory connects to deep-learning in several ways:&lt;/p&gt;

&lt;h4 id=&quot;maximum-likelihood-estimation&quot;&gt;Maximum Likelihood Estimation&lt;/h4&gt;
&lt;p&gt;Find parameters Œ∏ that maximize the likelihood:
\(\hat{\theta} = \arg\max_\theta P(\text{data}|\theta)\)&lt;/p&gt;

&lt;h4 id=&quot;expected-value-deep-learning&quot;&gt;Expected Value Deep Learning&lt;/h4&gt;
&lt;p&gt;Minimize expected loss:
\(\min_\theta \mathbb{E}[L(Y, f(X; \theta))]\)&lt;/p&gt;

&lt;h4 id=&quot;bayesian-deep-learning&quot;&gt;Bayesian Deep Learning&lt;/h4&gt;
&lt;p&gt;Use probability distributions to model uncertainty in objective functions and guide search for optimal solutions.&lt;/p&gt;

&lt;div id=&quot;deep-learning-connection&quot; style=&quot;border: 2px solid #ddd; padding: 20px; margin: 20px 0; border-radius: 10px; background-color: #f0f8ff;&quot;&gt;
    &lt;h4 style=&quot;text-align: center; color: #333;&quot;&gt;Probability in Deep Learning Example&lt;/h4&gt;
    
    &lt;div style=&quot;display: flex; flex-wrap: wrap; gap: 20px; align-items: flex-start;&quot;&gt;
        &lt;div style=&quot;flex: 1; min-width: 400px;&quot;&gt;
            &lt;canvas id=&quot;deep-learningCanvas&quot; width=&quot;400&quot; height=&quot;300&quot; style=&quot;border: 1px solid #ccc; background: white;&quot;&gt;&lt;/canvas&gt;
            &lt;p style=&quot;font-size: 12px; color: #666; margin-top: 5px;&quot;&gt;
                &lt;strong&gt;MLE Example:&lt;/strong&gt; Finding the parameter Œº that maximizes likelihood of observed data from Normal(Œº, 1).
            &lt;/p&gt;
        &lt;/div&gt;
        
        &lt;div style=&quot;flex: 1; min-width: 250px;&quot;&gt;
            &lt;div style=&quot;background: white; padding: 15px; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);&quot;&gt;
                &lt;h5 style=&quot;margin-top: 0; color: #444;&quot;&gt;MLE Demo&lt;/h5&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;true-mu-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;True Œº: &lt;span id=&quot;true-mu-value&quot;&gt;2.0&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;true-mu-slider&quot; min=&quot;-2&quot; max=&quot;4&quot; step=&quot;0.1&quot; value=&quot;2.0&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;div style=&quot;margin-bottom: 15px;&quot;&gt;
                    &lt;label for=&quot;sample-size-slider&quot; style=&quot;display: block; margin-bottom: 5px; font-weight: bold;&quot;&gt;Sample Size: &lt;span id=&quot;sample-size-value&quot;&gt;20&lt;/span&gt;&lt;/label&gt;
                    &lt;input type=&quot;range&quot; id=&quot;sample-size-slider&quot; min=&quot;5&quot; max=&quot;100&quot; step=&quot;5&quot; value=&quot;20&quot; style=&quot;width: 100%;&quot; /&gt;
                &lt;/div&gt;
                
                &lt;button id=&quot;generate-mle-data&quot; style=&quot;width: 100%; padding: 10px; background: #28a745; color: white; border: none; border-radius: 5px; cursor: pointer; margin-bottom: 15px;&quot;&gt;Generate Data &amp;amp; Find MLE&lt;/button&gt;
                
                &lt;div id=&quot;mle-results&quot; style=&quot;font-family: monospace; font-size: 12px; line-height: 1.4; background: #f8f9fa; padding: 10px; border-radius: 4px;&quot;&gt;
                    &lt;div&gt;&lt;strong&gt;Results:&lt;/strong&gt;&lt;/div&gt;
                    &lt;div&gt;True Œº: &lt;span id=&quot;display-true-mu&quot;&gt;2.000&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Sample mean: &lt;span id=&quot;sample-mean&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;MLE estimate: &lt;span id=&quot;mle-estimate&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                    &lt;div&gt;Error: &lt;span id=&quot;mle-error&quot;&gt;--&lt;/span&gt;&lt;/div&gt;
                &lt;/div&gt;
            &lt;/div&gt;
        &lt;/div&gt;
    &lt;/div&gt;
&lt;/div&gt;

&lt;h3 id=&quot;key-takeaways&quot;&gt;Key Takeaways&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Foundation&lt;/strong&gt;: Probability axioms provide the mathematical foundation for reasoning about uncertainty&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Conditional Probability&lt;/strong&gt;: Essential for updating beliefs with new information&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Independence&lt;/strong&gt;: Simplifies calculations and modeling assumptions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Random Variables&lt;/strong&gt;: Bridge between abstract probability and concrete applications&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Deep Learning Connection&lt;/strong&gt;: Many deep-learning problems arise from probabilistic modeling&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Understanding these basics prepares you for more advanced topics like Bayesian inference, maximum likelihood estimation, and stochastic deep-learning that are central to modern machine learning and data science.&lt;/p&gt;

&lt;script&gt;
// Sample Space Visualization
class SampleSpaceDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;sampleSpaceCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.samples = [];
        this.experimentType = &apos;coin&apos;;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const radios = document.querySelectorAll(&apos;input[name=&quot;experiment&quot;]&apos;);
        const generateBtn = document.getElementById(&apos;generate-sample&apos;);
        const clearBtn = document.getElementById(&apos;clear-samples&apos;);
        
        radios.forEach(radio =&gt; {
            radio.addEventListener(&apos;change&apos;, (e) =&gt; {
                this.experimentType = e.target.value;
                this.samples = [];
                this.updateStats();
                this.draw();
            });
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
        clearBtn.addEventListener(&apos;click&apos;, () =&gt; {
            this.samples = [];
            this.updateStats();
            this.draw();
        });
        
        this.canvas.addEventListener(&apos;click&apos;, () =&gt; this.generateSample());
    }
    
    generateSample() {
        let sample;
        
        switch(this.experimentType) {
            case &apos;coin&apos;:
                sample = {
                    value: Math.random() &lt; 0.5 ? &apos;H&apos; : &apos;T&apos;,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: Math.random() &lt; 0.5, // Event A: Heads
                    eventB: Math.random() &lt; 0.3  // Event B: Lucky flip
                };
                break;
            case &apos;dice&apos;:
                const diceValue = Math.floor(Math.random() * 6) + 1;
                sample = {
                    value: diceValue,
                    x: Math.random() * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: diceValue &gt;= 4, // Event A: 4, 5, or 6
                    eventB: diceValue % 2 === 0 // Event B: Even
                };
                break;
            case &apos;uniform&apos;:
                const uniformValue = Math.random();
                sample = {
                    value: uniformValue.toFixed(3),
                    x: uniformValue * (this.width - 40) + 20,
                    y: Math.random() * (this.height - 40) + 20,
                    eventA: uniformValue &gt; 0.5, // Event A: &gt; 0.5
                    eventB: uniformValue &lt; 0.7  // Event B: &lt; 0.7
                };
                break;
        }
        
        this.samples.push(sample);
        this.updateStats();
        this.draw();
    }
    
    updateStats() {
        const total = this.samples.length;
        const eventACount = this.samples.filter(s =&gt; s.eventA).length;
        const eventBCount = this.samples.filter(s =&gt; s.eventB).length;
        
        document.getElementById(&apos;total-samples&apos;).textContent = total;
        document.getElementById(&apos;event-a-count&apos;).textContent = eventACount;
        document.getElementById(&apos;event-b-count&apos;).textContent = eventBCount;
        document.getElementById(&apos;prob-a&apos;).textContent = total &gt; 0 ? (eventACount / total).toFixed(3) : &apos;0.000&apos;;
        document.getElementById(&apos;prob-b&apos;).textContent = total &gt; 0 ? (eventBCount / total).toFixed(3) : &apos;0.000&apos;;
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw background
        this.ctx.fillStyle = &apos;#f8f9fa&apos;;
        this.ctx.fillRect(0, 0, this.width, this.height);
        
        // Draw samples
        this.samples.forEach(sample =&gt; {
            // Determine color based on events
            let color = &apos;#666&apos;;
            if (sample.eventA &amp;&amp; sample.eventB) color = &apos;#9c27b0&apos;; // Both events
            else if (sample.eventA) color = &apos;#2196f3&apos;; // Event A only
            else if (sample.eventB) color = &apos;#f44336&apos;; // Event B only
            
            this.ctx.fillStyle = color;
            this.ctx.beginPath();
            this.ctx.arc(sample.x, sample.y, 5, 0, 2 * Math.PI);
            this.ctx.fill();
            
            // Draw value
            this.ctx.fillStyle = &apos;#000&apos;;
            this.ctx.font = &apos;10px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(sample.value, sample.x, sample.y - 8);
        });
        
        // Draw legend
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;Legend:&apos;, 10, 20);
        
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 35, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Event A only&apos;, 30, 38);
        
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 50, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Event B only&apos;, 30, 53);
        
        this.ctx.fillStyle = &apos;#9c27b0&apos;;
        this.ctx.beginPath();
        this.ctx.arc(20, 65, 4, 0, 2 * Math.PI);
        this.ctx.fill();
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.fillText(&apos;Both A and B&apos;, 30, 68);
    }
}

// Conditional Probability Visualization
class ConditionalProbDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;conditionalCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.probA = 0.4;
        this.probB = 0.5;
        this.overlap = 0.2;
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const probASlider = document.getElementById(&apos;prob-a-slider&apos;);
        const probBSlider = document.getElementById(&apos;prob-b-slider&apos;);
        const overlapSlider = document.getElementById(&apos;overlap-slider&apos;);
        
        probASlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probA = parseFloat(e.target.value);
            document.getElementById(&apos;prob-a-value&apos;).textContent = this.probA.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        probBSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.probB = parseFloat(e.target.value);
            document.getElementById(&apos;prob-b-value&apos;).textContent = this.probB.toFixed(1);
            this.updateCalculations();
            this.draw();
        });
        
        overlapSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.overlap = parseFloat(e.target.value);
            document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            // Ensure overlap doesn&apos;t exceed min(probA, probB)
            const maxOverlap = Math.min(this.probA, this.probB);
            if (this.overlap &gt; maxOverlap) {
                this.overlap = maxOverlap;
                overlapSlider.value = this.overlap;
                document.getElementById(&apos;overlap-value&apos;).textContent = this.overlap.toFixed(1);
            }
            this.updateCalculations();
            this.draw();
        });
        
        this.updateCalculations();
    }
    
    updateCalculations() {
        const probUnion = this.probA + this.probB - this.overlap;
        const probAGivenB = this.probB &gt; 0 ? this.overlap / this.probB : 0;
        const probBGivenA = this.probA &gt; 0 ? this.overlap / this.probA : 0;
        
        document.getElementById(&apos;display-prob-a&apos;).textContent = this.probA.toFixed(3);
        document.getElementById(&apos;display-prob-b&apos;).textContent = this.probB.toFixed(3);
        document.getElementById(&apos;display-prob-ab&apos;).textContent = this.overlap.toFixed(3);
        document.getElementById(&apos;display-prob-union&apos;).textContent = probUnion.toFixed(3);
        document.getElementById(&apos;display-prob-a-given-b&apos;).textContent = probAGivenB.toFixed(3);
        document.getElementById(&apos;display-prob-b-given-a&apos;).textContent = probBGivenA.toFixed(3);
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        // Draw universe rectangle
        this.ctx.strokeStyle = &apos;#000&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.strokeRect(50, 50, 300, 200);
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;14px Arial&apos;;
        this.ctx.fillText(&apos;Œ© (Sample Space)&apos;, 55, 45);
        
        // Calculate circle parameters
        const centerAX = 150;
        const centerAY = 150;
        const centerBX = 250;
        const centerBY = 150;
        
        // Calculate radii based on probabilities (area proportional to probability)
        const radiusA = Math.sqrt(this.probA * 10000 / Math.PI);
        const radiusB = Math.sqrt(this.probB * 10000 / Math.PI);
        
        // Draw circle A
        this.ctx.globalAlpha = 0.3;
        this.ctx.fillStyle = &apos;#2196f3&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw circle B
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.fill();
        
        // Draw intersection (approximate)
        if (this.overlap &gt; 0) {
            this.ctx.fillStyle = &apos;#9c27b0&apos;;
            const overlapRadius = Math.sqrt(this.overlap * 5000 / Math.PI);
            this.ctx.beginPath();
            this.ctx.arc((centerAX + centerBX) / 2, (centerAY + centerBY) / 2, overlapRadius, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        this.ctx.globalAlpha = 1.0;
        
        // Draw circle outlines
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.arc(centerAX, centerAY, radiusA, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.beginPath();
        this.ctx.arc(centerBX, centerBY, radiusB, 0, 2 * Math.PI);
        this.ctx.stroke();
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;16px Arial&apos;;
        this.ctx.fillText(&apos;A&apos;, centerAX - 40, centerAY);
        this.ctx.fillText(&apos;B&apos;, centerBX + 30, centerBY);
        
        if (this.overlap &gt; 0) {
            this.ctx.fillText(&apos;A‚à©B&apos;, (centerAX + centerBX) / 2 - 15, (centerAY + centerBY) / 2 + 5);
        }
    }
}

// MLE Deep Learning Demo
class MLEDemo {
    constructor() {
        this.canvas = document.getElementById(&apos;deep-learningCanvas&apos;);
        this.ctx = this.canvas.getContext(&apos;2d&apos;);
        this.width = this.canvas.width;
        this.height = this.canvas.height;
        
        this.trueMu = 2.0;
        this.sampleSize = 20;
        this.data = [];
        
        this.setupControls();
        this.draw();
    }
    
    setupControls() {
        const trueMuSlider = document.getElementById(&apos;true-mu-slider&apos;);
        const sampleSizeSlider = document.getElementById(&apos;sample-size-slider&apos;);
        const generateBtn = document.getElementById(&apos;generate-mle-data&apos;);
        
        trueMuSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.trueMu = parseFloat(e.target.value);
            document.getElementById(&apos;true-mu-value&apos;).textContent = this.trueMu.toFixed(1);
            document.getElementById(&apos;display-true-mu&apos;).textContent = this.trueMu.toFixed(3);
        });
        
        sampleSizeSlider.addEventListener(&apos;input&apos;, (e) =&gt; {
            this.sampleSize = parseInt(e.target.value);
            document.getElementById(&apos;sample-size-value&apos;).textContent = this.sampleSize;
        });
        
        generateBtn.addEventListener(&apos;click&apos;, () =&gt; this.generateDataAndFindMLE());
    }
    
    generateDataAndFindMLE() {
        // Generate data from Normal(trueMu, 1)
        this.data = [];
        for (let i = 0; i &lt; this.sampleSize; i++) {
            // Box-Muller transform for normal distribution
            const u1 = Math.random();
            const u2 = Math.random();
            const z = Math.sqrt(-2 * Math.log(u1)) * Math.cos(2 * Math.PI * u2);
            this.data.push(this.trueMu + z); // Normal(trueMu, 1)
        }
        
        // Calculate MLE (sample mean for normal distribution)
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const error = Math.abs(sampleMean - this.trueMu);
        
        // Update display
        document.getElementById(&apos;sample-mean&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-estimate&apos;).textContent = sampleMean.toFixed(3);
        document.getElementById(&apos;mle-error&apos;).textContent = error.toFixed(3);
        
        this.draw();
    }
    
    draw() {
        this.ctx.clearRect(0, 0, this.width, this.height);
        
        if (this.data.length === 0) {
            this.ctx.fillStyle = &apos;#666&apos;;
            this.ctx.font = &apos;16px Arial&apos;;
            this.ctx.textAlign = &apos;center&apos;;
            this.ctx.fillText(&apos;Click &quot;Generate Data &amp; Find MLE&quot; to start&apos;, this.width / 2, this.height / 2);
            return;
        }
        
        // Draw axes
        this.ctx.strokeStyle = &apos;#ddd&apos;;
        this.ctx.lineWidth = 1;
        const marginX = 50;
        const marginY = 50;
        const plotWidth = this.width - 2 * marginX;
        const plotHeight = this.height - 2 * marginY;
        
        // X-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, this.height - marginY);
        this.ctx.lineTo(this.width - marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Y-axis
        this.ctx.beginPath();
        this.ctx.moveTo(marginX, marginY);
        this.ctx.lineTo(marginX, this.height - marginY);
        this.ctx.stroke();
        
        // Find data range
        const minX = Math.min(...this.data) - 1;
        const maxX = Math.max(...this.data) + 1;
        
        // Draw likelihood function
        this.ctx.strokeStyle = &apos;#2196f3&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        
        for (let i = 0; i &lt;= 100; i++) {
            const mu = minX + (maxX - minX) * i / 100;
            let logLikelihood = 0;
            
            // Calculate log-likelihood
            for (const x of this.data) {
                logLikelihood -= 0.5 * Math.log(2 * Math.PI);
                logLikelihood -= 0.5 * (x - mu) * (x - mu);
            }
            
            const x = marginX + (mu - minX) / (maxX - minX) * plotWidth;
            const y = this.height - marginY - (logLikelihood - (-this.data.length * 2)) / (this.data.length) * plotHeight * 0.8;
            
            if (i === 0) {
                this.ctx.moveTo(x, y);
            } else {
                this.ctx.lineTo(x, y);
            }
        }
        this.ctx.stroke();
        
        // Mark MLE
        const sampleMean = this.data.reduce((sum, x) =&gt; sum + x, 0) / this.data.length;
        const mleX = marginX + (sampleMean - minX) / (maxX - minX) * plotWidth;
        
        this.ctx.strokeStyle = &apos;#f44336&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.beginPath();
        this.ctx.moveTo(mleX, marginY);
        this.ctx.lineTo(mleX, this.height - marginY);
        this.ctx.stroke();
        
        // Mark true value
        const trueX = marginX + (this.trueMu - minX) / (maxX - minX) * plotWidth;
        this.ctx.strokeStyle = &apos;#4caf50&apos;;
        this.ctx.lineWidth = 2;
        this.ctx.setLineDash([5, 5]);
        this.ctx.beginPath();
        this.ctx.moveTo(trueX, marginY);
        this.ctx.lineTo(trueX, this.height - marginY);
        this.ctx.stroke();
        this.ctx.setLineDash([]);
        
        // Draw data points
        this.ctx.fillStyle = &apos;#666&apos;;
        for (const x of this.data) {
            const pointX = marginX + (x - minX) / (maxX - minX) * plotWidth;
            this.ctx.beginPath();
            this.ctx.arc(pointX, this.height - marginY + 10, 2, 0, 2 * Math.PI);
            this.ctx.fill();
        }
        
        // Labels
        this.ctx.fillStyle = &apos;#000&apos;;
        this.ctx.font = &apos;12px Arial&apos;;
        this.ctx.textAlign = &apos;center&apos;;
        this.ctx.fillText(&apos;Œº&apos;, this.width / 2, this.height - 10);
        
        this.ctx.save();
        this.ctx.translate(15, this.height / 2);
        this.ctx.rotate(-Math.PI / 2);
        this.ctx.fillText(&apos;Log-Likelihood&apos;, 0, 0);
        this.ctx.restore();
        
        // Legend
        this.ctx.textAlign = &apos;left&apos;;
        this.ctx.fillText(&apos;‚Äî Likelihood&apos;, 10, 20);
        this.ctx.fillStyle = &apos;#f44336&apos;;
        this.ctx.fillText(&apos;‚Äî MLE&apos;, 10, 35);
        this.ctx.fillStyle = &apos;#4caf50&apos;;
        this.ctx.fillText(&apos;--- True Œº&apos;, 10, 50);
    }
}

// Initialize when DOM is loaded
document.addEventListener(&apos;DOMContentLoaded&apos;, function() {
    new SampleSpaceDemo();
    new ConditionalProbDemo();
    new MLEDemo();
});
&lt;/script&gt;

&lt;style&gt;
input[type=&quot;range&quot;] {
    -webkit-appearance: none;
    appearance: none;
    height: 5px;
    background: #ddd;
    outline: none;
    border-radius: 5px;
}

input[type=&quot;range&quot;]::-webkit-slider-thumb {
    -webkit-appearance: none;
    appearance: none;
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
}

input[type=&quot;range&quot;]::-moz-range-thumb {
    width: 15px;
    height: 15px;
    background: #007bff;
    cursor: pointer;
    border-radius: 50%;
    border: none;
}

canvas {
    border-radius: 5px;
}

.demo-container {
    margin: 20px 0;
}
&lt;/style&gt;

</content>
 </entry>
 
 <entry>
   <title>00-03 Real Analysis And Set Theory</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_Real_Analysis_and_Set_Theory/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_03_Real_Analysis_and_Set_Theory</id>
   <content type="html">&lt;p&gt;This lesson covers essential concepts from real analysis and set theory needed for deep-learning, organized into two main sections for comprehensive understanding.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-02 Topology in Real Analysis</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_02_Topology_in_Real_Analysis/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_03_02_Topology_in_Real_Analysis</id>
   <content type="html">&lt;p&gt;This lesson covers essential topological concepts from real analysis that are crucial for understanding the structure of feasible regions, continuity, and the existence of optimal solutions in deep-learning problems.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;introduction-to-topology&quot;&gt;Introduction to Topology&lt;/h2&gt;

&lt;p&gt;Topology studies the properties of space that are preserved under continuous deformations. In deep-learning, topological concepts help us understand the structure of feasible regions and the behavior of functions, particularly regarding the existence and characterization of optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;metric-spaces-and-distance&quot;&gt;Metric Spaces and Distance&lt;/h3&gt;

&lt;p&gt;Before discussing topology, we need the concept of distance. In \(\mathbb{R}^n\), the standard &lt;strong&gt;Euclidean distance&lt;/strong&gt; between points \(\mathbf{x}\) and \(\mathbf{y}\) is:&lt;/p&gt;

\[d(\mathbf{x}, \mathbf{y}) = \|\mathbf{x} - \mathbf{y}\|_2 = \sqrt{\sum_{i=1}^n (x_i - y_i)^2}\]

&lt;h3 id=&quot;open-balls-and-neighborhoods&quot;&gt;Open Balls and Neighborhoods&lt;/h3&gt;

&lt;p&gt;An &lt;strong&gt;open ball&lt;/strong&gt; centered at \(\mathbf{x}_0\) with radius \(\epsilon &amp;gt; 0\) is:&lt;/p&gt;

\[B(\mathbf{x}_0, \epsilon) = \{\mathbf{y} \in \mathbb{R}^n : d(\mathbf{x}_0, \mathbf{y}) &amp;lt; \epsilon\}\]

&lt;p&gt;This represents all points within distance \(\epsilon\) from \(\mathbf{x}_0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;In \(\mathbb{R}\): \(B(0, 1) = (-1, 1)\) (open interval)&lt;/li&gt;
  &lt;li&gt;In \(\mathbb{R}^2\): \(B(\mathbf{0}, 1) = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;open-sets&quot;&gt;Open Sets&lt;/h2&gt;

&lt;p&gt;An &lt;strong&gt;open set&lt;/strong&gt; is characterized by the property that it &lt;strong&gt;contains none of its boundary points&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) in \(\mathbb{R}^n\) is &lt;strong&gt;open&lt;/strong&gt; if for every point \(\mathbf{x} \in S\), there exists a positive real number \(\epsilon &amp;gt; 0\) such that the open ball \(B(\mathbf{x}, \epsilon)\) is entirely contained within \(S\):&lt;/p&gt;

\[\forall \mathbf{x} \in S, \exists \epsilon &amp;gt; 0 : B(\mathbf{x}, \epsilon) \subseteq S\]

&lt;h3 id=&quot;intuitive-understanding&quot;&gt;Intuitive Understanding&lt;/h3&gt;

&lt;p&gt;An open set has the property that if you‚Äôre inside it, you can move a small distance in any direction and still remain inside the set. There‚Äôs always some ‚Äúwiggle room‚Äù around every point.&lt;/p&gt;

&lt;h3 id=&quot;examples-of-open-sets&quot;&gt;Examples of Open Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(0, 1) = \{x : 0 &amp;lt; x &amp;lt; 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(-\infty, 5) = \{x : x &amp;lt; 5\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 &amp;lt; 1\}\) (open unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x &amp;gt; 0, y &amp;gt; 0\}\) (first quadrant, excluding axes)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^2\) itself&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any open ball \(B(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set - vacuously open)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-open-sets&quot;&gt;Properties of Open Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The union of any collection of open sets is open&lt;/li&gt;
  &lt;li&gt;The intersection of finitely many open sets is open&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both open&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;closed-sets&quot;&gt;Closed Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;closed set&lt;/strong&gt; is defined as a set that contains all of its boundary points. Equivalently, a set \(S\) is closed if its complement \(\mathbb{R}^n \setminus S\) is an &lt;strong&gt;open set&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;formal-definition-1&quot;&gt;Formal Definition&lt;/h3&gt;

&lt;p&gt;A set \(S\) is &lt;strong&gt;closed&lt;/strong&gt; if it contains all its limit points. That is, if a sequence of points \((x_n)\) from \(S\) converges to a point \(\mathbf{x}\), then \(\mathbf{x}\) must also be in \(S\):&lt;/p&gt;

\[\text{If } \mathbf{x}_n \in S \text{ for all } n \text{ and } \lim_{n \to \infty} \mathbf{x}_n = \mathbf{x}, \text{ then } \mathbf{x} \in S\]

&lt;h3 id=&quot;examples-of-closed-sets&quot;&gt;Examples of Closed Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[[0, 1] = \{x : 0 \leq x \leq 1\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[[a, \infty) = \{x : x \geq a\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{Z}\) (integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\(\{(x, y) : x \geq 0, y \geq 0\}\) (first quadrant, including axes)&lt;/li&gt;
  &lt;li&gt;\(\{(0, 0)\}\) (single point)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r) = \{\mathbf{x} : d(\mathbf{x}, \mathbf{x}_0) \leq r\}\)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) itself&lt;/li&gt;
  &lt;li&gt;\(\emptyset\) (empty set)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-closed-sets&quot;&gt;Properties of Closed Sets&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;The intersection of any collection of closed sets is closed&lt;/li&gt;
  &lt;li&gt;The union of finitely many closed sets is closed&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) and \(\emptyset\) are both closed&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;important-note&quot;&gt;Important Note&lt;/h3&gt;

&lt;p&gt;Sets can be:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open but not closed:&lt;/strong&gt; \((0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed but not open:&lt;/strong&gt; \([0, 1]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Both open and closed:&lt;/strong&gt; \(\mathbb{R}^n\), \(\emptyset\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Neither open nor closed:&lt;/strong&gt; \([0, 1)\), \((0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;boundary-interior-and-closure&quot;&gt;Boundary, Interior, and Closure&lt;/h2&gt;

&lt;h3 id=&quot;boundary&quot;&gt;Boundary&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;boundary&lt;/strong&gt; of a set \(S\), denoted \(\partial S\), consists of points that are ‚Äúon the edge‚Äù of the set. A point \(\mathbf{x}\) is a &lt;strong&gt;boundary point&lt;/strong&gt; of \(S\) if every open ball centered at \(\mathbf{x}\) intersects both \(S\) and its complement \(S^c\):&lt;/p&gt;

\[\partial S = \{\mathbf{x} : \forall \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \cap S \neq \emptyset \text{ and } B(\mathbf{x}, \epsilon) \cap S^c \neq \emptyset\}\]

&lt;h3 id=&quot;interior&quot;&gt;Interior&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;interior&lt;/strong&gt; of a set \(S\), denoted \(S^\circ\) or \(\text{int}(S)\), includes all points strictly ‚Äúinside‚Äù the set, excluding the boundary:&lt;/p&gt;

\[S^\circ = \{\mathbf{x} \in S : \exists \epsilon &amp;gt; 0, B(\mathbf{x}, \epsilon) \subseteq S\}\]

&lt;h3 id=&quot;closure&quot;&gt;Closure&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;closure&lt;/strong&gt; of a set \(S\), denoted \(\overline{S}\) or \(\text{cl}(S)\), is the smallest closed set containing \(S\):&lt;/p&gt;

\[\overline{S} = S \cup \partial S\]

&lt;h3 id=&quot;example-analysis&quot;&gt;Example Analysis&lt;/h3&gt;

&lt;p&gt;For the interval \(S = [0, 1)\) in \(\mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = (0, 1)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{0, 1\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = [0, 1]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For the open disk \(S = \{(x, y) : x^2 + y^2 &amp;lt; 1\}\) in \(\mathbb{R}^2\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Interior:&lt;/strong&gt; \(S^\circ = S\) (the set is already open)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Boundary:&lt;/strong&gt; \(\partial S = \{(x, y) : x^2 + y^2 = 1\}\) (unit circle)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closure:&lt;/strong&gt; \(\overline{S} = \{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;compact-sets&quot;&gt;Compact Sets&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;compact set&lt;/strong&gt; is one of the most important concepts in deep-learning theory.&lt;/p&gt;

&lt;h3 id=&quot;definition-in-euclidean-spaces&quot;&gt;Definition in Euclidean Spaces&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Heine-Borel Theorem:&lt;/strong&gt; In Euclidean spaces (\(\mathbb{R}^n\)), a set is compact if and only if it is both &lt;strong&gt;closed and bounded&lt;/strong&gt;.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; A set \(S\) is bounded if it can be contained within some sufficiently large open ball: \(\exists M &amp;gt; 0, \mathbf{x}_0\) such that \(S \subseteq B(\mathbf{x}_0, M)\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; As defined above&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples-of-compact-sets&quot;&gt;Examples of Compact Sets&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\([a, b]\) (any closed, bounded interval)&lt;/li&gt;
  &lt;li&gt;\(\{0\}\) (single point)&lt;/li&gt;
  &lt;li&gt;Any finite set&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\{(x, y) : x^2 + y^2 \leq 1\}\) (closed unit disk)&lt;/li&gt;
  &lt;li&gt;\([0, 1] \times [0, 1]\) (unit square)&lt;/li&gt;
  &lt;li&gt;Any finite set of points&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;In \(\mathbb{R}^n\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Any closed ball \(\overline{B}(\mathbf{x}_0, r)\)&lt;/li&gt;
  &lt;li&gt;Any closed, bounded rectangle \([a_1, b_1] \times [a_2, b_2] \times \cdots \times [a_n, b_n]\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;non-compact-sets&quot;&gt;Non-Compact Sets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\((0, 1)\) (bounded but not closed)&lt;/li&gt;
  &lt;li&gt;\([0, \infty)\) (closed but not bounded)&lt;/li&gt;
  &lt;li&gt;\(\mathbb{R}^n\) (not bounded)&lt;/li&gt;
  &lt;li&gt;\(\{1, 1/2, 1/3, 1/4, \ldots\}\) (bounded but not closed, since 0 is a limit point not in the set)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-of-functions&quot;&gt;Continuity of Functions&lt;/h2&gt;

&lt;h3 id=&quot;point-wise-continuity&quot;&gt;Point-wise Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is &lt;strong&gt;continuous at a point&lt;/strong&gt; \(\mathbf{c} \in A\) if for every \(\varepsilon &amp;gt; 0\), there exists \(\delta &amp;gt; 0\) such that for all \(\mathbf{x} \in A\):&lt;/p&gt;

\[\|\mathbf{x} - \mathbf{c}\| &amp;lt; \delta \implies |f(\mathbf{x}) - f(\mathbf{c})| &amp;lt; \varepsilon\]

&lt;p&gt;&lt;strong&gt;Intuitive meaning:&lt;/strong&gt; Small changes in input lead to small changes in output.&lt;/p&gt;

&lt;h3 id=&quot;global-continuity&quot;&gt;Global Continuity&lt;/h3&gt;

&lt;p&gt;\(f\) is &lt;strong&gt;continuous on \(A\)&lt;/strong&gt; if it‚Äôs continuous at every point in \(A\).&lt;/p&gt;

&lt;h3 id=&quot;sequential-characterization&quot;&gt;Sequential Characterization&lt;/h3&gt;

&lt;p&gt;\(f\) is continuous at \(\mathbf{c}\) if and only if for every sequence \((\mathbf{x}_n)\) in \(A\) converging to \(\mathbf{c}\):&lt;/p&gt;

\[\lim_{n \to \infty} f(\mathbf{x}_n) = f(\mathbf{c})\]

&lt;hr /&gt;

&lt;h2 id=&quot;important-theorems-for-deep-learning&quot;&gt;Important Theorems for Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;extreme-value-theorem&quot;&gt;Extreme Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on a compact set \(K\), then \(f\) attains its maximum and minimum on \(K\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is fundamental for deep-learning: it guarantees that continuous objective functions have optimal solutions on compact feasible regions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Proof idea:&lt;/strong&gt; Compactness ensures that the supremum and infimum of \(f\) on \(K\) are actually achieved at points in \(K\).&lt;/p&gt;

&lt;h3 id=&quot;intermediate-value-theorem&quot;&gt;Intermediate Value Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;If \(f\) is continuous on \([a, b]\) and \(y\) is between \(f(a)\) and \(f(b)\), then there exists \(c \in [a, b]\) such that \(f(c) = y\).&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This helps establish the existence of solutions to equations \(f(x) = 0\).&lt;/p&gt;

&lt;h3 id=&quot;bolzano-weierstrass-theorem&quot;&gt;Bolzano-Weierstrass Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every bounded sequence in \(\mathbb{R}^n\) has a convergent subsequence.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This is crucial for proving convergence of deep-learning algorithms.&lt;/p&gt;

&lt;h3 id=&quot;weierstrass-approximation-theorem&quot;&gt;Weierstrass Approximation Theorem&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Every continuous function on a closed interval can be uniformly approximated by polynomials.&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;This justifies using polynomial approximations in deep-learning algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;h3 id=&quot;1-existence-of-solutions&quot;&gt;1. Existence of Solutions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Compact feasible sets guarantee optimal solutions exist:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If the feasible region \(S\) is compact and the objective function \(f\) is continuous, then the deep-learning problem \(\min_{\mathbf{x} \in S} f(\mathbf{x})\) has a solution.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-constraint-qualification&quot;&gt;2. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding topological properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Regular points:&lt;/strong&gt; Points where constraint gradients are linearly independent&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Interior point methods:&lt;/strong&gt; Require the feasible region to have non-empty interior&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-convergence-analysis&quot;&gt;3. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Analyzing whether deep-learning algorithms converge:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed sets:&lt;/strong&gt; Ensure limit points of convergent sequences remain feasible&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compactness:&lt;/strong&gt; Guarantees convergent subsequences exist&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-local-vs-global-optima&quot;&gt;4. Local vs Global Optima&lt;/h3&gt;

&lt;p&gt;Using neighborhoods to define optimality:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in some neighborhood of \(\mathbf{x}^*\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Global minimum:&lt;/strong&gt; \(f(\mathbf{x}^*) \leq f(\mathbf{x})\) for all \(\mathbf{x}\) in the feasible region&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-feasible-region-analysis&quot;&gt;5. Feasible Region Analysis&lt;/h3&gt;

&lt;p&gt;Determining properties of constraint sets:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Linear constraints:&lt;/strong&gt; Define closed sets (half-spaces)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Nonlinear constraints:&lt;/strong&gt; May create sets that are neither open nor closed&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact feasible regions:&lt;/strong&gt; Guarantee existence of optimal solutions&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example-portfolio-deep-learning&quot;&gt;Example: Portfolio Deep Learning&lt;/h3&gt;

&lt;p&gt;Consider minimizing portfolio risk subject to constraints:&lt;/p&gt;

\[\begin{align}
\min_{\mathbf{w}} \quad &amp;amp; \mathbf{w}^T \mathbf{\Sigma} \mathbf{w} \\
\text{s.t.} \quad &amp;amp; \mathbf{1}^T \mathbf{w} = 1 \\
&amp;amp; \mathbf{w} \geq \mathbf{0}
\end{align}\]

&lt;p&gt;The feasible region \(S = \{\mathbf{w} : \mathbf{1}^T \mathbf{w} = 1, \mathbf{w} \geq \mathbf{0}\}\) is:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Closed:&lt;/strong&gt; It‚Äôs the intersection of closed sets&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Bounded:&lt;/strong&gt; The constraint \(\mathbf{1}^T \mathbf{w} = 1\) with \(\mathbf{w} \geq \mathbf{0}\) bounds the feasible region&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Compact:&lt;/strong&gt; Being closed and bounded in \(\mathbb{R}^n\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Since the objective function \(\mathbf{w}^T \mathbf{\Sigma} \mathbf{w}\) is continuous and \(S\) is compact, the Extreme Value Theorem guarantees that an optimal portfolio exists.&lt;/p&gt;

&lt;p&gt;Understanding topology and real analysis provides the rigorous foundation needed to prove that deep-learning problems have solutions and that algorithms will find them. These concepts are essential for both theoretical analysis and practical algorithm design.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-03-01 Set Theory Fundamentals</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_03_01_Set_Theory_Fundamentals/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_03_01_Set_Theory_Fundamentals</id>
   <content type="html">&lt;p&gt;This lesson covers fundamental concepts from set theory that provide the mathematical foundation for understanding deep-learning problems, constraints, and feasible regions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;introduction-to-set-theory&quot;&gt;Introduction to Set Theory&lt;/h2&gt;

&lt;p&gt;Set theory provides the foundation for modern mathematics and is essential for understanding deep-learning concepts. A &lt;strong&gt;set&lt;/strong&gt; is simply a collection of distinct objects, called elements or members.&lt;/p&gt;

&lt;h3 id=&quot;basic-notation&quot;&gt;Basic Notation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Set notation:&lt;/strong&gt; \(A = \{1, 2, 3, 4\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Element membership:&lt;/strong&gt; \(x \in A\) (x is in A) or \(x \notin A\) (x is not in A)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Empty set:&lt;/strong&gt; \(\emptyset = \{\}\) (the set with no elements)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Set builder notation:&lt;/strong&gt; \(A = \{x : P(x)\}\) (the set of all x such that property P(x) holds)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;examples&quot;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(A = \{1, 2, 3, 4\}\) (explicit listing)&lt;/li&gt;
  &lt;li&gt;\(B = \{x \in \mathbb{R} : x^2 &amp;lt; 4\} = (-2, 2)\) (set builder notation)&lt;/li&gt;
  &lt;li&gt;\(C = \{x \in \mathbb{Z} : x \text{ is even}\}\) (all even integers)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;basic-set-operations&quot;&gt;Basic Set Operations&lt;/h2&gt;

&lt;h3 id=&quot;sets-and-subsets&quot;&gt;Sets and Subsets&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Subset:&lt;/strong&gt; \(A \subseteq B\) means every element of \(A\) is also in \(B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Proper Subset:&lt;/strong&gt; \(A \subset B\) means \(A \subseteq B\) and \(A \neq B\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Set Equality:&lt;/strong&gt; \(A = B\) if and only if \(A \subseteq B\) and \(B \subseteq A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\{1, 2\} \subseteq \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;
\[\{1, 2\} \subset \{1, 2, 3, 4\}\]
  &lt;/li&gt;
  &lt;li&gt;\(\emptyset \subseteq A\) for any set \(A\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;union-and-intersection&quot;&gt;Union and Intersection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Union (\(A \cup B\)):&lt;/strong&gt; All elements that are in \(A\) or \(B\) (or both)
\(A \cup B = \{x : x \in A \text{ or } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intersection (\(A \cap B\)):&lt;/strong&gt; All elements that are in both \(A\) and \(B\)
\(A \cap B = \{x : x \in A \text{ and } x \in B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(A = \{1, 2, 3\}\) and \(B = \{3, 4, 5\}\), then:
    &lt;ul&gt;
      &lt;li&gt;
\[A \cup B = \{1, 2, 3, 4, 5\}\]
      &lt;/li&gt;
      &lt;li&gt;
\[A \cap B = \{3\}\]
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Disjoint Sets:&lt;/strong&gt; \(A\) and \(B\) are disjoint if \(A \cap B = \emptyset\)&lt;/p&gt;

&lt;h3 id=&quot;complement-and-difference&quot;&gt;Complement and Difference&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Complement (\(A^c\)):&lt;/strong&gt; All elements not in \(A\) (within some universal set \(U\))
\(A^c = \{x \in U : x \notin A\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Set Difference (\(A \setminus B\)):&lt;/strong&gt; Elements in \(A\) but not in \(B\)
\(A \setminus B = \{x : x \in A \text{ and } x \notin B\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Symmetric Difference:&lt;/strong&gt; \((A \setminus B) \cup (B \setminus A) = (A \cup B) \setminus (A \cap B)\)&lt;/p&gt;

&lt;h3 id=&quot;set-laws&quot;&gt;Set Laws&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Commutative Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cup B = B \cup A\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cap B = B \cap A\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Associative Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B) \cup C = A \cup (B \cup C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B) \cap C = A \cap (B \cap C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Distributive Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[A \cap (B \cup C) = (A \cap B) \cup (A \cap C)\]
  &lt;/li&gt;
  &lt;li&gt;
\[A \cup (B \cap C) = (A \cup B) \cap (A \cup C)\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;De Morgan‚Äôs Laws:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(A \cup B)^c = A^c \cap B^c\]
  &lt;/li&gt;
  &lt;li&gt;
\[(A \cap B)^c = A^c \cup B^c\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;important-number-sets&quot;&gt;Important Number Sets&lt;/h2&gt;

&lt;p&gt;Understanding the hierarchy of number systems is crucial for deep-learning:&lt;/p&gt;

&lt;h3 id=&quot;natural-numbers&quot;&gt;Natural Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{N} = \{1, 2, 3, 4, \ldots\}\)
(Sometimes includes 0: \(\mathbb{N}_0 = \{0, 1, 2, 3, \ldots\}\))&lt;/p&gt;

&lt;h3 id=&quot;integers&quot;&gt;Integers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Z} = \{\ldots, -2, -1, 0, 1, 2, \ldots\}\)&lt;/p&gt;

&lt;h3 id=&quot;rational-numbers&quot;&gt;Rational Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{Q} = \left\{\frac{p}{q} : p, q \in \mathbb{Z}, q \neq 0\right\}\)&lt;/p&gt;

&lt;p&gt;All numbers that can be expressed as fractions.&lt;/p&gt;

&lt;h3 id=&quot;real-numbers&quot;&gt;Real Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{R}\) includes all rational and irrational numbers (like \(\pi\), \(e\), \(\sqrt{2}\)).&lt;/p&gt;

&lt;h3 id=&quot;complex-numbers&quot;&gt;Complex Numbers&lt;/h3&gt;
&lt;p&gt;\(\mathbb{C} = \{a + bi : a, b \in \mathbb{R}, i^2 = -1\}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hierarchy:&lt;/strong&gt; \(\mathbb{N} \subset \mathbb{Z} \subset \mathbb{Q} \subset \mathbb{R} \subset \mathbb{C}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;functions-domain-and-range&quot;&gt;Functions: Domain and Range&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;function&lt;/strong&gt; \(f: A \to B\) is a rule that assigns to each element in set \(A\) exactly one element in set \(B\).&lt;/p&gt;

&lt;h3 id=&quot;key-concepts&quot;&gt;Key Concepts&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Domain:&lt;/strong&gt; The set \(A\) of all possible input values&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Codomain:&lt;/strong&gt; The set \(B\) where outputs are taken from&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Range (Image):&lt;/strong&gt; The set of all actual output values: \(\text{Range}(f) = \{f(x) : x \in A\} \subseteq B\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; For \(f(x) = x^2\) with \(f: \mathbb{R} \to \mathbb{R}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Domain: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Codomain: \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;Range: \([0, \infty)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;types-of-functions&quot;&gt;Types of Functions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Injective (One-to-One):&lt;/strong&gt; Each element in the range corresponds to exactly one element in the domain
\(f(x_1) = f(x_2) \implies x_1 = x_2\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Surjective (Onto):&lt;/strong&gt; Every element in the codomain is in the range
For every \(y \in B\), there exists \(x \in A\) such that \(f(x) = y\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Bijective:&lt;/strong&gt; Both injective and surjective
There‚Äôs a perfect one-to-one correspondence between domain and codomain.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = 2x\) on \(\mathbb{R}\) is bijective&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) on \(\mathbb{R}\) is neither injective nor surjective&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) on \([0, \infty) \to [0, \infty)\) is bijective&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;inequalities&quot;&gt;Inequalities&lt;/h2&gt;

&lt;p&gt;Understanding inequalities is crucial for deep-learning, as constraints are often expressed as inequalities.&lt;/p&gt;

&lt;h3 id=&quot;basic-inequality-symbols&quot;&gt;Basic Inequality Symbols&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;\(a &amp;lt; b\): \(a\) is strictly less than \(b\)&lt;/li&gt;
  &lt;li&gt;\(a \leq b\): \(a\) is less than or equal to \(b\)&lt;/li&gt;
  &lt;li&gt;\(a &amp;gt; b\): \(a\) is strictly greater than \(b\)&lt;/li&gt;
  &lt;li&gt;\(a \geq b\): \(a\) is greater than or equal to \(b\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;properties-of-inequalities&quot;&gt;Properties of Inequalities&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Transitivity:&lt;/strong&gt; If \(a \leq b\) and \(b \leq c\), then \(a \leq c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Addition:&lt;/strong&gt; If \(a \leq b\), then \(a + c \leq b + c\) for any \(c\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multiplication by Positive:&lt;/strong&gt; If \(a \leq b\) and \(c &amp;gt; 0\), then \(ac \leq bc\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Multiplication by Negative:&lt;/strong&gt; If \(a \leq b\) and \(c &amp;lt; 0\), then \(ac \geq bc\) (inequality flips!)&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;interval-notation&quot;&gt;Interval Notation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Open interval:&lt;/strong&gt; \((a, b) = \{x \in \mathbb{R} : a &amp;lt; x &amp;lt; b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Closed interval:&lt;/strong&gt; \([a, b] = \{x \in \mathbb{R} : a \leq x \leq b\}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Half-open intervals:&lt;/strong&gt; \([a, b)\), \((a, b]\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Unbounded intervals:&lt;/strong&gt; \((-\infty, a)\), \([a, \infty)\), \((-\infty, \infty) = \mathbb{R}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Set theory concepts are fundamental to deep-learning:&lt;/p&gt;

&lt;h3 id=&quot;1-feasible-regions&quot;&gt;1. Feasible Regions&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;feasible region&lt;/strong&gt; is the set of all points satisfying the constraints:
\(S = \{x \in \mathbb{R}^n : g_i(x) \leq 0, i = 1, \ldots, m; h_j(x) = 0, j = 1, \ldots, p\}\)&lt;/p&gt;

&lt;h3 id=&quot;2-level-sets&quot;&gt;2. Level Sets&lt;/h3&gt;

&lt;p&gt;For a function \(f: \mathbb{R}^n \to \mathbb{R}\), the &lt;strong&gt;level set&lt;/strong&gt; at level \(c\) is:
\(L_c = \{x \in \mathbb{R}^n : f(x) = c\}\)&lt;/p&gt;

&lt;h3 id=&quot;3-constraint-qualification&quot;&gt;3. Constraint Qualification&lt;/h3&gt;

&lt;p&gt;Understanding when constraint sets have ‚Äúnice‚Äù properties (like being closed or having non-empty interior) affects the existence and characterization of optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;Sequences and limits are essential for analyzing whether deep-learning algorithms converge to optimal solutions.&lt;/p&gt;

&lt;h3 id=&quot;5-set-operations-in-algorithms&quot;&gt;5. Set Operations in Algorithms&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Intersection:&lt;/strong&gt; Finding points that satisfy multiple constraints&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Union:&lt;/strong&gt; Combining feasible regions from different scenarios&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Complement:&lt;/strong&gt; Understanding infeasible regions&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; In linear programming, the feasible region is:
\(S = \{x \in \mathbb{R}^n : Ax \leq b, x \geq 0\} = \bigcap_{i=1}^{m} \{x : a_i^T x \leq b_i\} \cap \{x : x \geq 0\}\)&lt;/p&gt;

&lt;p&gt;This is the intersection of half-spaces, demonstrating how set operations naturally arise in deep-learning problem formulation.&lt;/p&gt;

&lt;p&gt;Understanding set theory provides the rigorous mathematical foundation needed to formulate deep-learning problems precisely and analyze their properties systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02 Basic Linear Algebra</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_Basic_Linear_Algebra/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_02_Basic_Linear_Algebra</id>
   <content type="html">&lt;p&gt;This lesson covers essential linear algebra concepts needed for deep-learning, organized into three main sections for systematic learning.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-03 Eigenvalues and Eigenvectors</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_03_Eigenvalues_and_Eigenvectors/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_02_03_Eigenvalues_and_Eigenvectors</id>
   <content type="html">&lt;p&gt;This lesson covers eigenvalues and eigenvectors, which are crucial for understanding the behavior of linear transformations and quadratic functions in deep-learning.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;definition-and-intuition&quot;&gt;Definition and Intuition&lt;/h2&gt;

&lt;p&gt;When a matrix transforms a vector, it usually changes both the vector‚Äôs direction and its length. However, &lt;strong&gt;eigenvectors&lt;/strong&gt; are special vectors that, when transformed by a given matrix, only get scaled but do not change their direction.&lt;/p&gt;

&lt;h3 id=&quot;mathematical-definition&quot;&gt;Mathematical Definition&lt;/h3&gt;

&lt;p&gt;For a square matrix \(\mathbf{A}\) and a non-zero vector \(\mathbf{v}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}\) is an &lt;strong&gt;eigenvector&lt;/strong&gt; of \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;\(\lambda\) is the corresponding &lt;strong&gt;eigenvalue&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;if they satisfy the &lt;strong&gt;eigenvalue equation&lt;/strong&gt;:&lt;/p&gt;

\[\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Eigenvectors:&lt;/strong&gt; Non-zero vectors that maintain their direction under the transformation \(\mathbf{A}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Eigenvalues:&lt;/strong&gt; The scalar factors by which the eigenvectors are scaled&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Visual Understanding:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;If \(\lambda &amp;gt; 1\): The eigenvector is stretched&lt;/li&gt;
  &lt;li&gt;If \(0 &amp;lt; \lambda &amp;lt; 1\): The eigenvector is shrunk&lt;/li&gt;
  &lt;li&gt;If \(\lambda &amp;lt; 0\): The eigenvector is scaled and flipped&lt;/li&gt;
  &lt;li&gt;If \(\lambda = 0\): The eigenvector is mapped to the zero vector&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;finding-eigenvalues-and-eigenvectors&quot;&gt;Finding Eigenvalues and Eigenvectors&lt;/h2&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

&lt;p&gt;Rearrange the eigenvalue equation:
\(\mathbf{A}\mathbf{v} = \lambda\mathbf{v}\)
\(\mathbf{A}\mathbf{v} - \lambda\mathbf{v} = \mathbf{0}\)
\((\mathbf{A} - \lambda\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;For a non-trivial solution (\(\mathbf{v} \neq \mathbf{0}\)), the matrix \((\mathbf{A} - \lambda\mathbf{I})\) must be singular, so:&lt;/p&gt;

\[\det(\mathbf{A} - \lambda\mathbf{I}) = 0\]

&lt;p&gt;This is called the &lt;strong&gt;characteristic equation&lt;/strong&gt;.&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;For each eigenvalue \(\lambda_i\), solve the system:
\((\mathbf{A} - \lambda_i\mathbf{I})\mathbf{v} = \mathbf{0}\)&lt;/p&gt;

&lt;p&gt;The solutions form the &lt;strong&gt;eigenspace&lt;/strong&gt; corresponding to \(\lambda_i\).&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;detailed-example&quot;&gt;Detailed Example&lt;/h2&gt;

&lt;p&gt;Let‚Äôs find the eigenvalues and eigenvectors of \(\mathbf{A} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\).&lt;/p&gt;

&lt;h3 id=&quot;step-1-find-eigenvalues-1&quot;&gt;Step 1: Find Eigenvalues&lt;/h3&gt;

\[\mathbf{A} - \lambda\mathbf{I} = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix} - \lambda\begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix} = \begin{pmatrix} 3-\lambda &amp;amp; 1 \\ 0 &amp;amp; 2-\lambda \end{pmatrix}\]

\[\det(\mathbf{A} - \lambda\mathbf{I}) = (3-\lambda)(2-\lambda) - (1)(0) = (3-\lambda)(2-\lambda) = 0\]

&lt;p&gt;This gives us \(\lambda_1 = 3\) and \(\lambda_2 = 2\).&lt;/p&gt;

&lt;h3 id=&quot;step-2-find-eigenvectors-1&quot;&gt;Step 2: Find Eigenvectors&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_1 = 3\):&lt;/strong&gt;
\((\mathbf{A} - 3\mathbf{I})\mathbf{v} = \begin{pmatrix} 0 &amp;amp; 1 \\ 0 &amp;amp; -1 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_2 = 0\) and \(v_1\) can be any non-zero value. So \(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;For \(\lambda_2 = 2\):&lt;/strong&gt;
\((\mathbf{A} - 2\mathbf{I})\mathbf{v} = \begin{pmatrix} 1 &amp;amp; 1 \\ 0 &amp;amp; 0 \end{pmatrix}\begin{pmatrix} v_1 \\ v_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This gives us \(v_1 + v_2 = 0\), so \(v_2 = -v_1\). Thus \(\mathbf{v}_2 = \begin{pmatrix} 1 \\ -1 \end{pmatrix}\) (or any scalar multiple).&lt;/p&gt;

&lt;h3 id=&quot;verification&quot;&gt;Verification&lt;/h3&gt;

&lt;p&gt;Let‚Äôs verify our results:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_1 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} 3 \\ 0 \end{pmatrix} = 3\begin{pmatrix} 1 \\ 0 \end{pmatrix} = 3\mathbf{v}_1\) ‚úì&lt;/li&gt;
  &lt;li&gt;\(\mathbf{A}\mathbf{v}_2 = \begin{pmatrix} 3 &amp;amp; 1 \\ 0 &amp;amp; 2 \end{pmatrix}\begin{pmatrix} 1 \\ -1 \end{pmatrix} = \begin{pmatrix} 2 \\ -2 \end{pmatrix} = 2\begin{pmatrix} 1 \\ -1 \end{pmatrix} = 2\mathbf{v}_2\) ‚úì&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;properties-and-important-theorems&quot;&gt;Properties and Important Theorems&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Sum of eigenvalues = trace of matrix:&lt;/strong&gt;
\(\sum_{i=1}^n \lambda_i = \text{tr}(\mathbf{A}) = \sum_{i=1}^n a_{ii}\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Product of eigenvalues = determinant of matrix:&lt;/strong&gt;
\(\prod_{i=1}^n \lambda_i = \det(\mathbf{A})\)&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Eigenvectors corresponding to different eigenvalues are linearly independent&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;If \(\mathbf{A}\) is symmetric, all eigenvalues are real and eigenvectors are orthogonal&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;eigenvalue-multiplicity&quot;&gt;Eigenvalue Multiplicity&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Algebraic multiplicity:&lt;/strong&gt; How many times \(\lambda\) appears as a root of the characteristic polynomial&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Geometric multiplicity:&lt;/strong&gt; The dimension of the eigenspace (number of linearly independent eigenvectors)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For any eigenvalue: geometric multiplicity ‚â§ algebraic multiplicity&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;diagonalization&quot;&gt;Diagonalization&lt;/h2&gt;

&lt;p&gt;A matrix \(\mathbf{A}\) is &lt;strong&gt;diagonalizable&lt;/strong&gt; if it can be written as:&lt;/p&gt;

\[\mathbf{A} = \mathbf{P}\mathbf{D}\mathbf{P}^{-1}\]

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{D}\) is a diagonal matrix of eigenvalues&lt;/li&gt;
  &lt;li&gt;\(\mathbf{P}\) is a matrix whose columns are the corresponding eigenvectors&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;benefits-of-diagonalization&quot;&gt;Benefits of Diagonalization&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Easy computation of powers:&lt;/strong&gt; \(\mathbf{A}^k = \mathbf{P}\mathbf{D}^k\mathbf{P}^{-1}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Understanding behavior:&lt;/strong&gt; The eigenvalues determine the transformation‚Äôs behavior along each eigenvector direction&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Eigenvalues and eigenvectors are crucial in deep-learning for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-quadratic-forms-and-definiteness&quot;&gt;1. Quadratic Forms and Definiteness&lt;/h3&gt;

&lt;p&gt;For a quadratic function \(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x}\):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Positive definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;gt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues of \(\mathbf{Q}\) are positive&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Positive semidefinite&lt;/strong&gt; (\(f(\mathbf{x}) \geq 0\)): All eigenvalues are non-negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Negative definite&lt;/strong&gt; (\(f(\mathbf{x}) &amp;lt; 0\) for \(\mathbf{x} \neq \mathbf{0}\)): All eigenvalues are negative&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Indefinite&lt;/strong&gt; (\(f(\mathbf{x})\) can be positive or negative): Mixed positive and negative eigenvalues&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-second-order-optimality-conditions&quot;&gt;2. Second-Order Optimality Conditions&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) at a critical point \(\mathbf{x}^*\) (where \(\nabla f(\mathbf{x}^*) = \mathbf{0}\)):&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Local minimum:&lt;/strong&gt; Hessian \(\nabla^2 f(\mathbf{x}^*)\) is positive definite (all eigenvalues &amp;gt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Local maximum:&lt;/strong&gt; Hessian is negative definite (all eigenvalues &amp;lt; 0)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Saddle point:&lt;/strong&gt; Hessian is indefinite (mixed eigenvalues)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;3-principal-component-analysis-pca&quot;&gt;3. Principal Component Analysis (PCA)&lt;/h3&gt;

&lt;p&gt;PCA finds the directions of maximum variance in data:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Eigenvectors of the covariance matrix give the principal directions&lt;/li&gt;
  &lt;li&gt;Eigenvalues give the variance along each principal direction&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;4-convergence-analysis&quot;&gt;4. Convergence Analysis&lt;/h3&gt;

&lt;p&gt;In iterative deep-learning algorithms:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;The &lt;strong&gt;condition number&lt;/strong&gt; \(\kappa = \frac{\lambda_{\max}}{\lambda_{\min}}\) affects convergence speed&lt;/li&gt;
  &lt;li&gt;Large condition numbers lead to slow convergence&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-newtons-method&quot;&gt;5. Newton‚Äôs Method&lt;/h3&gt;

&lt;p&gt;Newton‚Äôs method uses the inverse Hessian:
\(\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\)&lt;/p&gt;

&lt;p&gt;The eigenvalues of the Hessian determine the method‚Äôs behavior and convergence rate.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-deep-learning-application&quot;&gt;Example: Deep Learning Application&lt;/h2&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = 2x^2 + 3y^2 + 2xy\).&lt;/p&gt;

&lt;p&gt;The Hessian is: \(\mathbf{H} = \begin{pmatrix} 4 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Finding eigenvalues:&lt;/strong&gt;
\(\det(\mathbf{H} - \lambda\mathbf{I}) = (4-\lambda)(6-\lambda) - 4 = \lambda^2 - 10\lambda + 20 = 0\)&lt;/p&gt;

\[\lambda = \frac{10 \pm \sqrt{100-80}}{2} = \frac{10 \pm 2\sqrt{5}}{2} = 5 \pm \sqrt{5}\]

&lt;p&gt;Since both eigenvalues are positive (\(\lambda_1 = 5 + \sqrt{5} &amp;gt; 0\) and \(\lambda_2 = 5 - \sqrt{5} &amp;gt; 0\)), the Hessian is positive definite, confirming that the origin is a global minimum.&lt;/p&gt;

&lt;p&gt;The condition number is \(\kappa = \frac{5 + \sqrt{5}}{5 - \sqrt{5}} \approx 4.24\), indicating reasonably good conditioning for deep-learning algorithms.&lt;/p&gt;

&lt;p&gt;Understanding eigenvalues and eigenvectors provides deep insights into the geometric and analytical properties of deep-learning problems, enabling better algorithm design and convergence analysis.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-02 Matrices and Linear Transformations</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_02_Matrices_and_Linear_Transformations/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_02_02_Matrices_and_Linear_Transformations</id>
   <content type="html">&lt;p&gt;This lesson covers matrices, matrix operations, and linear transformations, which are fundamental tools for representing and solving deep-learning problems.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;matrices-and-matrix-operations&quot;&gt;Matrices and Matrix Operations&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-matrix&quot;&gt;What is a Matrix?&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;matrix&lt;/strong&gt; is a rectangular grid of numbers arranged in rows and columns. Matrices represent data, transformations, systems of equations, and relationships between variables.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;General Form:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 
a_{11} &amp;amp; a_{12} &amp;amp; \cdots &amp;amp; a_{1n} \\
a_{21} &amp;amp; a_{22} &amp;amp; \cdots &amp;amp; a_{2n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
a_{m1} &amp;amp; a_{m2} &amp;amp; \cdots &amp;amp; a_{mn}
\end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;This is an \(m \times n\) matrix (\(m\) rows, \(n\) columns).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\) is a \(2 \times 3\) matrix.&lt;/p&gt;

&lt;h3 id=&quot;matrix-addition&quot;&gt;Matrix Addition&lt;/h3&gt;

&lt;p&gt;Matrices are added by summing corresponding elements. Both matrices must have the same dimensions.&lt;/p&gt;

\[\mathbf{A} + \mathbf{B} = \begin{pmatrix} a_{11} + b_{11} &amp;amp; a_{12} + b_{12} \\ a_{21} + b_{21} &amp;amp; a_{22} + b_{22} \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} + \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 6 &amp;amp; 8 \\ 10 &amp;amp; 12 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;scalar-multiplication&quot;&gt;Scalar Multiplication&lt;/h3&gt;

&lt;p&gt;Multiply every element of the matrix by the scalar:&lt;/p&gt;

\[c\mathbf{A} = \begin{pmatrix} ca_{11} &amp;amp; ca_{12} \\ ca_{21} &amp;amp; ca_{22} \end{pmatrix}\]

&lt;h3 id=&quot;matrix-multiplication&quot;&gt;Matrix Multiplication&lt;/h3&gt;

&lt;p&gt;For matrices \(\mathbf{A}_{m \times n}\) and \(\mathbf{B}_{n \times p}\), the product \(\mathbf{C}_{m \times p}\) is formed by taking the dot product of rows from \(\mathbf{A}\) and columns from \(\mathbf{B}\):&lt;/p&gt;

\[c_{ij} = \sum_{k=1}^{n} a_{ik} b_{kj}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 1 &amp;amp; 2 \\ 3 &amp;amp; 4 \end{pmatrix} \begin{pmatrix} 5 &amp;amp; 6 \\ 7 &amp;amp; 8 \end{pmatrix} = \begin{pmatrix} 1 \cdot 5 + 2 \cdot 7 &amp;amp; 1 \cdot 6 + 2 \cdot 8 \\ 3 \cdot 5 + 4 \cdot 7 &amp;amp; 3 \cdot 6 + 4 \cdot 8 \end{pmatrix} = \begin{pmatrix} 19 &amp;amp; 22 \\ 43 &amp;amp; 50 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Important:&lt;/strong&gt; Matrix multiplication is &lt;strong&gt;not commutative&lt;/strong&gt;: \(\mathbf{AB} \neq \mathbf{BA}\) in general.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-transformations&quot;&gt;Linear Transformations&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;linear transformation&lt;/strong&gt; is a function \(T: \mathbb{R}^n \to \mathbb{R}^m\) that preserves vector addition and scalar multiplication. Every linear transformation can be represented by a matrix.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;A transformation \(T(\mathbf{v}) = \mathbf{Av}\) is linear if and only if:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Additivity:&lt;/strong&gt; \(T(\mathbf{u} + \mathbf{v}) = T(\mathbf{u}) + T(\mathbf{v})\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; \(T(c\mathbf{v}) = cT(\mathbf{v})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;These can be combined into: \(T(c_1\mathbf{u} + c_2\mathbf{v}) = c_1T(\mathbf{u}) + c_2T(\mathbf{v})\)&lt;/p&gt;

&lt;h3 id=&quot;matrix-vector-multiplication&quot;&gt;Matrix-Vector Multiplication&lt;/h3&gt;

&lt;p&gt;If \(\mathbf{A}\) is an \(m \times n\) matrix and \(\mathbf{v}\) is an \(n \times 1\) column vector, their product \(\mathbf{Av}\) is an \(m \times 1\) column vector:&lt;/p&gt;

\[\mathbf{w} = \mathbf{Av} = \begin{pmatrix} 
a_{11}v_1 + a_{12}v_2 + \cdots + a_{1n}v_n \\
a_{21}v_1 + a_{22}v_2 + \cdots + a_{2n}v_n \\
\vdots \\
a_{m1}v_1 + a_{m2}v_2 + \cdots + a_{mn}v_n
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
\(\begin{pmatrix} 2 &amp;amp; 1 \\ 0 &amp;amp; 3 \end{pmatrix} \begin{pmatrix} 4 \\ 5 \end{pmatrix} = \begin{pmatrix} 2 \cdot 4 + 1 \cdot 5 \\ 0 \cdot 4 + 3 \cdot 5 \end{pmatrix} = \begin{pmatrix} 13 \\ 15 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;common-2d-transformations&quot;&gt;Common 2D Transformations&lt;/h2&gt;

&lt;p&gt;Understanding geometric transformations helps visualize how matrices affect vectors.&lt;/p&gt;

&lt;h3 id=&quot;scaling&quot;&gt;Scaling&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Scaling Matrix:&lt;/strong&gt;
\(\mathbf{S} = \begin{pmatrix} s_x &amp;amp; 0 \\ 0 &amp;amp; s_y \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Scales x-coordinates by \(s_x\) and y-coordinates by \(s_y\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; \(\begin{pmatrix} 2 &amp;amp; 0 \\ 0 &amp;amp; 3 \end{pmatrix}\) doubles x-values and triples y-values&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;rotation&quot;&gt;Rotation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Rotation Matrix (counter-clockwise by angle \(\theta\)):&lt;/strong&gt;
\(\mathbf{R} = \begin{pmatrix} \cos\theta &amp;amp; -\sin\theta \\ \sin\theta &amp;amp; \cos\theta \end{pmatrix}\)&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; 90¬∞ rotation: \(\begin{pmatrix} 0 &amp;amp; -1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/li&gt;
  &lt;li&gt;Transforms \((x, y) \mapsto (-y, x)\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;reflection&quot;&gt;Reflection&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Reflection across x-axis:&lt;/strong&gt;
\(\mathbf{F}_x = \begin{pmatrix} 1 &amp;amp; 0 \\ 0 &amp;amp; -1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across y-axis:&lt;/strong&gt;
\(\mathbf{F}_y = \begin{pmatrix} -1 &amp;amp; 0 \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Reflection across line \(y = x\):&lt;/strong&gt;
\(\mathbf{F}_{y=x} = \begin{pmatrix} 0 &amp;amp; 1 \\ 1 &amp;amp; 0 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;shearing&quot;&gt;Shearing&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Horizontal Shear:&lt;/strong&gt;
\(\mathbf{H} = \begin{pmatrix} 1 &amp;amp; k \\ 0 &amp;amp; 1 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;Transforms \((x, y) \mapsto (x + ky, y)\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;special-types-of-matrices&quot;&gt;Special Types of Matrices&lt;/h2&gt;

&lt;h3 id=&quot;identity-matrix&quot;&gt;Identity Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;identity matrix&lt;/strong&gt; \(\mathbf{I}\) acts like the number 1 for matrix multiplication:&lt;/p&gt;

\[\mathbf{I}_n = \begin{pmatrix} 
1 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 0 \\
0 &amp;amp; 1 &amp;amp; \cdots &amp;amp; 0 \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
0 &amp;amp; 0 &amp;amp; \cdots &amp;amp; 1
\end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Property:&lt;/strong&gt; \(\mathbf{AI} = \mathbf{IA} = \mathbf{A}\) for any compatible matrix \(\mathbf{A}\).&lt;/p&gt;

&lt;h3 id=&quot;transpose&quot;&gt;Transpose&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;transpose&lt;/strong&gt; \(\mathbf{A}^T\) flips a matrix across its main diagonal:&lt;/p&gt;

\[\text{If } \mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 4 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}, \text{ then } \mathbf{A}^T = \begin{pmatrix} 1 &amp;amp; 4 \\ 2 &amp;amp; 5 \\ 3 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;&lt;strong&gt;Properties:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[(\mathbf{A}^T)^T = \mathbf{A}\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{A} + \mathbf{B})^T = \mathbf{A}^T + \mathbf{B}^T\]
  &lt;/li&gt;
  &lt;li&gt;
\[(\mathbf{AB})^T = \mathbf{B}^T\mathbf{A}^T\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;symmetric-matrices&quot;&gt;Symmetric Matrices&lt;/h3&gt;

&lt;p&gt;A matrix is &lt;strong&gt;symmetric&lt;/strong&gt; if \(\mathbf{A} = \mathbf{A}^T\):&lt;/p&gt;

\[\mathbf{A} = \begin{pmatrix} 1 &amp;amp; 2 &amp;amp; 3 \\ 2 &amp;amp; 4 &amp;amp; 5 \\ 3 &amp;amp; 5 &amp;amp; 6 \end{pmatrix}\]

&lt;p&gt;Symmetric matrices have special properties important in deep-learning.&lt;/p&gt;

&lt;h3 id=&quot;inverse-matrix&quot;&gt;Inverse Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;inverse&lt;/strong&gt; \(\mathbf{A}^{-1}\) of a square matrix \(\mathbf{A}\) satisfies:&lt;/p&gt;

\[\mathbf{A}\mathbf{A}^{-1} = \mathbf{A}^{-1}\mathbf{A} = \mathbf{I}\]

&lt;p&gt;&lt;strong&gt;For 2√ó2 matrices:&lt;/strong&gt;
\(\mathbf{A}^{-1} = \frac{1}{\det(\mathbf{A})} \begin{pmatrix} d &amp;amp; -b \\ -c &amp;amp; a \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{A} = \begin{pmatrix} a &amp;amp; b \\ c &amp;amp; d \end{pmatrix}\) and \(\det(\mathbf{A}) = ad - bc\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Not all matrices have inverses. A matrix is &lt;strong&gt;invertible&lt;/strong&gt; (non-singular) if and only if its determinant is non-zero.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Matrices and linear transformations are fundamental in deep-learning for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-system-of-linear-equations&quot;&gt;1. System of Linear Equations&lt;/h3&gt;

&lt;p&gt;Many deep-learning problems involve solving \(\mathbf{Ax} = \mathbf{b}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Unique solution:&lt;/strong&gt; \(\mathbf{x} = \mathbf{A}^{-1}\mathbf{b}\) (when \(\mathbf{A}\) is invertible)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Least squares:&lt;/strong&gt; Minimize \(\|\mathbf{Ax} - \mathbf{b}\|^2\) when no exact solution exists&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-quadratic-forms&quot;&gt;2. Quadratic Forms&lt;/h3&gt;

&lt;p&gt;Quadratic functions appear frequently in deep-learning:
\(f(\mathbf{x}) = \mathbf{x}^T\mathbf{Q}\mathbf{x} + \mathbf{c}^T\mathbf{x} + d\)&lt;/p&gt;

&lt;p&gt;The matrix \(\mathbf{Q}\) determines the curvature properties of the function.&lt;/p&gt;

&lt;h3 id=&quot;3-linear-programming&quot;&gt;3. Linear Programming&lt;/h3&gt;

&lt;p&gt;Standard form: Minimize \(\mathbf{c}^T\mathbf{x}\) subject to \(\mathbf{Ax} = \mathbf{b}\), \(\mathbf{x} \geq \mathbf{0}\)&lt;/p&gt;

&lt;h3 id=&quot;4-constraint-representation&quot;&gt;4. Constraint Representation&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Equality constraints:&lt;/strong&gt; \(\mathbf{Ax} = \mathbf{b}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Inequality constraints:&lt;/strong&gt; \(\mathbf{Ax} \leq \mathbf{b}\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;5-transformations-of-variables&quot;&gt;5. Transformations of Variables&lt;/h3&gt;

&lt;p&gt;Change of variables: \(\mathbf{y} = \mathbf{T}\mathbf{x}\) can simplify deep-learning problems.&lt;/p&gt;

&lt;h3 id=&quot;example-portfolio-deep-learning&quot;&gt;Example: Portfolio Deep Learning&lt;/h3&gt;

&lt;p&gt;In finance, we might minimize portfolio risk:
\(\text{minimize } \mathbf{w}^T\mathbf{\Sigma}\mathbf{w}\)&lt;/p&gt;

&lt;p&gt;where \(\mathbf{w}\) is the vector of portfolio weights and \(\mathbf{\Sigma}\) is the covariance matrix of asset returns.&lt;/p&gt;

&lt;p&gt;Understanding matrices and linear transformations provides the tools to formulate, analyze, and solve a wide variety of deep-learning problems efficiently.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-02-01 Vectors and Vector Spaces</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_02_01_Vectors_and_Vector_Spaces/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_02_01_Vectors_and_Vector_Spaces</id>
   <content type="html">&lt;p&gt;This lesson introduces vectors, vector spaces, and fundamental concepts that form the foundation for understanding linear algebra in deep-learning contexts.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;vectors-and-vector-spaces-mathbbrn&quot;&gt;Vectors and Vector Spaces (\(\mathbb{R}^n\))&lt;/h2&gt;

&lt;h3 id=&quot;what-is-a-vector&quot;&gt;What is a Vector?&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vectors:&lt;/strong&gt; Think of a vector as an arrow in space, representing both a direction and a magnitude (length). Mathematically, it‚Äôs an ordered list of numbers, like coordinates. For example, a vector in 2D space could be \(\mathbf{v} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\), meaning 3 units along the x-axis and 4 units along the y-axis.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Geometric vs Algebraic View:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Geometric:&lt;/strong&gt; Vectors are arrows with direction and magnitude&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Algebraic:&lt;/strong&gt; Vectors are ordered lists of real numbers&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-spaces&quot;&gt;Vector Spaces&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Vector Space (\(\mathbb{R}^n\)):&lt;/strong&gt; This is the collection of all possible vectors that have \(n\) components (numbers). For instance, \(\mathbb{R}^2\) includes all 2-component vectors, representing all points or arrows in a 2D plane.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
    &lt;ul&gt;
      &lt;li&gt;\(\mathbb{R}^2 = \left\{\begin{pmatrix} x \\ y \end{pmatrix} : x, y \in \mathbb{R}\right\}\) (the plane)&lt;/li&gt;
      &lt;li&gt;\(\mathbb{R}^3 = \left\{\begin{pmatrix} x \\ y \\ z \end{pmatrix} : x, y, z \in \mathbb{R}\right\}\) (3D space)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;vector-operations&quot;&gt;Vector Operations&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Vector Addition:&lt;/strong&gt;
\(\mathbf{u} + \mathbf{v} = \begin{pmatrix} u_1 \\ u_2 \\ \vdots \\ u_n \end{pmatrix} + \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} u_1 + v_1 \\ u_2 + v_2 \\ \vdots \\ u_n + v_n \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Scalar Multiplication:&lt;/strong&gt;
\(c\mathbf{v} = c \begin{pmatrix} v_1 \\ v_2 \\ \vdots \\ v_n \end{pmatrix} = \begin{pmatrix} cv_1 \\ cv_2 \\ \vdots \\ cv_n \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;linear-independence-basis-and-dimension&quot;&gt;Linear Independence, Basis, and Dimension&lt;/h2&gt;

&lt;h3 id=&quot;linear-independence&quot;&gt;Linear Independence&lt;/h3&gt;

&lt;p&gt;A set of vectors \(\{\mathbf{v}_1, \mathbf{v}_2, \ldots, \mathbf{v}_k\}\) is &lt;strong&gt;linearly independent&lt;/strong&gt; if the only solution to:&lt;/p&gt;

\[c_1\mathbf{v}_1 + c_2\mathbf{v}_2 + \cdots + c_k\mathbf{v}_k = \mathbf{0}\]

&lt;p&gt;is \(c_1 = c_2 = \cdots = c_k = 0\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Intuitive Understanding:&lt;/strong&gt; A set of vectors is ‚Äúlinearly independent‚Äù if no vector in the set can be created by scaling and adding the other vectors in the set. They all point in ‚Äúdifferent enough‚Äù directions.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example in \(\mathbb{R}^2\):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) and \(\mathbf{v}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) are linearly independent&lt;/li&gt;
  &lt;li&gt;\(\mathbf{v}_1 = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) and \(\mathbf{v}_2 = \begin{pmatrix} 2 \\ 4 \end{pmatrix}\) are linearly dependent (since \(\mathbf{v}_2 = 2\mathbf{v}_1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;basis&quot;&gt;Basis&lt;/h3&gt;

&lt;p&gt;A &lt;strong&gt;basis&lt;/strong&gt; for a vector space is a minimal set of linearly independent vectors that can be combined (scaled and added) to create &lt;em&gt;any&lt;/em&gt; other vector in that space. It‚Äôs like a fundamental set of building blocks.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Properties of a Basis:&lt;/strong&gt;&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The vectors are linearly independent&lt;/li&gt;
  &lt;li&gt;They span the entire vector space&lt;/li&gt;
  &lt;li&gt;Every vector in the space can be written uniquely as a linear combination of basis vectors&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Standard Basis for \(\mathbb{R}^n\):&lt;/strong&gt;
\(\mathbf{e}_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix}, \mathbf{e}_2 = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}, \ldots, \mathbf{e}_n = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix}\)&lt;/p&gt;

&lt;h3 id=&quot;dimension&quot;&gt;Dimension&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;dimension&lt;/strong&gt; of a vector space is simply the number of vectors in any of its bases. It tells you how many independent directions are needed to describe the space.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^2) = 2\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^3) = 3\]
  &lt;/li&gt;
  &lt;li&gt;
\[\dim(\mathbb{R}^n) = n\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;norms-of-vectors&quot;&gt;Norms of Vectors&lt;/h2&gt;

&lt;p&gt;A &lt;strong&gt;norm&lt;/strong&gt; is a function that assigns a ‚Äúlength‚Äù or ‚Äúsize‚Äù to a vector. It generalizes the concept of distance from the origin.&lt;/p&gt;

&lt;h3 id=&quot;properties-of-norms&quot;&gt;Properties of Norms&lt;/h3&gt;

&lt;p&gt;Any norm \(\|\cdot\|\) must satisfy three properties:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Non-negativity:&lt;/strong&gt; \(\|\mathbf{x}\| \geq 0\), and \(\|\mathbf{x}\| = 0\) if and only if \(\mathbf{x} = \mathbf{0}\)&lt;/li&gt;
  &lt;li&gt;
    &lt;table&gt;
      &lt;tbody&gt;
        &lt;tr&gt;
          &lt;td&gt;&lt;strong&gt;Homogeneity:&lt;/strong&gt; $$|t\mathbf{x}| =&lt;/td&gt;
          &lt;td&gt;t&lt;/td&gt;
          &lt;td&gt;|\mathbf{x}|\(for any scalar\)t$$&lt;/td&gt;
        &lt;/tr&gt;
      &lt;/tbody&gt;
    &lt;/table&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Triangle Inequality:&lt;/strong&gt; \(\|\mathbf{x} + \mathbf{y}\| \leq \|\mathbf{x}\| + \|\mathbf{y}\|\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;common-norms&quot;&gt;Common Norms&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Euclidean Norm (L2 Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_2 = \sqrt{\sum_{i=1}^n x_i^2} = \sqrt{x_1^2 + x_2^2 + \cdots + x_n^2}\)&lt;/p&gt;

&lt;p&gt;This is the ‚Äúordinary‚Äù distance we‚Äôre familiar with.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Manhattan Norm (L1 Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_1 = \sum_{i=1}^n |x_i| = |x_1| + |x_2| + \cdots + |x_n|\)&lt;/p&gt;

&lt;p&gt;Also called ‚Äútaxicab norm‚Äù - the distance a taxi would travel in a city with a grid layout.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Maximum Norm (L‚àû Norm):&lt;/strong&gt;
\(\|\mathbf{x}\|_\infty = \max_{i} |x_i|\)&lt;/p&gt;

&lt;p&gt;The largest component in absolute value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt; For \(\mathbf{x} = \begin{pmatrix} 3 \\ -4 \\ 1 \end{pmatrix}\):&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_2 = \sqrt{3^2 + (-4)^2 + 1^2} = \sqrt{26} \approx 5.1\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_1 = |3| + |-4| + |1| = 8\]
  &lt;/li&gt;
  &lt;li&gt;
\[\|\mathbf{x}\|_\infty = \max\{|3|, |-4|, |1|\} = 4\]
  &lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;inner-products-dot-product&quot;&gt;Inner Products (Dot Product)&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;dot product&lt;/strong&gt; (or inner product) is the most common way to multiply two vectors, producing a scalar result.&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;For two vectors \(\mathbf{x}\) and \(\mathbf{y}\) in \(\mathbb{R}^n\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = \mathbf{x} \cdot \mathbf{y} = \sum_{i=1}^n x_i y_i = x_1 y_1 + x_2 y_2 + \cdots + x_n y_n\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

\[\mathbf{x} \cdot \mathbf{y} = \|\mathbf{x}\| \|\mathbf{y}\| \cos \theta\]

&lt;p&gt;where \(\theta\) is the angle between the vectors.&lt;/p&gt;

&lt;h3 id=&quot;properties&quot;&gt;Properties&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Commutative:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \mathbf{y} \cdot \mathbf{x}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Distributive:&lt;/strong&gt; \(\mathbf{x} \cdot (\mathbf{y} + \mathbf{z}) = \mathbf{x} \cdot \mathbf{y} + \mathbf{x} \cdot \mathbf{z}\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Homogeneous:&lt;/strong&gt; \((c\mathbf{x}) \cdot \mathbf{y} = c(\mathbf{x} \cdot \mathbf{y})\)&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;special-cases&quot;&gt;Special Cases&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;Orthogonal vectors:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = 0\) (perpendicular)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Parallel vectors:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{y} = \pm \|\mathbf{x}\| \|\mathbf{y}\|\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Self dot product:&lt;/strong&gt; \(\mathbf{x} \cdot \mathbf{x} = \|\mathbf{x}\|_2^2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;example&quot;&gt;Example&lt;/h3&gt;

&lt;p&gt;For \(\mathbf{x} = \begin{pmatrix} 1 \\ 2 \end{pmatrix}\) and \(\mathbf{y} = \begin{pmatrix} 3 \\ 4 \end{pmatrix}\):&lt;/p&gt;

\[\mathbf{x}^T \mathbf{y} = (1)(3) + (2)(4) = 3 + 8 = 11\]

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Understanding vectors and vector spaces is crucial for deep-learning because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Decision Variables:&lt;/strong&gt; Deep Learning problems often involve finding the best values for multiple variables, naturally represented as vectors.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradients:&lt;/strong&gt; The gradient of a function is a vector pointing in the direction of steepest increase.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Constraints:&lt;/strong&gt; Linear constraints in deep-learning can be expressed using dot products: \(\mathbf{a}^T \mathbf{x} \leq b\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Distance and Similarity:&lt;/strong&gt; Different norms provide different ways to measure distances between solutions or the size of changes.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Orthogonality:&lt;/strong&gt; Many deep-learning concepts rely on perpendicularity, such as the relationship between gradients and level curves.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Linear Combinations:&lt;/strong&gt; Feasible regions are often defined as linear combinations of vectors (convex hulls, cones, etc.).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The vector space framework provides the mathematical foundation for formulating and solving deep-learning problems systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01 Calculus</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_01_Calculus</id>
   <content type="html">&lt;p&gt;This lesson covers essential calculus concepts needed for deep-learning, organized into four main sections for better understanding.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-04 Taylor Series</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_04_Taylor_Series/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_01_04_Taylor_Series</id>
   <content type="html">&lt;p&gt;This lesson covers Taylor series expansions, which are fundamental for approximating functions and understanding the local behavior of functions in deep-learning algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;taylor-series-definition&quot;&gt;Taylor Series Definition&lt;/h2&gt;

&lt;p&gt;The Taylor series is a representation of a function as an infinite sum of terms calculated from the values of the function‚Äôs derivatives at a single point. It provides a way to approximate complex functions using polynomials.&lt;/p&gt;

&lt;h3 id=&quot;single-variable-taylor-series&quot;&gt;Single Variable Taylor Series&lt;/h3&gt;

&lt;p&gt;A Taylor series is a series expansion of a function \(f(x)\) about a point \(a\):&lt;/p&gt;

\[f(x) = \sum_{n=0}^{\infty} \frac{f^{(n)}(a)}{n!}(x-a)^n\]

&lt;p&gt;In expanded form:&lt;/p&gt;

\[f(x) = f(a) + \frac{f&apos;(a)}{1!}(x-a) + \frac{f&apos;&apos;(a)}{2!}(x-a)^2 + \frac{f&apos;&apos;&apos;(a)}{3!}(x-a)^3 + \dots\]

&lt;h3 id=&quot;maclaurin-series&quot;&gt;Maclaurin Series&lt;/h3&gt;

&lt;p&gt;When the expansion is around \(a = 0\), the Taylor series is called a &lt;strong&gt;Maclaurin series&lt;/strong&gt;:&lt;/p&gt;

\[f(x) = f(0) + f&apos;(0)x + \frac{f&apos;&apos;(0)}{2!}x^2 + \frac{f&apos;&apos;&apos;(0)}{3!}x^3 + \dots\]

&lt;h3 id=&quot;common-maclaurin-series&quot;&gt;Common Maclaurin Series&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Exponential Function:&lt;/strong&gt;
\(e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \frac{x^4}{4!} + \dots = \sum_{n=0}^{\infty} \frac{x^n}{n!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Sine Function:&lt;/strong&gt;
\(\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Cosine Function:&lt;/strong&gt;
\(\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \frac{x^6}{6!} + \dots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Natural Logarithm (for \(|x| &amp;lt; 1\)):&lt;/strong&gt;
\(\ln(1 + x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \frac{x^4}{4} + \dots = \sum_{n=1}^{\infty} \frac{(-1)^{n+1} x^n}{n}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;multivariable-taylor-series&quot;&gt;Multivariable Taylor Series&lt;/h2&gt;

&lt;p&gt;For functions of multiple variables, Taylor series become more complex but follow similar principles. The expansion around a point \(\mathbf{x}_0\) involves partial derivatives.&lt;/p&gt;

&lt;h3 id=&quot;first-order-taylor-expansion&quot;&gt;First-Order Taylor Expansion&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;linear approximation&lt;/strong&gt; of \(f(\mathbf{x})\) around \(\mathbf{x}_0\):&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;This is the equation of the tangent plane to the function at \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;second-order-taylor-expansion&quot;&gt;Second-Order Taylor Expansion&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;quadratic approximation&lt;/strong&gt; includes curvature information:&lt;/p&gt;

\[f(\mathbf{x}) \approx f(\mathbf{x}_0) + \nabla f(\mathbf{x}_0)^T (\mathbf{x} - \mathbf{x}_0) + \frac{1}{2} (\mathbf{x} - \mathbf{x}_0)^T \nabla^2 f(\mathbf{x}_0) (\mathbf{x} - \mathbf{x}_0)\]

&lt;p&gt;where \(\nabla^2 f(\mathbf{x}_0)\) is the Hessian matrix at \(\mathbf{x}_0\).&lt;/p&gt;

&lt;h3 id=&quot;general-form&quot;&gt;General Form&lt;/h3&gt;

&lt;p&gt;The complete multivariable Taylor series involves higher-order tensors:&lt;/p&gt;

\[f(\mathbf{x}) = \sum_{|\alpha|=0}^{\infty} \frac{D^{\alpha} f(\mathbf{x}_0)}{\alpha!} (\mathbf{x} - \mathbf{x}_0)^{\alpha}\]

&lt;p&gt;where \(\alpha = (\alpha_1, \alpha_2, \ldots, \alpha_n)\) is a multi-index.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h2&gt;

&lt;p&gt;Taylor series are fundamental to deep-learning theory and algorithms for several reasons:&lt;/p&gt;

&lt;h3 id=&quot;1-local-function-approximation&quot;&gt;1. Local Function Approximation&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Linear Approximation (First-Order Methods):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Used in gradient descent algorithms&lt;/li&gt;
  &lt;li&gt;Assumes the function is approximately linear in a small neighborhood&lt;/li&gt;
  &lt;li&gt;Step size must be small enough for the approximation to be valid&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Quadratic Approximation (Second-Order Methods):&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Used in Newton‚Äôs method and quasi-Newton methods&lt;/li&gt;
  &lt;li&gt;Captures curvature information through the Hessian&lt;/li&gt;
  &lt;li&gt;Often provides faster convergence than first-order methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;2-optimality-conditions&quot;&gt;2. Optimality Conditions&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;First-Order Necessary Condition:&lt;/strong&gt;
At a local minimum \(\mathbf{x}^*\), we must have \(\nabla f(\mathbf{x}^*) = \mathbf{0}\).&lt;/p&gt;

&lt;p&gt;This comes from the first-order Taylor expansion: if \(\nabla f(\mathbf{x}^*) \neq \mathbf{0}\), we could move in the direction \(-\nabla f(\mathbf{x}^*)\) to decrease the function value.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-Order Sufficient Condition:&lt;/strong&gt;
If \(\nabla f(\mathbf{x}^*) = \mathbf{0}\) and \(\nabla^2 f(\mathbf{x}^*)\) is positive definite, then \(\mathbf{x}^*\) is a local minimum.&lt;/p&gt;

&lt;p&gt;This follows from the second-order Taylor expansion: the quadratic term dominates near \(\mathbf{x}^*\).&lt;/p&gt;

&lt;h3 id=&quot;3-algorithm-design&quot;&gt;3. Algorithm Design&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Newton‚Äôs Method:&lt;/strong&gt;
Uses the second-order Taylor approximation to find the minimum of the quadratic model:&lt;/p&gt;

\[\mathbf{x}_{k+1} = \mathbf{x}_k - [\nabla^2 f(\mathbf{x}_k)]^{-1} \nabla f(\mathbf{x}_k)\]

&lt;p&gt;&lt;strong&gt;Trust Region Methods:&lt;/strong&gt;
Use Taylor approximations within a trusted region where the approximation is believed to be accurate.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Line Search Methods:&lt;/strong&gt;
Use Taylor expansions to determine appropriate step sizes along search directions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;example-quadratic-function-analysis&quot;&gt;Example: Quadratic Function Analysis&lt;/h2&gt;

&lt;p&gt;Consider \(f(x, y) = x^2 + 2xy + 3y^2\) around the point \((0, 0)\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Gradient:&lt;/strong&gt;
\(\nabla f = \begin{pmatrix} 2x + 2y \\ 2x + 6y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;At \((0, 0)\): \(\nabla f(0, 0) = \begin{pmatrix} 0 \\ 0 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Hessian:&lt;/strong&gt;
\(\nabla^2 f = \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Second-Order Taylor Expansion around \((0, 0)\):&lt;/strong&gt;
\(f(x, y) \approx f(0, 0) + 0 + \frac{1}{2} \begin{pmatrix} x &amp;amp; y \end{pmatrix} \begin{pmatrix} 2 &amp;amp; 2 \\ 2 &amp;amp; 6 \end{pmatrix} \begin{pmatrix} x \\ y \end{pmatrix}\)&lt;/p&gt;

\[= 0 + \frac{1}{2}(2x^2 + 4xy + 6y^2) = x^2 + 2xy + 3y^2\]

&lt;p&gt;In this case, the function is exactly quadratic, so the second-order Taylor expansion is exact.&lt;/p&gt;

&lt;p&gt;Since the Hessian has eigenvalues \(\lambda_1 = 2 + 2\sqrt{2} &amp;gt; 0\) and \(\lambda_2 = 2 - 2\sqrt{2} &amp;lt; 0\), the point \((0, 0)\) is a saddle point, not a minimum.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;practical-considerations&quot;&gt;Practical Considerations&lt;/h2&gt;

&lt;h3 id=&quot;convergence-and-accuracy&quot;&gt;Convergence and Accuracy&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Radius of Convergence&lt;/strong&gt;: Taylor series only converge within a certain radius from the expansion point&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Truncation Error&lt;/strong&gt;: Using finite terms introduces approximation errors&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Computational Cost&lt;/strong&gt;: Higher-order terms require more derivative computations&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;deep-learning-algorithm-choice&quot;&gt;Deep Learning Algorithm Choice&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;First-order methods&lt;/strong&gt; (gradient descent): Use only gradient information, slower but cheaper per iteration&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Second-order methods&lt;/strong&gt; (Newton): Use Hessian information, faster convergence but expensive per iteration&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Quasi-Newton methods&lt;/strong&gt;: Approximate the Hessian, balancing speed and computational cost&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The Taylor series expansion helps us approximate complex functions with simpler polynomial functions around a specific point, which is vital for deep-learning algorithms and understanding local behavior of functions.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-03 Gradient and Directional Derivatives</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_03_Gradient_and_Directional_Derivatives/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_01_03_Gradient_and_Directional_Derivatives</id>
   <content type="html">&lt;p&gt;This lesson explores the gradient vector and directional derivatives, which are central concepts in deep-learning for understanding how functions change in different directions.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;gradient-vector&quot;&gt;Gradient Vector&lt;/h2&gt;

&lt;p&gt;The gradient \(\nabla f\) is a vector composed of the partial derivatives of the function \(f\) with respect to each of its variables. It indicates the direction of the steepest ascent of the function at a given point.&lt;/p&gt;

&lt;h3 id=&quot;definition-and-computation&quot;&gt;Definition and Computation&lt;/h3&gt;

&lt;p&gt;For a function of two variables, \(f(x, y)\), its gradient is:&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x} \\ \frac{\partial f}{\partial y} \end{pmatrix}\]

&lt;p&gt;For a function of \(n\) variables, \(f(x_1, x_2, \ldots, x_n)\):&lt;/p&gt;

\[\nabla f = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;h3 id=&quot;example-computing-a-gradient&quot;&gt;Example: Computing a Gradient&lt;/h3&gt;

&lt;p&gt;For \(f(x, y) = x^2 + 3xy + y^2\):&lt;/p&gt;

&lt;p&gt;\(\frac{\partial f}{\partial x} = 2x + 3y\)
\(\frac{\partial f}{\partial y} = 3x + 2y\)&lt;/p&gt;

&lt;p&gt;Therefore: \(\nabla f = \begin{pmatrix} 2x + 3y \\ 3x + 2y \end{pmatrix}\)&lt;/p&gt;

&lt;p&gt;At the point \((1, 2)\): \(\nabla f(1, 2) = \begin{pmatrix} 2(1) + 3(2) \\ 3(1) + 2(2) \end{pmatrix} = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;directional-derivatives&quot;&gt;Directional Derivatives&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;directional derivative&lt;/strong&gt; measures the rate of change of \(f\) when we move in any chosen direction \(\mathbf{u}\). Here \(\mathbf{u}\) must be a unit vector (length 1).&lt;/p&gt;

&lt;h3 id=&quot;definition&quot;&gt;Definition&lt;/h3&gt;

&lt;p&gt;For a function \(f(\mathbf{x})\) and unit vector \(\mathbf{u} = \langle u_1, u_2, \ldots, u_n \rangle\):&lt;/p&gt;

\[D_{\mathbf{u}}f(\mathbf{x}) = \nabla f(\mathbf{x}) \cdot \mathbf{u} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} u_i\]

&lt;h3 id=&quot;geometric-interpretation&quot;&gt;Geometric Interpretation&lt;/h3&gt;

&lt;p&gt;The directional derivative can be written as:&lt;/p&gt;

\[D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\]

&lt;p&gt;where \(\theta\) is the angle between \(\nabla f\) and \(\mathbf{u}\), and \(\lvert \nabla f \rvert\) is the magnitude of the gradient.&lt;/p&gt;

&lt;h3 id=&quot;example-computing-directional-derivatives&quot;&gt;Example: Computing Directional Derivatives&lt;/h3&gt;

&lt;p&gt;Using our previous example \(f(x, y) = x^2 + 3xy + y^2\) at point \((1, 2)\) where \(\nabla f(1, 2) = \begin{pmatrix} 8 \\ 7 \end{pmatrix}\):&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 1:&lt;/strong&gt; \(\mathbf{u}_1 = \begin{pmatrix} 1 \\ 0 \end{pmatrix}\) (positive x-direction)
\(D_{\mathbf{u}_1}f(1, 2) = 8 \cdot 1 + 7 \cdot 0 = 8\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 2:&lt;/strong&gt; \(\mathbf{u}_2 = \begin{pmatrix} 0 \\ 1 \end{pmatrix}\) (positive y-direction)
\(D_{\mathbf{u}_2}f(1, 2) = 8 \cdot 0 + 7 \cdot 1 = 7\)&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Direction 3:&lt;/strong&gt; \(\mathbf{u}_3 = \frac{1}{\sqrt{2}}\begin{pmatrix} 1 \\ 1 \end{pmatrix}\) (45¬∞ diagonal)
\(D_{\mathbf{u}_3}f(1, 2) = 8 \cdot \frac{1}{\sqrt{2}} + 7 \cdot \frac{1}{\sqrt{2}} = \frac{15}{\sqrt{2}} \approx 10.61\)&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;maximum-and-minimum-rates-of-change&quot;&gt;Maximum and Minimum Rates of Change&lt;/h2&gt;

&lt;h3 id=&quot;key-properties&quot;&gt;Key Properties&lt;/h3&gt;

&lt;p&gt;From the formula \(D_{\mathbf{u}}f = \lvert \nabla f \rvert \cos \theta\), we can determine:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Maximum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 1\) (i.e., \(\theta = 0¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = \frac{\nabla f}{\lvert \nabla f \rvert}\) (same direction as gradient)&lt;/li&gt;
      &lt;li&gt;Maximum rate: \(D_{\max}f = \lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Minimum Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = -1\) (i.e., \(\theta = 180¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: \(\mathbf{u} = -\frac{\nabla f}{\lvert \nabla f \rvert}\) (opposite to gradient)&lt;/li&gt;
      &lt;li&gt;Minimum rate: \(D_{\min}f = -\lvert \nabla f \rvert\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Zero Rate of Change&lt;/strong&gt;: Occurs when \(\cos \theta = 0\) (i.e., \(\theta = 90¬∞\))
    &lt;ul&gt;
      &lt;li&gt;Direction: Any vector perpendicular to \(\nabla f\)&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;summary-of-gradient-properties&quot;&gt;Summary of Gradient Properties&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;The gradient \(\nabla f\) points in the direction of &lt;strong&gt;steepest increase&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The direction \(-\nabla f\) points in the direction of &lt;strong&gt;steepest decrease&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;The magnitude \(\lvert \nabla f \rvert\) gives the &lt;strong&gt;maximum rate of change&lt;/strong&gt;&lt;/li&gt;
  &lt;li&gt;When \(\nabla f = \mathbf{0}\), the point is a &lt;strong&gt;critical point&lt;/strong&gt; (potential optimum)&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;relation-to-level-curves&quot;&gt;Relation to Level Curves&lt;/h2&gt;

&lt;p&gt;At any point on a level curve \(f(x, y) = c\), the gradient vector \(\nabla f\) is &lt;strong&gt;orthogonal (perpendicular)&lt;/strong&gt; to the tangent line of the level curve at that point.&lt;/p&gt;

&lt;h3 id=&quot;why-this-matters&quot;&gt;Why This Matters&lt;/h3&gt;

&lt;p&gt;This orthogonality property is fundamental because:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Level curves represent constant function values&lt;/strong&gt;: Moving along a level curve doesn‚Äôt change the function value, so the directional derivative is zero.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Gradient points to steepest increase&lt;/strong&gt;: The direction that increases the function value most rapidly must be perpendicular to the direction that doesn‚Äôt change it at all.&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Deep Learning insight&lt;/strong&gt;: To find extrema, we look for points where the gradient is zero (critical points) or where the gradient is perpendicular to the constraint boundary.&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h3&gt;

&lt;p&gt;Understanding gradients and directional derivatives is crucial for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Descent&lt;/strong&gt;: Moving in the direction \(-\nabla f\) to minimize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Ascent&lt;/strong&gt;: Moving in the direction \(+\nabla f\) to maximize \(f\)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constrained Deep Learning&lt;/strong&gt;: Using the relationship between gradients and level curves&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Convergence Analysis&lt;/strong&gt;: Understanding when algorithms will converge to optimal solutions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Step Size Selection&lt;/strong&gt;: Determining how far to move in the gradient direction&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;The gradient provides both the direction to move and information about how quickly the function is changing, making it the foundation for most deep-learning algorithms.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-02 Derivatives and Multivariable Calculus</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_01_02_Derivatives_and_Multivariable_Calculus</id>
   <content type="html">&lt;p&gt;This lesson covers derivatives and essential multivariable calculus concepts that form the foundation for deep-learning theory and algorithms.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;derivatives-and-rate-of-change&quot;&gt;Derivatives and Rate of Change&lt;/h2&gt;

&lt;p&gt;The derivative of a single variable function represents its instantaneous rate of change, which is fundamental to understanding how functions behave locally.&lt;/p&gt;

&lt;h3 id=&quot;basic-derivative-concepts&quot;&gt;Basic Derivative Concepts&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Slope between two points:&lt;/strong&gt;&lt;/p&gt;

\[\text{Slope} = \frac{y_2 - y_1}{x_2 - x_1}\]

&lt;p&gt;&lt;strong&gt;Derivative (instantaneous rate of change):&lt;/strong&gt;&lt;/p&gt;

\[f&apos;(x_0) = \lim_{x_1 \to x_0} \frac{f(x_1) - f(x_0)}{x_1 - x_0} = \lim_{\Delta x \to 0} \frac{f(x_0 + \Delta x) - f(x_0)}{\Delta x}\]

&lt;p&gt;The derivative tells us how quickly the function is changing at any given point, which is essential for finding optimal points where the rate of change is zero.&lt;/p&gt;

&lt;h3 id=&quot;level-curves-of-functions&quot;&gt;Level Curves of Functions&lt;/h3&gt;

&lt;p&gt;Level curves are a fundamental concept in multivariable calculus used to visualize functions of two variables, typically denoted as \(f(x, y)\). They provide a way to represent a 3D surface in a 2D plane.&lt;/p&gt;

&lt;p&gt;A &lt;strong&gt;level curve&lt;/strong&gt; of a function \(f(x, y)\) is the set of all points \((x, y)\) in the domain of \(f\) where the function takes a constant value:&lt;/p&gt;

\[f(x, y) = c\]

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;For \(f(x, y) = x^2 + y^2\), the level curves are circles: \(x^2 + y^2 = c\)&lt;/li&gt;
  &lt;li&gt;For \(f(x, y) = x + y\), the level curves are parallel lines: \(x + y = c\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Level curves help us understand:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;The topography of the function&lt;/li&gt;
  &lt;li&gt;Directions of steepest ascent and descent&lt;/li&gt;
  &lt;li&gt;Locations of potential optima&lt;/li&gt;
&lt;/ol&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;multivariable-calculus-key-concepts&quot;&gt;Multivariable Calculus Key Concepts&lt;/h2&gt;

&lt;h3 id=&quot;partial-derivatives&quot;&gt;Partial Derivatives&lt;/h3&gt;

&lt;p&gt;For a function \(f(x_1, x_2, \ldots, x_n)\), the &lt;strong&gt;partial derivative&lt;/strong&gt; with respect to \(x_i\) is:&lt;/p&gt;

\[\frac{\partial f}{\partial x_i} = \lim_{h \to 0} \frac{f(x_1, \ldots, x_i + h, \ldots, x_n) - f(x_1, \ldots, x_i, \ldots, x_n)}{h}\]

&lt;p&gt;This measures how \(f\) changes when only \(x_i\) varies while all other variables remain fixed.&lt;/p&gt;

&lt;h3 id=&quot;gradient-vector&quot;&gt;Gradient Vector&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;gradient&lt;/strong&gt; is a vector composed of all partial derivatives:&lt;/p&gt;

\[\nabla f(\mathbf{x}) = \begin{pmatrix} \frac{\partial f}{\partial x_1} \\ \frac{\partial f}{\partial x_2} \\ \vdots \\ \frac{\partial f}{\partial x_n} \end{pmatrix}\]

&lt;p&gt;The gradient points in the direction of steepest increase of the function and is perpendicular to level curves.&lt;/p&gt;

&lt;h3 id=&quot;hessian-matrix&quot;&gt;Hessian Matrix&lt;/h3&gt;

&lt;p&gt;The &lt;strong&gt;Hessian matrix&lt;/strong&gt; contains all second-order partial derivatives:&lt;/p&gt;

\[\nabla^2 f(\mathbf{x}) = \mathbf{H} = \begin{pmatrix} 
\frac{\partial^2 f}{\partial x_1^2} &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_1 \partial x_n} \\
\frac{\partial^2 f}{\partial x_2 \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_2^2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_2 \partial x_n} \\
\vdots &amp;amp; \vdots &amp;amp; \ddots &amp;amp; \vdots \\
\frac{\partial^2 f}{\partial x_n \partial x_1} &amp;amp; \frac{\partial^2 f}{\partial x_n \partial x_2} &amp;amp; \cdots &amp;amp; \frac{\partial^2 f}{\partial x_n^2}
\end{pmatrix}\]

&lt;p&gt;The Hessian provides information about the curvature of the function and is crucial for:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Determining the nature of critical points (minimum, maximum, or saddle point)&lt;/li&gt;
  &lt;li&gt;Second-order deep-learning methods like Newton‚Äôs method&lt;/li&gt;
&lt;/ul&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;chain-rule-for-multivariable-functions&quot;&gt;Chain Rule for Multivariable Functions&lt;/h2&gt;

&lt;p&gt;The chain rule is fundamental for computing derivatives of composite functions, which frequently appear in deep-learning problems.&lt;/p&gt;

&lt;h3 id=&quot;basic-chain-rule&quot;&gt;Basic Chain Rule&lt;/h3&gt;

&lt;p&gt;For a function \(z = f(x, y)\) where \(x = g(t)\) and \(y = h(t)\):&lt;/p&gt;

\[\frac{dz}{dt} = \frac{\partial f}{\partial x} \frac{dx}{dt} + \frac{\partial f}{\partial y} \frac{dy}{dt}\]

&lt;h3 id=&quot;general-chain-rule&quot;&gt;General Chain Rule&lt;/h3&gt;

&lt;p&gt;For \(z = f(x_1, x_2, \ldots, x_n)\) where each \(x_i = x_i(t_1, t_2, \ldots, t_m)\):&lt;/p&gt;

\[\frac{\partial z}{\partial t_j} = \sum_{i=1}^{n} \frac{\partial f}{\partial x_i} \frac{\partial x_i}{\partial t_j}\]

&lt;h3 id=&quot;applications-in-deep-learning&quot;&gt;Applications in Deep Learning&lt;/h3&gt;

&lt;p&gt;The chain rule is essential for:&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Gradient Computation&lt;/strong&gt;: Computing gradients of composite objective functions&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Constraint Handling&lt;/strong&gt;: Dealing with constraints that are functions of other variables&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Algorithm Implementation&lt;/strong&gt;: Backpropagation in neural networks and automatic differentiation&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Sensitivity Analysis&lt;/strong&gt;: Understanding how changes in parameters affect optimal solutions&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;example-deep-learning-with-constraints&quot;&gt;Example: Deep Learning with Constraints&lt;/h3&gt;

&lt;p&gt;Consider minimizing \(f(x, y) = x^2 + y^2\) subject to \(g(x, y) = x + y - 1 = 0\).&lt;/p&gt;

&lt;p&gt;Using the constraint to eliminate one variable: \(y = 1 - x\), so we minimize:
\(h(x) = f(x, 1-x) = x^2 + (1-x)^2\)&lt;/p&gt;

&lt;p&gt;Using the chain rule:
\(h&apos;(x) = \frac{\partial f}{\partial x} \cdot 1 + \frac{\partial f}{\partial y} \cdot \frac{d(1-x)}{dx} = 2x + 2(1-x)(-1) = 4x - 2\)&lt;/p&gt;

&lt;p&gt;Setting \(h&apos;(x) = 0\) gives \(x = 1/2\), so the optimal point is \((1/2, 1/2)\).&lt;/p&gt;

&lt;p&gt;This demonstrates how multivariable calculus concepts work together to solve deep-learning problems systematically.&lt;/p&gt;
</content>
 </entry>
 
 <entry>
   <title>00-01-01 Continuity and Uniform Continuity</title>
   <link href="http://localhost:4000/contents/en/chapter00/00_01_01_Continuity_and_Uniform_Continuity/"/>
   <updated>2021-01-01T00:00:00+07:00</updated>
   <id>http://localhost:4000/deep-learning-self-learning/contents/en/chapter00/00_01_01_Continuity_and_Uniform_Continuity</id>
   <content type="html">&lt;p&gt;This lesson introduces the fundamental concepts of continuity and uniform continuity, which are essential for understanding the behavior of functions in deep-learning.&lt;/p&gt;

&lt;hr /&gt;

&lt;h2 id=&quot;continuity-and-uniform-continuity&quot;&gt;Continuity and Uniform Continuity&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Continuity&lt;/strong&gt; and &lt;strong&gt;Uniform Continuity&lt;/strong&gt; are fundamental concepts that describe the behavior of functions, particularly concerning their ‚Äúsmoothness‚Äù or ‚Äúpredictability.‚Äù While closely related, they capture distinct properties, with uniform continuity being a stronger condition than mere continuity.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-continuity&quot;&gt;Definition of Continuity&lt;/h3&gt;

&lt;p&gt;A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;continuous at a point&lt;/strong&gt; \(c \in A\) if, for every positive real number \(\varepsilon &amp;gt; 0\), there exists a positive real number \(\delta &amp;gt; 0\) such that for all \(x \in A\), if&lt;/p&gt;

\[\lvert x - c \rvert &amp;lt; \delta\]

&lt;p&gt;then&lt;/p&gt;

\[\lvert f(x) - f(c) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;Intuitively, it means that for any desired level of precision \(\varepsilon\) in the output \(f(x)\), we can find a sufficiently small interval around \(c\) (of width \(2\delta\)) such that all \(x\) values within this interval map to \(f(x)\) values within an \(\varepsilon\)-interval around \(f(c)\). The crucial aspect here is that the choice of \(\delta\) generally depends not only on \(\varepsilon\) but also on the specific point \(c\).&lt;/p&gt;

&lt;p&gt;A function is &lt;strong&gt;continuous on a set&lt;/strong&gt; \(A\) if it is continuous at every point \(c \in A\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Examples of continuous functions&lt;/strong&gt; include all polynomials (e.g., \(f(x) = x^2 + 3x - 1\)), trigonometric functions like \(\sin(x)\) and \(\cos(x)\), and exponential functions \(e^x\) on their respective domains.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-uniform-continuity&quot;&gt;Definition of Uniform Continuity&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;, on the other hand, imposes a more stringent condition. A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;uniformly continuous on a set&lt;/strong&gt; \(A\) if, for every positive real number \(\varepsilon &amp;gt; 0\), there exists a positive real number \(\delta &amp;gt; 0\) such that for all \(x, y \in A\), if&lt;/p&gt;

\[\lvert x - y \rvert &amp;lt; \delta\]

&lt;p&gt;then&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert &amp;lt; \varepsilon\]

&lt;p&gt;The &lt;strong&gt;key distinction&lt;/strong&gt; from point-wise continuity lies in the order of quantifiers: for &lt;strong&gt;uniform&lt;/strong&gt; continuity, the \(\delta\) depends &lt;em&gt;only&lt;/em&gt; on \(\varepsilon\) and is independent of the specific points \(x\) and \(y\) in the domain.&lt;/p&gt;

&lt;h3 id=&quot;definition-of-lipschitz-continuity&quot;&gt;Definition of Lipschitz Continuity&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt; provides an even more specific and quantitative notion of continuity. A function \(f: A \to \mathbb{R}\) is said to be &lt;strong&gt;Lipschitz continuous&lt;/strong&gt; (or &lt;strong&gt;L-Lipschitz&lt;/strong&gt;) on a set \(A\) if there exists a constant \(L \geq 0\) such that for all \(x, y \in A\):&lt;/p&gt;

\[\lvert f(x) - f(y) \rvert \leq L \lvert x - y \rvert\]

&lt;p&gt;The smallest such constant \(L\) is called the &lt;strong&gt;Lipschitz constant&lt;/strong&gt; or &lt;strong&gt;Lipschitz modulus&lt;/strong&gt; of \(f\).&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Key Properties of Lipschitz Continuity:&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Bounded Rate of Change&lt;/strong&gt;: The Lipschitz condition ensures that the function cannot change faster than a linear rate determined by \(L\).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Every Lipschitz continuous function is uniformly continuous (choose \(\delta = \varepsilon/L\) for \(L &amp;gt; 0\)).&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Almost Everywhere Differentiability&lt;/strong&gt;: Lipschitz continuous functions are differentiable almost everywhere, and where the derivative exists, \(\lvert f&apos;(x) \rvert \leq L\).&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;strong&gt;Examples:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;\(f(x) = \lvert x \rvert\) is 1-Lipschitz on \(\mathbb{R}\)&lt;/li&gt;
  &lt;li&gt;\(f(x) = \sin(x)\) is 1-Lipschitz on \(\mathbb{R}\) (since \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
  &lt;li&gt;\(f(x) = x^2\) is not Lipschitz on \(\mathbb{R}\) but is Lipschitz on any bounded interval&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;key-differences-and-hierarchy&quot;&gt;Key Differences and Hierarchy&lt;/h3&gt;

&lt;p&gt;The three types of continuity form a hierarchy of increasingly strong conditions:&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Continuity ‚äÜ Uniform Continuity ‚äÜ Lipschitz Continuity&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;strong&gt;Point-wise vs Global&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: Local property (checked at each point)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Global property of the entire function&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: Global property with quantitative bounds&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Choice of \(\delta\)&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: \(\delta\) can depend on both \(\varepsilon\) and the specific point \(c\)&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: \(\delta\) depends only on \(\varepsilon\), working for all points simultaneously&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: \(\delta = \varepsilon/L\) provides explicit relationship&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Rate of Change Control&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Continuity&lt;/strong&gt;: No control over rate of change&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Uniform Continuity&lt;/strong&gt;: Ensures bounded variation over small intervals&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Lipschitz Continuity&lt;/strong&gt;: Provides explicit linear bound on rate of change&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Strength Relationships&lt;/strong&gt;:
    &lt;ul&gt;
      &lt;li&gt;Every Lipschitz continuous function is uniformly continuous&lt;/li&gt;
      &lt;li&gt;Every uniformly continuous function is continuous&lt;/li&gt;
      &lt;li&gt;The converses are not generally true&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&quot;detailed-examples-and-comparisons&quot;&gt;Detailed Examples and Comparisons&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;Example 1: \(f(x) = x^2\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous but not uniformly continuous (rate of change \(\lvert f&apos;(x) \rvert = 2\lvert x \rvert\) is unbounded)&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;On \([0,1]\)&lt;/strong&gt;: Continuous, uniformly continuous, and Lipschitz with \(L = 2\)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 2: \(f(x) = \sin(x)\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous, uniformly continuous, and 1-Lipschitz (since \(\lvert \cos(x) \rvert \leq 1\))&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 3: \(f(x) = \lvert x \rvert\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \(\mathbb{R}\)&lt;/strong&gt;: Continuous, uniformly continuous, and 1-Lipschitz&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;Note&lt;/strong&gt;: Not differentiable at \(x = 0\), but still Lipschitz&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Example 4: \(f(x) = \sqrt{x}\)&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;On \([0,1]\)&lt;/strong&gt;: Continuous and uniformly continuous, but not Lipschitz (derivative unbounded near \(x = 0\))&lt;/li&gt;
  &lt;li&gt;&lt;strong&gt;On \([a,1]\) for \(a &amp;gt; 0\)&lt;/strong&gt;: Lipschitz with \(L = 1/(2\sqrt{a})\)&lt;/li&gt;
&lt;/ul&gt;
</content>
 </entry>
 

</feed>
